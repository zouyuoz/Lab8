{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dceedafe-2782-41a1-8119-50ee3d6c21fd",
   "metadata": {},
   "source": [
    "# 2025 DL Lab8: RL Assignment_Super Mario World"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fa555a-e61c-4fb3-b5d0-289b66570139",
   "metadata": {},
   "source": [
    "**Your Answer:**    \n",
    "Hi I'm XXX, XXXXXXXXXX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5b0974-9605-488a-9fd5-00816e7832cc",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This project implements a **Deep Reinforcement Learning** pipeline to train an autonomous agent for Super Mario World. Leveraging the **Proximal Policy Optimization (PPO)** algorithm, the system interacts with the **stable-retro** environment to master the YoshiIsland1 level. Key components include a custom Vision Backbone for extracting features from raw pixel data and a suite of Environment Wrappers that handle frame preprocessing, action discretization, and reward shaping to facilitate efficient learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02696447",
   "metadata": {},
   "source": [
    "Reward function implement  \n",
    "should do something in the beginning (monster attack)  \n",
    "Custom PPO implement  \n",
    "pre train weight 差不多，主要是 reward function  \n",
    "model weight capacity 1GB  \n",
    "class name 不要動 (可以新增，但是原本有的不要動)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8a0ab9-f86d-4038-833d-761ec81fc4f2",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00b10def-362c-4910-9ed0-f3d0904343ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import retro\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "\n",
    "from eval import evaluate_policy, record_video\n",
    "from custom_policy import VisionBackbonePolicy, CustomPPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10361fd-f291-4d93-b50d-cc749a3af588",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b4f6a25-738c-49dd-8e66-ae164b74a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game Settings\n",
    "GAME = \"SuperMarioWorld-Snes\"\n",
    "STATE = \"YoshiIsland1\"\n",
    "\n",
    "# Training Settings\n",
    "TOTAL_STEPS = 13_107_200\n",
    "TRAIN_CHUNK =    327_680\n",
    "N_ENVS = 16\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# Evaluation & Recording Settings\n",
    "EVAL_EPISODES = 3\n",
    "EVAL_MAX_STEPS = 18000\n",
    "RECORD_STEPS = 1200\n",
    "\n",
    "# Directories\n",
    "LOG_DIR = \"./runs_smw\"\n",
    "VIDEO_DIR       = os.path.join(LOG_DIR, \"videos\")\n",
    "CKPT_DIR        = os.path.join(LOG_DIR, \"checkpoints\")\n",
    "TENSORBOARD_LOG = os.path.join(LOG_DIR, \"tb\")\n",
    "\n",
    "os.makedirs(LOG_DIR,   exist_ok=True)\n",
    "os.makedirs(CKPT_DIR,  exist_ok=True)\n",
    "os.makedirs(VIDEO_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a34b783-0273-4835-ad2e-f9186064f76f",
   "metadata": {},
   "source": [
    "## Environment Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c34213d-2c7c-42b8-922d-bafa285d1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrappers import make_base_env\n",
    "def _make_env_thunk(game: str, state: str):\n",
    "    \"\"\"Return a function that creates an environment (for multiprocessing).\"\"\"\n",
    "    def _thunk():\n",
    "        return make_base_env(game, state)\n",
    "    return _thunk\n",
    "\n",
    "def make_vec_env(game: str, state: str, n_envs: int, use_subproc: bool = True):\n",
    "    \"\"\"Create a vectorized environment (multiple envs running in parallel).\"\"\"\n",
    "    env_fns = [_make_env_thunk(game, state) for _ in range(n_envs)]\n",
    "    \n",
    "    if use_subproc and n_envs > 1:\n",
    "        vec_env = SubprocVecEnv(env_fns)\n",
    "    else:\n",
    "        vec_env = DummyVecEnv(env_fns)\n",
    "\n",
    "    return vec_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dff476-ea2e-4262-8780-afb32ef1b233",
   "metadata": {},
   "source": [
    "## Initialize Env & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c7c5fe-6421-4dbc-9bd8-822d61769c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment created: SuperMarioWorld-Snes - YoshiIsland1 with 16 parallel envs.\n",
      "[Fail] Can't load None. Will use new model\n",
      "Using cuda:0 device\n"
     ]
    }
   ],
   "source": [
    "# 1. Create Training Environment\n",
    "train_env = make_vec_env(GAME, STATE, n_envs=N_ENVS)\n",
    "# train_env = VecNormalize(train_env, norm_obs=True, norm_reward=True, clip_obs=10., clip_reward=10.)\n",
    "print(f\"Environment created: {GAME} - {STATE} with {N_ENVS} parallel envs.\")\n",
    "\n",
    "checkpoint_path = \"None\" # 6225920 (19) 有破壞\n",
    "# checkpoint_path = \"runs_smw/checkpoints/P_RWD_18.zip\"\n",
    "\n",
    "best_mean = -1e18\n",
    "trained = 0\n",
    "round_idx = 0\n",
    "\n",
    "# 2. Initialize Model\n",
    "if os.path.exists(checkpoint_path):\n",
    "    # 讀取現有模型\n",
    "    model = CustomPPO.load(\n",
    "        checkpoint_path, \n",
    "        env=train_env,\n",
    "        device=\"cuda:0\" # 確保使用 GPU\n",
    "    )\n",
    "    trained = model.num_timesteps\n",
    "    round_idx = int(trained / TRAIN_CHUNK)\n",
    "    print(f\"[Sucess] Loaded model from {checkpoint_path}\")\n",
    "    print(f\"trained: {trained}, round_index: {round_idx}\")\n",
    "else:\n",
    "    print(f\"[Fail] Can't load {checkpoint_path}. Will use new model\")\n",
    "    model = CustomPPO(\n",
    "        VisionBackbonePolicy,\n",
    "        train_env,\n",
    "        policy_kwargs   = dict(normalize_images=False),\n",
    "        n_epochs        = 4,\n",
    "        n_steps         = 512,\n",
    "        batch_size      = 512,\n",
    "        learning_rate   = LEARNING_RATE,\n",
    "        verbose         = 1,\n",
    "        gamma           = 0.96875,\n",
    "        kl_coef         = 1,\n",
    "        clip_range      = 0.125,\n",
    "        ent_coef        = 0.025,\n",
    "        tensorboard_log = TENSORBOARD_LOG,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cb3d0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"policy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eb7a896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "# from custom_policy import CustomPPO\n",
    "# from eval import record_video  # 確保 eval.py 在同一目錄下\n",
    "\n",
    "# # ================= 設定區 =================\n",
    "# # 遊戲設定 (請確保跟訓練時一致)\n",
    "# # target_numbers = [3932160, 6225920, 12451840] \n",
    "\n",
    "# # 方法 B: 自動搜尋資料夾下所有 PIPE_{number}.zip (如果你想全部測的話，把下面解註解)\n",
    "# files = glob.glob(os.path.join(CKPT_DIR, \"SF84G_*.zip\"))\n",
    "# target_numbers = list(range(35, 40))\n",
    "\n",
    "# # ================= 執行迴圈 =================\n",
    "# print(f\"準備測試以下 Checkpoints: {target_numbers}\")\n",
    "\n",
    "# for num in target_numbers:\n",
    "#     model_path = os.path.join(CKPT_DIR, f\"PIPE_{num}.zip\")\n",
    "    \n",
    "#     # 檢查檔案是否存在\n",
    "#     if not os.path.exists(model_path):\n",
    "#         print(f\"⚠️ 找不到檔案: {model_path}，跳過。\")\n",
    "#         continue\n",
    "    \n",
    "#     print(f\"\\n[{num}] 正在載入模型: {model_path} ...\")\n",
    "    \n",
    "#     try:\n",
    "#         # 1. 載入模型 (不需要 env 參數也能載入權重)\n",
    "#         # 如果你有改過 CustomPPO 的參數，load 會自動讀取 zip 裡的設定\n",
    "#         model = CustomPPO.load(model_path, device=\"auto\") # device=\"auto\" 會自動用 GPU\n",
    "        \n",
    "#         # 2. 錄製影片\n",
    "#         prefix_name = f\"test_{num}\"\n",
    "#         print(f\"[{num}] 正在錄影 (長度 {RECORD_STEPS} steps)...\")\n",
    "        \n",
    "#         record_video(\n",
    "#             model=model,\n",
    "#             game=GAME,\n",
    "#             state=STATE,\n",
    "#             out_dir=VIDEO_DIR,\n",
    "#             video_len=RECORD_STEPS,\n",
    "#             prefix=prefix_name\n",
    "#         )\n",
    "#         print(f\"✅ 完成！影片已儲存為 {prefix_name}.mp4\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"❌ 發生錯誤 (Model: {num}): {e}\")\n",
    "\n",
    "# print(\"\\n所有測試結束。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f594e443-843f-42c1-9fc6-3fbc82962021",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3af4932-c531-4113-a33a-defc6fb5858e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Round 1 | Learn 327680 steps (Total trained: 0) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1169 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 7    |\n",
      "|    total_timesteps | 8192 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 893            |\n",
      "|    iterations         | 2              |\n",
      "|    time_elapsed       | 18             |\n",
      "|    total_timesteps    | 16384          |\n",
      "| train/                |                |\n",
      "|    approx_kl          | 0.0051269354   |\n",
      "|    entropy_loss       | -2.3           |\n",
      "|    explained_variance | -0.00392       |\n",
      "|    learning_rate      | 0.0001         |\n",
      "|    loss               | -0.0482        |\n",
      "|    mean_step_reward   | -0.00036650547 |\n",
      "|    n_updates          | 4              |\n",
      "|    policyGradLoss     | -0.00885       |\n",
      "|    value_loss         | 0.0429         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 827          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 29           |\n",
      "|    total_timesteps    | 24576        |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0052542337 |\n",
      "|    entropy_loss       | -2.29        |\n",
      "|    explained_variance | 0.159        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0497      |\n",
      "|    mean_step_reward   | -0.004695576 |\n",
      "|    n_updates          | 8            |\n",
      "|    policyGradLoss     | -0.00626     |\n",
      "|    value_loss         | 0.0323       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 804          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 40           |\n",
      "|    total_timesteps    | 32768        |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0015891078 |\n",
      "|    entropy_loss       | -2.28        |\n",
      "|    explained_variance | 0.296        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0478      |\n",
      "|    mean_step_reward   | -0.009289915 |\n",
      "|    n_updates          | 12           |\n",
      "|    policyGradLoss     | -0.0011      |\n",
      "|    value_loss         | 0.022        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 791          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 51           |\n",
      "|    total_timesteps    | 40960        |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025727716 |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.442        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0549      |\n",
      "|    mean_step_reward   | -0.010568308 |\n",
      "|    n_updates          | 16           |\n",
      "|    policyGradLoss     | -0.00145     |\n",
      "|    value_loss         | 0.0218       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 782          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 62           |\n",
      "|    total_timesteps    | 49152        |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0022892165 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.47         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0564      |\n",
      "|    mean_step_reward   | -0.010490848 |\n",
      "|    n_updates          | 20           |\n",
      "|    policyGradLoss     | -0.00151     |\n",
      "|    value_loss         | 0.0212       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 773          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 74           |\n",
      "|    total_timesteps    | 57344        |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0039815977 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.53         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0494      |\n",
      "|    mean_step_reward   | -0.009916155 |\n",
      "|    n_updates          | 24           |\n",
      "|    policyGradLoss     | -0.00232     |\n",
      "|    value_loss         | 0.0258       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 771           |\n",
      "|    iterations         | 8             |\n",
      "|    time_elapsed       | 84            |\n",
      "|    total_timesteps    | 65536         |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0024988027  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.54          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0282       |\n",
      "|    mean_step_reward   | -0.0077926177 |\n",
      "|    n_updates          | 28            |\n",
      "|    policyGradLoss     | -0.00125      |\n",
      "|    value_loss         | 0.0569        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 768          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 95           |\n",
      "|    total_timesteps    | 73728        |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023609109 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.41         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0321      |\n",
      "|    mean_step_reward   | -0.0120786   |\n",
      "|    n_updates          | 32           |\n",
      "|    policyGradLoss     | -0.00118     |\n",
      "|    value_loss         | 0.0393       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 762          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 107          |\n",
      "|    total_timesteps    | 81920        |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025881962 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.62         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.047       |\n",
      "|    mean_step_reward   | -0.012032831 |\n",
      "|    n_updates          | 36           |\n",
      "|    policyGradLoss     | -0.00122     |\n",
      "|    value_loss         | 0.026        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 767          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 117          |\n",
      "|    total_timesteps    | 90112        |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004604562  |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.613        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0458      |\n",
      "|    mean_step_reward   | -0.008035045 |\n",
      "|    n_updates          | 40           |\n",
      "|    policyGradLoss     | -0.00261     |\n",
      "|    value_loss         | 0.0494       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 763          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 128          |\n",
      "|    total_timesteps    | 98304        |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.002662273  |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.511        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0222      |\n",
      "|    mean_step_reward   | -0.007619058 |\n",
      "|    n_updates          | 44           |\n",
      "|    policyGradLoss     | -0.00163     |\n",
      "|    value_loss         | 0.0851       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 758          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 140          |\n",
      "|    total_timesteps    | 106496       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0017594041 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.596        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0386      |\n",
      "|    mean_step_reward   | -0.01150256  |\n",
      "|    n_updates          | 48           |\n",
      "|    policyGradLoss     | -0.000548    |\n",
      "|    value_loss         | 0.0437       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 763          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 150          |\n",
      "|    total_timesteps    | 114688       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030375153 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.725        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0435      |\n",
      "|    mean_step_reward   | -0.009072034 |\n",
      "|    n_updates          | 52           |\n",
      "|    policyGradLoss     | -0.00146     |\n",
      "|    value_loss         | 0.0524       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 759          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 161          |\n",
      "|    total_timesteps    | 122880       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0017540208 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.577        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0197      |\n",
      "|    mean_step_reward   | -0.008127625 |\n",
      "|    n_updates          | 56           |\n",
      "|    policyGradLoss     | -0.000747    |\n",
      "|    value_loss         | 0.0789       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 758          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 172          |\n",
      "|    total_timesteps    | 131072       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00286098   |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.75         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0497      |\n",
      "|    mean_step_reward   | -0.010258831 |\n",
      "|    n_updates          | 60           |\n",
      "|    policyGradLoss     | -0.00119     |\n",
      "|    value_loss         | 0.0412       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 759           |\n",
      "|    iterations         | 17            |\n",
      "|    time_elapsed       | 183           |\n",
      "|    total_timesteps    | 139264        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.00303415    |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.802         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0396       |\n",
      "|    mean_step_reward   | -0.0070368983 |\n",
      "|    n_updates          | 64            |\n",
      "|    policyGradLoss     | -0.00195      |\n",
      "|    value_loss         | 0.055         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 757          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 194          |\n",
      "|    total_timesteps    | 147456       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0016707997 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.757        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0297      |\n",
      "|    mean_step_reward   | -0.008059696 |\n",
      "|    n_updates          | 68           |\n",
      "|    policyGradLoss     | -0.00101     |\n",
      "|    value_loss         | 0.0493       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 759            |\n",
      "|    iterations         | 19             |\n",
      "|    time_elapsed       | 204            |\n",
      "|    total_timesteps    | 155648         |\n",
      "| train/                |                |\n",
      "|    approx_kl          | 0.001734159    |\n",
      "|    entropy_loss       | -2.14          |\n",
      "|    explained_variance | 0.801          |\n",
      "|    learning_rate      | 0.0001         |\n",
      "|    loss               | -0.024         |\n",
      "|    mean_step_reward   | -0.00087208877 |\n",
      "|    n_updates          | 72             |\n",
      "|    policyGradLoss     | -0.00116       |\n",
      "|    value_loss         | 0.0747         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 757          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 216          |\n",
      "|    total_timesteps    | 163840       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0018525583 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.794        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0393      |\n",
      "|    mean_step_reward   | -0.010189541 |\n",
      "|    n_updates          | 76           |\n",
      "|    policyGradLoss     | -0.000877    |\n",
      "|    value_loss         | 0.0363       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 756           |\n",
      "|    iterations         | 21            |\n",
      "|    time_elapsed       | 227           |\n",
      "|    total_timesteps    | 172032        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.002398834   |\n",
      "|    entropy_loss       | -2.17         |\n",
      "|    explained_variance | 0.838         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.036        |\n",
      "|    mean_step_reward   | -0.0075557916 |\n",
      "|    n_updates          | 80            |\n",
      "|    policyGradLoss     | -0.00172      |\n",
      "|    value_loss         | 0.0436        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 759          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 237          |\n",
      "|    total_timesteps    | 180224       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0022561033 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.653        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0417      |\n",
      "|    mean_step_reward   | -0.011890029 |\n",
      "|    n_updates          | 84           |\n",
      "|    policyGradLoss     | -0.00151     |\n",
      "|    value_loss         | 0.0351       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 757          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 248          |\n",
      "|    total_timesteps    | 188416       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0021588628 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.628        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0475      |\n",
      "|    mean_step_reward   | -0.014277684 |\n",
      "|    n_updates          | 88           |\n",
      "|    policyGradLoss     | -0.000829    |\n",
      "|    value_loss         | 0.019        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 259          |\n",
      "|    total_timesteps    | 196608       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0011573894 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.591        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0434      |\n",
      "|    mean_step_reward   | -0.010900687 |\n",
      "|    n_updates          | 92           |\n",
      "|    policyGradLoss     | -0.000567    |\n",
      "|    value_loss         | 0.0303       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 270          |\n",
      "|    total_timesteps    | 204800       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0013919692 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.697        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0403      |\n",
      "|    mean_step_reward   | -0.008872338 |\n",
      "|    n_updates          | 96           |\n",
      "|    policyGradLoss     | -0.00139     |\n",
      "|    value_loss         | 0.0366       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 282          |\n",
      "|    total_timesteps    | 212992       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0031996309 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.587        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0419      |\n",
      "|    mean_step_reward   | -0.012212116 |\n",
      "|    n_updates          | 100          |\n",
      "|    policyGradLoss     | -0.00123     |\n",
      "|    value_loss         | 0.0303       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 292          |\n",
      "|    total_timesteps    | 221184       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00247317   |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.798        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0357      |\n",
      "|    mean_step_reward   | -0.007322935 |\n",
      "|    n_updates          | 104          |\n",
      "|    policyGradLoss     | -0.0017      |\n",
      "|    value_loss         | 0.0444       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 304          |\n",
      "|    total_timesteps    | 229376       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0018913237 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.504        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0411      |\n",
      "|    mean_step_reward   | -0.011954969 |\n",
      "|    n_updates          | 108          |\n",
      "|    policyGradLoss     | -0.00144     |\n",
      "|    value_loss         | 0.0248       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 315          |\n",
      "|    total_timesteps    | 237568       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00211418   |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.81         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0551      |\n",
      "|    mean_step_reward   | -0.013060028 |\n",
      "|    n_updates          | 112          |\n",
      "|    policyGradLoss     | -0.00135     |\n",
      "|    value_loss         | 0.0102       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 754           |\n",
      "|    iterations         | 30            |\n",
      "|    time_elapsed       | 325           |\n",
      "|    total_timesteps    | 245760        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0015035695  |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.576         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0418       |\n",
      "|    mean_step_reward   | -0.0114943925 |\n",
      "|    n_updates          | 116           |\n",
      "|    policyGradLoss     | -0.00217      |\n",
      "|    value_loss         | 0.0302        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 337          |\n",
      "|    total_timesteps    | 253952       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0012011435 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.683        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0441      |\n",
      "|    mean_step_reward   | -0.011975663 |\n",
      "|    n_updates          | 120          |\n",
      "|    policyGradLoss     | -0.00113     |\n",
      "|    value_loss         | 0.0303       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 347          |\n",
      "|    total_timesteps    | 262144       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0012917893 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.62         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.043       |\n",
      "|    mean_step_reward   | -0.011288724 |\n",
      "|    n_updates          | 124          |\n",
      "|    policyGradLoss     | -0.00149     |\n",
      "|    value_loss         | 0.0356       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 754           |\n",
      "|    iterations         | 33            |\n",
      "|    time_elapsed       | 358           |\n",
      "|    total_timesteps    | 270336        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0017473581  |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.792         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0262       |\n",
      "|    mean_step_reward   | -0.0027764398 |\n",
      "|    n_updates          | 128           |\n",
      "|    policyGradLoss     | -0.00244      |\n",
      "|    value_loss         | 0.0851        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 34            |\n",
      "|    time_elapsed       | 369           |\n",
      "|    total_timesteps    | 278528        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0023708679  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.661         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0413       |\n",
      "|    mean_step_reward   | -0.0024118992 |\n",
      "|    n_updates          | 132           |\n",
      "|    policyGradLoss     | -0.00199      |\n",
      "|    value_loss         | 0.105         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 379          |\n",
      "|    total_timesteps    | 286720       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.002111765  |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.672        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0445      |\n",
      "|    mean_step_reward   | -0.008549826 |\n",
      "|    n_updates          | 136          |\n",
      "|    policyGradLoss     | -0.00297     |\n",
      "|    value_loss         | 0.0531       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 391          |\n",
      "|    total_timesteps    | 294912       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0009851905 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.677        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0426      |\n",
      "|    mean_step_reward   | -0.011408687 |\n",
      "|    n_updates          | 140          |\n",
      "|    policyGradLoss     | -0.00197     |\n",
      "|    value_loss         | 0.0299       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 403          |\n",
      "|    total_timesteps    | 303104       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026954764 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.638        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.055       |\n",
      "|    mean_step_reward   | -0.011919249 |\n",
      "|    n_updates          | 144          |\n",
      "|    policyGradLoss     | -0.00386     |\n",
      "|    value_loss         | 0.0258       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 413          |\n",
      "|    total_timesteps    | 311296       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0020292052 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.614        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0435      |\n",
      "|    mean_step_reward   | -0.010524157 |\n",
      "|    n_updates          | 148          |\n",
      "|    policyGradLoss     | -0.00235     |\n",
      "|    value_loss         | 0.0374       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 424          |\n",
      "|    total_timesteps    | 319488       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0019445246 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.753        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0461      |\n",
      "|    mean_step_reward   | -0.007420798 |\n",
      "|    n_updates          | 152          |\n",
      "|    policyGradLoss     | -0.00344     |\n",
      "|    value_loss         | 0.0372       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 435          |\n",
      "|    total_timesteps    | 327680       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0029478502 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.793        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0536      |\n",
      "|    mean_step_reward   | -0.008312031 |\n",
      "|    n_updates          | 156          |\n",
      "|    policyGradLoss     | -0.00404     |\n",
      "|    value_loss         | 0.0281       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_0.zip\n",
      "[EVAL] Mean Return: -1.154, Best Return: -0.274\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_0_-1.15.mp4\n",
      "\n",
      "=== Round 2 | Learn 327680 steps (Total trained: 327680) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1144   |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 7      |\n",
      "|    total_timesteps | 335872 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 878          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 344064       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023141312 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.599        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0583      |\n",
      "|    mean_step_reward   | -0.010438935 |\n",
      "|    n_updates          | 164          |\n",
      "|    policyGradLoss     | -0.00427     |\n",
      "|    value_loss         | 0.0152       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 853          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 352256       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0024790876 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.54         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0538      |\n",
      "|    mean_step_reward   | -0.009113517 |\n",
      "|    n_updates          | 168          |\n",
      "|    policyGradLoss     | -0.0038      |\n",
      "|    value_loss         | 0.0199       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 813           |\n",
      "|    iterations         | 4             |\n",
      "|    time_elapsed       | 40            |\n",
      "|    total_timesteps    | 360448        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0023292196  |\n",
      "|    entropy_loss       | -2.25         |\n",
      "|    explained_variance | 0.401         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0565       |\n",
      "|    mean_step_reward   | -0.0097405985 |\n",
      "|    n_updates          | 172           |\n",
      "|    policyGradLoss     | -0.00305      |\n",
      "|    value_loss         | 0.0235        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 790          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 51           |\n",
      "|    total_timesteps    | 368640       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025112387 |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.603        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0592      |\n",
      "|    mean_step_reward   | -0.010687223 |\n",
      "|    n_updates          | 176          |\n",
      "|    policyGradLoss     | -0.00292     |\n",
      "|    value_loss         | 0.00903      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 799          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 61           |\n",
      "|    total_timesteps    | 376832       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026200945 |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.392        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0574      |\n",
      "|    mean_step_reward   | -0.00828073  |\n",
      "|    n_updates          | 180          |\n",
      "|    policyGradLoss     | -0.00441     |\n",
      "|    value_loss         | 0.0199       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 783          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 73           |\n",
      "|    total_timesteps    | 385024       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0021651457 |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.494        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0506      |\n",
      "|    mean_step_reward   | -0.008077158 |\n",
      "|    n_updates          | 184          |\n",
      "|    policyGradLoss     | -0.00485     |\n",
      "|    value_loss         | 0.0187       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 778          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 84           |\n",
      "|    total_timesteps    | 393216       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0017685662 |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.289        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0535      |\n",
      "|    mean_step_reward   | -0.008087588 |\n",
      "|    n_updates          | 188          |\n",
      "|    policyGradLoss     | -0.00246     |\n",
      "|    value_loss         | 0.0241       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 778          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 94           |\n",
      "|    total_timesteps    | 401408       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034468616 |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.352        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0646      |\n",
      "|    mean_step_reward   | -0.009000275 |\n",
      "|    n_updates          | 192          |\n",
      "|    policyGradLoss     | -0.00369     |\n",
      "|    value_loss         | 0.0128       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 769          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 106          |\n",
      "|    total_timesteps    | 409600       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023903581 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.474        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0505      |\n",
      "|    mean_step_reward   | -0.008192936 |\n",
      "|    n_updates          | 196          |\n",
      "|    policyGradLoss     | -0.00328     |\n",
      "|    value_loss         | 0.0182       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 774          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 116          |\n",
      "|    total_timesteps    | 417792       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026719447 |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.479        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.051       |\n",
      "|    mean_step_reward   | -0.007208111 |\n",
      "|    n_updates          | 200          |\n",
      "|    policyGradLoss     | -0.00345     |\n",
      "|    value_loss         | 0.029        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 767          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 128          |\n",
      "|    total_timesteps    | 425984       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003079046  |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.0384       |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0503      |\n",
      "|    mean_step_reward   | -0.007815015 |\n",
      "|    n_updates          | 204          |\n",
      "|    policyGradLoss     | -0.0036      |\n",
      "|    value_loss         | 0.0239       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 762          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 139          |\n",
      "|    total_timesteps    | 434176       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0022947951 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.315        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0563      |\n",
      "|    mean_step_reward   | -0.008025126 |\n",
      "|    n_updates          | 208          |\n",
      "|    policyGradLoss     | -0.00259     |\n",
      "|    value_loss         | 0.02         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 766          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 149          |\n",
      "|    total_timesteps    | 442368       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026118956 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | -0.316       |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0552      |\n",
      "|    mean_step_reward   | -0.00810354  |\n",
      "|    n_updates          | 212          |\n",
      "|    policyGradLoss     | -0.00304     |\n",
      "|    value_loss         | 0.00902      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 762           |\n",
      "|    iterations         | 15            |\n",
      "|    time_elapsed       | 161           |\n",
      "|    total_timesteps    | 450560        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0028874902  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.453         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0563       |\n",
      "|    mean_step_reward   | -0.0063031493 |\n",
      "|    n_updates          | 216           |\n",
      "|    policyGradLoss     | -0.00321      |\n",
      "|    value_loss         | 0.0255        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 762          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 171          |\n",
      "|    total_timesteps    | 458752       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003385535  |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | -0.224       |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0628      |\n",
      "|    mean_step_reward   | -0.009282248 |\n",
      "|    n_updates          | 220          |\n",
      "|    policyGradLoss     | -0.00349     |\n",
      "|    value_loss         | 0.0038       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 760          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 183          |\n",
      "|    total_timesteps    | 466944       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0024261835 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.148        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0626      |\n",
      "|    mean_step_reward   | -0.008739041 |\n",
      "|    n_updates          | 224          |\n",
      "|    policyGradLoss     | -0.00326     |\n",
      "|    value_loss         | 0.00759      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 758          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 194          |\n",
      "|    total_timesteps    | 475136       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030317442 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.384        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0569      |\n",
      "|    mean_step_reward   | -0.006606763 |\n",
      "|    n_updates          | 228          |\n",
      "|    policyGradLoss     | -0.00412     |\n",
      "|    value_loss         | 0.0213       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 203         |\n",
      "|    total_timesteps    | 483328      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002962937 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.28        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0609     |\n",
      "|    mean_step_reward   | -0.00753172 |\n",
      "|    n_updates          | 232         |\n",
      "|    policyGradLoss     | -0.00563    |\n",
      "|    value_loss         | 0.0202      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 759          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 215          |\n",
      "|    total_timesteps    | 491520       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0036011466 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.481        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.057       |\n",
      "|    mean_step_reward   | -0.007463253 |\n",
      "|    n_updates          | 236          |\n",
      "|    policyGradLoss     | -0.00422     |\n",
      "|    value_loss         | 0.0223       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 757           |\n",
      "|    iterations         | 21            |\n",
      "|    time_elapsed       | 227           |\n",
      "|    total_timesteps    | 499712        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0023200898  |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.575         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0589       |\n",
      "|    mean_step_reward   | -0.0069036577 |\n",
      "|    n_updates          | 240           |\n",
      "|    policyGradLoss     | -0.00351      |\n",
      "|    value_loss         | 0.0162        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 759          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 237          |\n",
      "|    total_timesteps    | 507904       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027821471 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.583        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0523      |\n",
      "|    mean_step_reward   | -0.007704063 |\n",
      "|    n_updates          | 244          |\n",
      "|    policyGradLoss     | -0.00417     |\n",
      "|    value_loss         | 0.0187       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 757          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 248          |\n",
      "|    total_timesteps    | 516096       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025225985 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.0501       |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0607      |\n",
      "|    mean_step_reward   | -0.008341627 |\n",
      "|    n_updates          | 248          |\n",
      "|    policyGradLoss     | -0.00441     |\n",
      "|    value_loss         | 0.0118       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 758          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 259          |\n",
      "|    total_timesteps    | 524288       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0020192482 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.516        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0592      |\n",
      "|    mean_step_reward   | -0.007006931 |\n",
      "|    n_updates          | 252          |\n",
      "|    policyGradLoss     | -0.0034      |\n",
      "|    value_loss         | 0.0216       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 757          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 270          |\n",
      "|    total_timesteps    | 532480       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026617346 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.314        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0584      |\n",
      "|    mean_step_reward   | -0.007445924 |\n",
      "|    n_updates          | 256          |\n",
      "|    policyGradLoss     | -0.00314     |\n",
      "|    value_loss         | 0.0161       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 282          |\n",
      "|    total_timesteps    | 540672       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003071352  |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | -1.06        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0599      |\n",
      "|    mean_step_reward   | -0.008712025 |\n",
      "|    n_updates          | 260          |\n",
      "|    policyGradLoss     | -0.00321     |\n",
      "|    value_loss         | 0.00297      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 757          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 291          |\n",
      "|    total_timesteps    | 548864       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026937467 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.304        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0581      |\n",
      "|    mean_step_reward   | -0.008022575 |\n",
      "|    n_updates          | 264          |\n",
      "|    policyGradLoss     | -0.00138     |\n",
      "|    value_loss         | 0.00929      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 303          |\n",
      "|    total_timesteps    | 557056       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0024490436 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.317        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0587      |\n",
      "|    mean_step_reward   | -0.008651145 |\n",
      "|    n_updates          | 268          |\n",
      "|    policyGradLoss     | -0.00377     |\n",
      "|    value_loss         | 0.00943      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 314          |\n",
      "|    total_timesteps    | 565248       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030590186 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.441        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0593      |\n",
      "|    mean_step_reward   | -0.006198564 |\n",
      "|    n_updates          | 272          |\n",
      "|    policyGradLoss     | -0.00393     |\n",
      "|    value_loss         | 0.0232       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 324          |\n",
      "|    total_timesteps    | 573440       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.002496926  |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | -0.959       |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0611      |\n",
      "|    mean_step_reward   | -0.008763153 |\n",
      "|    n_updates          | 276          |\n",
      "|    policyGradLoss     | -0.00406     |\n",
      "|    value_loss         | 0.00322      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 756           |\n",
      "|    iterations         | 31            |\n",
      "|    time_elapsed       | 335           |\n",
      "|    total_timesteps    | 581632        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0025935122  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.196         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0564       |\n",
      "|    mean_step_reward   | -0.0075249965 |\n",
      "|    n_updates          | 280           |\n",
      "|    policyGradLoss     | -0.00495      |\n",
      "|    value_loss         | 0.0126        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 756           |\n",
      "|    iterations         | 32            |\n",
      "|    time_elapsed       | 346           |\n",
      "|    total_timesteps    | 589824        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0030275262  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.475         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0622       |\n",
      "|    mean_step_reward   | -0.0075743785 |\n",
      "|    n_updates          | 284           |\n",
      "|    policyGradLoss     | -0.00311      |\n",
      "|    value_loss         | 0.0161        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 757          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 357          |\n",
      "|    total_timesteps    | 598016       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0019016359 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.437        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0566      |\n",
      "|    mean_step_reward   | -0.008466256 |\n",
      "|    n_updates          | 288          |\n",
      "|    policyGradLoss     | -0.00324     |\n",
      "|    value_loss         | 0.00622      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 368          |\n",
      "|    total_timesteps    | 606208       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0032852143 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.447        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0537      |\n",
      "|    mean_step_reward   | -0.007453573 |\n",
      "|    n_updates          | 292          |\n",
      "|    policyGradLoss     | -0.00383     |\n",
      "|    value_loss         | 0.0166       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 379          |\n",
      "|    total_timesteps    | 614400       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025657262 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.291        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0558      |\n",
      "|    mean_step_reward   | -0.00813894  |\n",
      "|    n_updates          | 296          |\n",
      "|    policyGradLoss     | -0.00362     |\n",
      "|    value_loss         | 0.014        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 754           |\n",
      "|    iterations         | 36            |\n",
      "|    time_elapsed       | 390           |\n",
      "|    total_timesteps    | 622592        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0043320847  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.576         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0545       |\n",
      "|    mean_step_reward   | -0.0076238336 |\n",
      "|    n_updates          | 300           |\n",
      "|    policyGradLoss     | -0.00299      |\n",
      "|    value_loss         | 0.0131        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 400          |\n",
      "|    total_timesteps    | 630784       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035081962 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.434        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.054       |\n",
      "|    mean_step_reward   | -0.007736778 |\n",
      "|    n_updates          | 304          |\n",
      "|    policyGradLoss     | -0.00166     |\n",
      "|    value_loss         | 0.0185       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 754           |\n",
      "|    iterations         | 38            |\n",
      "|    time_elapsed       | 412           |\n",
      "|    total_timesteps    | 638976        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0031767036  |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.294         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0557       |\n",
      "|    mean_step_reward   | -0.0076439995 |\n",
      "|    n_updates          | 308           |\n",
      "|    policyGradLoss     | -0.00334      |\n",
      "|    value_loss         | 0.0132        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 39            |\n",
      "|    time_elapsed       | 424           |\n",
      "|    total_timesteps    | 647168        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0026093866  |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.463         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0551       |\n",
      "|    mean_step_reward   | -0.0074077826 |\n",
      "|    n_updates          | 312           |\n",
      "|    policyGradLoss     | -0.00338      |\n",
      "|    value_loss         | 0.0136        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 434          |\n",
      "|    total_timesteps    | 655360       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0020096092 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.462        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0527      |\n",
      "|    mean_step_reward   | -0.008211474 |\n",
      "|    n_updates          | 316          |\n",
      "|    policyGradLoss     | -0.00364     |\n",
      "|    value_loss         | 0.0124       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_1.zip\n",
      "[EVAL] Mean Return: -1.151, Best Return: -0.271\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_1_-1.15.mp4\n",
      "\n",
      "=== Round 3 | Learn 327680 steps (Total trained: 655360) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 978    |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 8      |\n",
      "|    total_timesteps | 663552 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 833          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 671744       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028044062 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.382        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0507      |\n",
      "|    mean_step_reward   | -0.007621128 |\n",
      "|    n_updates          | 324          |\n",
      "|    policyGradLoss     | -0.00398     |\n",
      "|    value_loss         | 0.0182       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 812           |\n",
      "|    iterations         | 3             |\n",
      "|    time_elapsed       | 30            |\n",
      "|    total_timesteps    | 679936        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0033657094  |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.384         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0564       |\n",
      "|    mean_step_reward   | -0.0077233757 |\n",
      "|    n_updates          | 328           |\n",
      "|    policyGradLoss     | -0.00337      |\n",
      "|    value_loss         | 0.012         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 780           |\n",
      "|    iterations         | 4             |\n",
      "|    time_elapsed       | 41            |\n",
      "|    total_timesteps    | 688128        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0029616035  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.562         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0531       |\n",
      "|    mean_step_reward   | -0.0071187858 |\n",
      "|    n_updates          | 332           |\n",
      "|    policyGradLoss     | -0.00355      |\n",
      "|    value_loss         | 0.0121        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 786          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 52           |\n",
      "|    total_timesteps    | 696320       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0032505365 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | -2.08        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0613      |\n",
      "|    mean_step_reward   | -0.008467658 |\n",
      "|    n_updates          | 336          |\n",
      "|    policyGradLoss     | -0.00385     |\n",
      "|    value_loss         | 0.00387      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 770           |\n",
      "|    iterations         | 6             |\n",
      "|    time_elapsed       | 63            |\n",
      "|    total_timesteps    | 704512        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0033032736  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.21          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0501       |\n",
      "|    mean_step_reward   | -0.0073170606 |\n",
      "|    n_updates          | 340           |\n",
      "|    policyGradLoss     | -0.0036       |\n",
      "|    value_loss         | 0.0195        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 75          |\n",
      "|    total_timesteps    | 712704      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003491247 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.311       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0592     |\n",
      "|    mean_step_reward   | -0.00819191 |\n",
      "|    n_updates          | 344         |\n",
      "|    policyGradLoss     | -0.00471    |\n",
      "|    value_loss         | 0.0133      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 766          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 85           |\n",
      "|    total_timesteps    | 720896       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026714806 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.455        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0533      |\n",
      "|    mean_step_reward   | -0.007228477 |\n",
      "|    n_updates          | 348          |\n",
      "|    policyGradLoss     | -0.00267     |\n",
      "|    value_loss         | 0.0215       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 760          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 96           |\n",
      "|    total_timesteps    | 729088       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030771298 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.33         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.063       |\n",
      "|    mean_step_reward   | -0.008153224 |\n",
      "|    n_updates          | 352          |\n",
      "|    policyGradLoss     | -0.00521     |\n",
      "|    value_loss         | 0.0079       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 761          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 107          |\n",
      "|    total_timesteps    | 737280       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026074627 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.403        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0484      |\n",
      "|    mean_step_reward   | -0.007308125 |\n",
      "|    n_updates          | 356          |\n",
      "|    policyGradLoss     | -0.004       |\n",
      "|    value_loss         | 0.0208       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 758          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 118          |\n",
      "|    total_timesteps    | 745472       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030468055 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | -0.227       |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.063       |\n",
      "|    mean_step_reward   | -0.008539595 |\n",
      "|    n_updates          | 360          |\n",
      "|    policyGradLoss     | -0.00554     |\n",
      "|    value_loss         | 0.00122      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 130          |\n",
      "|    total_timesteps    | 753664       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0029590912 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.386        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0619      |\n",
      "|    mean_step_reward   | -0.008556346 |\n",
      "|    n_updates          | 364          |\n",
      "|    policyGradLoss     | -0.00234     |\n",
      "|    value_loss         | 0.00731      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 758           |\n",
      "|    iterations         | 13            |\n",
      "|    time_elapsed       | 140           |\n",
      "|    total_timesteps    | 761856        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0034952173  |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.521         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0604       |\n",
      "|    mean_step_reward   | -0.0075112795 |\n",
      "|    n_updates          | 368           |\n",
      "|    policyGradLoss     | -0.00361      |\n",
      "|    value_loss         | 0.0182        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 754           |\n",
      "|    iterations         | 14            |\n",
      "|    time_elapsed       | 151           |\n",
      "|    total_timesteps    | 770048        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0029468846  |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.536         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0465       |\n",
      "|    mean_step_reward   | -0.0071537043 |\n",
      "|    n_updates          | 372           |\n",
      "|    policyGradLoss     | -0.0038       |\n",
      "|    value_loss         | 0.0183        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 15            |\n",
      "|    time_elapsed       | 163           |\n",
      "|    total_timesteps    | 778240        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003017807   |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.503         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0492       |\n",
      "|    mean_step_reward   | -0.0070863417 |\n",
      "|    n_updates          | 376           |\n",
      "|    policyGradLoss     | -0.00476      |\n",
      "|    value_loss         | 0.0193        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 173          |\n",
      "|    total_timesteps    | 786432       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.002817172  |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.687        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0573      |\n",
      "|    mean_step_reward   | -0.007155988 |\n",
      "|    n_updates          | 380          |\n",
      "|    policyGradLoss     | -0.00441     |\n",
      "|    value_loss         | 0.0122       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 185          |\n",
      "|    total_timesteps    | 794624       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.002957326  |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | -1.26        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0689      |\n",
      "|    mean_step_reward   | -0.008554406 |\n",
      "|    n_updates          | 384          |\n",
      "|    policyGradLoss     | -0.00461     |\n",
      "|    value_loss         | 0.00172      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 195          |\n",
      "|    total_timesteps    | 802816       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.002201614  |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.338        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0584      |\n",
      "|    mean_step_reward   | -0.008425169 |\n",
      "|    n_updates          | 388          |\n",
      "|    policyGradLoss     | -0.00273     |\n",
      "|    value_loss         | 0.0057       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 19            |\n",
      "|    time_elapsed       | 207           |\n",
      "|    total_timesteps    | 811008        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0031997422  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.54          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0591       |\n",
      "|    mean_step_reward   | -0.0067665717 |\n",
      "|    n_updates          | 392           |\n",
      "|    policyGradLoss     | -0.00431      |\n",
      "|    value_loss         | 0.0201        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 747           |\n",
      "|    iterations         | 20            |\n",
      "|    time_elapsed       | 219           |\n",
      "|    total_timesteps    | 819200        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0023059552  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.42          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0634       |\n",
      "|    mean_step_reward   | -0.0083474405 |\n",
      "|    n_updates          | 396           |\n",
      "|    policyGradLoss     | -0.00373      |\n",
      "|    value_loss         | 0.00773       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 229          |\n",
      "|    total_timesteps    | 827392       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003975344  |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.149        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0578      |\n",
      "|    mean_step_reward   | -0.008183983 |\n",
      "|    n_updates          | 400          |\n",
      "|    policyGradLoss     | -0.00306     |\n",
      "|    value_loss         | 0.009        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 240          |\n",
      "|    total_timesteps    | 835584       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023975354 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.498        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0522      |\n",
      "|    mean_step_reward   | -0.007771225 |\n",
      "|    n_updates          | 404          |\n",
      "|    policyGradLoss     | -0.00315     |\n",
      "|    value_loss         | 0.00957      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 23            |\n",
      "|    time_elapsed       | 251           |\n",
      "|    total_timesteps    | 843776        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0033425426  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.471         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0612       |\n",
      "|    mean_step_reward   | -0.0069608698 |\n",
      "|    n_updates          | 408           |\n",
      "|    policyGradLoss     | -0.00278      |\n",
      "|    value_loss         | 0.0139        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 262          |\n",
      "|    total_timesteps    | 851968       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0022843746 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.307        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0578      |\n",
      "|    mean_step_reward   | -0.008434371 |\n",
      "|    n_updates          | 412          |\n",
      "|    policyGradLoss     | -0.00372     |\n",
      "|    value_loss         | 0.00909      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 747           |\n",
      "|    iterations         | 25            |\n",
      "|    time_elapsed       | 274           |\n",
      "|    total_timesteps    | 860160        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0039402707  |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.531         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0592       |\n",
      "|    mean_step_reward   | -0.0073631993 |\n",
      "|    n_updates          | 416           |\n",
      "|    policyGradLoss     | -0.00336      |\n",
      "|    value_loss         | 0.0192        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 284          |\n",
      "|    total_timesteps    | 868352       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.002038211  |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.683        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0643      |\n",
      "|    mean_step_reward   | -0.005874419 |\n",
      "|    n_updates          | 420          |\n",
      "|    policyGradLoss     | -0.00427     |\n",
      "|    value_loss         | 0.0147       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 747           |\n",
      "|    iterations         | 27            |\n",
      "|    time_elapsed       | 295           |\n",
      "|    total_timesteps    | 876544        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.00420434    |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.609         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0609       |\n",
      "|    mean_step_reward   | -0.0077185766 |\n",
      "|    n_updates          | 424           |\n",
      "|    policyGradLoss     | -0.00341      |\n",
      "|    value_loss         | 0.0127        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 746          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 307          |\n",
      "|    total_timesteps    | 884736       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0037753033 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | -0.882       |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0675      |\n",
      "|    mean_step_reward   | -0.008669479 |\n",
      "|    n_updates          | 428          |\n",
      "|    policyGradLoss     | -0.00464     |\n",
      "|    value_loss         | 0.00242      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 317          |\n",
      "|    total_timesteps    | 892928       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034059342 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.149        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0563      |\n",
      "|    mean_step_reward   | -0.007975202 |\n",
      "|    n_updates          | 432          |\n",
      "|    policyGradLoss     | -0.00459     |\n",
      "|    value_loss         | 0.0059       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 328          |\n",
      "|    total_timesteps    | 901120       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0037261662 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.619        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0568      |\n",
      "|    mean_step_reward   | -0.008000429 |\n",
      "|    n_updates          | 436          |\n",
      "|    policyGradLoss     | -0.00254     |\n",
      "|    value_loss         | 0.00709      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 339          |\n",
      "|    total_timesteps    | 909312       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00235723   |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.543        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0536      |\n",
      "|    mean_step_reward   | -0.008095119 |\n",
      "|    n_updates          | 440          |\n",
      "|    policyGradLoss     | -0.00375     |\n",
      "|    value_loss         | 0.0158       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 350          |\n",
      "|    total_timesteps    | 917504       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.002272513  |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.682        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0535      |\n",
      "|    mean_step_reward   | -0.007215754 |\n",
      "|    n_updates          | 444          |\n",
      "|    policyGradLoss     | -0.0038      |\n",
      "|    value_loss         | 0.0161       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 745           |\n",
      "|    iterations         | 33            |\n",
      "|    time_elapsed       | 362           |\n",
      "|    total_timesteps    | 925696        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0030473946  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.606         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0537       |\n",
      "|    mean_step_reward   | -0.0072596734 |\n",
      "|    n_updates          | 448           |\n",
      "|    policyGradLoss     | -0.0051       |\n",
      "|    value_loss         | 0.017         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 372          |\n",
      "|    total_timesteps    | 933888       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026741307 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.627        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0608      |\n",
      "|    mean_step_reward   | -0.007769968 |\n",
      "|    n_updates          | 452          |\n",
      "|    policyGradLoss     | -0.00435     |\n",
      "|    value_loss         | 0.00966      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 746          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 384          |\n",
      "|    total_timesteps    | 942080       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023919533 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.706        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0546      |\n",
      "|    mean_step_reward   | -0.007885833 |\n",
      "|    n_updates          | 456          |\n",
      "|    policyGradLoss     | -0.0044      |\n",
      "|    value_loss         | 0.00593      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 746          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 395          |\n",
      "|    total_timesteps    | 950272       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0036396887 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.478        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0642      |\n",
      "|    mean_step_reward   | -0.008539494 |\n",
      "|    n_updates          | 460          |\n",
      "|    policyGradLoss     | -0.0034      |\n",
      "|    value_loss         | 0.00587      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 746          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 405          |\n",
      "|    total_timesteps    | 958464       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026520444 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.482        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0607      |\n",
      "|    mean_step_reward   | -0.008195253 |\n",
      "|    n_updates          | 464          |\n",
      "|    policyGradLoss     | -0.00587     |\n",
      "|    value_loss         | 0.0138       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 745          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 417          |\n",
      "|    total_timesteps    | 966656       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0029852549 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.6          |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0591      |\n",
      "|    mean_step_reward   | -0.007830891 |\n",
      "|    n_updates          | 468          |\n",
      "|    policyGradLoss     | -0.00564     |\n",
      "|    value_loss         | 0.00958      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 427          |\n",
      "|    total_timesteps    | 974848       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027334301 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.314        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0538      |\n",
      "|    mean_step_reward   | -0.007535316 |\n",
      "|    n_updates          | 472          |\n",
      "|    policyGradLoss     | -0.0041      |\n",
      "|    value_loss         | 0.0208       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 746          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 439          |\n",
      "|    total_timesteps    | 983040       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00308244   |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.486        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0572      |\n",
      "|    mean_step_reward   | -0.006971826 |\n",
      "|    n_updates          | 476          |\n",
      "|    policyGradLoss     | -0.00426     |\n",
      "|    value_loss         | 0.0162       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_2.zip\n",
      "[EVAL] Mean Return: -1.154, Best Return: -0.274\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_2_-1.15.mp4\n",
      "\n",
      "=== Round 4 | Learn 327680 steps (Total trained: 983040) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 993    |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 8      |\n",
      "|    total_timesteps | 991232 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 913          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 999424       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0022459424 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.754        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0571      |\n",
      "|    mean_step_reward   | -0.00763316  |\n",
      "|    n_updates          | 484          |\n",
      "|    policyGradLoss     | -0.00335     |\n",
      "|    value_loss         | 0.00476      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 829          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 29           |\n",
      "|    total_timesteps    | 1007616      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025134918 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.482        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0606      |\n",
      "|    mean_step_reward   | -0.00835941  |\n",
      "|    n_updates          | 488          |\n",
      "|    policyGradLoss     | -0.0045      |\n",
      "|    value_loss         | 0.0115       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 799          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 40           |\n",
      "|    total_timesteps    | 1015808      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023565295 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.594        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0552      |\n",
      "|    mean_step_reward   | -0.00696801  |\n",
      "|    n_updates          | 492          |\n",
      "|    policyGradLoss     | -0.00417     |\n",
      "|    value_loss         | 0.0201       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 795           |\n",
      "|    iterations         | 5             |\n",
      "|    time_elapsed       | 51            |\n",
      "|    total_timesteps    | 1024000       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0026691305  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.5           |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0544       |\n",
      "|    mean_step_reward   | -0.0072278623 |\n",
      "|    n_updates          | 496           |\n",
      "|    policyGradLoss     | -0.00522      |\n",
      "|    value_loss         | 0.0206        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 778          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 63           |\n",
      "|    total_timesteps    | 1032192      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023244522 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.692        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0587      |\n",
      "|    mean_step_reward   | -0.007452691 |\n",
      "|    n_updates          | 500          |\n",
      "|    policyGradLoss     | -0.00468     |\n",
      "|    value_loss         | 0.0103       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 779          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 73           |\n",
      "|    total_timesteps    | 1040384      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0032700603 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.723        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0601      |\n",
      "|    mean_step_reward   | -0.007725067 |\n",
      "|    n_updates          | 504          |\n",
      "|    policyGradLoss     | -0.00398     |\n",
      "|    value_loss         | 0.00486      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 770           |\n",
      "|    iterations         | 8             |\n",
      "|    time_elapsed       | 85            |\n",
      "|    total_timesteps    | 1048576       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0031521246  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.739         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0626       |\n",
      "|    mean_step_reward   | -0.0081717335 |\n",
      "|    n_updates          | 508           |\n",
      "|    policyGradLoss     | -0.00448      |\n",
      "|    value_loss         | 0.00321       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 762          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 96           |\n",
      "|    total_timesteps    | 1056768      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034651053 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.521        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0604      |\n",
      "|    mean_step_reward   | -0.007822834 |\n",
      "|    n_updates          | 512          |\n",
      "|    policyGradLoss     | -0.00495     |\n",
      "|    value_loss         | 0.0147       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 771           |\n",
      "|    iterations         | 10            |\n",
      "|    time_elapsed       | 106           |\n",
      "|    total_timesteps    | 1064960       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0023609665  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.712         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0582       |\n",
      "|    mean_step_reward   | -0.0072147683 |\n",
      "|    n_updates          | 516           |\n",
      "|    policyGradLoss     | -0.00448      |\n",
      "|    value_loss         | 0.0108        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 764           |\n",
      "|    iterations         | 11            |\n",
      "|    time_elapsed       | 117           |\n",
      "|    total_timesteps    | 1073152       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.00334576    |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.581         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0629       |\n",
      "|    mean_step_reward   | -0.0076787546 |\n",
      "|    n_updates          | 520           |\n",
      "|    policyGradLoss     | -0.00352      |\n",
      "|    value_loss         | 0.0138        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 762          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 128          |\n",
      "|    total_timesteps    | 1081344      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0024416018 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.691        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0592      |\n",
      "|    mean_step_reward   | -0.007298597 |\n",
      "|    n_updates          | 524          |\n",
      "|    policyGradLoss     | -0.00443     |\n",
      "|    value_loss         | 0.0118       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 761          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 139          |\n",
      "|    total_timesteps    | 1089536      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023432425 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.484        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0559      |\n",
      "|    mean_step_reward   | -0.008160897 |\n",
      "|    n_updates          | 528          |\n",
      "|    policyGradLoss     | -0.0033      |\n",
      "|    value_loss         | 0.00487      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 757          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 151          |\n",
      "|    total_timesteps    | 1097728      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0031588804 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | -1.3         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0665      |\n",
      "|    mean_step_reward   | -0.008406462 |\n",
      "|    n_updates          | 532          |\n",
      "|    policyGradLoss     | -0.00414     |\n",
      "|    value_loss         | 0.00104      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 761          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 161          |\n",
      "|    total_timesteps    | 1105920      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0031390511 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.473        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0628      |\n",
      "|    mean_step_reward   | -0.008457296 |\n",
      "|    n_updates          | 536          |\n",
      "|    policyGradLoss     | -0.0029      |\n",
      "|    value_loss         | 0.0117       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 759           |\n",
      "|    iterations         | 16            |\n",
      "|    time_elapsed       | 172           |\n",
      "|    total_timesteps    | 1114112       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0027287437  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.386         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0488       |\n",
      "|    mean_step_reward   | -0.0068993745 |\n",
      "|    n_updates          | 540           |\n",
      "|    policyGradLoss     | -0.00393      |\n",
      "|    value_loss         | 0.0186        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 759          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 183          |\n",
      "|    total_timesteps    | 1122304      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027067969 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.643        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.059       |\n",
      "|    mean_step_reward   | -0.00761216  |\n",
      "|    n_updates          | 544          |\n",
      "|    policyGradLoss     | -0.00506     |\n",
      "|    value_loss         | 0.0126       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 758          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 194          |\n",
      "|    total_timesteps    | 1130496      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030490435 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.483        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.057       |\n",
      "|    mean_step_reward   | -0.00775926  |\n",
      "|    n_updates          | 548          |\n",
      "|    policyGradLoss     | -0.00393     |\n",
      "|    value_loss         | 0.0136       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 757          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 205          |\n",
      "|    total_timesteps    | 1138688      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0032656095 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.478        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0612      |\n",
      "|    mean_step_reward   | -0.007362771 |\n",
      "|    n_updates          | 552          |\n",
      "|    policyGradLoss     | -0.00383     |\n",
      "|    value_loss         | 0.0153       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 216          |\n",
      "|    total_timesteps    | 1146880      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.002380154  |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.649        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0608      |\n",
      "|    mean_step_reward   | -0.007819202 |\n",
      "|    n_updates          | 556          |\n",
      "|    policyGradLoss     | -0.0042      |\n",
      "|    value_loss         | 0.00691      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 228          |\n",
      "|    total_timesteps    | 1155072      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003548326  |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.573        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0572      |\n",
      "|    mean_step_reward   | -0.008194534 |\n",
      "|    n_updates          | 560          |\n",
      "|    policyGradLoss     | -0.00472     |\n",
      "|    value_loss         | 0.00768      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 22            |\n",
      "|    time_elapsed       | 239           |\n",
      "|    total_timesteps    | 1163264       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0028891843  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.596         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0557       |\n",
      "|    mean_step_reward   | -0.0076221167 |\n",
      "|    n_updates          | 564           |\n",
      "|    policyGradLoss     | -0.00434      |\n",
      "|    value_loss         | 0.018         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 23            |\n",
      "|    time_elapsed       | 250           |\n",
      "|    total_timesteps    | 1171456       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0021784888  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.526         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0619       |\n",
      "|    mean_step_reward   | -0.0074062585 |\n",
      "|    n_updates          | 568           |\n",
      "|    policyGradLoss     | -0.0053       |\n",
      "|    value_loss         | 0.0149        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 261          |\n",
      "|    total_timesteps    | 1179648      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0036896386 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.46         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0641      |\n",
      "|    mean_step_reward   | -0.008064669 |\n",
      "|    n_updates          | 572          |\n",
      "|    policyGradLoss     | -0.00381     |\n",
      "|    value_loss         | 0.0103       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 272          |\n",
      "|    total_timesteps    | 1187840      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033755202 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.701        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0644      |\n",
      "|    mean_step_reward   | -0.006898471 |\n",
      "|    n_updates          | 576          |\n",
      "|    policyGradLoss     | -0.00578     |\n",
      "|    value_loss         | 0.0109       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 283          |\n",
      "|    total_timesteps    | 1196032      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0039699334 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.477        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0609      |\n",
      "|    mean_step_reward   | -0.008075345 |\n",
      "|    n_updates          | 580          |\n",
      "|    policyGradLoss     | -0.00449     |\n",
      "|    value_loss         | 0.00491      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 295          |\n",
      "|    total_timesteps    | 1204224      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025360063 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.633        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0547      |\n",
      "|    mean_step_reward   | -0.008124104 |\n",
      "|    n_updates          | 584          |\n",
      "|    policyGradLoss     | -0.00373     |\n",
      "|    value_loss         | 0.00965      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 28            |\n",
      "|    time_elapsed       | 305           |\n",
      "|    total_timesteps    | 1212416       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0021285228  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.703         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0513       |\n",
      "|    mean_step_reward   | -0.0070400257 |\n",
      "|    n_updates          | 588           |\n",
      "|    policyGradLoss     | -0.00421      |\n",
      "|    value_loss         | 0.0159        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 29            |\n",
      "|    time_elapsed       | 317           |\n",
      "|    total_timesteps    | 1220608       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003102772   |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.647         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0565       |\n",
      "|    mean_step_reward   | -0.0073705437 |\n",
      "|    n_updates          | 592           |\n",
      "|    policyGradLoss     | -0.00338      |\n",
      "|    value_loss         | 0.0165        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 328          |\n",
      "|    total_timesteps    | 1228800      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0031285172 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.584        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0618      |\n",
      "|    mean_step_reward   | -0.008267375 |\n",
      "|    n_updates          | 596          |\n",
      "|    policyGradLoss     | -0.00404     |\n",
      "|    value_loss         | 0.00456      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 31            |\n",
      "|    time_elapsed       | 338           |\n",
      "|    total_timesteps    | 1236992       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0034184437  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.695         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0473       |\n",
      "|    mean_step_reward   | -0.0075626113 |\n",
      "|    n_updates          | 600           |\n",
      "|    policyGradLoss     | -0.00391      |\n",
      "|    value_loss         | 0.0112        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 350          |\n",
      "|    total_timesteps    | 1245184      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0024647198 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.0208       |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0625      |\n",
      "|    mean_step_reward   | -0.008398775 |\n",
      "|    n_updates          | 604          |\n",
      "|    policyGradLoss     | -0.00502     |\n",
      "|    value_loss         | 0.00141      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 33            |\n",
      "|    time_elapsed       | 360           |\n",
      "|    total_timesteps    | 1253376       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0029473298  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.395         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0589       |\n",
      "|    mean_step_reward   | -0.0077825184 |\n",
      "|    n_updates          | 608           |\n",
      "|    policyGradLoss     | -0.00407      |\n",
      "|    value_loss         | 0.0126        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 34            |\n",
      "|    time_elapsed       | 372           |\n",
      "|    total_timesteps    | 1261568       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0026785661  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.634         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0549       |\n",
      "|    mean_step_reward   | -0.0072007063 |\n",
      "|    n_updates          | 612           |\n",
      "|    policyGradLoss     | -0.00458      |\n",
      "|    value_loss         | 0.021         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 383          |\n",
      "|    total_timesteps    | 1269760      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035622204 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.669        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0544      |\n",
      "|    mean_step_reward   | -0.006493133 |\n",
      "|    n_updates          | 616          |\n",
      "|    policyGradLoss     | -0.00512     |\n",
      "|    value_loss         | 0.0262       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 394          |\n",
      "|    total_timesteps    | 1277952      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026319334 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.57         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0635      |\n",
      "|    mean_step_reward   | -0.008221469 |\n",
      "|    n_updates          | 620          |\n",
      "|    policyGradLoss     | -0.0054      |\n",
      "|    value_loss         | 0.00575      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 747           |\n",
      "|    iterations         | 37            |\n",
      "|    time_elapsed       | 405           |\n",
      "|    total_timesteps    | 1286144       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0030952943  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.692         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0582       |\n",
      "|    mean_step_reward   | -0.0070322077 |\n",
      "|    n_updates          | 624           |\n",
      "|    policyGradLoss     | -0.00342      |\n",
      "|    value_loss         | 0.0126        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 415          |\n",
      "|    total_timesteps    | 1294336      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.002546222  |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.0587       |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0628      |\n",
      "|    mean_step_reward   | -0.008213175 |\n",
      "|    n_updates          | 628          |\n",
      "|    policyGradLoss     | -0.00284     |\n",
      "|    value_loss         | 0.00786      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 427          |\n",
      "|    total_timesteps    | 1302528      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033439414 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.468        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0536      |\n",
      "|    mean_step_reward   | -0.008258497 |\n",
      "|    n_updates          | 632          |\n",
      "|    policyGradLoss     | -0.00413     |\n",
      "|    value_loss         | 0.0102       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 746           |\n",
      "|    iterations         | 40            |\n",
      "|    time_elapsed       | 439           |\n",
      "|    total_timesteps    | 1310720       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0026055453  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.722         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0639       |\n",
      "|    mean_step_reward   | -0.0070690466 |\n",
      "|    n_updates          | 636           |\n",
      "|    policyGradLoss     | -0.00457      |\n",
      "|    value_loss         | 0.0133        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_3.zip\n",
      "[EVAL] Mean Return: -1.174, Best Return: -0.294\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_3_-1.17.mp4\n",
      "\n",
      "=== Round 5 | Learn 327680 steps (Total trained: 1310720) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1276    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 6       |\n",
      "|    total_timesteps | 1318912 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 915           |\n",
      "|    iterations         | 2             |\n",
      "|    time_elapsed       | 17            |\n",
      "|    total_timesteps    | 1327104       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0038887302  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.54          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0589       |\n",
      "|    mean_step_reward   | -0.0077984035 |\n",
      "|    n_updates          | 644           |\n",
      "|    policyGradLoss     | -0.0042       |\n",
      "|    value_loss         | 0.00923       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 848           |\n",
      "|    iterations         | 3             |\n",
      "|    time_elapsed       | 28            |\n",
      "|    total_timesteps    | 1335296       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0025374622  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.773         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0556       |\n",
      "|    mean_step_reward   | -0.0076089725 |\n",
      "|    n_updates          | 648           |\n",
      "|    policyGradLoss     | -0.00349      |\n",
      "|    value_loss         | 0.00801       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 825          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 39           |\n",
      "|    total_timesteps    | 1343488      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0020554415 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.744        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0652      |\n",
      "|    mean_step_reward   | -0.008450888 |\n",
      "|    n_updates          | 652          |\n",
      "|    policyGradLoss     | -0.00249     |\n",
      "|    value_loss         | 0.0035       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 797          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 51           |\n",
      "|    total_timesteps    | 1351680      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003123622  |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.566        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0619      |\n",
      "|    mean_step_reward   | -0.007842792 |\n",
      "|    n_updates          | 656          |\n",
      "|    policyGradLoss     | -0.00433     |\n",
      "|    value_loss         | 0.00957      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 800          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 61           |\n",
      "|    total_timesteps    | 1359872      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035034162 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.461        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0563      |\n",
      "|    mean_step_reward   | -0.008334557 |\n",
      "|    n_updates          | 660          |\n",
      "|    policyGradLoss     | -0.000678    |\n",
      "|    value_loss         | 0.0126       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 786           |\n",
      "|    iterations         | 7             |\n",
      "|    time_elapsed       | 72            |\n",
      "|    total_timesteps    | 1368064       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0043453057  |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.649         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0523       |\n",
      "|    mean_step_reward   | -0.0070639024 |\n",
      "|    n_updates          | 664           |\n",
      "|    policyGradLoss     | -0.00421      |\n",
      "|    value_loss         | 0.0218        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 775          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 84           |\n",
      "|    total_timesteps    | 1376256      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028657154 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.773        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0595      |\n",
      "|    mean_step_reward   | -0.006565978 |\n",
      "|    n_updates          | 668          |\n",
      "|    policyGradLoss     | -0.00548     |\n",
      "|    value_loss         | 0.0117       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 781           |\n",
      "|    iterations         | 9             |\n",
      "|    time_elapsed       | 94            |\n",
      "|    total_timesteps    | 1384448       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0023220142  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.778         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0589       |\n",
      "|    mean_step_reward   | -0.0073511265 |\n",
      "|    n_updates          | 672           |\n",
      "|    policyGradLoss     | -0.00414      |\n",
      "|    value_loss         | 0.0109        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 772           |\n",
      "|    iterations         | 10            |\n",
      "|    time_elapsed       | 105           |\n",
      "|    total_timesteps    | 1392640       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0034602927  |\n",
      "|    entropy_loss       | -2.25         |\n",
      "|    explained_variance | 0.353         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0597       |\n",
      "|    mean_step_reward   | -0.0087838555 |\n",
      "|    n_updates          | 676           |\n",
      "|    policyGradLoss     | -0.00331      |\n",
      "|    value_loss         | 0.00125       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 771          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 116          |\n",
      "|    total_timesteps    | 1400832      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034893763 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.672        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0644      |\n",
      "|    mean_step_reward   | -0.00801258  |\n",
      "|    n_updates          | 680          |\n",
      "|    policyGradLoss     | -0.00601     |\n",
      "|    value_loss         | 0.00875      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 770           |\n",
      "|    iterations         | 12            |\n",
      "|    time_elapsed       | 127           |\n",
      "|    total_timesteps    | 1409024       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003294292   |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.407         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0616       |\n",
      "|    mean_step_reward   | -0.0076764454 |\n",
      "|    n_updates          | 684           |\n",
      "|    policyGradLoss     | -0.00508      |\n",
      "|    value_loss         | 0.0183        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 765          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 139          |\n",
      "|    total_timesteps    | 1417216      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0032788883 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.739        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0572      |\n",
      "|    mean_step_reward   | -0.005742145 |\n",
      "|    n_updates          | 688          |\n",
      "|    policyGradLoss     | -0.00545     |\n",
      "|    value_loss         | 0.0189       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 768          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 149          |\n",
      "|    total_timesteps    | 1425408      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0029893946 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.5          |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0639      |\n",
      "|    mean_step_reward   | -0.008200133 |\n",
      "|    n_updates          | 692          |\n",
      "|    policyGradLoss     | -0.0036      |\n",
      "|    value_loss         | 0.00523      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 763           |\n",
      "|    iterations         | 15            |\n",
      "|    time_elapsed       | 160           |\n",
      "|    total_timesteps    | 1433600       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0024474561  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.738         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0611       |\n",
      "|    mean_step_reward   | -0.0078002214 |\n",
      "|    n_updates          | 696           |\n",
      "|    policyGradLoss     | -0.00278      |\n",
      "|    value_loss         | 0.00473       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 759          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 172          |\n",
      "|    total_timesteps    | 1441792      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025616614 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.732        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0624      |\n",
      "|    mean_step_reward   | -0.008171274 |\n",
      "|    n_updates          | 700          |\n",
      "|    policyGradLoss     | -0.00325     |\n",
      "|    value_loss         | 0.00322      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 762          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 182          |\n",
      "|    total_timesteps    | 1449984      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034178947 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.642        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0551      |\n",
      "|    mean_step_reward   | -0.007375634 |\n",
      "|    n_updates          | 704          |\n",
      "|    policyGradLoss     | -0.00382     |\n",
      "|    value_loss         | 0.0164       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 759          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 194          |\n",
      "|    total_timesteps    | 1458176      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0044401796 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.658        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.06        |\n",
      "|    mean_step_reward   | -0.007917156 |\n",
      "|    n_updates          | 708          |\n",
      "|    policyGradLoss     | -0.00583     |\n",
      "|    value_loss         | 0.00773      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 760          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 204          |\n",
      "|    total_timesteps    | 1466368      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0036719057 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.55         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0549      |\n",
      "|    mean_step_reward   | -0.007341342 |\n",
      "|    n_updates          | 712          |\n",
      "|    policyGradLoss     | -0.00409     |\n",
      "|    value_loss         | 0.0177       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 758          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 215          |\n",
      "|    total_timesteps    | 1474560      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.002624982  |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.742        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.059       |\n",
      "|    mean_step_reward   | -0.006850074 |\n",
      "|    n_updates          | 716          |\n",
      "|    policyGradLoss     | -0.00447     |\n",
      "|    value_loss         | 0.0119       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 227          |\n",
      "|    total_timesteps    | 1482752      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0041014175 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.743        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0544      |\n",
      "|    mean_step_reward   | -0.008235441 |\n",
      "|    n_updates          | 720          |\n",
      "|    policyGradLoss     | -0.00242     |\n",
      "|    value_loss         | 0.00271      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 759          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 237          |\n",
      "|    total_timesteps    | 1490944      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023725075 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.787        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0573      |\n",
      "|    mean_step_reward   | -0.008153948 |\n",
      "|    n_updates          | 724          |\n",
      "|    policyGradLoss     | -0.00343     |\n",
      "|    value_loss         | 0.00339      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 249         |\n",
      "|    total_timesteps    | 1499136     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003245901 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.709       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0596     |\n",
      "|    mean_step_reward   | -0.00808172 |\n",
      "|    n_updates          | 728         |\n",
      "|    policyGradLoss     | -0.00273    |\n",
      "|    value_loss         | 0.00881     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 755           |\n",
      "|    iterations         | 24            |\n",
      "|    time_elapsed       | 260           |\n",
      "|    total_timesteps    | 1507328       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003461423   |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.752         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0599       |\n",
      "|    mean_step_reward   | -0.0062891664 |\n",
      "|    n_updates          | 732           |\n",
      "|    policyGradLoss     | -0.00479      |\n",
      "|    value_loss         | 0.019         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 270          |\n",
      "|    total_timesteps    | 1515520      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027539055 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.608        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0559      |\n",
      "|    mean_step_reward   | -0.007587757 |\n",
      "|    n_updates          | 736          |\n",
      "|    policyGradLoss     | -0.00422     |\n",
      "|    value_loss         | 0.0143       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 754           |\n",
      "|    iterations         | 26            |\n",
      "|    time_elapsed       | 282           |\n",
      "|    total_timesteps    | 1523712       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0020891826  |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.669         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0618       |\n",
      "|    mean_step_reward   | -0.0068710856 |\n",
      "|    n_updates          | 740           |\n",
      "|    policyGradLoss     | -0.00667      |\n",
      "|    value_loss         | 0.0149        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 757          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 292          |\n",
      "|    total_timesteps    | 1531904      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0019139459 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.7          |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0583      |\n",
      "|    mean_step_reward   | -0.008230893 |\n",
      "|    n_updates          | 744          |\n",
      "|    policyGradLoss     | -0.00301     |\n",
      "|    value_loss         | 0.00379      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 303          |\n",
      "|    total_timesteps    | 1540096      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003231207  |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.686        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0639      |\n",
      "|    mean_step_reward   | -0.008420086 |\n",
      "|    n_updates          | 748          |\n",
      "|    policyGradLoss     | -0.00377     |\n",
      "|    value_loss         | 0.00391      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 315          |\n",
      "|    total_timesteps    | 1548288      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003059667  |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.605        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0545      |\n",
      "|    mean_step_reward   | -0.008341828 |\n",
      "|    n_updates          | 752          |\n",
      "|    policyGradLoss     | -0.00475     |\n",
      "|    value_loss         | 0.0106       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 755           |\n",
      "|    iterations         | 30            |\n",
      "|    time_elapsed       | 325           |\n",
      "|    total_timesteps    | 1556480       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.002918201   |\n",
      "|    entropy_loss       | -2.19         |\n",
      "|    explained_variance | 0.692         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0543       |\n",
      "|    mean_step_reward   | -0.0061459946 |\n",
      "|    n_updates          | 756           |\n",
      "|    policyGradLoss     | -0.00523      |\n",
      "|    value_loss         | 0.0266        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 336          |\n",
      "|    total_timesteps    | 1564672      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0022358522 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.693        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0606      |\n",
      "|    mean_step_reward   | -0.00675904  |\n",
      "|    n_updates          | 760          |\n",
      "|    policyGradLoss     | -0.00572     |\n",
      "|    value_loss         | 0.0181       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 347          |\n",
      "|    total_timesteps    | 1572864      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030864174 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.646        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0579      |\n",
      "|    mean_step_reward   | -0.007569884 |\n",
      "|    n_updates          | 764          |\n",
      "|    policyGradLoss     | -0.00406     |\n",
      "|    value_loss         | 0.0135       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 359          |\n",
      "|    total_timesteps    | 1581056      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0032117711 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.76         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0607      |\n",
      "|    mean_step_reward   | -0.007509902 |\n",
      "|    n_updates          | 768          |\n",
      "|    policyGradLoss     | -0.00472     |\n",
      "|    value_loss         | 0.00604      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 370          |\n",
      "|    total_timesteps    | 1589248      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0022621606 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.681        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0627      |\n",
      "|    mean_step_reward   | -0.008215098 |\n",
      "|    n_updates          | 772          |\n",
      "|    policyGradLoss     | -0.00471     |\n",
      "|    value_loss         | 0.00376      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 380          |\n",
      "|    total_timesteps    | 1597440      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028952388 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.718        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0585      |\n",
      "|    mean_step_reward   | -0.007364047 |\n",
      "|    n_updates          | 776          |\n",
      "|    policyGradLoss     | -0.00461     |\n",
      "|    value_loss         | 0.0151       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 36            |\n",
      "|    time_elapsed       | 392           |\n",
      "|    total_timesteps    | 1605632       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0024658744  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.727         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0582       |\n",
      "|    mean_step_reward   | -0.0069098305 |\n",
      "|    n_updates          | 780           |\n",
      "|    policyGradLoss     | -0.00588      |\n",
      "|    value_loss         | 0.0144        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 37            |\n",
      "|    time_elapsed       | 403           |\n",
      "|    total_timesteps    | 1613824       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0033220593  |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.743         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0637       |\n",
      "|    mean_step_reward   | -0.0067670713 |\n",
      "|    n_updates          | 784           |\n",
      "|    policyGradLoss     | -0.00641      |\n",
      "|    value_loss         | 0.0144        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 38            |\n",
      "|    time_elapsed       | 414           |\n",
      "|    total_timesteps    | 1622016       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0026872419  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.462         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0637       |\n",
      "|    mean_step_reward   | -0.0081442185 |\n",
      "|    n_updates          | 788           |\n",
      "|    policyGradLoss     | -0.00371      |\n",
      "|    value_loss         | 0.00601       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 425          |\n",
      "|    total_timesteps    | 1630208      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026723624 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.577        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0625      |\n",
      "|    mean_step_reward   | -0.008081388 |\n",
      "|    n_updates          | 792          |\n",
      "|    policyGradLoss     | -0.00381     |\n",
      "|    value_loss         | 0.00385      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 436          |\n",
      "|    total_timesteps    | 1638400      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0022682268 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.548        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0492      |\n",
      "|    mean_step_reward   | -0.007753952 |\n",
      "|    n_updates          | 796          |\n",
      "|    policyGradLoss     | -0.0029      |\n",
      "|    value_loss         | 0.0161       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_4.zip\n",
      "[EVAL] Mean Return: -113.362, Best Return: -109.938\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_4_-113.36.mp4\n",
      "\n",
      "=== Round 6 | Learn 327680 steps (Total trained: 1638400) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1010    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 8       |\n",
      "|    total_timesteps | 1646592 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 826          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 1654784      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028427192 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.688        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0552      |\n",
      "|    mean_step_reward   | -0.007298706 |\n",
      "|    n_updates          | 804          |\n",
      "|    policyGradLoss     | -0.00413     |\n",
      "|    value_loss         | 0.0128       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 827          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 29           |\n",
      "|    total_timesteps    | 1662976      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0020738551 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.68         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0514      |\n",
      "|    mean_step_reward   | -0.007064796 |\n",
      "|    n_updates          | 808          |\n",
      "|    policyGradLoss     | -0.00451     |\n",
      "|    value_loss         | 0.019        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 792          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 41           |\n",
      "|    total_timesteps    | 1671168      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.002433242  |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.753        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0644      |\n",
      "|    mean_step_reward   | -0.006958236 |\n",
      "|    n_updates          | 812          |\n",
      "|    policyGradLoss     | -0.00685     |\n",
      "|    value_loss         | 0.01         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 783          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 52           |\n",
      "|    total_timesteps    | 1679360      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027461443 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.825        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0581      |\n",
      "|    mean_step_reward   | -0.008062491 |\n",
      "|    n_updates          | 816          |\n",
      "|    policyGradLoss     | -0.00295     |\n",
      "|    value_loss         | 0.00208      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 778          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 63           |\n",
      "|    total_timesteps    | 1687552      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0029612728 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.603        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.056       |\n",
      "|    mean_step_reward   | -0.008381228 |\n",
      "|    n_updates          | 820          |\n",
      "|    policyGradLoss     | -0.00414     |\n",
      "|    value_loss         | 0.00862      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 767           |\n",
      "|    iterations         | 7             |\n",
      "|    time_elapsed       | 74            |\n",
      "|    total_timesteps    | 1695744       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0026049004  |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.748         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0553       |\n",
      "|    mean_step_reward   | -0.0070446376 |\n",
      "|    n_updates          | 824           |\n",
      "|    policyGradLoss     | -0.00519      |\n",
      "|    value_loss         | 0.0154        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 776          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 84           |\n",
      "|    total_timesteps    | 1703936      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.002683401  |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.636        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0555      |\n",
      "|    mean_step_reward   | -0.008132302 |\n",
      "|    n_updates          | 828          |\n",
      "|    policyGradLoss     | -0.00603     |\n",
      "|    value_loss         | 0.0076       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 766          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 96           |\n",
      "|    total_timesteps    | 1712128      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003078485  |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.655        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0631      |\n",
      "|    mean_step_reward   | -0.007821975 |\n",
      "|    n_updates          | 832          |\n",
      "|    policyGradLoss     | -0.00432     |\n",
      "|    value_loss         | 0.00915      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 760           |\n",
      "|    iterations         | 10            |\n",
      "|    time_elapsed       | 107           |\n",
      "|    total_timesteps    | 1720320       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0032419467  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.671         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0592       |\n",
      "|    mean_step_reward   | -0.0070850006 |\n",
      "|    n_updates          | 836           |\n",
      "|    policyGradLoss     | -0.00491      |\n",
      "|    value_loss         | 0.0145        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 767           |\n",
      "|    iterations         | 11            |\n",
      "|    time_elapsed       | 117           |\n",
      "|    total_timesteps    | 1728512       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0023763655  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.649         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0672       |\n",
      "|    mean_step_reward   | -0.0082746865 |\n",
      "|    n_updates          | 840           |\n",
      "|    policyGradLoss     | -0.00545      |\n",
      "|    value_loss         | 0.00428       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 762           |\n",
      "|    iterations         | 12            |\n",
      "|    time_elapsed       | 128           |\n",
      "|    total_timesteps    | 1736704       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.002961024   |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.783         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0594       |\n",
      "|    mean_step_reward   | -0.0075710393 |\n",
      "|    n_updates          | 844           |\n",
      "|    policyGradLoss     | -0.00388      |\n",
      "|    value_loss         | 0.00877       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 762           |\n",
      "|    iterations         | 13            |\n",
      "|    time_elapsed       | 139           |\n",
      "|    total_timesteps    | 1744896       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0021465556  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.717         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0603       |\n",
      "|    mean_step_reward   | -0.0072312416 |\n",
      "|    n_updates          | 848           |\n",
      "|    policyGradLoss     | -0.00516      |\n",
      "|    value_loss         | 0.0121        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 761          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 150          |\n",
      "|    total_timesteps    | 1753088      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.001963905  |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.535        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.063       |\n",
      "|    mean_step_reward   | -0.007958868 |\n",
      "|    n_updates          | 852          |\n",
      "|    policyGradLoss     | -0.00517     |\n",
      "|    value_loss         | 0.0111       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 756           |\n",
      "|    iterations         | 15            |\n",
      "|    time_elapsed       | 162           |\n",
      "|    total_timesteps    | 1761280       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0025903273  |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.536         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0596       |\n",
      "|    mean_step_reward   | -0.0074639367 |\n",
      "|    n_updates          | 856           |\n",
      "|    policyGradLoss     | -0.00371      |\n",
      "|    value_loss         | 0.0134        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 762          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 171          |\n",
      "|    total_timesteps    | 1769472      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003179927  |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.552        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0619      |\n",
      "|    mean_step_reward   | -0.007043995 |\n",
      "|    n_updates          | 860          |\n",
      "|    policyGradLoss     | -0.00498     |\n",
      "|    value_loss         | 0.0147       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 758          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 183          |\n",
      "|    total_timesteps    | 1777664      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030484628 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.602        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.062       |\n",
      "|    mean_step_reward   | -0.007872391 |\n",
      "|    n_updates          | 864          |\n",
      "|    policyGradLoss     | -0.00518     |\n",
      "|    value_loss         | 0.007        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 195          |\n",
      "|    total_timesteps    | 1785856      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.002662708  |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.573        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0636      |\n",
      "|    mean_step_reward   | -0.007936674 |\n",
      "|    n_updates          | 868          |\n",
      "|    policyGradLoss     | -0.00485     |\n",
      "|    value_loss         | 0.00789      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 758          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 205          |\n",
      "|    total_timesteps    | 1794048      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0031503735 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.574        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0601      |\n",
      "|    mean_step_reward   | -0.008283787 |\n",
      "|    n_updates          | 872          |\n",
      "|    policyGradLoss     | -0.00571     |\n",
      "|    value_loss         | 0.00853      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 755           |\n",
      "|    iterations         | 20            |\n",
      "|    time_elapsed       | 216           |\n",
      "|    total_timesteps    | 1802240       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0027956413  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.657         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0593       |\n",
      "|    mean_step_reward   | -0.0068552177 |\n",
      "|    n_updates          | 876           |\n",
      "|    policyGradLoss     | -0.00568      |\n",
      "|    value_loss         | 0.0125        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 758           |\n",
      "|    iterations         | 21            |\n",
      "|    time_elapsed       | 226           |\n",
      "|    total_timesteps    | 1810432       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0022074028  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.485         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.053        |\n",
      "|    mean_step_reward   | -0.0077033574 |\n",
      "|    n_updates          | 880           |\n",
      "|    policyGradLoss     | -0.00502      |\n",
      "|    value_loss         | 0.0163        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 756           |\n",
      "|    iterations         | 22            |\n",
      "|    time_elapsed       | 238           |\n",
      "|    total_timesteps    | 1818624       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004236488   |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.531         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0533       |\n",
      "|    mean_step_reward   | -0.0075025815 |\n",
      "|    n_updates          | 884           |\n",
      "|    policyGradLoss     | -0.00591      |\n",
      "|    value_loss         | 0.0215        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 754           |\n",
      "|    iterations         | 23            |\n",
      "|    time_elapsed       | 249           |\n",
      "|    total_timesteps    | 1826816       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0027705128  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.607         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0614       |\n",
      "|    mean_step_reward   | -0.0066559883 |\n",
      "|    n_updates          | 888           |\n",
      "|    policyGradLoss     | -0.00475      |\n",
      "|    value_loss         | 0.0175        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 758           |\n",
      "|    iterations         | 24            |\n",
      "|    time_elapsed       | 259           |\n",
      "|    total_timesteps    | 1835008       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0026651167  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.684         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.058        |\n",
      "|    mean_step_reward   | -0.0068409787 |\n",
      "|    n_updates          | 892           |\n",
      "|    policyGradLoss     | -0.00579      |\n",
      "|    value_loss         | 0.0182        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 756           |\n",
      "|    iterations         | 25            |\n",
      "|    time_elapsed       | 270           |\n",
      "|    total_timesteps    | 1843200       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0022723554  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.599         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0623       |\n",
      "|    mean_step_reward   | -0.0075491564 |\n",
      "|    n_updates          | 896           |\n",
      "|    policyGradLoss     | -0.00527      |\n",
      "|    value_loss         | 0.0138        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 282          |\n",
      "|    total_timesteps    | 1851392      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026625856 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.6          |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0608      |\n",
      "|    mean_step_reward   | -0.007732364 |\n",
      "|    n_updates          | 900          |\n",
      "|    policyGradLoss     | -0.0061      |\n",
      "|    value_loss         | 0.0124       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 1859584     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.00300855  |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.728       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0634     |\n",
      "|    mean_step_reward   | -0.00752901 |\n",
      "|    n_updates          | 904         |\n",
      "|    policyGradLoss     | -0.00628    |\n",
      "|    value_loss         | 0.00984     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 303          |\n",
      "|    total_timesteps    | 1867776      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.002672045  |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.67         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0626      |\n",
      "|    mean_step_reward   | -0.007181009 |\n",
      "|    n_updates          | 908          |\n",
      "|    policyGradLoss     | -0.0062      |\n",
      "|    value_loss         | 0.0149       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 314          |\n",
      "|    total_timesteps    | 1875968      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.002950829  |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.731        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0606      |\n",
      "|    mean_step_reward   | -0.007831765 |\n",
      "|    n_updates          | 912          |\n",
      "|    policyGradLoss     | -0.0054      |\n",
      "|    value_loss         | 0.00687      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 325          |\n",
      "|    total_timesteps    | 1884160      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0021991676 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.649        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0596      |\n",
      "|    mean_step_reward   | -0.007949557 |\n",
      "|    n_updates          | 916          |\n",
      "|    policyGradLoss     | -0.00384     |\n",
      "|    value_loss         | 0.00844      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 31            |\n",
      "|    time_elapsed       | 337           |\n",
      "|    total_timesteps    | 1892352       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0019427509  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.583         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0617       |\n",
      "|    mean_step_reward   | -0.0074389484 |\n",
      "|    n_updates          | 920           |\n",
      "|    policyGradLoss     | -0.00376      |\n",
      "|    value_loss         | 0.0123        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 346          |\n",
      "|    total_timesteps    | 1900544      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0018383118 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.714        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.064       |\n",
      "|    mean_step_reward   | -0.008141134 |\n",
      "|    n_updates          | 924          |\n",
      "|    policyGradLoss     | -0.00422     |\n",
      "|    value_loss         | 0.00798      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 33            |\n",
      "|    time_elapsed       | 358           |\n",
      "|    total_timesteps    | 1908736       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0030290904  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.628         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0624       |\n",
      "|    mean_step_reward   | -0.0069751777 |\n",
      "|    n_updates          | 928           |\n",
      "|    policyGradLoss     | -0.00608      |\n",
      "|    value_loss         | 0.0152        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 34            |\n",
      "|    time_elapsed       | 369           |\n",
      "|    total_timesteps    | 1916928       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0024158666  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.767         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0599       |\n",
      "|    mean_step_reward   | -0.0072418298 |\n",
      "|    n_updates          | 932           |\n",
      "|    policyGradLoss     | -0.00471      |\n",
      "|    value_loss         | 0.00962       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 380          |\n",
      "|    total_timesteps    | 1925120      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0022213596 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.658        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0646      |\n",
      "|    mean_step_reward   | -0.008146629 |\n",
      "|    n_updates          | 936          |\n",
      "|    policyGradLoss     | -0.00435     |\n",
      "|    value_loss         | 0.00846      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 391          |\n",
      "|    total_timesteps    | 1933312      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003088057  |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.671        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0558      |\n",
      "|    mean_step_reward   | -0.007425244 |\n",
      "|    n_updates          | 940          |\n",
      "|    policyGradLoss     | -0.00558     |\n",
      "|    value_loss         | 0.016        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 402          |\n",
      "|    total_timesteps    | 1941504      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0031887107 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.742        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.064       |\n",
      "|    mean_step_reward   | -0.006493369 |\n",
      "|    n_updates          | 944          |\n",
      "|    policyGradLoss     | -0.00644     |\n",
      "|    value_loss         | 0.0136       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 413          |\n",
      "|    total_timesteps    | 1949696      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028314828 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.755        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0645      |\n",
      "|    mean_step_reward   | -0.007467501 |\n",
      "|    n_updates          | 948          |\n",
      "|    policyGradLoss     | -0.00569     |\n",
      "|    value_loss         | 0.00861      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 425          |\n",
      "|    total_timesteps    | 1957888      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026076694 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.605        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0569      |\n",
      "|    mean_step_reward   | -0.006401974 |\n",
      "|    n_updates          | 952          |\n",
      "|    policyGradLoss     | -0.00535     |\n",
      "|    value_loss         | 0.0258       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 434          |\n",
      "|    total_timesteps    | 1966080      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026265737 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.791        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0601      |\n",
      "|    mean_step_reward   | -0.006802627 |\n",
      "|    n_updates          | 956          |\n",
      "|    policyGradLoss     | -0.00559     |\n",
      "|    value_loss         | 0.0139       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_5.zip\n",
      "[EVAL] Mean Return: -1.154, Best Return: -0.274\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_5_-1.15.mp4\n",
      "\n",
      "=== Round 7 | Learn 327680 steps (Total trained: 1966080) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 998     |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 8       |\n",
      "|    total_timesteps | 1974272 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 823          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 1982464      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0021975925 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.803        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0673      |\n",
      "|    mean_step_reward   | -0.008027091 |\n",
      "|    n_updates          | 964          |\n",
      "|    policyGradLoss     | -0.00522     |\n",
      "|    value_loss         | 0.00524      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 809          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 30           |\n",
      "|    total_timesteps    | 1990656      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00285151   |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.733        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0633      |\n",
      "|    mean_step_reward   | -0.007884526 |\n",
      "|    n_updates          | 968          |\n",
      "|    policyGradLoss     | -0.00422     |\n",
      "|    value_loss         | 0.00616      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 782          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 41           |\n",
      "|    total_timesteps    | 1998848      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025006856 |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.71         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0645      |\n",
      "|    mean_step_reward   | -0.00886391  |\n",
      "|    n_updates          | 972          |\n",
      "|    policyGradLoss     | -0.00273     |\n",
      "|    value_loss         | 0.00364      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 781          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 52           |\n",
      "|    total_timesteps    | 2007040      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0040612444 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.67         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0608      |\n",
      "|    mean_step_reward   | -0.006838366 |\n",
      "|    n_updates          | 976          |\n",
      "|    policyGradLoss     | -0.00598     |\n",
      "|    value_loss         | 0.0156       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 771           |\n",
      "|    iterations         | 6             |\n",
      "|    time_elapsed       | 63            |\n",
      "|    total_timesteps    | 2015232       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0031247353  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.719         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0655       |\n",
      "|    mean_step_reward   | -0.0078667635 |\n",
      "|    n_updates          | 980           |\n",
      "|    policyGradLoss     | -0.00563      |\n",
      "|    value_loss         | 0.00668       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 762          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 75           |\n",
      "|    total_timesteps    | 2023424      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003356007  |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.664        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0637      |\n",
      "|    mean_step_reward   | -0.007815674 |\n",
      "|    n_updates          | 984          |\n",
      "|    policyGradLoss     | -0.00475     |\n",
      "|    value_loss         | 0.0122       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 769           |\n",
      "|    iterations         | 8             |\n",
      "|    time_elapsed       | 85            |\n",
      "|    total_timesteps    | 2031616       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0035160263  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.662         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0606       |\n",
      "|    mean_step_reward   | -0.0074459137 |\n",
      "|    n_updates          | 988           |\n",
      "|    policyGradLoss     | -0.00524      |\n",
      "|    value_loss         | 0.00977       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 760          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 96           |\n",
      "|    total_timesteps    | 2039808      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034121089 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.599        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0547      |\n",
      "|    mean_step_reward   | -0.007838461 |\n",
      "|    n_updates          | 992          |\n",
      "|    policyGradLoss     | -0.00575     |\n",
      "|    value_loss         | 0.0147       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 759           |\n",
      "|    iterations         | 10            |\n",
      "|    time_elapsed       | 107           |\n",
      "|    total_timesteps    | 2048000       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0025268714  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.643         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0617       |\n",
      "|    mean_step_reward   | -0.0076967757 |\n",
      "|    n_updates          | 996           |\n",
      "|    policyGradLoss     | -0.00483      |\n",
      "|    value_loss         | 0.0164        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 758           |\n",
      "|    iterations         | 11            |\n",
      "|    time_elapsed       | 118           |\n",
      "|    total_timesteps    | 2056192       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0029220236  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.665         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0571       |\n",
      "|    mean_step_reward   | -0.0061549973 |\n",
      "|    n_updates          | 1000          |\n",
      "|    policyGradLoss     | -0.00458      |\n",
      "|    value_loss         | 0.0196        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 130          |\n",
      "|    total_timesteps    | 2064384      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003508586  |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.757        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0605      |\n",
      "|    mean_step_reward   | -0.006886851 |\n",
      "|    n_updates          | 1004         |\n",
      "|    policyGradLoss     | -0.00443     |\n",
      "|    value_loss         | 0.0123       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 757          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 140          |\n",
      "|    total_timesteps    | 2072576      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0037792332 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.781        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0647      |\n",
      "|    mean_step_reward   | -0.006567302 |\n",
      "|    n_updates          | 1008         |\n",
      "|    policyGradLoss     | -0.00651     |\n",
      "|    value_loss         | 0.0143       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 152          |\n",
      "|    total_timesteps    | 2080768      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0029326784 |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.545        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0616      |\n",
      "|    mean_step_reward   | -0.008865832 |\n",
      "|    n_updates          | 1012         |\n",
      "|    policyGradLoss     | -0.00237     |\n",
      "|    value_loss         | 0.00139      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 163          |\n",
      "|    total_timesteps    | 2088960      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025615518 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.621        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0628      |\n",
      "|    mean_step_reward   | -0.008136298 |\n",
      "|    n_updates          | 1016         |\n",
      "|    policyGradLoss     | -0.00572     |\n",
      "|    value_loss         | 0.00908      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 173          |\n",
      "|    total_timesteps    | 2097152      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.002216666  |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.72         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0671      |\n",
      "|    mean_step_reward   | -0.007816371 |\n",
      "|    n_updates          | 1020         |\n",
      "|    policyGradLoss     | -0.0057      |\n",
      "|    value_loss         | 0.00614      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 185          |\n",
      "|    total_timesteps    | 2105344      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026839506 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.441        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0609      |\n",
      "|    mean_step_reward   | -0.007878523 |\n",
      "|    n_updates          | 1024         |\n",
      "|    policyGradLoss     | -0.0057      |\n",
      "|    value_loss         | 0.0094       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 18            |\n",
      "|    time_elapsed       | 196           |\n",
      "|    total_timesteps    | 2113536       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0032393462  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.657         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0633       |\n",
      "|    mean_step_reward   | -0.0074325185 |\n",
      "|    n_updates          | 1028          |\n",
      "|    policyGradLoss     | -0.0063       |\n",
      "|    value_loss         | 0.0169        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 207          |\n",
      "|    total_timesteps    | 2121728      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0020770621 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.743        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0603      |\n",
      "|    mean_step_reward   | -0.00718178  |\n",
      "|    n_updates          | 1032         |\n",
      "|    policyGradLoss     | -0.00623     |\n",
      "|    value_loss         | 0.0119       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 219          |\n",
      "|    total_timesteps    | 2129920      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0021083008 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.499        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0577      |\n",
      "|    mean_step_reward   | -0.00811396  |\n",
      "|    n_updates          | 1036         |\n",
      "|    policyGradLoss     | -0.00564     |\n",
      "|    value_loss         | 0.00541      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 228          |\n",
      "|    total_timesteps    | 2138112      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027276399 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.626        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0648      |\n",
      "|    mean_step_reward   | -0.007528062 |\n",
      "|    n_updates          | 1040         |\n",
      "|    policyGradLoss     | -0.00596     |\n",
      "|    value_loss         | 0.00916      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 240          |\n",
      "|    total_timesteps    | 2146304      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023031544 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.582        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.061       |\n",
      "|    mean_step_reward   | -0.007331201 |\n",
      "|    n_updates          | 1044         |\n",
      "|    policyGradLoss     | -0.00618     |\n",
      "|    value_loss         | 0.0136       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 23            |\n",
      "|    time_elapsed       | 251           |\n",
      "|    total_timesteps    | 2154496       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0018345735  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.691         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.062        |\n",
      "|    mean_step_reward   | -0.0078745745 |\n",
      "|    n_updates          | 1048          |\n",
      "|    policyGradLoss     | -0.00542      |\n",
      "|    value_loss         | 0.00692       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 261          |\n",
      "|    total_timesteps    | 2162688      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027044718 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.811        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.066       |\n",
      "|    mean_step_reward   | -0.007273143 |\n",
      "|    n_updates          | 1052         |\n",
      "|    policyGradLoss     | -0.00451     |\n",
      "|    value_loss         | 0.00944      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 273          |\n",
      "|    total_timesteps    | 2170880      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026354692 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.552        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.064       |\n",
      "|    mean_step_reward   | -0.008165041 |\n",
      "|    n_updates          | 1056         |\n",
      "|    policyGradLoss     | -0.00616     |\n",
      "|    value_loss         | 0.0178       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 746          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 285          |\n",
      "|    total_timesteps    | 2179072      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028258637 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.792        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.065       |\n",
      "|    mean_step_reward   | -0.005981762 |\n",
      "|    n_updates          | 1060         |\n",
      "|    policyGradLoss     | -0.00563     |\n",
      "|    value_loss         | 0.011        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 746          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 296          |\n",
      "|    total_timesteps    | 2187264      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027800659 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.481        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0641      |\n",
      "|    mean_step_reward   | -0.008771211 |\n",
      "|    n_updates          | 1064         |\n",
      "|    policyGradLoss     | -0.00617     |\n",
      "|    value_loss         | 0.00882      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 746           |\n",
      "|    iterations         | 28            |\n",
      "|    time_elapsed       | 307           |\n",
      "|    total_timesteps    | 2195456       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0035400188  |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.738         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.047        |\n",
      "|    mean_step_reward   | -0.0065104086 |\n",
      "|    n_updates          | 1068          |\n",
      "|    policyGradLoss     | -0.00493      |\n",
      "|    value_loss         | 0.0263        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 746           |\n",
      "|    iterations         | 29            |\n",
      "|    time_elapsed       | 318           |\n",
      "|    total_timesteps    | 2203648       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.002064725   |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.801         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0662       |\n",
      "|    mean_step_reward   | -0.0054345406 |\n",
      "|    n_updates          | 1072          |\n",
      "|    policyGradLoss     | -0.00628      |\n",
      "|    value_loss         | 0.0166        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 744           |\n",
      "|    iterations         | 30            |\n",
      "|    time_elapsed       | 329           |\n",
      "|    total_timesteps    | 2211840       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0023236624  |\n",
      "|    entropy_loss       | -2.25         |\n",
      "|    explained_variance | 0.768         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0688       |\n",
      "|    mean_step_reward   | -0.0076843537 |\n",
      "|    n_updates          | 1076          |\n",
      "|    policyGradLoss     | -0.00566      |\n",
      "|    value_loss         | 0.00751       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 747           |\n",
      "|    iterations         | 31            |\n",
      "|    time_elapsed       | 339           |\n",
      "|    total_timesteps    | 2220032       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.002899509   |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.723         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0679       |\n",
      "|    mean_step_reward   | -0.0074568316 |\n",
      "|    n_updates          | 1080          |\n",
      "|    policyGradLoss     | -0.00696      |\n",
      "|    value_loss         | 0.0117        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 745          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 351          |\n",
      "|    total_timesteps    | 2228224      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026338294 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.694        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0618      |\n",
      "|    mean_step_reward   | -0.008082094 |\n",
      "|    n_updates          | 1084         |\n",
      "|    policyGradLoss     | -0.00458     |\n",
      "|    value_loss         | 0.00792      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 744           |\n",
      "|    iterations         | 33            |\n",
      "|    time_elapsed       | 362           |\n",
      "|    total_timesteps    | 2236416       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0031510573  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.77          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0655       |\n",
      "|    mean_step_reward   | -0.0077440045 |\n",
      "|    n_updates          | 1088          |\n",
      "|    policyGradLoss     | -0.00513      |\n",
      "|    value_loss         | 0.00602       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 745           |\n",
      "|    iterations         | 34            |\n",
      "|    time_elapsed       | 373           |\n",
      "|    total_timesteps    | 2244608       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0026665647  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.686         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0544       |\n",
      "|    mean_step_reward   | -0.0068143774 |\n",
      "|    n_updates          | 1092          |\n",
      "|    policyGradLoss     | -0.00548      |\n",
      "|    value_loss         | 0.0224        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 744           |\n",
      "|    iterations         | 35            |\n",
      "|    time_elapsed       | 385           |\n",
      "|    total_timesteps    | 2252800       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0029689507  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.793         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0615       |\n",
      "|    mean_step_reward   | -0.0069004074 |\n",
      "|    n_updates          | 1096          |\n",
      "|    policyGradLoss     | -0.00632      |\n",
      "|    value_loss         | 0.0114        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 745          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 395          |\n",
      "|    total_timesteps    | 2260992      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026584647 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.779        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0665      |\n",
      "|    mean_step_reward   | -0.007627951 |\n",
      "|    n_updates          | 1100         |\n",
      "|    policyGradLoss     | -0.00518     |\n",
      "|    value_loss         | 0.00924      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 744          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 407          |\n",
      "|    total_timesteps    | 2269184      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027597165 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.814        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0571      |\n",
      "|    mean_step_reward   | -0.006999954 |\n",
      "|    n_updates          | 1104         |\n",
      "|    policyGradLoss     | -0.00547     |\n",
      "|    value_loss         | 0.0118       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 743           |\n",
      "|    iterations         | 38            |\n",
      "|    time_elapsed       | 418           |\n",
      "|    total_timesteps    | 2277376       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0026269981  |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.71          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0592       |\n",
      "|    mean_step_reward   | -0.0067389403 |\n",
      "|    n_updates          | 1108          |\n",
      "|    policyGradLoss     | -0.0057       |\n",
      "|    value_loss         | 0.0241        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 745          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 428          |\n",
      "|    total_timesteps    | 2285568      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033359262 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.682        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0586      |\n",
      "|    mean_step_reward   | -0.006663434 |\n",
      "|    n_updates          | 1112         |\n",
      "|    policyGradLoss     | -0.00503     |\n",
      "|    value_loss         | 0.0177       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 744           |\n",
      "|    iterations         | 40            |\n",
      "|    time_elapsed       | 440           |\n",
      "|    total_timesteps    | 2293760       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.002675415   |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.637         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0596       |\n",
      "|    mean_step_reward   | -0.0074497703 |\n",
      "|    n_updates          | 1116          |\n",
      "|    policyGradLoss     | -0.0055       |\n",
      "|    value_loss         | 0.0126        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_6.zip\n",
      "[EVAL] Mean Return: -1.174, Best Return: -0.294\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_6_-1.17.mp4\n",
      "\n",
      "=== Round 8 | Learn 327680 steps (Total trained: 2293760) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 977     |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 8       |\n",
      "|    total_timesteps | 2301952 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 886          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 2310144      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003479539  |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.691        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0635      |\n",
      "|    mean_step_reward   | -0.007878711 |\n",
      "|    n_updates          | 1124         |\n",
      "|    policyGradLoss     | -0.00431     |\n",
      "|    value_loss         | 0.0113       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 819          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 29           |\n",
      "|    total_timesteps    | 2318336      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.002872799  |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.753        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0603      |\n",
      "|    mean_step_reward   | -0.007204727 |\n",
      "|    n_updates          | 1128         |\n",
      "|    policyGradLoss     | -0.00595     |\n",
      "|    value_loss         | 0.0165       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 806          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 40           |\n",
      "|    total_timesteps    | 2326528      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0032654044 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.724        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0649      |\n",
      "|    mean_step_reward   | -0.006270306 |\n",
      "|    n_updates          | 1132         |\n",
      "|    policyGradLoss     | -0.0072      |\n",
      "|    value_loss         | 0.0186       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 792          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 51           |\n",
      "|    total_timesteps    | 2334720      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0031090847 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.771        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0655      |\n",
      "|    mean_step_reward   | -0.007015644 |\n",
      "|    n_updates          | 1136         |\n",
      "|    policyGradLoss     | -0.0067      |\n",
      "|    value_loss         | 0.0104       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 776          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 63           |\n",
      "|    total_timesteps    | 2342912      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028857952 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.709        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0653      |\n",
      "|    mean_step_reward   | -0.007869873 |\n",
      "|    n_updates          | 1140         |\n",
      "|    policyGradLoss     | -0.00564     |\n",
      "|    value_loss         | 0.00586      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 786          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 72           |\n",
      "|    total_timesteps    | 2351104      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.001991623  |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.69         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0623      |\n",
      "|    mean_step_reward   | -0.007829751 |\n",
      "|    n_updates          | 1144         |\n",
      "|    policyGradLoss     | -0.00611     |\n",
      "|    value_loss         | 0.00706      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 773          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 84           |\n",
      "|    total_timesteps    | 2359296      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0024077087 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.71         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0605      |\n",
      "|    mean_step_reward   | -0.00782962  |\n",
      "|    n_updates          | 1148         |\n",
      "|    policyGradLoss     | -0.0065      |\n",
      "|    value_loss         | 0.00573      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 766           |\n",
      "|    iterations         | 9             |\n",
      "|    time_elapsed       | 96            |\n",
      "|    total_timesteps    | 2367488       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0033329022  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.771         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0687       |\n",
      "|    mean_step_reward   | -0.0073890467 |\n",
      "|    n_updates          | 1152          |\n",
      "|    policyGradLoss     | -0.00651      |\n",
      "|    value_loss         | 0.00882       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 769           |\n",
      "|    iterations         | 10            |\n",
      "|    time_elapsed       | 106           |\n",
      "|    total_timesteps    | 2375680       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.002339874   |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.766         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0637       |\n",
      "|    mean_step_reward   | -0.0067260973 |\n",
      "|    n_updates          | 1156          |\n",
      "|    policyGradLoss     | -0.00641      |\n",
      "|    value_loss         | 0.013         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 762           |\n",
      "|    iterations         | 11            |\n",
      "|    time_elapsed       | 118           |\n",
      "|    total_timesteps    | 2383872       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0026685882  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.687         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0642       |\n",
      "|    mean_step_reward   | -0.0070155333 |\n",
      "|    n_updates          | 1160          |\n",
      "|    policyGradLoss     | -0.00569      |\n",
      "|    value_loss         | 0.0145        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 764          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 128          |\n",
      "|    total_timesteps    | 2392064      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028192569 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.652        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0615      |\n",
      "|    mean_step_reward   | -0.008326201 |\n",
      "|    n_updates          | 1164         |\n",
      "|    policyGradLoss     | -0.00604     |\n",
      "|    value_loss         | 0.00542      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 760          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 140          |\n",
      "|    total_timesteps    | 2400256      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0036632314 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.715        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0609      |\n",
      "|    mean_step_reward   | -0.007147814 |\n",
      "|    n_updates          | 1168         |\n",
      "|    policyGradLoss     | -0.00599     |\n",
      "|    value_loss         | 0.011        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 757           |\n",
      "|    iterations         | 14            |\n",
      "|    time_elapsed       | 151           |\n",
      "|    total_timesteps    | 2408448       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0026885897  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.742         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0634       |\n",
      "|    mean_step_reward   | -0.0072574466 |\n",
      "|    n_updates          | 1172          |\n",
      "|    policyGradLoss     | -0.0059       |\n",
      "|    value_loss         | 0.0141        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 763           |\n",
      "|    iterations         | 15            |\n",
      "|    time_elapsed       | 160           |\n",
      "|    total_timesteps    | 2416640       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0028620563  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.871         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0632       |\n",
      "|    mean_step_reward   | -0.0066121556 |\n",
      "|    n_updates          | 1176          |\n",
      "|    policyGradLoss     | -0.00489      |\n",
      "|    value_loss         | 0.0125        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 758           |\n",
      "|    iterations         | 16            |\n",
      "|    time_elapsed       | 172           |\n",
      "|    total_timesteps    | 2424832       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0030727966  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.747         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0541       |\n",
      "|    mean_step_reward   | -0.0057917023 |\n",
      "|    n_updates          | 1180          |\n",
      "|    policyGradLoss     | -0.00763      |\n",
      "|    value_loss         | 0.0215        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 757          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 183          |\n",
      "|    total_timesteps    | 2433024      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003013863  |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.245        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0677      |\n",
      "|    mean_step_reward   | -0.008524558 |\n",
      "|    n_updates          | 1184         |\n",
      "|    policyGradLoss     | -0.00484     |\n",
      "|    value_loss         | 0.00192      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 757          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 194          |\n",
      "|    total_timesteps    | 2441216      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034906878 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.758        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0677      |\n",
      "|    mean_step_reward   | -0.008000512 |\n",
      "|    n_updates          | 1188         |\n",
      "|    policyGradLoss     | -0.00654     |\n",
      "|    value_loss         | 0.00419      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 754           |\n",
      "|    iterations         | 19            |\n",
      "|    time_elapsed       | 206           |\n",
      "|    total_timesteps    | 2449408       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.00283879    |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.742         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0604       |\n",
      "|    mean_step_reward   | -0.0066689104 |\n",
      "|    n_updates          | 1192          |\n",
      "|    policyGradLoss     | -0.00475      |\n",
      "|    value_loss         | 0.0209        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 757          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 216          |\n",
      "|    total_timesteps    | 2457600      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0021370787 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.569        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0662      |\n",
      "|    mean_step_reward   | -0.008197167 |\n",
      "|    n_updates          | 1196         |\n",
      "|    policyGradLoss     | -0.00602     |\n",
      "|    value_loss         | 0.00537      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 21            |\n",
      "|    time_elapsed       | 228           |\n",
      "|    total_timesteps    | 2465792       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0036934544  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.757         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0607       |\n",
      "|    mean_step_reward   | -0.0070591257 |\n",
      "|    n_updates          | 1200          |\n",
      "|    policyGradLoss     | -0.00589      |\n",
      "|    value_loss         | 0.017         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 239          |\n",
      "|    total_timesteps    | 2473984      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0041379035 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.65         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0547      |\n",
      "|    mean_step_reward   | -0.007412182 |\n",
      "|    n_updates          | 1204         |\n",
      "|    policyGradLoss     | -0.00635     |\n",
      "|    value_loss         | 0.0231       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 250          |\n",
      "|    total_timesteps    | 2482176      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.002571257  |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.761        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.059       |\n",
      "|    mean_step_reward   | -0.006182804 |\n",
      "|    n_updates          | 1208         |\n",
      "|    policyGradLoss     | -0.00509     |\n",
      "|    value_loss         | 0.0108       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 261          |\n",
      "|    total_timesteps    | 2490368      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035665082 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.678        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0647      |\n",
      "|    mean_step_reward   | -0.008639676 |\n",
      "|    n_updates          | 1212         |\n",
      "|    policyGradLoss     | -0.00696     |\n",
      "|    value_loss         | 0.00699      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 272          |\n",
      "|    total_timesteps    | 2498560      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0041253883 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.69         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0528      |\n",
      "|    mean_step_reward   | -0.006747196 |\n",
      "|    n_updates          | 1216         |\n",
      "|    policyGradLoss     | -0.00574     |\n",
      "|    value_loss         | 0.0229       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 26            |\n",
      "|    time_elapsed       | 283           |\n",
      "|    total_timesteps    | 2506752       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0029738643  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.771         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0669       |\n",
      "|    mean_step_reward   | -0.0070394753 |\n",
      "|    n_updates          | 1220          |\n",
      "|    policyGradLoss     | -0.00677      |\n",
      "|    value_loss         | 0.012         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 27            |\n",
      "|    time_elapsed       | 295           |\n",
      "|    total_timesteps    | 2514944       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.00422087    |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.774         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0583       |\n",
      "|    mean_step_reward   | -0.0073817745 |\n",
      "|    n_updates          | 1224          |\n",
      "|    policyGradLoss     | -0.00652      |\n",
      "|    value_loss         | 0.0143        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 28            |\n",
      "|    time_elapsed       | 305           |\n",
      "|    total_timesteps    | 2523136       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003849993   |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.762         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0539       |\n",
      "|    mean_step_reward   | -0.0066197296 |\n",
      "|    n_updates          | 1228          |\n",
      "|    policyGradLoss     | -0.00564      |\n",
      "|    value_loss         | 0.0171        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 316          |\n",
      "|    total_timesteps    | 2531328      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003599769  |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.53         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0626      |\n",
      "|    mean_step_reward   | -0.006544046 |\n",
      "|    n_updates          | 1232         |\n",
      "|    policyGradLoss     | -0.00664     |\n",
      "|    value_loss         | 0.0238       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 327          |\n",
      "|    total_timesteps    | 2539520      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025951467 |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.624        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0634      |\n",
      "|    mean_step_reward   | -0.008517016 |\n",
      "|    n_updates          | 1236         |\n",
      "|    policyGradLoss     | -0.00386     |\n",
      "|    value_loss         | 0.000626     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 338          |\n",
      "|    total_timesteps    | 2547712      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030673286 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.741        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0624      |\n",
      "|    mean_step_reward   | -0.007904198 |\n",
      "|    n_updates          | 1240         |\n",
      "|    policyGradLoss     | -0.00615     |\n",
      "|    value_loss         | 0.00674      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 350          |\n",
      "|    total_timesteps    | 2555904      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034634601 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.622        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0619      |\n",
      "|    mean_step_reward   | -0.007870128 |\n",
      "|    n_updates          | 1244         |\n",
      "|    policyGradLoss     | -0.00526     |\n",
      "|    value_loss         | 0.0117       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 33            |\n",
      "|    time_elapsed       | 359           |\n",
      "|    total_timesteps    | 2564096       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0042164964  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.624         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0507       |\n",
      "|    mean_step_reward   | -0.0073682386 |\n",
      "|    n_updates          | 1248          |\n",
      "|    policyGradLoss     | -0.00587      |\n",
      "|    value_loss         | 0.0197        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 371          |\n",
      "|    total_timesteps    | 2572288      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0031928022 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.716        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0603      |\n",
      "|    mean_step_reward   | -0.007345069 |\n",
      "|    n_updates          | 1252         |\n",
      "|    policyGradLoss     | -0.00658     |\n",
      "|    value_loss         | 0.00907      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 35            |\n",
      "|    time_elapsed       | 383           |\n",
      "|    total_timesteps    | 2580480       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0033019322  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.673         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0629       |\n",
      "|    mean_step_reward   | -0.0072902692 |\n",
      "|    n_updates          | 1256          |\n",
      "|    policyGradLoss     | -0.00549      |\n",
      "|    value_loss         | 0.0129        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 393          |\n",
      "|    total_timesteps    | 2588672      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0020534922 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.719        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.065       |\n",
      "|    mean_step_reward   | -0.007747951 |\n",
      "|    n_updates          | 1260         |\n",
      "|    policyGradLoss     | -0.00487     |\n",
      "|    value_loss         | 0.00757      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 37            |\n",
      "|    time_elapsed       | 405           |\n",
      "|    total_timesteps    | 2596864       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0027354336  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.781         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0632       |\n",
      "|    mean_step_reward   | -0.0074322475 |\n",
      "|    n_updates          | 1264          |\n",
      "|    policyGradLoss     | -0.00537      |\n",
      "|    value_loss         | 0.00616       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 415          |\n",
      "|    total_timesteps    | 2605056      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0021585883 |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.755        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0626      |\n",
      "|    mean_step_reward   | -0.00835786  |\n",
      "|    n_updates          | 1268         |\n",
      "|    policyGradLoss     | -0.00409     |\n",
      "|    value_loss         | 0.00316      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 427          |\n",
      "|    total_timesteps    | 2613248      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034348613 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.769        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0599      |\n",
      "|    mean_step_reward   | -0.006750172 |\n",
      "|    n_updates          | 1272         |\n",
      "|    policyGradLoss     | -0.0063      |\n",
      "|    value_loss         | 0.0146       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 746          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 438          |\n",
      "|    total_timesteps    | 2621440      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0037734204 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.778        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0565      |\n",
      "|    mean_step_reward   | -0.007574878 |\n",
      "|    n_updates          | 1276         |\n",
      "|    policyGradLoss     | -0.0055      |\n",
      "|    value_loss         | 0.0083       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_7.zip\n",
      "[EVAL] Mean Return: -1.151, Best Return: -0.271\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_7_-1.15.mp4\n",
      "\n",
      "=== Round 9 | Learn 327680 steps (Total trained: 2621440) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1202    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 6       |\n",
      "|    total_timesteps | 2629632 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 889          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 2637824      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003803788  |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.802        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.066       |\n",
      "|    mean_step_reward   | -0.007904179 |\n",
      "|    n_updates          | 1284         |\n",
      "|    policyGradLoss     | -0.00509     |\n",
      "|    value_loss         | 0.00525      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 817           |\n",
      "|    iterations         | 3             |\n",
      "|    time_elapsed       | 30            |\n",
      "|    total_timesteps    | 2646016       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0025029848  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.749         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0596       |\n",
      "|    mean_step_reward   | -0.0068249255 |\n",
      "|    n_updates          | 1288          |\n",
      "|    policyGradLoss     | -0.00587      |\n",
      "|    value_loss         | 0.0125        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 817          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 40           |\n",
      "|    total_timesteps    | 2654208      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033904987 |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.886        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0591      |\n",
      "|    mean_step_reward   | -0.008248893 |\n",
      "|    n_updates          | 1292         |\n",
      "|    policyGradLoss     | -0.00421     |\n",
      "|    value_loss         | 0.00191      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 790           |\n",
      "|    iterations         | 5             |\n",
      "|    time_elapsed       | 51            |\n",
      "|    total_timesteps    | 2662400       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004424312   |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.75          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0615       |\n",
      "|    mean_step_reward   | -0.0077252677 |\n",
      "|    n_updates          | 1296          |\n",
      "|    policyGradLoss     | -0.00634      |\n",
      "|    value_loss         | 0.00953       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 789          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 62           |\n",
      "|    total_timesteps    | 2670592      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034293944 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.699        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0593      |\n",
      "|    mean_step_reward   | -0.0075119   |\n",
      "|    n_updates          | 1300         |\n",
      "|    policyGradLoss     | -0.00625     |\n",
      "|    value_loss         | 0.0117       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 778           |\n",
      "|    iterations         | 7             |\n",
      "|    time_elapsed       | 73            |\n",
      "|    total_timesteps    | 2678784       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.00347697    |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.672         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.066        |\n",
      "|    mean_step_reward   | -0.0076246415 |\n",
      "|    n_updates          | 1304          |\n",
      "|    policyGradLoss     | -0.00711      |\n",
      "|    value_loss         | 0.00981       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 769          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 85           |\n",
      "|    total_timesteps    | 2686976      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003232298  |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.754        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0696      |\n",
      "|    mean_step_reward   | -0.007171679 |\n",
      "|    n_updates          | 1308         |\n",
      "|    policyGradLoss     | -0.00763     |\n",
      "|    value_loss         | 0.00976      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 776          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 94           |\n",
      "|    total_timesteps    | 2695168      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033902698 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.734        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0658      |\n",
      "|    mean_step_reward   | -0.00784861  |\n",
      "|    n_updates          | 1312         |\n",
      "|    policyGradLoss     | -0.00392     |\n",
      "|    value_loss         | 0.00513      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 769          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 106          |\n",
      "|    total_timesteps    | 2703360      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028070263 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.843        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0622      |\n",
      "|    mean_step_reward   | -0.007076539 |\n",
      "|    n_updates          | 1316         |\n",
      "|    policyGradLoss     | -0.00705     |\n",
      "|    value_loss         | 0.011        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 768          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 117          |\n",
      "|    total_timesteps    | 2711552      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003055475  |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.868        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0672      |\n",
      "|    mean_step_reward   | -0.007237916 |\n",
      "|    n_updates          | 1320         |\n",
      "|    policyGradLoss     | -0.00664     |\n",
      "|    value_loss         | 0.00471      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 767           |\n",
      "|    iterations         | 12            |\n",
      "|    time_elapsed       | 128           |\n",
      "|    total_timesteps    | 2719744       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004157793   |\n",
      "|    entropy_loss       | -2.25         |\n",
      "|    explained_variance | 0.706         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0663       |\n",
      "|    mean_step_reward   | -0.0077769407 |\n",
      "|    n_updates          | 1324          |\n",
      "|    policyGradLoss     | -0.00433      |\n",
      "|    value_loss         | 0.0101        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 766          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 138          |\n",
      "|    total_timesteps    | 2727936      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0036075457 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.848        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0643      |\n",
      "|    mean_step_reward   | -0.006787548 |\n",
      "|    n_updates          | 1328         |\n",
      "|    policyGradLoss     | -0.00625     |\n",
      "|    value_loss         | 0.0112       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 765           |\n",
      "|    iterations         | 14            |\n",
      "|    time_elapsed       | 149           |\n",
      "|    total_timesteps    | 2736128       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0030031567  |\n",
      "|    entropy_loss       | -2.25         |\n",
      "|    explained_variance | 0.851         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0602       |\n",
      "|    mean_step_reward   | -0.0070041385 |\n",
      "|    n_updates          | 1332          |\n",
      "|    policyGradLoss     | -0.00465      |\n",
      "|    value_loss         | 0.00719       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 760           |\n",
      "|    iterations         | 15            |\n",
      "|    time_elapsed       | 161           |\n",
      "|    total_timesteps    | 2744320       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.002845054   |\n",
      "|    entropy_loss       | -2.27         |\n",
      "|    explained_variance | 0.879         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0653       |\n",
      "|    mean_step_reward   | -0.0081406385 |\n",
      "|    n_updates          | 1336          |\n",
      "|    policyGradLoss     | -0.00376      |\n",
      "|    value_loss         | 0.000903      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 757          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 172          |\n",
      "|    total_timesteps    | 2752512      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0040968927 |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.857        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0601      |\n",
      "|    mean_step_reward   | -0.008011691 |\n",
      "|    n_updates          | 1340         |\n",
      "|    policyGradLoss     | -0.00463     |\n",
      "|    value_loss         | 0.00419      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 760          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 183          |\n",
      "|    total_timesteps    | 2760704      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0020474559 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.823        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0617      |\n",
      "|    mean_step_reward   | -0.007791152 |\n",
      "|    n_updates          | 1344         |\n",
      "|    policyGradLoss     | -0.00565     |\n",
      "|    value_loss         | 0.00411      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 194          |\n",
      "|    total_timesteps    | 2768896      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025524409 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.846        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0626      |\n",
      "|    mean_step_reward   | -0.00748018  |\n",
      "|    n_updates          | 1348         |\n",
      "|    policyGradLoss     | -0.00542     |\n",
      "|    value_loss         | 0.00578      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 757          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 205          |\n",
      "|    total_timesteps    | 2777088      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028092044 |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.754        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0554      |\n",
      "|    mean_step_reward   | -0.008355351 |\n",
      "|    n_updates          | 1352         |\n",
      "|    policyGradLoss     | -0.00281     |\n",
      "|    value_loss         | 0.00455      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 216         |\n",
      "|    total_timesteps    | 2785280     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004751265 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.722       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0656     |\n",
      "|    mean_step_reward   | -0.00659136 |\n",
      "|    n_updates          | 1356        |\n",
      "|    policyGradLoss     | -0.00652    |\n",
      "|    value_loss         | 0.0137      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 228          |\n",
      "|    total_timesteps    | 2793472      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026371987 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.722        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0656      |\n",
      "|    mean_step_reward   | -0.00812927  |\n",
      "|    n_updates          | 1360         |\n",
      "|    policyGradLoss     | -0.00673     |\n",
      "|    value_loss         | 0.00391      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 238          |\n",
      "|    total_timesteps    | 2801664      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026338384 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.77         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0656      |\n",
      "|    mean_step_reward   | -0.008109619 |\n",
      "|    n_updates          | 1364         |\n",
      "|    policyGradLoss     | -0.00696     |\n",
      "|    value_loss         | 0.00732      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 249          |\n",
      "|    total_timesteps    | 2809856      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028841328 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.768        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0654      |\n",
      "|    mean_step_reward   | -0.006656129 |\n",
      "|    n_updates          | 1368         |\n",
      "|    policyGradLoss     | -0.00728     |\n",
      "|    value_loss         | 0.0123       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 754           |\n",
      "|    iterations         | 24            |\n",
      "|    time_elapsed       | 260           |\n",
      "|    total_timesteps    | 2818048       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0027916387  |\n",
      "|    entropy_loss       | -2.26         |\n",
      "|    explained_variance | 0.72          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0645       |\n",
      "|    mean_step_reward   | -0.0081087705 |\n",
      "|    n_updates          | 1372          |\n",
      "|    policyGradLoss     | -0.00583      |\n",
      "|    value_loss         | 0.00632       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 271          |\n",
      "|    total_timesteps    | 2826240      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.002836234  |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.699        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0634      |\n",
      "|    mean_step_reward   | -0.007668813 |\n",
      "|    n_updates          | 1376         |\n",
      "|    policyGradLoss     | -0.00565     |\n",
      "|    value_loss         | 0.0124       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 283          |\n",
      "|    total_timesteps    | 2834432      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026140963 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.761        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0609      |\n",
      "|    mean_step_reward   | -0.006848523 |\n",
      "|    n_updates          | 1380         |\n",
      "|    policyGradLoss     | -0.00736     |\n",
      "|    value_loss         | 0.0167       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 755           |\n",
      "|    iterations         | 27            |\n",
      "|    time_elapsed       | 292           |\n",
      "|    total_timesteps    | 2842624       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0026614768  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.807         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0657       |\n",
      "|    mean_step_reward   | -0.0054890756 |\n",
      "|    n_updates          | 1384          |\n",
      "|    policyGradLoss     | -0.00813      |\n",
      "|    value_loss         | 0.0196        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 28            |\n",
      "|    time_elapsed       | 304           |\n",
      "|    total_timesteps    | 2850816       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0034288568  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.832         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0593       |\n",
      "|    mean_step_reward   | -0.0068436563 |\n",
      "|    n_updates          | 1388          |\n",
      "|    policyGradLoss     | -0.00811      |\n",
      "|    value_loss         | 0.0193        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 29            |\n",
      "|    time_elapsed       | 316           |\n",
      "|    total_timesteps    | 2859008       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0040053986  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.76          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0588       |\n",
      "|    mean_step_reward   | -0.0053194324 |\n",
      "|    n_updates          | 1392          |\n",
      "|    policyGradLoss     | -0.00868      |\n",
      "|    value_loss         | 0.0283        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 326          |\n",
      "|    total_timesteps    | 2867200      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035965396 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.805        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0656      |\n",
      "|    mean_step_reward   | -0.006320836 |\n",
      "|    n_updates          | 1396         |\n",
      "|    policyGradLoss     | -0.0073      |\n",
      "|    value_loss         | 0.0248       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 31            |\n",
      "|    time_elapsed       | 337           |\n",
      "|    total_timesteps    | 2875392       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003274648   |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.803         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.064        |\n",
      "|    mean_step_reward   | -0.0056279157 |\n",
      "|    n_updates          | 1400          |\n",
      "|    policyGradLoss     | -0.00726      |\n",
      "|    value_loss         | 0.0168        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 32            |\n",
      "|    time_elapsed       | 348           |\n",
      "|    total_timesteps    | 2883584       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003062871   |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.853         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0653       |\n",
      "|    mean_step_reward   | -0.0073447297 |\n",
      "|    n_updates          | 1404          |\n",
      "|    policyGradLoss     | -0.00626      |\n",
      "|    value_loss         | 0.00562       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 33            |\n",
      "|    time_elapsed       | 359           |\n",
      "|    total_timesteps    | 2891776       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.002619227   |\n",
      "|    entropy_loss       | -2.25         |\n",
      "|    explained_variance | 0.89          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0648       |\n",
      "|    mean_step_reward   | -0.0075465012 |\n",
      "|    n_updates          | 1408          |\n",
      "|    policyGradLoss     | -0.00599      |\n",
      "|    value_loss         | 0.00392       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 371          |\n",
      "|    total_timesteps    | 2899968      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0024889782 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.778        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0579      |\n",
      "|    mean_step_reward   | -0.008355485 |\n",
      "|    n_updates          | 1412         |\n",
      "|    policyGradLoss     | -0.00556     |\n",
      "|    value_loss         | 0.00297      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 35            |\n",
      "|    time_elapsed       | 380           |\n",
      "|    total_timesteps    | 2908160       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0028768494  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.857         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0612       |\n",
      "|    mean_step_reward   | -0.0072062025 |\n",
      "|    n_updates          | 1416          |\n",
      "|    policyGradLoss     | -0.00664      |\n",
      "|    value_loss         | 0.00611       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 36            |\n",
      "|    time_elapsed       | 392           |\n",
      "|    total_timesteps    | 2916352       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0027818345  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.772         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0669       |\n",
      "|    mean_step_reward   | -0.0075315447 |\n",
      "|    n_updates          | 1420          |\n",
      "|    policyGradLoss     | -0.00561      |\n",
      "|    value_loss         | 0.0116        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 403          |\n",
      "|    total_timesteps    | 2924544      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00314378   |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.863        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.058       |\n",
      "|    mean_step_reward   | -0.006543052 |\n",
      "|    n_updates          | 1424         |\n",
      "|    policyGradLoss     | -0.00635     |\n",
      "|    value_loss         | 0.00746      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 38            |\n",
      "|    time_elapsed       | 414           |\n",
      "|    total_timesteps    | 2932736       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0030328524  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.865         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0677       |\n",
      "|    mean_step_reward   | -0.0079369005 |\n",
      "|    n_updates          | 1428          |\n",
      "|    policyGradLoss     | -0.00431      |\n",
      "|    value_loss         | 0.00218       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 39            |\n",
      "|    time_elapsed       | 425           |\n",
      "|    total_timesteps    | 2940928       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0030895094  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.851         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.067        |\n",
      "|    mean_step_reward   | -0.0077500157 |\n",
      "|    n_updates          | 1432          |\n",
      "|    policyGradLoss     | -0.00392      |\n",
      "|    value_loss         | 0.00282       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 436          |\n",
      "|    total_timesteps    | 2949120      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.002783972  |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.368        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0584      |\n",
      "|    mean_step_reward   | -0.008800572 |\n",
      "|    n_updates          | 1436         |\n",
      "|    policyGradLoss     | -0.00227     |\n",
      "|    value_loss         | 0.00158      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_8.zip\n",
      "[EVAL] Mean Return: -1.151, Best Return: -0.271\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_8_-1.15.mp4\n",
      "\n",
      "=== Round 10 | Learn 327680 steps (Total trained: 2949120) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1074    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 2957312 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 849           |\n",
      "|    iterations         | 2             |\n",
      "|    time_elapsed       | 19            |\n",
      "|    total_timesteps    | 2965504       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0034970483  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.788         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0618       |\n",
      "|    mean_step_reward   | -0.0073480546 |\n",
      "|    n_updates          | 1444          |\n",
      "|    policyGradLoss     | -0.00572      |\n",
      "|    value_loss         | 0.00976       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 847           |\n",
      "|    iterations         | 3             |\n",
      "|    time_elapsed       | 28            |\n",
      "|    total_timesteps    | 2973696       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0032696812  |\n",
      "|    entropy_loss       | -2.19         |\n",
      "|    explained_variance | 0.747         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0604       |\n",
      "|    mean_step_reward   | -0.0059601367 |\n",
      "|    n_updates          | 1448          |\n",
      "|    policyGradLoss     | -0.00651      |\n",
      "|    value_loss         | 0.0245        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 807          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 40           |\n",
      "|    total_timesteps    | 2981888      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0031961782 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.498        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0656      |\n",
      "|    mean_step_reward   | -0.008114019 |\n",
      "|    n_updates          | 1452         |\n",
      "|    policyGradLoss     | -0.00497     |\n",
      "|    value_loss         | 0.00587      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 789          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 51           |\n",
      "|    total_timesteps    | 2990080      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003031903  |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.739        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0614      |\n",
      "|    mean_step_reward   | -0.007293018 |\n",
      "|    n_updates          | 1456         |\n",
      "|    policyGradLoss     | -0.00513     |\n",
      "|    value_loss         | 0.00658      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 786          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 62           |\n",
      "|    total_timesteps    | 2998272      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028150417 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.607        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0646      |\n",
      "|    mean_step_reward   | -0.008851246 |\n",
      "|    n_updates          | 1460         |\n",
      "|    policyGradLoss     | -0.00369     |\n",
      "|    value_loss         | 0.00137      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 774          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 74           |\n",
      "|    total_timesteps    | 3006464      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033150546 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.749        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0689      |\n",
      "|    mean_step_reward   | -0.0077768   |\n",
      "|    n_updates          | 1464         |\n",
      "|    policyGradLoss     | -0.00424     |\n",
      "|    value_loss         | 0.0093       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 778           |\n",
      "|    iterations         | 8             |\n",
      "|    time_elapsed       | 84            |\n",
      "|    total_timesteps    | 3014656       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003584925   |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.713         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0613       |\n",
      "|    mean_step_reward   | -0.0076261815 |\n",
      "|    n_updates          | 1468          |\n",
      "|    policyGradLoss     | -0.00654      |\n",
      "|    value_loss         | 0.0139        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 769          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 95           |\n",
      "|    total_timesteps    | 3022848      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035158251 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.671        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0607      |\n",
      "|    mean_step_reward   | -0.006949879 |\n",
      "|    n_updates          | 1472         |\n",
      "|    policyGradLoss     | -0.00596     |\n",
      "|    value_loss         | 0.0247       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 762           |\n",
      "|    iterations         | 10            |\n",
      "|    time_elapsed       | 107           |\n",
      "|    total_timesteps    | 3031040       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0032218425  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.697         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0662       |\n",
      "|    mean_step_reward   | -0.0065600323 |\n",
      "|    n_updates          | 1476          |\n",
      "|    policyGradLoss     | -0.00714      |\n",
      "|    value_loss         | 0.0249        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 766          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 117          |\n",
      "|    total_timesteps    | 3039232      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.002274951  |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.854        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0685      |\n",
      "|    mean_step_reward   | -0.006855631 |\n",
      "|    n_updates          | 1480         |\n",
      "|    policyGradLoss     | -0.00637     |\n",
      "|    value_loss         | 0.00405      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 761           |\n",
      "|    iterations         | 12            |\n",
      "|    time_elapsed       | 129           |\n",
      "|    total_timesteps    | 3047424       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0035042146  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.841         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0592       |\n",
      "|    mean_step_reward   | -0.0065833023 |\n",
      "|    n_updates          | 1484          |\n",
      "|    policyGradLoss     | -0.00854      |\n",
      "|    value_loss         | 0.0164        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 762          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 139          |\n",
      "|    total_timesteps    | 3055616      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030506968 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.826        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0645      |\n",
      "|    mean_step_reward   | -0.005520826 |\n",
      "|    n_updates          | 1488         |\n",
      "|    policyGradLoss     | -0.0092      |\n",
      "|    value_loss         | 0.0159       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 760          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 150          |\n",
      "|    total_timesteps    | 3063808      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028661927 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.829        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0664      |\n",
      "|    mean_step_reward   | -0.007368469 |\n",
      "|    n_updates          | 1492         |\n",
      "|    policyGradLoss     | -0.00794     |\n",
      "|    value_loss         | 0.0136       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 756           |\n",
      "|    iterations         | 15            |\n",
      "|    time_elapsed       | 162           |\n",
      "|    total_timesteps    | 3072000       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0031453108  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.821         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.062        |\n",
      "|    mean_step_reward   | -0.0057845665 |\n",
      "|    n_updates          | 1496          |\n",
      "|    policyGradLoss     | -0.00784      |\n",
      "|    value_loss         | 0.0161        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 762           |\n",
      "|    iterations         | 16            |\n",
      "|    time_elapsed       | 171           |\n",
      "|    total_timesteps    | 3080192       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.002176072   |\n",
      "|    entropy_loss       | -2.26         |\n",
      "|    explained_variance | 0.794         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0629       |\n",
      "|    mean_step_reward   | -0.0077298284 |\n",
      "|    n_updates          | 1500          |\n",
      "|    policyGradLoss     | -0.00538      |\n",
      "|    value_loss         | 0.00457       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 758           |\n",
      "|    iterations         | 17            |\n",
      "|    time_elapsed       | 183           |\n",
      "|    total_timesteps    | 3088384       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.002409562   |\n",
      "|    entropy_loss       | -2.26         |\n",
      "|    explained_variance | 0.691         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0685       |\n",
      "|    mean_step_reward   | -0.0077114915 |\n",
      "|    n_updates          | 1504          |\n",
      "|    policyGradLoss     | -0.00521      |\n",
      "|    value_loss         | 0.00719       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 194          |\n",
      "|    total_timesteps    | 3096576      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026572375 |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.777        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0678      |\n",
      "|    mean_step_reward   | -0.008504108 |\n",
      "|    n_updates          | 1508         |\n",
      "|    policyGradLoss     | -0.00745     |\n",
      "|    value_loss         | 0.00407      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 758           |\n",
      "|    iterations         | 19            |\n",
      "|    time_elapsed       | 205           |\n",
      "|    total_timesteps    | 3104768       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0041391226  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.729         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.06         |\n",
      "|    mean_step_reward   | -0.0073967255 |\n",
      "|    n_updates          | 1512          |\n",
      "|    policyGradLoss     | -0.00571      |\n",
      "|    value_loss         | 0.0111        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 216         |\n",
      "|    total_timesteps    | 3112960     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.00323904  |\n",
      "|    entropy_loss       | -2.25       |\n",
      "|    explained_variance | 0.769       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0623     |\n",
      "|    mean_step_reward   | -0.00787276 |\n",
      "|    n_updates          | 1516        |\n",
      "|    policyGradLoss     | -0.00675    |\n",
      "|    value_loss         | 0.00844     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 757           |\n",
      "|    iterations         | 21            |\n",
      "|    time_elapsed       | 227           |\n",
      "|    total_timesteps    | 3121152       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0033831957  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.579         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0574       |\n",
      "|    mean_step_reward   | -0.0074840277 |\n",
      "|    n_updates          | 1520          |\n",
      "|    policyGradLoss     | -0.00692      |\n",
      "|    value_loss         | 0.0183        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 755           |\n",
      "|    iterations         | 22            |\n",
      "|    time_elapsed       | 238           |\n",
      "|    total_timesteps    | 3129344       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0029009716  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.771         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.064        |\n",
      "|    mean_step_reward   | -0.0065585235 |\n",
      "|    n_updates          | 1524          |\n",
      "|    policyGradLoss     | -0.00594      |\n",
      "|    value_loss         | 0.013         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 23            |\n",
      "|    time_elapsed       | 250           |\n",
      "|    total_timesteps    | 3137536       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003091753   |\n",
      "|    entropy_loss       | -2.26         |\n",
      "|    explained_variance | 0.764         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0648       |\n",
      "|    mean_step_reward   | -0.0073407353 |\n",
      "|    n_updates          | 1528          |\n",
      "|    policyGradLoss     | -0.00647      |\n",
      "|    value_loss         | 0.00557       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 260          |\n",
      "|    total_timesteps    | 3145728      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030803313 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.799        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0653      |\n",
      "|    mean_step_reward   | -0.007802398 |\n",
      "|    n_updates          | 1532         |\n",
      "|    policyGradLoss     | -0.00685     |\n",
      "|    value_loss         | 0.0112       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 25            |\n",
      "|    time_elapsed       | 271           |\n",
      "|    total_timesteps    | 3153920       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0037004214  |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.829         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0577       |\n",
      "|    mean_step_reward   | -0.0056406795 |\n",
      "|    n_updates          | 1536          |\n",
      "|    policyGradLoss     | -0.00897      |\n",
      "|    value_loss         | 0.0217        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 26            |\n",
      "|    time_elapsed       | 282           |\n",
      "|    total_timesteps    | 3162112       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0037253492  |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.761         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0589       |\n",
      "|    mean_step_reward   | -0.0056999233 |\n",
      "|    n_updates          | 1540          |\n",
      "|    policyGradLoss     | -0.00671      |\n",
      "|    value_loss         | 0.0263        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 27            |\n",
      "|    time_elapsed       | 293           |\n",
      "|    total_timesteps    | 3170304       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003532873   |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.788         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0582       |\n",
      "|    mean_step_reward   | -0.0052452562 |\n",
      "|    n_updates          | 1544          |\n",
      "|    policyGradLoss     | -0.00792      |\n",
      "|    value_loss         | 0.0246        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 28            |\n",
      "|    time_elapsed       | 305           |\n",
      "|    total_timesteps    | 3178496       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0038731047  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.836         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0599       |\n",
      "|    mean_step_reward   | -0.0074269692 |\n",
      "|    n_updates          | 1548          |\n",
      "|    policyGradLoss     | -0.00657      |\n",
      "|    value_loss         | 0.00846       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 29            |\n",
      "|    time_elapsed       | 315           |\n",
      "|    total_timesteps    | 3186688       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.002763809   |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.834         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0664       |\n",
      "|    mean_step_reward   | -0.0064479886 |\n",
      "|    n_updates          | 1552          |\n",
      "|    policyGradLoss     | -0.00538      |\n",
      "|    value_loss         | 0.0118        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 30            |\n",
      "|    time_elapsed       | 326           |\n",
      "|    total_timesteps    | 3194880       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0039138803  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.809         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0627       |\n",
      "|    mean_step_reward   | -0.0075172614 |\n",
      "|    n_updates          | 1556          |\n",
      "|    policyGradLoss     | -0.00588      |\n",
      "|    value_loss         | 0.00857       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 31            |\n",
      "|    time_elapsed       | 338           |\n",
      "|    total_timesteps    | 3203072       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004323612   |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.806         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0603       |\n",
      "|    mean_step_reward   | -0.0073328256 |\n",
      "|    n_updates          | 1560          |\n",
      "|    policyGradLoss     | -0.00681      |\n",
      "|    value_loss         | 0.0122        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 32            |\n",
      "|    time_elapsed       | 348           |\n",
      "|    total_timesteps    | 3211264       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0029084547  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.783         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0631       |\n",
      "|    mean_step_reward   | -0.0064439857 |\n",
      "|    n_updates          | 1564          |\n",
      "|    policyGradLoss     | -0.00787      |\n",
      "|    value_loss         | 0.0163        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 360          |\n",
      "|    total_timesteps    | 3219456      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025306086 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.831        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0638      |\n",
      "|    mean_step_reward   | -0.007173732 |\n",
      "|    n_updates          | 1568         |\n",
      "|    policyGradLoss     | -0.00575     |\n",
      "|    value_loss         | 0.00762      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 34            |\n",
      "|    time_elapsed       | 370           |\n",
      "|    total_timesteps    | 3227648       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0023935102  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.871         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0633       |\n",
      "|    mean_step_reward   | -0.0074841743 |\n",
      "|    n_updates          | 1572          |\n",
      "|    policyGradLoss     | -0.00666      |\n",
      "|    value_loss         | 0.0105        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 35            |\n",
      "|    time_elapsed       | 382           |\n",
      "|    total_timesteps    | 3235840       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003503297   |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.849         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0707       |\n",
      "|    mean_step_reward   | -0.0065904306 |\n",
      "|    n_updates          | 1576          |\n",
      "|    policyGradLoss     | -0.00566      |\n",
      "|    value_loss         | 0.0109        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 393          |\n",
      "|    total_timesteps    | 3244032      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038676914 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.751        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0695      |\n",
      "|    mean_step_reward   | -0.007206974 |\n",
      "|    n_updates          | 1580         |\n",
      "|    policyGradLoss     | -0.00667     |\n",
      "|    value_loss         | 0.0122       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 37            |\n",
      "|    time_elapsed       | 403           |\n",
      "|    total_timesteps    | 3252224       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0030489725  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.828         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0687       |\n",
      "|    mean_step_reward   | -0.0075487746 |\n",
      "|    n_updates          | 1584          |\n",
      "|    policyGradLoss     | -0.0069       |\n",
      "|    value_loss         | 0.0073        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 414          |\n",
      "|    total_timesteps    | 3260416      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030985982 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.808        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0582      |\n",
      "|    mean_step_reward   | -0.006132119 |\n",
      "|    n_updates          | 1588         |\n",
      "|    policyGradLoss     | -0.00634     |\n",
      "|    value_loss         | 0.0152       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 425          |\n",
      "|    total_timesteps    | 3268608      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025646712 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.826        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0696      |\n",
      "|    mean_step_reward   | -0.007229827 |\n",
      "|    n_updates          | 1592         |\n",
      "|    policyGradLoss     | -0.00506     |\n",
      "|    value_loss         | 0.00886      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 436          |\n",
      "|    total_timesteps    | 3276800      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0037539606 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.758        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0648      |\n",
      "|    mean_step_reward   | -0.00872175  |\n",
      "|    n_updates          | 1596         |\n",
      "|    policyGradLoss     | -0.00649     |\n",
      "|    value_loss         | 0.00448      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_9.zip\n",
      "[EVAL] Mean Return: -1.151, Best Return: -0.271\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_9_-1.15.mp4\n",
      "\n",
      "=== Round 11 | Learn 327680 steps (Total trained: 3276800) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 983     |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 8       |\n",
      "|    total_timesteps | 3284992 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 862           |\n",
      "|    iterations         | 2             |\n",
      "|    time_elapsed       | 19            |\n",
      "|    total_timesteps    | 3293184       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0027364679  |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.772         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0613       |\n",
      "|    mean_step_reward   | -0.0063714907 |\n",
      "|    n_updates          | 1604          |\n",
      "|    policyGradLoss     | -0.00488      |\n",
      "|    value_loss         | 0.0179        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 804          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 30           |\n",
      "|    total_timesteps    | 3301376      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0044440953 |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.83         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0631      |\n",
      "|    mean_step_reward   | -0.008255217 |\n",
      "|    n_updates          | 1608         |\n",
      "|    policyGradLoss     | -0.00525     |\n",
      "|    value_loss         | 0.00243      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 801           |\n",
      "|    iterations         | 4             |\n",
      "|    time_elapsed       | 40            |\n",
      "|    total_timesteps    | 3309568       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0025086221  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.755         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0658       |\n",
      "|    mean_step_reward   | -0.0070799375 |\n",
      "|    n_updates          | 1612          |\n",
      "|    policyGradLoss     | -0.00628      |\n",
      "|    value_loss         | 0.0103        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 781          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 52           |\n",
      "|    total_timesteps    | 3317760      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0020927726 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.792        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0638      |\n",
      "|    mean_step_reward   | -0.008687202 |\n",
      "|    n_updates          | 1616         |\n",
      "|    policyGradLoss     | -0.00486     |\n",
      "|    value_loss         | 0.00251      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 768          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 63           |\n",
      "|    total_timesteps    | 3325952      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025766063 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.706        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0673      |\n",
      "|    mean_step_reward   | -0.007449582 |\n",
      "|    n_updates          | 1620         |\n",
      "|    policyGradLoss     | -0.00681     |\n",
      "|    value_loss         | 0.00742      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 776           |\n",
      "|    iterations         | 7             |\n",
      "|    time_elapsed       | 73            |\n",
      "|    total_timesteps    | 3334144       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0030948848  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.832         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.065        |\n",
      "|    mean_step_reward   | -0.0075981626 |\n",
      "|    n_updates          | 1624          |\n",
      "|    policyGradLoss     | -0.00624      |\n",
      "|    value_loss         | 0.00593       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 767           |\n",
      "|    iterations         | 8             |\n",
      "|    time_elapsed       | 85            |\n",
      "|    total_timesteps    | 3342336       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0028927578  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.859         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0659       |\n",
      "|    mean_step_reward   | -0.0067271395 |\n",
      "|    n_updates          | 1628          |\n",
      "|    policyGradLoss     | -0.00665      |\n",
      "|    value_loss         | 0.00969       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 764          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 96           |\n",
      "|    total_timesteps    | 3350528      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00300347   |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.702        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0605      |\n",
      "|    mean_step_reward   | -0.008411557 |\n",
      "|    n_updates          | 1632         |\n",
      "|    policyGradLoss     | -0.00632     |\n",
      "|    value_loss         | 0.00022      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 763          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 107          |\n",
      "|    total_timesteps    | 3358720      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.002891641  |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.804        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.06        |\n",
      "|    mean_step_reward   | -0.007117578 |\n",
      "|    n_updates          | 1636         |\n",
      "|    policyGradLoss     | -0.00473     |\n",
      "|    value_loss         | 0.00909      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 758          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 118          |\n",
      "|    total_timesteps    | 3366912      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0031537903 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.809        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0644      |\n",
      "|    mean_step_reward   | -0.008605213 |\n",
      "|    n_updates          | 1640         |\n",
      "|    policyGradLoss     | -0.00632     |\n",
      "|    value_loss         | 0.000663     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 763          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 128          |\n",
      "|    total_timesteps    | 3375104      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035081564 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.766        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0643      |\n",
      "|    mean_step_reward   | -0.007351066 |\n",
      "|    n_updates          | 1644         |\n",
      "|    policyGradLoss     | -0.00585     |\n",
      "|    value_loss         | 0.00844      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 757          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 140          |\n",
      "|    total_timesteps    | 3383296      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004208302  |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.752        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0626      |\n",
      "|    mean_step_reward   | -0.007653786 |\n",
      "|    n_updates          | 1648         |\n",
      "|    policyGradLoss     | -0.00604     |\n",
      "|    value_loss         | 0.00825      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 754           |\n",
      "|    iterations         | 14            |\n",
      "|    time_elapsed       | 151           |\n",
      "|    total_timesteps    | 3391488       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0024701753  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.8           |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0598       |\n",
      "|    mean_step_reward   | -0.0065374738 |\n",
      "|    n_updates          | 1652          |\n",
      "|    policyGradLoss     | -0.00618      |\n",
      "|    value_loss         | 0.013         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 757          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 162          |\n",
      "|    total_timesteps    | 3399680      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0036495058 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.201        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0691      |\n",
      "|    mean_step_reward   | -0.008452368 |\n",
      "|    n_updates          | 1656         |\n",
      "|    policyGradLoss     | -0.0087      |\n",
      "|    value_loss         | 0.000114     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 173          |\n",
      "|    total_timesteps    | 3407872      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030937162 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.639        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0655      |\n",
      "|    mean_step_reward   | -0.008081408 |\n",
      "|    n_updates          | 1660         |\n",
      "|    policyGradLoss     | -0.00721     |\n",
      "|    value_loss         | 0.00789      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 755           |\n",
      "|    iterations         | 17            |\n",
      "|    time_elapsed       | 184           |\n",
      "|    total_timesteps    | 3416064       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0028644607  |\n",
      "|    entropy_loss       | -2.25         |\n",
      "|    explained_variance | 0.84          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0697       |\n",
      "|    mean_step_reward   | -0.0077326465 |\n",
      "|    n_updates          | 1664          |\n",
      "|    policyGradLoss     | -0.00377      |\n",
      "|    value_loss         | 0.00254       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 18            |\n",
      "|    time_elapsed       | 195           |\n",
      "|    total_timesteps    | 3424256       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003701454   |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.852         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0635       |\n",
      "|    mean_step_reward   | -0.0073142126 |\n",
      "|    n_updates          | 1668          |\n",
      "|    policyGradLoss     | -0.00698      |\n",
      "|    value_loss         | 0.00685       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 207          |\n",
      "|    total_timesteps    | 3432448      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030367784 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.84         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0631      |\n",
      "|    mean_step_reward   | -0.008063343 |\n",
      "|    n_updates          | 1672         |\n",
      "|    policyGradLoss     | -0.00595     |\n",
      "|    value_loss         | 0.0025       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 216          |\n",
      "|    total_timesteps    | 3440640      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0039032386 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.831        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0675      |\n",
      "|    mean_step_reward   | -0.006536954 |\n",
      "|    n_updates          | 1676         |\n",
      "|    policyGradLoss     | -0.00601     |\n",
      "|    value_loss         | 0.0113       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 228          |\n",
      "|    total_timesteps    | 3448832      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030964059 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.706        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0654      |\n",
      "|    mean_step_reward   | -0.007983625 |\n",
      "|    n_updates          | 1680         |\n",
      "|    policyGradLoss     | -0.00527     |\n",
      "|    value_loss         | 0.00332      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 239          |\n",
      "|    total_timesteps    | 3457024      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038285546 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.668        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.064       |\n",
      "|    mean_step_reward   | -0.007854463 |\n",
      "|    n_updates          | 1684         |\n",
      "|    policyGradLoss     | -0.00547     |\n",
      "|    value_loss         | 0.00959      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 23            |\n",
      "|    time_elapsed       | 250           |\n",
      "|    total_timesteps    | 3465216       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0039104307  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.564         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0601       |\n",
      "|    mean_step_reward   | -0.0081329765 |\n",
      "|    n_updates          | 1688          |\n",
      "|    policyGradLoss     | -0.0074       |\n",
      "|    value_loss         | 0.00494       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 24            |\n",
      "|    time_elapsed       | 261           |\n",
      "|    total_timesteps    | 3473408       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.002779084   |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.718         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.063        |\n",
      "|    mean_step_reward   | -0.0075866575 |\n",
      "|    n_updates          | 1692          |\n",
      "|    policyGradLoss     | -0.0053       |\n",
      "|    value_loss         | 0.00865       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 25            |\n",
      "|    time_elapsed       | 271           |\n",
      "|    total_timesteps    | 3481600       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.002856084   |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.805         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0648       |\n",
      "|    mean_step_reward   | -0.0067471555 |\n",
      "|    n_updates          | 1696          |\n",
      "|    policyGradLoss     | -0.00505      |\n",
      "|    value_loss         | 0.00931       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 283          |\n",
      "|    total_timesteps    | 3489792      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0032905075 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.833        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.064       |\n",
      "|    mean_step_reward   | -0.006757646 |\n",
      "|    n_updates          | 1700         |\n",
      "|    policyGradLoss     | -0.007       |\n",
      "|    value_loss         | 0.0129       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 27            |\n",
      "|    time_elapsed       | 295           |\n",
      "|    total_timesteps    | 3497984       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0036080545  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.685         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0633       |\n",
      "|    mean_step_reward   | -0.0077980566 |\n",
      "|    n_updates          | 1704          |\n",
      "|    policyGradLoss     | -0.00712      |\n",
      "|    value_loss         | 0.0113        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 305          |\n",
      "|    total_timesteps    | 3506176      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0032205065 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.772        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0647      |\n",
      "|    mean_step_reward   | -0.007046721 |\n",
      "|    n_updates          | 1708         |\n",
      "|    policyGradLoss     | -0.00659     |\n",
      "|    value_loss         | 0.014        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 317          |\n",
      "|    total_timesteps    | 3514368      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003046319  |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.705        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0689      |\n",
      "|    mean_step_reward   | -0.007823516 |\n",
      "|    n_updates          | 1712         |\n",
      "|    policyGradLoss     | -0.0052      |\n",
      "|    value_loss         | 0.00471      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 327          |\n",
      "|    total_timesteps    | 3522560      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034800014 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.754        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0625      |\n",
      "|    mean_step_reward   | -0.007477035 |\n",
      "|    n_updates          | 1716         |\n",
      "|    policyGradLoss     | -0.00681     |\n",
      "|    value_loss         | 0.0107       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 747           |\n",
      "|    iterations         | 31            |\n",
      "|    time_elapsed       | 339           |\n",
      "|    total_timesteps    | 3530752       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0034753892  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.795         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0642       |\n",
      "|    mean_step_reward   | -0.0065584867 |\n",
      "|    n_updates          | 1720          |\n",
      "|    policyGradLoss     | -0.00765      |\n",
      "|    value_loss         | 0.0106        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 746          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 351          |\n",
      "|    total_timesteps    | 3538944      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030308594 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.718        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.063       |\n",
      "|    mean_step_reward   | -0.007988254 |\n",
      "|    n_updates          | 1724         |\n",
      "|    policyGradLoss     | -0.00564     |\n",
      "|    value_loss         | 0.00682      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 33            |\n",
      "|    time_elapsed       | 360           |\n",
      "|    total_timesteps    | 3547136       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0028072982  |\n",
      "|    entropy_loss       | -2.25         |\n",
      "|    explained_variance | 0.676         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0657       |\n",
      "|    mean_step_reward   | -0.0074598608 |\n",
      "|    n_updates          | 1728          |\n",
      "|    policyGradLoss     | -0.00555      |\n",
      "|    value_loss         | 0.0091        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 372          |\n",
      "|    total_timesteps    | 3555328      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0041750167 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.684        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0603      |\n",
      "|    mean_step_reward   | -0.008287992 |\n",
      "|    n_updates          | 1732         |\n",
      "|    policyGradLoss     | -0.00653     |\n",
      "|    value_loss         | 0.0104       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 747           |\n",
      "|    iterations         | 35            |\n",
      "|    time_elapsed       | 383           |\n",
      "|    total_timesteps    | 3563520       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0036980808  |\n",
      "|    entropy_loss       | -2.25         |\n",
      "|    explained_variance | 0.73          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0689       |\n",
      "|    mean_step_reward   | -0.0074794586 |\n",
      "|    n_updates          | 1736          |\n",
      "|    policyGradLoss     | -0.00722      |\n",
      "|    value_loss         | 0.00954       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 394          |\n",
      "|    total_timesteps    | 3571712      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033342792 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.794        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0612      |\n",
      "|    mean_step_reward   | -0.007606864 |\n",
      "|    n_updates          | 1740         |\n",
      "|    policyGradLoss     | -0.00752     |\n",
      "|    value_loss         | 0.00862      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 746          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 405          |\n",
      "|    total_timesteps    | 3579904      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030458681 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.805        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0604      |\n",
      "|    mean_step_reward   | -0.005861331 |\n",
      "|    n_updates          | 1744         |\n",
      "|    policyGradLoss     | -0.00812     |\n",
      "|    value_loss         | 0.0161       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 416          |\n",
      "|    total_timesteps    | 3588096      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003451772  |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.719        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0587      |\n",
      "|    mean_step_reward   | -0.007377534 |\n",
      "|    n_updates          | 1748         |\n",
      "|    policyGradLoss     | -0.008       |\n",
      "|    value_loss         | 0.0136       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 746          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 427          |\n",
      "|    total_timesteps    | 3596288      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003754273  |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.765        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.064       |\n",
      "|    mean_step_reward   | -0.006835135 |\n",
      "|    n_updates          | 1752         |\n",
      "|    policyGradLoss     | -0.00711     |\n",
      "|    value_loss         | 0.0131       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 745           |\n",
      "|    iterations         | 40            |\n",
      "|    time_elapsed       | 439           |\n",
      "|    total_timesteps    | 3604480       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0029775181  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.835         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0644       |\n",
      "|    mean_step_reward   | -0.0070226872 |\n",
      "|    n_updates          | 1756          |\n",
      "|    policyGradLoss     | -0.0071       |\n",
      "|    value_loss         | 0.00892       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_10.zip\n",
      "[EVAL] Mean Return: -1.154, Best Return: -0.274\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_10_-1.15.mp4\n",
      "\n",
      "=== Round 12 | Learn 327680 steps (Total trained: 3604480) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1375    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 5       |\n",
      "|    total_timesteps | 3612672 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 930           |\n",
      "|    iterations         | 2             |\n",
      "|    time_elapsed       | 17            |\n",
      "|    total_timesteps    | 3620864       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003470254   |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.762         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0616       |\n",
      "|    mean_step_reward   | -0.0063473796 |\n",
      "|    n_updates          | 1764          |\n",
      "|    policyGradLoss     | -0.00732      |\n",
      "|    value_loss         | 0.0144        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 849          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 3629056      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0039139767 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.654        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0673      |\n",
      "|    mean_step_reward   | -0.008253949 |\n",
      "|    n_updates          | 1768         |\n",
      "|    policyGradLoss     | -0.00786     |\n",
      "|    value_loss         | 0.00924      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 828          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 39           |\n",
      "|    total_timesteps    | 3637248      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035083555 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.801        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0639      |\n",
      "|    mean_step_reward   | -0.006941599 |\n",
      "|    n_updates          | 1772         |\n",
      "|    policyGradLoss     | -0.00578     |\n",
      "|    value_loss         | 0.011        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 799           |\n",
      "|    iterations         | 5             |\n",
      "|    time_elapsed       | 51            |\n",
      "|    total_timesteps    | 3645440       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0030581949  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.77          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0594       |\n",
      "|    mean_step_reward   | -0.0075639295 |\n",
      "|    n_updates          | 1776          |\n",
      "|    policyGradLoss     | -0.00645      |\n",
      "|    value_loss         | 0.0147        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 803          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 61           |\n",
      "|    total_timesteps    | 3653632      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028974258 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.774        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0547      |\n",
      "|    mean_step_reward   | -0.006924091 |\n",
      "|    n_updates          | 1780         |\n",
      "|    policyGradLoss     | -0.00664     |\n",
      "|    value_loss         | 0.0154       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 788           |\n",
      "|    iterations         | 7             |\n",
      "|    time_elapsed       | 72            |\n",
      "|    total_timesteps    | 3661824       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003024552   |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.839         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0612       |\n",
      "|    mean_step_reward   | -0.0061539765 |\n",
      "|    n_updates          | 1784          |\n",
      "|    policyGradLoss     | -0.00824      |\n",
      "|    value_loss         | 0.015         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 776           |\n",
      "|    iterations         | 8             |\n",
      "|    time_elapsed       | 84            |\n",
      "|    total_timesteps    | 3670016       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0041262354  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.814         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0637       |\n",
      "|    mean_step_reward   | -0.0068257176 |\n",
      "|    n_updates          | 1788          |\n",
      "|    policyGradLoss     | -0.00623      |\n",
      "|    value_loss         | 0.0113        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 782          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 94           |\n",
      "|    total_timesteps    | 3678208      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025733905 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.781        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.061       |\n",
      "|    mean_step_reward   | -0.008060046 |\n",
      "|    n_updates          | 1792         |\n",
      "|    policyGradLoss     | -0.00532     |\n",
      "|    value_loss         | 0.00557      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 773           |\n",
      "|    iterations         | 10            |\n",
      "|    time_elapsed       | 105           |\n",
      "|    total_timesteps    | 3686400       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0035934595  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.839         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0698       |\n",
      "|    mean_step_reward   | -0.0076188473 |\n",
      "|    n_updates          | 1796          |\n",
      "|    policyGradLoss     | -0.00662      |\n",
      "|    value_loss         | 0.00441       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 771          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 116          |\n",
      "|    total_timesteps    | 3694592      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003480173  |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.856        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0692      |\n",
      "|    mean_step_reward   | -0.007561995 |\n",
      "|    n_updates          | 1800         |\n",
      "|    policyGradLoss     | -0.00693     |\n",
      "|    value_loss         | 0.00562      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 769           |\n",
      "|    iterations         | 12            |\n",
      "|    time_elapsed       | 127           |\n",
      "|    total_timesteps    | 3702784       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0032417187  |\n",
      "|    entropy_loss       | -2.25         |\n",
      "|    explained_variance | 0.799         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0669       |\n",
      "|    mean_step_reward   | -0.0077093802 |\n",
      "|    n_updates          | 1804          |\n",
      "|    policyGradLoss     | -0.00422      |\n",
      "|    value_loss         | 0.00491       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 763          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 139          |\n",
      "|    total_timesteps    | 3710976      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003481042  |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.744        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0665      |\n",
      "|    mean_step_reward   | -0.007360868 |\n",
      "|    n_updates          | 1808         |\n",
      "|    policyGradLoss     | -0.00757     |\n",
      "|    value_loss         | 0.0116       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 767          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 149          |\n",
      "|    total_timesteps    | 3719168      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025336877 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.758        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0631      |\n",
      "|    mean_step_reward   | -0.007931425 |\n",
      "|    n_updates          | 1812         |\n",
      "|    policyGradLoss     | -0.00449     |\n",
      "|    value_loss         | 0.00594      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 761          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 161          |\n",
      "|    total_timesteps    | 3727360      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0029026056 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.848        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0643      |\n",
      "|    mean_step_reward   | -0.007762059 |\n",
      "|    n_updates          | 1816         |\n",
      "|    policyGradLoss     | -0.00695     |\n",
      "|    value_loss         | 0.00557      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 759          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 172          |\n",
      "|    total_timesteps    | 3735552      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0029016198 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.809        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0564      |\n",
      "|    mean_step_reward   | -0.007590199 |\n",
      "|    n_updates          | 1820         |\n",
      "|    policyGradLoss     | -0.00516     |\n",
      "|    value_loss         | 0.00501      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 759          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 183          |\n",
      "|    total_timesteps    | 3743744      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004766761  |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.888        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0664      |\n",
      "|    mean_step_reward   | -0.006755119 |\n",
      "|    n_updates          | 1824         |\n",
      "|    policyGradLoss     | -0.00617     |\n",
      "|    value_loss         | 0.00543      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 195          |\n",
      "|    total_timesteps    | 3751936      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0032294067 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.706        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.069       |\n",
      "|    mean_step_reward   | -0.008091697 |\n",
      "|    n_updates          | 1828         |\n",
      "|    policyGradLoss     | -0.0071      |\n",
      "|    value_loss         | 0.00462      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 759           |\n",
      "|    iterations         | 19            |\n",
      "|    time_elapsed       | 204           |\n",
      "|    total_timesteps    | 3760128       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0026558586  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.863         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0605       |\n",
      "|    mean_step_reward   | -0.0058795623 |\n",
      "|    n_updates          | 1832          |\n",
      "|    policyGradLoss     | -0.00653      |\n",
      "|    value_loss         | 0.0126        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 216          |\n",
      "|    total_timesteps    | 3768320      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0037601735 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.836        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0544      |\n",
      "|    mean_step_reward   | -0.008232445 |\n",
      "|    n_updates          | 1836         |\n",
      "|    policyGradLoss     | -0.00608     |\n",
      "|    value_loss         | 0.00705      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 228          |\n",
      "|    total_timesteps    | 3776512      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025608642 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.676        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0667      |\n",
      "|    mean_step_reward   | -0.007033562 |\n",
      "|    n_updates          | 1840         |\n",
      "|    policyGradLoss     | -0.00606     |\n",
      "|    value_loss         | 0.0099       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 757           |\n",
      "|    iterations         | 22            |\n",
      "|    time_elapsed       | 238           |\n",
      "|    total_timesteps    | 3784704       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0041394215  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.83          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0594       |\n",
      "|    mean_step_reward   | -0.0077994894 |\n",
      "|    n_updates          | 1844          |\n",
      "|    policyGradLoss     | -0.00543      |\n",
      "|    value_loss         | 0.00539       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 756           |\n",
      "|    iterations         | 23            |\n",
      "|    time_elapsed       | 248           |\n",
      "|    total_timesteps    | 3792896       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0040568616  |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.791         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0586       |\n",
      "|    mean_step_reward   | -0.0071857246 |\n",
      "|    n_updates          | 1848          |\n",
      "|    policyGradLoss     | -0.00783      |\n",
      "|    value_loss         | 0.0144        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 757           |\n",
      "|    iterations         | 24            |\n",
      "|    time_elapsed       | 259           |\n",
      "|    total_timesteps    | 3801088       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0034472272  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.697         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0662       |\n",
      "|    mean_step_reward   | -0.0071522687 |\n",
      "|    n_updates          | 1852          |\n",
      "|    policyGradLoss     | -0.00727      |\n",
      "|    value_loss         | 0.0125        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 757           |\n",
      "|    iterations         | 25            |\n",
      "|    time_elapsed       | 270           |\n",
      "|    total_timesteps    | 3809280       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0029361378  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.815         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0694       |\n",
      "|    mean_step_reward   | -0.0066139675 |\n",
      "|    n_updates          | 1856          |\n",
      "|    policyGradLoss     | -0.00821      |\n",
      "|    value_loss         | 0.0109        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 756           |\n",
      "|    iterations         | 26            |\n",
      "|    time_elapsed       | 281           |\n",
      "|    total_timesteps    | 3817472       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003188083   |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.783         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0638       |\n",
      "|    mean_step_reward   | -0.0069524087 |\n",
      "|    n_updates          | 1860          |\n",
      "|    policyGradLoss     | -0.00777      |\n",
      "|    value_loss         | 0.0112        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 292          |\n",
      "|    total_timesteps    | 3825664      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035682917 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.742        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0704      |\n",
      "|    mean_step_reward   | -0.008223448 |\n",
      "|    n_updates          | 1864         |\n",
      "|    policyGradLoss     | -0.00554     |\n",
      "|    value_loss         | 0.00418      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 303          |\n",
      "|    total_timesteps    | 3833856      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033491412 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.857        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0618      |\n",
      "|    mean_step_reward   | -0.008064203 |\n",
      "|    n_updates          | 1868         |\n",
      "|    policyGradLoss     | -0.00501     |\n",
      "|    value_loss         | 0.00329      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 315          |\n",
      "|    total_timesteps    | 3842048      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0044966233 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.809        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.065       |\n",
      "|    mean_step_reward   | -0.006729548 |\n",
      "|    n_updates          | 1872         |\n",
      "|    policyGradLoss     | -0.00681     |\n",
      "|    value_loss         | 0.0157       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 325          |\n",
      "|    total_timesteps    | 3850240      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038253195 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.765        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0613      |\n",
      "|    mean_step_reward   | -0.006489875 |\n",
      "|    n_updates          | 1876         |\n",
      "|    policyGradLoss     | -0.00628     |\n",
      "|    value_loss         | 0.0128       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 337          |\n",
      "|    total_timesteps    | 3858432      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033002486 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.869        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0673      |\n",
      "|    mean_step_reward   | -0.006543785 |\n",
      "|    n_updates          | 1880         |\n",
      "|    policyGradLoss     | -0.0074      |\n",
      "|    value_loss         | 0.0111       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 32            |\n",
      "|    time_elapsed       | 347           |\n",
      "|    total_timesteps    | 3866624       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0035428605  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.863         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.067        |\n",
      "|    mean_step_reward   | -0.0063385717 |\n",
      "|    n_updates          | 1884          |\n",
      "|    policyGradLoss     | -0.00706      |\n",
      "|    value_loss         | 0.00867       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 358          |\n",
      "|    total_timesteps    | 3874816      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0036443686 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.801        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0692      |\n",
      "|    mean_step_reward   | -0.006389046 |\n",
      "|    n_updates          | 1888         |\n",
      "|    policyGradLoss     | -0.00659     |\n",
      "|    value_loss         | 0.0139       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 370          |\n",
      "|    total_timesteps    | 3883008      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033708452 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.835        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0669      |\n",
      "|    mean_step_reward   | -0.007662611 |\n",
      "|    n_updates          | 1892         |\n",
      "|    policyGradLoss     | -0.00589     |\n",
      "|    value_loss         | 0.0061       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 35            |\n",
      "|    time_elapsed       | 380           |\n",
      "|    total_timesteps    | 3891200       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003776814   |\n",
      "|    entropy_loss       | -2.25         |\n",
      "|    explained_variance | 0.8           |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0658       |\n",
      "|    mean_step_reward   | -0.0075257327 |\n",
      "|    n_updates          | 1896          |\n",
      "|    policyGradLoss     | -0.00538      |\n",
      "|    value_loss         | 0.00802       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 36            |\n",
      "|    time_elapsed       | 391           |\n",
      "|    total_timesteps    | 3899392       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003564014   |\n",
      "|    entropy_loss       | -2.25         |\n",
      "|    explained_variance | 0.832         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0698       |\n",
      "|    mean_step_reward   | -0.0078394795 |\n",
      "|    n_updates          | 1900          |\n",
      "|    policyGradLoss     | -0.00805      |\n",
      "|    value_loss         | 0.0076        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 403          |\n",
      "|    total_timesteps    | 3907584      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0031303973 |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.773        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0592      |\n",
      "|    mean_step_reward   | -0.007963485 |\n",
      "|    n_updates          | 1904         |\n",
      "|    policyGradLoss     | -0.00566     |\n",
      "|    value_loss         | 0.00651      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 413          |\n",
      "|    total_timesteps    | 3915776      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0037617886 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.885        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0695      |\n",
      "|    mean_step_reward   | -0.007258574 |\n",
      "|    n_updates          | 1908         |\n",
      "|    policyGradLoss     | -0.00616     |\n",
      "|    value_loss         | 0.0058       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 39            |\n",
      "|    time_elapsed       | 425           |\n",
      "|    total_timesteps    | 3923968       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003255588   |\n",
      "|    entropy_loss       | -2.25         |\n",
      "|    explained_variance | 0.912         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0682       |\n",
      "|    mean_step_reward   | -0.0072572213 |\n",
      "|    n_updates          | 1912          |\n",
      "|    policyGradLoss     | -0.00672      |\n",
      "|    value_loss         | 0.00429       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 40            |\n",
      "|    time_elapsed       | 435           |\n",
      "|    total_timesteps    | 3932160       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0047077024  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.761         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0641       |\n",
      "|    mean_step_reward   | -0.0072540985 |\n",
      "|    n_updates          | 1916          |\n",
      "|    policyGradLoss     | -0.00701      |\n",
      "|    value_loss         | 0.0106        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_11.zip\n",
      "[EVAL] Mean Return: -1.158, Best Return: -0.278\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_11_-1.16.mp4\n",
      "\n",
      "=== Round 13 | Learn 327680 steps (Total trained: 3932160) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1080    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 3940352 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 861           |\n",
      "|    iterations         | 2             |\n",
      "|    time_elapsed       | 19            |\n",
      "|    total_timesteps    | 3948544       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0043416447  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.866         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0717       |\n",
      "|    mean_step_reward   | -0.0071639693 |\n",
      "|    n_updates          | 1924          |\n",
      "|    policyGradLoss     | -0.00806      |\n",
      "|    value_loss         | 0.00472       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 857          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 3956736      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0045286785 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.805        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0637      |\n",
      "|    mean_step_reward   | -0.007979853 |\n",
      "|    n_updates          | 1928         |\n",
      "|    policyGradLoss     | -0.00489     |\n",
      "|    value_loss         | 0.00503      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 811          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 40           |\n",
      "|    total_timesteps    | 3964928      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0040683397 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.725        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0656      |\n",
      "|    mean_step_reward   | -0.007434207 |\n",
      "|    n_updates          | 1932         |\n",
      "|    policyGradLoss     | -0.00807     |\n",
      "|    value_loss         | 0.0096       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 793          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 51           |\n",
      "|    total_timesteps    | 3973120      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038109    |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.756        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0654      |\n",
      "|    mean_step_reward   | -0.007637622 |\n",
      "|    n_updates          | 1936         |\n",
      "|    policyGradLoss     | -0.00709     |\n",
      "|    value_loss         | 0.00987      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 788          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 62           |\n",
      "|    total_timesteps    | 3981312      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033097365 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.809        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0627      |\n",
      "|    mean_step_reward   | -0.007424706 |\n",
      "|    n_updates          | 1940         |\n",
      "|    policyGradLoss     | -0.00598     |\n",
      "|    value_loss         | 0.0104       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 776           |\n",
      "|    iterations         | 7             |\n",
      "|    time_elapsed       | 73            |\n",
      "|    total_timesteps    | 3989504       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0053929756  |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.804         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0607       |\n",
      "|    mean_step_reward   | -0.0075143697 |\n",
      "|    n_updates          | 1944          |\n",
      "|    policyGradLoss     | -0.00686      |\n",
      "|    value_loss         | 0.018         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 779           |\n",
      "|    iterations         | 8             |\n",
      "|    time_elapsed       | 84            |\n",
      "|    total_timesteps    | 3997696       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005018855   |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.839         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0625       |\n",
      "|    mean_step_reward   | -0.0052314084 |\n",
      "|    n_updates          | 1948          |\n",
      "|    policyGradLoss     | -0.00869      |\n",
      "|    value_loss         | 0.0219        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 770           |\n",
      "|    iterations         | 9             |\n",
      "|    time_elapsed       | 95            |\n",
      "|    total_timesteps    | 4005888       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.00346336    |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.874         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0633       |\n",
      "|    mean_step_reward   | -0.0048446255 |\n",
      "|    n_updates          | 1952          |\n",
      "|    policyGradLoss     | -0.00865      |\n",
      "|    value_loss         | 0.0114        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 763          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 107          |\n",
      "|    total_timesteps    | 4014080      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038578245 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.786        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0677      |\n",
      "|    mean_step_reward   | -0.007020736 |\n",
      "|    n_updates          | 1956         |\n",
      "|    policyGradLoss     | -0.00774     |\n",
      "|    value_loss         | 0.0141       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 768           |\n",
      "|    iterations         | 11            |\n",
      "|    time_elapsed       | 117           |\n",
      "|    total_timesteps    | 4022272       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0027946094  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.862         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0687       |\n",
      "|    mean_step_reward   | -0.0059070783 |\n",
      "|    n_updates          | 1960          |\n",
      "|    policyGradLoss     | -0.00769      |\n",
      "|    value_loss         | 0.0131        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 763          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 128          |\n",
      "|    total_timesteps    | 4030464      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0039687776 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.861        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0667      |\n",
      "|    mean_step_reward   | -0.007510588 |\n",
      "|    n_updates          | 1964         |\n",
      "|    policyGradLoss     | -0.00811     |\n",
      "|    value_loss         | 0.00912      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 762           |\n",
      "|    iterations         | 13            |\n",
      "|    time_elapsed       | 139           |\n",
      "|    total_timesteps    | 4038656       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0038605467  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.92          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0643       |\n",
      "|    mean_step_reward   | -0.0059800493 |\n",
      "|    n_updates          | 1968          |\n",
      "|    policyGradLoss     | -0.00867      |\n",
      "|    value_loss         | 0.00803       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 761          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 150          |\n",
      "|    total_timesteps    | 4046848      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0037882905 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.891        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0728      |\n",
      "|    mean_step_reward   | -0.006805891 |\n",
      "|    n_updates          | 1972         |\n",
      "|    policyGradLoss     | -0.00809     |\n",
      "|    value_loss         | 0.00727      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 757          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 162          |\n",
      "|    total_timesteps    | 4055040      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004586229  |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.856        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0662      |\n",
      "|    mean_step_reward   | -0.008056382 |\n",
      "|    n_updates          | 1976         |\n",
      "|    policyGradLoss     | -0.00457     |\n",
      "|    value_loss         | 0.0019       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 762          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 171          |\n",
      "|    total_timesteps    | 4063232      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0037632682 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.781        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.061       |\n",
      "|    mean_step_reward   | -0.008370496 |\n",
      "|    n_updates          | 1980         |\n",
      "|    policyGradLoss     | -0.00497     |\n",
      "|    value_loss         | 0.000389     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 758          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 183          |\n",
      "|    total_timesteps    | 4071424      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034244834 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.867        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0666      |\n",
      "|    mean_step_reward   | -0.007405792 |\n",
      "|    n_updates          | 1984         |\n",
      "|    policyGradLoss     | -0.00319     |\n",
      "|    value_loss         | 0.00399      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 195          |\n",
      "|    total_timesteps    | 4079616      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0036993034 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.87         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0683      |\n",
      "|    mean_step_reward   | -0.007836153 |\n",
      "|    n_updates          | 1988         |\n",
      "|    policyGradLoss     | -0.00832     |\n",
      "|    value_loss         | 0.00436      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 757           |\n",
      "|    iterations         | 19            |\n",
      "|    time_elapsed       | 205           |\n",
      "|    total_timesteps    | 4087808       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0034969565  |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.869         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0746       |\n",
      "|    mean_step_reward   | -0.0070036687 |\n",
      "|    n_updates          | 1992          |\n",
      "|    policyGradLoss     | -0.00756      |\n",
      "|    value_loss         | 0.0105        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 217          |\n",
      "|    total_timesteps    | 4096000      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038594394 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.879        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0655      |\n",
      "|    mean_step_reward   | -0.006214037 |\n",
      "|    n_updates          | 1996         |\n",
      "|    policyGradLoss     | -0.00938     |\n",
      "|    value_loss         | 0.0105       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 756           |\n",
      "|    iterations         | 21            |\n",
      "|    time_elapsed       | 227           |\n",
      "|    total_timesteps    | 4104192       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0033922982  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.907         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0615       |\n",
      "|    mean_step_reward   | -0.0070363777 |\n",
      "|    n_updates          | 2000          |\n",
      "|    policyGradLoss     | -0.00539      |\n",
      "|    value_loss         | 0.00378       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 238          |\n",
      "|    total_timesteps    | 4112384      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0039027103 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.746        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0586      |\n",
      "|    mean_step_reward   | -0.008067841 |\n",
      "|    n_updates          | 2004         |\n",
      "|    policyGradLoss     | -0.00559     |\n",
      "|    value_loss         | 0.00383      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 250          |\n",
      "|    total_timesteps    | 4120576      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0036392135 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.822        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0628      |\n",
      "|    mean_step_reward   | -0.008158139 |\n",
      "|    n_updates          | 2008         |\n",
      "|    policyGradLoss     | -0.00291     |\n",
      "|    value_loss         | 0.00145      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 260          |\n",
      "|    total_timesteps    | 4128768      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026119994 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.885        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.065       |\n",
      "|    mean_step_reward   | -0.007664012 |\n",
      "|    n_updates          | 2012         |\n",
      "|    policyGradLoss     | -0.00664     |\n",
      "|    value_loss         | 0.005        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 25            |\n",
      "|    time_elapsed       | 271           |\n",
      "|    total_timesteps    | 4136960       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0038842764  |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.834         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0634       |\n",
      "|    mean_step_reward   | -0.0059741274 |\n",
      "|    n_updates          | 2016          |\n",
      "|    policyGradLoss     | -0.00843      |\n",
      "|    value_loss         | 0.015         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 282          |\n",
      "|    total_timesteps    | 4145152      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0044141407 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.861        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0677      |\n",
      "|    mean_step_reward   | -0.006884721 |\n",
      "|    n_updates          | 2020         |\n",
      "|    policyGradLoss     | -0.00865     |\n",
      "|    value_loss         | 0.00849      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 27            |\n",
      "|    time_elapsed       | 293           |\n",
      "|    total_timesteps    | 4153344       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0049818465  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.827         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.069        |\n",
      "|    mean_step_reward   | -0.0076090656 |\n",
      "|    n_updates          | 2024          |\n",
      "|    policyGradLoss     | -0.00745      |\n",
      "|    value_loss         | 0.0067        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 305          |\n",
      "|    total_timesteps    | 4161536      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027963184 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.0975       |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0603      |\n",
      "|    mean_step_reward   | -0.008401383 |\n",
      "|    n_updates          | 2028         |\n",
      "|    policyGradLoss     | -0.00457     |\n",
      "|    value_loss         | 0.000785     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 29            |\n",
      "|    time_elapsed       | 315           |\n",
      "|    total_timesteps    | 4169728       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0031990204  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.874         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0636       |\n",
      "|    mean_step_reward   | -0.0074064704 |\n",
      "|    n_updates          | 2032          |\n",
      "|    policyGradLoss     | -0.00677      |\n",
      "|    value_loss         | 0.0047        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 30            |\n",
      "|    time_elapsed       | 326           |\n",
      "|    total_timesteps    | 4177920       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0042360006  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.844         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0652       |\n",
      "|    mean_step_reward   | -0.0067821587 |\n",
      "|    n_updates          | 2036          |\n",
      "|    policyGradLoss     | -0.00682      |\n",
      "|    value_loss         | 0.0104        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 338          |\n",
      "|    total_timesteps    | 4186112      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0039862725 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.853        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0627      |\n",
      "|    mean_step_reward   | -0.00735077  |\n",
      "|    n_updates          | 2040         |\n",
      "|    policyGradLoss     | -0.00678     |\n",
      "|    value_loss         | 0.00533      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 347          |\n",
      "|    total_timesteps    | 4194304      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0032767819 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.835        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0641      |\n",
      "|    mean_step_reward   | -0.007847768 |\n",
      "|    n_updates          | 2044         |\n",
      "|    policyGradLoss     | -0.00521     |\n",
      "|    value_loss         | 0.00649      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 359          |\n",
      "|    total_timesteps    | 4202496      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0041252635 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.552        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0682      |\n",
      "|    mean_step_reward   | -0.007697802 |\n",
      "|    n_updates          | 2048         |\n",
      "|    policyGradLoss     | -0.00957     |\n",
      "|    value_loss         | 0.00698      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 370          |\n",
      "|    total_timesteps    | 4210688      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0037980755 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.743        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0653      |\n",
      "|    mean_step_reward   | -0.007190495 |\n",
      "|    n_updates          | 2052         |\n",
      "|    policyGradLoss     | -0.00447     |\n",
      "|    value_loss         | 0.00734      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 35            |\n",
      "|    time_elapsed       | 381           |\n",
      "|    total_timesteps    | 4218880       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.002692782   |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.873         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0628       |\n",
      "|    mean_step_reward   | -0.0077195554 |\n",
      "|    n_updates          | 2056          |\n",
      "|    policyGradLoss     | -0.00688      |\n",
      "|    value_loss         | 0.00314       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 392          |\n",
      "|    total_timesteps    | 4227072      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.002986764  |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.889        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0678      |\n",
      "|    mean_step_reward   | -0.006989589 |\n",
      "|    n_updates          | 2060         |\n",
      "|    policyGradLoss     | -0.00614     |\n",
      "|    value_loss         | 0.0074       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 403          |\n",
      "|    total_timesteps    | 4235264      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0040529585 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.883        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0691      |\n",
      "|    mean_step_reward   | -0.006854341 |\n",
      "|    n_updates          | 2064         |\n",
      "|    policyGradLoss     | -0.00863     |\n",
      "|    value_loss         | 0.00774      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 414          |\n",
      "|    total_timesteps    | 4243456      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038954786 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.843        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0601      |\n",
      "|    mean_step_reward   | -0.006456444 |\n",
      "|    n_updates          | 2068         |\n",
      "|    policyGradLoss     | -0.007       |\n",
      "|    value_loss         | 0.0128       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 39            |\n",
      "|    time_elapsed       | 426           |\n",
      "|    total_timesteps    | 4251648       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0042075855  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.908         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0664       |\n",
      "|    mean_step_reward   | -0.0076243607 |\n",
      "|    n_updates          | 2072          |\n",
      "|    policyGradLoss     | -0.00598      |\n",
      "|    value_loss         | 0.00178       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 435          |\n",
      "|    total_timesteps    | 4259840      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0042213514 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.83         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0691      |\n",
      "|    mean_step_reward   | -0.007913967 |\n",
      "|    n_updates          | 2076         |\n",
      "|    policyGradLoss     | -0.00732     |\n",
      "|    value_loss         | 0.00405      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_12.zip\n",
      "[EVAL] Mean Return: -115.210, Best Return: -111.573\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_12_-115.21.mp4\n",
      "\n",
      "=== Round 14 | Learn 327680 steps (Total trained: 4259840) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1169    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 4268032 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 910          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 4276224      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035106766 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.881        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0623      |\n",
      "|    mean_step_reward   | -0.006448796 |\n",
      "|    n_updates          | 2084         |\n",
      "|    policyGradLoss     | -0.00778     |\n",
      "|    value_loss         | 0.00967      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 831          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 29           |\n",
      "|    total_timesteps    | 4284416      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004955628  |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.878        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0647      |\n",
      "|    mean_step_reward   | -0.007181515 |\n",
      "|    n_updates          | 2088         |\n",
      "|    policyGradLoss     | -0.00803     |\n",
      "|    value_loss         | 0.00717      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 809           |\n",
      "|    iterations         | 4             |\n",
      "|    time_elapsed       | 40            |\n",
      "|    total_timesteps    | 4292608       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0037516914  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.704         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0648       |\n",
      "|    mean_step_reward   | -0.0079743955 |\n",
      "|    n_updates          | 2092          |\n",
      "|    policyGradLoss     | -0.00571      |\n",
      "|    value_loss         | 0.00735       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 796          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 51           |\n",
      "|    total_timesteps    | 4300800      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0031053144 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.802        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0664      |\n",
      "|    mean_step_reward   | -0.006897068 |\n",
      "|    n_updates          | 2096         |\n",
      "|    policyGradLoss     | -0.00811     |\n",
      "|    value_loss         | 0.00891      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 785          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 62           |\n",
      "|    total_timesteps    | 4308992      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0029156131 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.761        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0672      |\n",
      "|    mean_step_reward   | -0.008177223 |\n",
      "|    n_updates          | 2100         |\n",
      "|    policyGradLoss     | -0.00513     |\n",
      "|    value_loss         | 0.00273      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 774          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 74           |\n",
      "|    total_timesteps    | 4317184      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003292995  |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.87         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0606      |\n",
      "|    mean_step_reward   | -0.007661743 |\n",
      "|    n_updates          | 2104         |\n",
      "|    policyGradLoss     | -0.00582     |\n",
      "|    value_loss         | 0.00246      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 778          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 84           |\n",
      "|    total_timesteps    | 4325376      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004349608  |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.849        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0693      |\n",
      "|    mean_step_reward   | -0.007342442 |\n",
      "|    n_updates          | 2108         |\n",
      "|    policyGradLoss     | -0.00786     |\n",
      "|    value_loss         | 0.00761      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 769          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 95           |\n",
      "|    total_timesteps    | 4333568      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0048392853 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.846        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0573      |\n",
      "|    mean_step_reward   | -0.006905115 |\n",
      "|    n_updates          | 2112         |\n",
      "|    policyGradLoss     | -0.0088      |\n",
      "|    value_loss         | 0.0108       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 763          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 107          |\n",
      "|    total_timesteps    | 4341760      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0029565964 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.662        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0616      |\n",
      "|    mean_step_reward   | -0.008220603 |\n",
      "|    n_updates          | 2116         |\n",
      "|    policyGradLoss     | -0.0075      |\n",
      "|    value_loss         | 0.00607      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 767          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 117          |\n",
      "|    total_timesteps    | 4349952      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004197424  |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.74         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0666      |\n",
      "|    mean_step_reward   | -0.006970804 |\n",
      "|    n_updates          | 2120         |\n",
      "|    policyGradLoss     | -0.00775     |\n",
      "|    value_loss         | 0.0103       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 762          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 128          |\n",
      "|    total_timesteps    | 4358144      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0036041383 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.793        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0664      |\n",
      "|    mean_step_reward   | -0.007803321 |\n",
      "|    n_updates          | 2124         |\n",
      "|    policyGradLoss     | -0.00781     |\n",
      "|    value_loss         | 0.00491      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 761           |\n",
      "|    iterations         | 13            |\n",
      "|    time_elapsed       | 139           |\n",
      "|    total_timesteps    | 4366336       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0040185107  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.833         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0634       |\n",
      "|    mean_step_reward   | -0.0068902383 |\n",
      "|    n_updates          | 2128          |\n",
      "|    policyGradLoss     | -0.00767      |\n",
      "|    value_loss         | 0.00538       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 759          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 150          |\n",
      "|    total_timesteps    | 4374528      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0053190915 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.727        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0656      |\n",
      "|    mean_step_reward   | -0.007609008 |\n",
      "|    n_updates          | 2132         |\n",
      "|    policyGradLoss     | -0.00724     |\n",
      "|    value_loss         | 0.014        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 162          |\n",
      "|    total_timesteps    | 4382720      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0057138326 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.799        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0646      |\n",
      "|    mean_step_reward   | -0.006821393 |\n",
      "|    n_updates          | 2136         |\n",
      "|    policyGradLoss     | -0.00516     |\n",
      "|    value_loss         | 0.0139       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 759          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 172          |\n",
      "|    total_timesteps    | 4390912      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004945742  |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.786        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0681      |\n",
      "|    mean_step_reward   | -0.007406785 |\n",
      "|    n_updates          | 2140         |\n",
      "|    policyGradLoss     | -0.00789     |\n",
      "|    value_loss         | 0.0114       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 755           |\n",
      "|    iterations         | 17            |\n",
      "|    time_elapsed       | 184           |\n",
      "|    total_timesteps    | 4399104       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0036993474  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.829         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.063        |\n",
      "|    mean_step_reward   | -0.0060619195 |\n",
      "|    n_updates          | 2144          |\n",
      "|    policyGradLoss     | -0.00848      |\n",
      "|    value_loss         | 0.0127        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 195          |\n",
      "|    total_timesteps    | 4407296      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030009996 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.791        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0603      |\n",
      "|    mean_step_reward   | -0.007559544 |\n",
      "|    n_updates          | 2148         |\n",
      "|    policyGradLoss     | -0.0068      |\n",
      "|    value_loss         | 0.0119       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 755           |\n",
      "|    iterations         | 19            |\n",
      "|    time_elapsed       | 205           |\n",
      "|    total_timesteps    | 4415488       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0035796387  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.803         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0649       |\n",
      "|    mean_step_reward   | -0.0060195215 |\n",
      "|    n_updates          | 2152          |\n",
      "|    policyGradLoss     | -0.0081       |\n",
      "|    value_loss         | 0.0157        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 20            |\n",
      "|    time_elapsed       | 217           |\n",
      "|    total_timesteps    | 4423680       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0038037836  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.823         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0679       |\n",
      "|    mean_step_reward   | -0.0076889144 |\n",
      "|    n_updates          | 2156          |\n",
      "|    policyGradLoss     | -0.00688      |\n",
      "|    value_loss         | 0.0108        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 227          |\n",
      "|    total_timesteps    | 4431872      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003540664  |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.797        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0666      |\n",
      "|    mean_step_reward   | -0.005907218 |\n",
      "|    n_updates          | 2160         |\n",
      "|    policyGradLoss     | -0.00831     |\n",
      "|    value_loss         | 0.017        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 239          |\n",
      "|    total_timesteps    | 4440064      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0045009414 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.865        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0694      |\n",
      "|    mean_step_reward   | -0.006184306 |\n",
      "|    n_updates          | 2164         |\n",
      "|    policyGradLoss     | -0.0089      |\n",
      "|    value_loss         | 0.0097       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 23            |\n",
      "|    time_elapsed       | 251           |\n",
      "|    total_timesteps    | 4448256       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0039733597  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.838         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0716       |\n",
      "|    mean_step_reward   | -0.0071593346 |\n",
      "|    n_updates          | 2168          |\n",
      "|    policyGradLoss     | -0.00844      |\n",
      "|    value_loss         | 0.00903       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 260          |\n",
      "|    total_timesteps    | 4456448      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033314046 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.876        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0679      |\n",
      "|    mean_step_reward   | -0.007247552 |\n",
      "|    n_updates          | 2172         |\n",
      "|    policyGradLoss     | -0.00711     |\n",
      "|    value_loss         | 0.00796      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 25            |\n",
      "|    time_elapsed       | 272           |\n",
      "|    total_timesteps    | 4464640       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005060315   |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.806         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0711       |\n",
      "|    mean_step_reward   | -0.0070795766 |\n",
      "|    n_updates          | 2176          |\n",
      "|    policyGradLoss     | -0.00929      |\n",
      "|    value_loss         | 0.00966       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 26            |\n",
      "|    time_elapsed       | 283           |\n",
      "|    total_timesteps    | 4472832       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0042146947  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.782         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0699       |\n",
      "|    mean_step_reward   | -0.0073293922 |\n",
      "|    n_updates          | 2180          |\n",
      "|    policyGradLoss     | -0.00813      |\n",
      "|    value_loss         | 0.0117        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 294          |\n",
      "|    total_timesteps    | 4481024      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0054928763 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.822        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0663      |\n",
      "|    mean_step_reward   | -0.005957651 |\n",
      "|    n_updates          | 2184         |\n",
      "|    policyGradLoss     | -0.00803     |\n",
      "|    value_loss         | 0.0151       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 28            |\n",
      "|    time_elapsed       | 306           |\n",
      "|    total_timesteps    | 4489216       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004040433   |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.851         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0604       |\n",
      "|    mean_step_reward   | -0.0075187874 |\n",
      "|    n_updates          | 2188          |\n",
      "|    policyGradLoss     | -0.0071       |\n",
      "|    value_loss         | 0.011         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 29            |\n",
      "|    time_elapsed       | 316           |\n",
      "|    total_timesteps    | 4497408       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0048333034  |\n",
      "|    entropy_loss       | -2.19         |\n",
      "|    explained_variance | 0.822         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0668       |\n",
      "|    mean_step_reward   | -0.0067707226 |\n",
      "|    n_updates          | 2192          |\n",
      "|    policyGradLoss     | -0.00875      |\n",
      "|    value_loss         | 0.0201        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 30            |\n",
      "|    time_elapsed       | 328           |\n",
      "|    total_timesteps    | 4505600       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0043158466  |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.833         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0673       |\n",
      "|    mean_step_reward   | -0.0060069417 |\n",
      "|    n_updates          | 2196          |\n",
      "|    policyGradLoss     | -0.00787      |\n",
      "|    value_loss         | 0.0197        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 339          |\n",
      "|    total_timesteps    | 4513792      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0048530553 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.839        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0656      |\n",
      "|    mean_step_reward   | -0.006790202 |\n",
      "|    n_updates          | 2200         |\n",
      "|    policyGradLoss     | -0.00922     |\n",
      "|    value_loss         | 0.0142       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 349          |\n",
      "|    total_timesteps    | 4521984      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030421987 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.827        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0563      |\n",
      "|    mean_step_reward   | -0.007723619 |\n",
      "|    n_updates          | 2204         |\n",
      "|    policyGradLoss     | -0.00352     |\n",
      "|    value_loss         | 0.00386      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 361          |\n",
      "|    total_timesteps    | 4530176      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005296488  |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.853        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0701      |\n",
      "|    mean_step_reward   | -0.007755737 |\n",
      "|    n_updates          | 2208         |\n",
      "|    policyGradLoss     | -0.00654     |\n",
      "|    value_loss         | 0.00329      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 34            |\n",
      "|    time_elapsed       | 372           |\n",
      "|    total_timesteps    | 4538368       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0033207186  |\n",
      "|    entropy_loss       | -2.25         |\n",
      "|    explained_variance | 0.882         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0633       |\n",
      "|    mean_step_reward   | -0.0077329963 |\n",
      "|    n_updates          | 2212          |\n",
      "|    policyGradLoss     | -0.00556      |\n",
      "|    value_loss         | 0.0023        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 383          |\n",
      "|    total_timesteps    | 4546560      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004692687  |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.88         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0678      |\n",
      "|    mean_step_reward   | -0.008128932 |\n",
      "|    n_updates          | 2216         |\n",
      "|    policyGradLoss     | -0.00535     |\n",
      "|    value_loss         | 0.0026       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 746           |\n",
      "|    iterations         | 36            |\n",
      "|    time_elapsed       | 395           |\n",
      "|    total_timesteps    | 4554752       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004691383   |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.929         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0668       |\n",
      "|    mean_step_reward   | -0.0063193333 |\n",
      "|    n_updates          | 2220          |\n",
      "|    policyGradLoss     | -0.00784      |\n",
      "|    value_loss         | 0.00566       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 747           |\n",
      "|    iterations         | 37            |\n",
      "|    time_elapsed       | 405           |\n",
      "|    total_timesteps    | 4562944       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005326689   |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.921         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0705       |\n",
      "|    mean_step_reward   | -0.0073922276 |\n",
      "|    n_updates          | 2224          |\n",
      "|    policyGradLoss     | -0.00853      |\n",
      "|    value_loss         | 0.00475       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 746          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 416          |\n",
      "|    total_timesteps    | 4571136      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004593136  |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.872        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.072       |\n",
      "|    mean_step_reward   | -0.007428459 |\n",
      "|    n_updates          | 2228         |\n",
      "|    policyGradLoss     | -0.00279     |\n",
      "|    value_loss         | 0.00494      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 746           |\n",
      "|    iterations         | 39            |\n",
      "|    time_elapsed       | 427           |\n",
      "|    total_timesteps    | 4579328       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0030652597  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.911         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0518       |\n",
      "|    mean_step_reward   | -0.0077973804 |\n",
      "|    n_updates          | 2232          |\n",
      "|    policyGradLoss     | -0.00687      |\n",
      "|    value_loss         | 0.00199       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 746           |\n",
      "|    iterations         | 40            |\n",
      "|    time_elapsed       | 438           |\n",
      "|    total_timesteps    | 4587520       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0033611264  |\n",
      "|    entropy_loss       | -2.25         |\n",
      "|    explained_variance | 0.943         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0701       |\n",
      "|    mean_step_reward   | -0.0077065574 |\n",
      "|    n_updates          | 2236          |\n",
      "|    policyGradLoss     | -0.00555      |\n",
      "|    value_loss         | 0.00173       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_13.zip\n",
      "[EVAL] Mean Return: -1.158, Best Return: -0.278\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_13_-1.16.mp4\n",
      "\n",
      "=== Round 15 | Learn 327680 steps (Total trained: 4587520) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 977     |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 8       |\n",
      "|    total_timesteps | 4595712 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 847          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 4603904      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0056002457 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.912        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0668      |\n",
      "|    mean_step_reward   | -0.006936313 |\n",
      "|    n_updates          | 2244         |\n",
      "|    policyGradLoss     | -0.00753     |\n",
      "|    value_loss         | 0.00495      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 816          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 30           |\n",
      "|    total_timesteps    | 4612096      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038638182 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.952        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0631      |\n",
      "|    mean_step_reward   | -0.007280738 |\n",
      "|    n_updates          | 2248         |\n",
      "|    policyGradLoss     | -0.00738     |\n",
      "|    value_loss         | 0.00254      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 783           |\n",
      "|    iterations         | 4             |\n",
      "|    time_elapsed       | 41            |\n",
      "|    total_timesteps    | 4620288       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0037981707  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.951         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0662       |\n",
      "|    mean_step_reward   | -0.0075060925 |\n",
      "|    n_updates          | 2252          |\n",
      "|    policyGradLoss     | -0.00682      |\n",
      "|    value_loss         | 0.00168       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 790           |\n",
      "|    iterations         | 5             |\n",
      "|    time_elapsed       | 51            |\n",
      "|    total_timesteps    | 4628480       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0031073976  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.916         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0692       |\n",
      "|    mean_step_reward   | -0.0077987625 |\n",
      "|    n_updates          | 2256          |\n",
      "|    policyGradLoss     | -0.00663      |\n",
      "|    value_loss         | 0.00227       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 773          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 63           |\n",
      "|    total_timesteps    | 4636672      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038271553 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.917        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0688      |\n",
      "|    mean_step_reward   | -0.007722351 |\n",
      "|    n_updates          | 2260         |\n",
      "|    policyGradLoss     | -0.00558     |\n",
      "|    value_loss         | 0.00264      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 763          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 75           |\n",
      "|    total_timesteps    | 4644864      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003788152  |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.948        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0687      |\n",
      "|    mean_step_reward   | -0.008021757 |\n",
      "|    n_updates          | 2264         |\n",
      "|    policyGradLoss     | -0.00542     |\n",
      "|    value_loss         | 0.000911     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 768           |\n",
      "|    iterations         | 8             |\n",
      "|    time_elapsed       | 85            |\n",
      "|    total_timesteps    | 4653056       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005145077   |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.908         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0679       |\n",
      "|    mean_step_reward   | -0.0070279045 |\n",
      "|    n_updates          | 2268          |\n",
      "|    policyGradLoss     | -0.00428      |\n",
      "|    value_loss         | 0.00643       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 760          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 96           |\n",
      "|    total_timesteps    | 4661248      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0047994815 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.89         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.069       |\n",
      "|    mean_step_reward   | -0.007376548 |\n",
      "|    n_updates          | 2272         |\n",
      "|    policyGradLoss     | -0.00804     |\n",
      "|    value_loss         | 0.00714      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 763          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 107          |\n",
      "|    total_timesteps    | 4669440      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004335801  |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.897        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0642      |\n",
      "|    mean_step_reward   | -0.006473042 |\n",
      "|    n_updates          | 2276         |\n",
      "|    policyGradLoss     | -0.00719     |\n",
      "|    value_loss         | 0.00683      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 758           |\n",
      "|    iterations         | 11            |\n",
      "|    time_elapsed       | 118           |\n",
      "|    total_timesteps    | 4677632       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0040384606  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.915         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0647       |\n",
      "|    mean_step_reward   | -0.0076936455 |\n",
      "|    n_updates          | 2280          |\n",
      "|    policyGradLoss     | -0.00457      |\n",
      "|    value_loss         | 0.00104       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 130          |\n",
      "|    total_timesteps    | 4685824      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035549572 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.854        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0653      |\n",
      "|    mean_step_reward   | -0.007966173 |\n",
      "|    n_updates          | 2284         |\n",
      "|    policyGradLoss     | -0.00485     |\n",
      "|    value_loss         | 0.00186      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 140         |\n",
      "|    total_timesteps    | 4694016     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004806514 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.483       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0716     |\n",
      "|    mean_step_reward   | -0.00847788 |\n",
      "|    n_updates          | 2288        |\n",
      "|    policyGradLoss     | -0.00655    |\n",
      "|    value_loss         | 0.00198     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 151          |\n",
      "|    total_timesteps    | 4702208      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0041979104 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.781        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.061       |\n",
      "|    mean_step_reward   | -0.006669728 |\n",
      "|    n_updates          | 2292         |\n",
      "|    policyGradLoss     | -0.00432     |\n",
      "|    value_loss         | 0.00599      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 162          |\n",
      "|    total_timesteps    | 4710400      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005076537  |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.845        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0664      |\n",
      "|    mean_step_reward   | -0.007445808 |\n",
      "|    n_updates          | 2296         |\n",
      "|    policyGradLoss     | -0.00644     |\n",
      "|    value_loss         | 0.00708      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 173         |\n",
      "|    total_timesteps    | 4718592     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004327514 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.846       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0619     |\n",
      "|    mean_step_reward   | -0.00642603 |\n",
      "|    n_updates          | 2300        |\n",
      "|    policyGradLoss     | -0.00563    |\n",
      "|    value_loss         | 0.0132      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 185          |\n",
      "|    total_timesteps    | 4726784      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0042339507 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.64         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0567      |\n",
      "|    mean_step_reward   | -0.008197723 |\n",
      "|    n_updates          | 2304         |\n",
      "|    policyGradLoss     | -0.0054      |\n",
      "|    value_loss         | 0.00334      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 195          |\n",
      "|    total_timesteps    | 4734976      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004921142  |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.878        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0663      |\n",
      "|    mean_step_reward   | -0.007307331 |\n",
      "|    n_updates          | 2308         |\n",
      "|    policyGradLoss     | -0.0061      |\n",
      "|    value_loss         | 0.00354      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 207          |\n",
      "|    total_timesteps    | 4743168      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038373885 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.95         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0671      |\n",
      "|    mean_step_reward   | -0.008006973 |\n",
      "|    n_updates          | 2312         |\n",
      "|    policyGradLoss     | -0.00469     |\n",
      "|    value_loss         | 0.000724     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 20            |\n",
      "|    time_elapsed       | 218           |\n",
      "|    total_timesteps    | 4751360       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003882377   |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.881         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0696       |\n",
      "|    mean_step_reward   | -0.0070332848 |\n",
      "|    n_updates          | 2316          |\n",
      "|    policyGradLoss     | -0.00685      |\n",
      "|    value_loss         | 0.00837       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 21            |\n",
      "|    time_elapsed       | 229           |\n",
      "|    total_timesteps    | 4759552       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0036764978  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.888         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0682       |\n",
      "|    mean_step_reward   | -0.0073282374 |\n",
      "|    n_updates          | 2320          |\n",
      "|    policyGradLoss     | -0.00657      |\n",
      "|    value_loss         | 0.00498       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 22            |\n",
      "|    time_elapsed       | 240           |\n",
      "|    total_timesteps    | 4767744       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0037761787  |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.825         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0742       |\n",
      "|    mean_step_reward   | -0.0072088214 |\n",
      "|    n_updates          | 2324          |\n",
      "|    policyGradLoss     | -0.00899      |\n",
      "|    value_loss         | 0.0095        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 251          |\n",
      "|    total_timesteps    | 4775936      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003650573  |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.904        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0672      |\n",
      "|    mean_step_reward   | -0.007464552 |\n",
      "|    n_updates          | 2328         |\n",
      "|    policyGradLoss     | -0.00629     |\n",
      "|    value_loss         | 0.00242      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 262          |\n",
      "|    total_timesteps    | 4784128      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0039087418 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.923        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.062       |\n",
      "|    mean_step_reward   | -0.008393119 |\n",
      "|    n_updates          | 2332         |\n",
      "|    policyGradLoss     | -0.00682     |\n",
      "|    value_loss         | 0.000212     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 746           |\n",
      "|    iterations         | 25            |\n",
      "|    time_elapsed       | 274           |\n",
      "|    total_timesteps    | 4792320       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0038218591  |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.664         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0671       |\n",
      "|    mean_step_reward   | -0.0076780864 |\n",
      "|    n_updates          | 2336          |\n",
      "|    policyGradLoss     | -0.00843      |\n",
      "|    value_loss         | 0.00581       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 26            |\n",
      "|    time_elapsed       | 284           |\n",
      "|    total_timesteps    | 4800512       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0037683118  |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.899         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0746       |\n",
      "|    mean_step_reward   | -0.0072153383 |\n",
      "|    n_updates          | 2340          |\n",
      "|    policyGradLoss     | -0.00829      |\n",
      "|    value_loss         | 0.00511       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 747           |\n",
      "|    iterations         | 27            |\n",
      "|    time_elapsed       | 295           |\n",
      "|    total_timesteps    | 4808704       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003684517   |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.884         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0634       |\n",
      "|    mean_step_reward   | -0.0070463936 |\n",
      "|    n_updates          | 2344          |\n",
      "|    policyGradLoss     | -0.00686      |\n",
      "|    value_loss         | 0.00671       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 306          |\n",
      "|    total_timesteps    | 4816896      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004635699  |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.769        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0662      |\n",
      "|    mean_step_reward   | -0.007702919 |\n",
      "|    n_updates          | 2348         |\n",
      "|    policyGradLoss     | -0.00716     |\n",
      "|    value_loss         | 0.00809      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 317          |\n",
      "|    total_timesteps    | 4825088      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003562951  |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.878        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0656      |\n",
      "|    mean_step_reward   | -0.007299141 |\n",
      "|    n_updates          | 2352         |\n",
      "|    policyGradLoss     | -0.00656     |\n",
      "|    value_loss         | 0.00331      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 328          |\n",
      "|    total_timesteps    | 4833280      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0036939585 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.892        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0608      |\n",
      "|    mean_step_reward   | -0.008055536 |\n",
      "|    n_updates          | 2356         |\n",
      "|    policyGradLoss     | -0.00457     |\n",
      "|    value_loss         | 0.00138      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 339          |\n",
      "|    total_timesteps    | 4841472      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0039598523 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.848        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0688      |\n",
      "|    mean_step_reward   | -0.007610691 |\n",
      "|    n_updates          | 2360         |\n",
      "|    policyGradLoss     | -0.00775     |\n",
      "|    value_loss         | 0.00394      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 350          |\n",
      "|    total_timesteps    | 4849664      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0051100943 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.89         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0617      |\n",
      "|    mean_step_reward   | -0.007465655 |\n",
      "|    n_updates          | 2364         |\n",
      "|    policyGradLoss     | -0.00669     |\n",
      "|    value_loss         | 0.00439      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 361          |\n",
      "|    total_timesteps    | 4857856      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00376439   |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.854        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0539      |\n",
      "|    mean_step_reward   | -0.006855317 |\n",
      "|    n_updates          | 2368         |\n",
      "|    policyGradLoss     | -0.00523     |\n",
      "|    value_loss         | 0.00958      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 747           |\n",
      "|    iterations         | 34            |\n",
      "|    time_elapsed       | 372           |\n",
      "|    total_timesteps    | 4866048       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0043758713  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.888         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0662       |\n",
      "|    mean_step_reward   | -0.0072318017 |\n",
      "|    n_updates          | 2372          |\n",
      "|    policyGradLoss     | -0.00718      |\n",
      "|    value_loss         | 0.00492       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 383          |\n",
      "|    total_timesteps    | 4874240      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003241804  |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.921        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.064       |\n",
      "|    mean_step_reward   | -0.007540649 |\n",
      "|    n_updates          | 2376         |\n",
      "|    policyGradLoss     | -0.00588     |\n",
      "|    value_loss         | 0.00155      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 394          |\n",
      "|    total_timesteps    | 4882432      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023048054 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.863        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.057       |\n",
      "|    mean_step_reward   | -0.007983096 |\n",
      "|    n_updates          | 2380         |\n",
      "|    policyGradLoss     | -0.00479     |\n",
      "|    value_loss         | 0.0014       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 746           |\n",
      "|    iterations         | 37            |\n",
      "|    time_elapsed       | 405           |\n",
      "|    total_timesteps    | 4890624       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0041413857  |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.888         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0556       |\n",
      "|    mean_step_reward   | -0.0077528837 |\n",
      "|    n_updates          | 2384          |\n",
      "|    policyGradLoss     | -0.00663      |\n",
      "|    value_loss         | 0.00291       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 415          |\n",
      "|    total_timesteps    | 4898816      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033084769 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.861        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.068       |\n",
      "|    mean_step_reward   | -0.00788644  |\n",
      "|    n_updates          | 2388         |\n",
      "|    policyGradLoss     | -0.00736     |\n",
      "|    value_loss         | 0.00402      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 747           |\n",
      "|    iterations         | 39            |\n",
      "|    time_elapsed       | 427           |\n",
      "|    total_timesteps    | 4907008       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0044150692  |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.913         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0658       |\n",
      "|    mean_step_reward   | -0.0065756897 |\n",
      "|    n_updates          | 2392          |\n",
      "|    policyGradLoss     | -0.00794      |\n",
      "|    value_loss         | 0.00742       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 438          |\n",
      "|    total_timesteps    | 4915200      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00344982   |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.676        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0689      |\n",
      "|    mean_step_reward   | -0.008078709 |\n",
      "|    n_updates          | 2396         |\n",
      "|    policyGradLoss     | -0.00761     |\n",
      "|    value_loss         | 0.0085       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_14.zip\n",
      "[EVAL] Mean Return: -1.158, Best Return: -0.278\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_14_-1.16.mp4\n",
      "\n",
      "=== Round 16 | Learn 327680 steps (Total trained: 4915200) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1255    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 6       |\n",
      "|    total_timesteps | 4923392 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 902          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 4931584      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026454246 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.839        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0623      |\n",
      "|    mean_step_reward   | -0.00802885  |\n",
      "|    n_updates          | 2404         |\n",
      "|    policyGradLoss     | -0.00482     |\n",
      "|    value_loss         | 0.00184      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 849          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 4939776      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003425541  |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.901        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0649      |\n",
      "|    mean_step_reward   | -0.007524562 |\n",
      "|    n_updates          | 2408         |\n",
      "|    policyGradLoss     | -0.00756     |\n",
      "|    value_loss         | 0.00342      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 821          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 39           |\n",
      "|    total_timesteps    | 4947968      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033345122 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.915        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0687      |\n",
      "|    mean_step_reward   | -0.007519506 |\n",
      "|    n_updates          | 2412         |\n",
      "|    policyGradLoss     | -0.00566     |\n",
      "|    value_loss         | 0.00362      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 796           |\n",
      "|    iterations         | 5             |\n",
      "|    time_elapsed       | 51            |\n",
      "|    total_timesteps    | 4956160       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0047855745  |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.884         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0674       |\n",
      "|    mean_step_reward   | -0.0071569863 |\n",
      "|    n_updates          | 2416          |\n",
      "|    policyGradLoss     | -0.00774      |\n",
      "|    value_loss         | 0.0078        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 803          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 61           |\n",
      "|    total_timesteps    | 4964352      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035806517 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.837        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0674      |\n",
      "|    mean_step_reward   | -0.008056691 |\n",
      "|    n_updates          | 2420         |\n",
      "|    policyGradLoss     | -0.0066      |\n",
      "|    value_loss         | 0.00521      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 786          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 72           |\n",
      "|    total_timesteps    | 4972544      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033504672 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.856        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0658      |\n",
      "|    mean_step_reward   | -0.00682303  |\n",
      "|    n_updates          | 2424         |\n",
      "|    policyGradLoss     | -0.00754     |\n",
      "|    value_loss         | 0.00868      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 776          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 84           |\n",
      "|    total_timesteps    | 4980736      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0042232303 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.869        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0642      |\n",
      "|    mean_step_reward   | -0.0081671   |\n",
      "|    n_updates          | 2428         |\n",
      "|    policyGradLoss     | -0.00752     |\n",
      "|    value_loss         | 0.00186      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 779          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 94           |\n",
      "|    total_timesteps    | 4988928      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003160847  |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.634        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0661      |\n",
      "|    mean_step_reward   | -0.008289374 |\n",
      "|    n_updates          | 2432         |\n",
      "|    policyGradLoss     | -0.00667     |\n",
      "|    value_loss         | 0.00454      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 772           |\n",
      "|    iterations         | 10            |\n",
      "|    time_elapsed       | 106           |\n",
      "|    total_timesteps    | 4997120       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0040194904  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.776         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0629       |\n",
      "|    mean_step_reward   | -0.0074320547 |\n",
      "|    n_updates          | 2436          |\n",
      "|    policyGradLoss     | -0.0067       |\n",
      "|    value_loss         | 0.00739       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 774           |\n",
      "|    iterations         | 11            |\n",
      "|    time_elapsed       | 116           |\n",
      "|    total_timesteps    | 5005312       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0043425094  |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.831         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0615       |\n",
      "|    mean_step_reward   | -0.0059959423 |\n",
      "|    n_updates          | 2440          |\n",
      "|    policyGradLoss     | -0.00785      |\n",
      "|    value_loss         | 0.0092        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 769          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 127          |\n",
      "|    total_timesteps    | 5013504      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004660248  |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.912        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0686      |\n",
      "|    mean_step_reward   | -0.006633037 |\n",
      "|    n_updates          | 2444         |\n",
      "|    policyGradLoss     | -0.00879     |\n",
      "|    value_loss         | 0.006        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 764          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 139          |\n",
      "|    total_timesteps    | 5021696      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0037782248 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.947        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0634      |\n",
      "|    mean_step_reward   | -0.008105042 |\n",
      "|    n_updates          | 2448         |\n",
      "|    policyGradLoss     | -0.00651     |\n",
      "|    value_loss         | 0.000606     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 769          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 149          |\n",
      "|    total_timesteps    | 5029888      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0049462887 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.138        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0686      |\n",
      "|    mean_step_reward   | -0.008350426 |\n",
      "|    n_updates          | 2452         |\n",
      "|    policyGradLoss     | -0.00833     |\n",
      "|    value_loss         | 0.00318      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 764           |\n",
      "|    iterations         | 15            |\n",
      "|    time_elapsed       | 160           |\n",
      "|    total_timesteps    | 5038080       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0034401696  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.702         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0617       |\n",
      "|    mean_step_reward   | -0.0077233315 |\n",
      "|    n_updates          | 2456          |\n",
      "|    policyGradLoss     | -0.00712      |\n",
      "|    value_loss         | 0.00314       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 762           |\n",
      "|    iterations         | 16            |\n",
      "|    time_elapsed       | 171           |\n",
      "|    total_timesteps    | 5046272       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0028691308  |\n",
      "|    entropy_loss       | -2.24         |\n",
      "|    explained_variance | 0.895         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0639       |\n",
      "|    mean_step_reward   | -0.0075505422 |\n",
      "|    n_updates          | 2460          |\n",
      "|    policyGradLoss     | -0.00542      |\n",
      "|    value_loss         | 0.00181       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 762          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 182          |\n",
      "|    total_timesteps    | 5054464      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0051228786 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.852        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0675      |\n",
      "|    mean_step_reward   | -0.007948597 |\n",
      "|    n_updates          | 2464         |\n",
      "|    policyGradLoss     | -0.00744     |\n",
      "|    value_loss         | 0.0078       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 759           |\n",
      "|    iterations         | 18            |\n",
      "|    time_elapsed       | 194           |\n",
      "|    total_timesteps    | 5062656       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0034112216  |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.897         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0691       |\n",
      "|    mean_step_reward   | -0.0063048564 |\n",
      "|    n_updates          | 2468          |\n",
      "|    policyGradLoss     | -0.0051       |\n",
      "|    value_loss         | 0.00824       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 762          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 204          |\n",
      "|    total_timesteps    | 5070848      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0045143403 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.945        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0632      |\n",
      "|    mean_step_reward   | -0.007643532 |\n",
      "|    n_updates          | 2472         |\n",
      "|    policyGradLoss     | -0.00686     |\n",
      "|    value_loss         | 0.00167      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 759          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 215          |\n",
      "|    total_timesteps    | 5079040      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0039018083 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.933        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0653      |\n",
      "|    mean_step_reward   | -0.008018899 |\n",
      "|    n_updates          | 2476         |\n",
      "|    policyGradLoss     | -0.00569     |\n",
      "|    value_loss         | 0.000927     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 227          |\n",
      "|    total_timesteps    | 5087232      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0049923165 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.935        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0643      |\n",
      "|    mean_step_reward   | -0.008190302 |\n",
      "|    n_updates          | 2480         |\n",
      "|    policyGradLoss     | -0.0048      |\n",
      "|    value_loss         | 0.00104      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 758           |\n",
      "|    iterations         | 22            |\n",
      "|    time_elapsed       | 237           |\n",
      "|    total_timesteps    | 5095424       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004544681   |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.798         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0713       |\n",
      "|    mean_step_reward   | -0.0074148127 |\n",
      "|    n_updates          | 2484          |\n",
      "|    policyGradLoss     | -0.00769      |\n",
      "|    value_loss         | 0.00736       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 249          |\n",
      "|    total_timesteps    | 5103616      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0050760405 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.825        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0598      |\n",
      "|    mean_step_reward   | -0.007467553 |\n",
      "|    n_updates          | 2488         |\n",
      "|    policyGradLoss     | -0.00675     |\n",
      "|    value_loss         | 0.00966      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 259          |\n",
      "|    total_timesteps    | 5111808      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0050621517 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.885        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0556      |\n",
      "|    mean_step_reward   | -0.00613874  |\n",
      "|    n_updates          | 2492         |\n",
      "|    policyGradLoss     | -0.00907     |\n",
      "|    value_loss         | 0.0127       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 271          |\n",
      "|    total_timesteps    | 5120000      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0042230524 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.89         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0696      |\n",
      "|    mean_step_reward   | -0.006474962 |\n",
      "|    n_updates          | 2496         |\n",
      "|    policyGradLoss     | -0.00853     |\n",
      "|    value_loss         | 0.00894      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 283          |\n",
      "|    total_timesteps    | 5128192      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004542205  |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.812        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0638      |\n",
      "|    mean_step_reward   | -0.007015015 |\n",
      "|    n_updates          | 2500         |\n",
      "|    policyGradLoss     | -0.00767     |\n",
      "|    value_loss         | 0.0118       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 292          |\n",
      "|    total_timesteps    | 5136384      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004249295  |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.924        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0612      |\n",
      "|    mean_step_reward   | -0.007639842 |\n",
      "|    n_updates          | 2504         |\n",
      "|    policyGradLoss     | -0.00521     |\n",
      "|    value_loss         | 0.00214      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 28            |\n",
      "|    time_elapsed       | 304           |\n",
      "|    total_timesteps    | 5144576       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0033210665  |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.943         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0701       |\n",
      "|    mean_step_reward   | -0.0077584814 |\n",
      "|    n_updates          | 2508          |\n",
      "|    policyGradLoss     | -0.00766      |\n",
      "|    value_loss         | 0.0017        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 315          |\n",
      "|    total_timesteps    | 5152768      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038168621 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.854        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0705      |\n",
      "|    mean_step_reward   | -0.007837029 |\n",
      "|    n_updates          | 2512         |\n",
      "|    policyGradLoss     | -0.00604     |\n",
      "|    value_loss         | 0.00136      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 30            |\n",
      "|    time_elapsed       | 326           |\n",
      "|    total_timesteps    | 5160960       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.00349853    |\n",
      "|    entropy_loss       | -2.19         |\n",
      "|    explained_variance | 0.851         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0747       |\n",
      "|    mean_step_reward   | -0.0082719475 |\n",
      "|    n_updates          | 2516          |\n",
      "|    policyGradLoss     | -0.00804      |\n",
      "|    value_loss         | 0.00542       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 31            |\n",
      "|    time_elapsed       | 338           |\n",
      "|    total_timesteps    | 5169152       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0044880537  |\n",
      "|    entropy_loss       | -2.19         |\n",
      "|    explained_variance | 0.898         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0676       |\n",
      "|    mean_step_reward   | -0.0064653265 |\n",
      "|    n_updates          | 2520          |\n",
      "|    policyGradLoss     | -0.00822      |\n",
      "|    value_loss         | 0.00762       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 347          |\n",
      "|    total_timesteps    | 5177344      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004360861  |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.673        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0662      |\n",
      "|    mean_step_reward   | -0.008048607 |\n",
      "|    n_updates          | 2524         |\n",
      "|    policyGradLoss     | -0.0107      |\n",
      "|    value_loss         | 0.00869      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 359          |\n",
      "|    total_timesteps    | 5185536      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0040434077 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.78         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.073       |\n",
      "|    mean_step_reward   | -0.007361507 |\n",
      "|    n_updates          | 2528         |\n",
      "|    policyGradLoss     | -0.00898     |\n",
      "|    value_loss         | 0.0102       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 34            |\n",
      "|    time_elapsed       | 371           |\n",
      "|    total_timesteps    | 5193728       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005062963   |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.888         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0567       |\n",
      "|    mean_step_reward   | -0.0071041463 |\n",
      "|    n_updates          | 2532          |\n",
      "|    policyGradLoss     | -0.00596      |\n",
      "|    value_loss         | 0.00324       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 381          |\n",
      "|    total_timesteps    | 5201920      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034497501 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.917        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0634      |\n",
      "|    mean_step_reward   | -0.007867315 |\n",
      "|    n_updates          | 2536         |\n",
      "|    policyGradLoss     | -0.00703     |\n",
      "|    value_loss         | 0.000821     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 36            |\n",
      "|    time_elapsed       | 392           |\n",
      "|    total_timesteps    | 5210112       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0035873763  |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.904         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.068        |\n",
      "|    mean_step_reward   | -0.0080875475 |\n",
      "|    n_updates          | 2540          |\n",
      "|    policyGradLoss     | -0.00704      |\n",
      "|    value_loss         | 0.00267       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 37            |\n",
      "|    time_elapsed       | 403           |\n",
      "|    total_timesteps    | 5218304       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0042464347  |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.856         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0608       |\n",
      "|    mean_step_reward   | -0.0066757184 |\n",
      "|    n_updates          | 2544          |\n",
      "|    policyGradLoss     | -0.00708      |\n",
      "|    value_loss         | 0.00943       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 414          |\n",
      "|    total_timesteps    | 5226496      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003605442  |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.88         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.065       |\n",
      "|    mean_step_reward   | -0.006992911 |\n",
      "|    n_updates          | 2548         |\n",
      "|    policyGradLoss     | -0.0067      |\n",
      "|    value_loss         | 0.0061       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 426          |\n",
      "|    total_timesteps    | 5234688      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0041229525 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.87         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0712      |\n",
      "|    mean_step_reward   | -0.008101192 |\n",
      "|    n_updates          | 2552         |\n",
      "|    policyGradLoss     | -0.00718     |\n",
      "|    value_loss         | 0.00235      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 436          |\n",
      "|    total_timesteps    | 5242880      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038207115 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.895        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0643      |\n",
      "|    mean_step_reward   | -0.00763309  |\n",
      "|    n_updates          | 2556         |\n",
      "|    policyGradLoss     | -0.00673     |\n",
      "|    value_loss         | 0.00296      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_15.zip\n",
      "[EVAL] Mean Return: -20.290, Best Return: -16.653\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_15_-20.29.mp4\n",
      "\n",
      "=== Round 17 | Learn 327680 steps (Total trained: 5242880) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1106    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 5251072 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 860           |\n",
      "|    iterations         | 2             |\n",
      "|    time_elapsed       | 19            |\n",
      "|    total_timesteps    | 5259264       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0037950207  |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.942         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0674       |\n",
      "|    mean_step_reward   | -0.0077464883 |\n",
      "|    n_updates          | 2564          |\n",
      "|    policyGradLoss     | -0.00531      |\n",
      "|    value_loss         | 0.00157       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 849          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 5267456      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0040119793 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.866        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0678      |\n",
      "|    mean_step_reward   | -0.006775773 |\n",
      "|    n_updates          | 2568         |\n",
      "|    policyGradLoss     | -0.00759     |\n",
      "|    value_loss         | 0.00749      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 807          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 40           |\n",
      "|    total_timesteps    | 5275648      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003587536  |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.907        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0674      |\n",
      "|    mean_step_reward   | -0.006895595 |\n",
      "|    n_updates          | 2572         |\n",
      "|    policyGradLoss     | -0.00657     |\n",
      "|    value_loss         | 0.00288      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 788          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 51           |\n",
      "|    total_timesteps    | 5283840      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0055209445 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.876        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0618      |\n",
      "|    mean_step_reward   | -0.00795507  |\n",
      "|    n_updates          | 2576         |\n",
      "|    policyGradLoss     | -0.0053      |\n",
      "|    value_loss         | 0.00171      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 792          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 62           |\n",
      "|    total_timesteps    | 5292032      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004046618  |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.946        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0653      |\n",
      "|    mean_step_reward   | -0.007217372 |\n",
      "|    n_updates          | 2580         |\n",
      "|    policyGradLoss     | -0.0052      |\n",
      "|    value_loss         | 0.00238      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 780          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 73           |\n",
      "|    total_timesteps    | 5300224      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004857625  |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.818        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0654      |\n",
      "|    mean_step_reward   | -0.007902932 |\n",
      "|    n_updates          | 2584         |\n",
      "|    policyGradLoss     | -0.00741     |\n",
      "|    value_loss         | 0.00216      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 777           |\n",
      "|    iterations         | 8             |\n",
      "|    time_elapsed       | 84            |\n",
      "|    total_timesteps    | 5308416       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004640159   |\n",
      "|    entropy_loss       | -2.19         |\n",
      "|    explained_variance | 0.896         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0625       |\n",
      "|    mean_step_reward   | -0.0076263235 |\n",
      "|    n_updates          | 2588          |\n",
      "|    policyGradLoss     | -0.00713      |\n",
      "|    value_loss         | 0.00277       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 773          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 95           |\n",
      "|    total_timesteps    | 5316608      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0045331726 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.848        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.065       |\n",
      "|    mean_step_reward   | -0.007714183 |\n",
      "|    n_updates          | 2592         |\n",
      "|    policyGradLoss     | -0.00723     |\n",
      "|    value_loss         | 0.00601      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 770          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 106          |\n",
      "|    total_timesteps    | 5324800      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0047330074 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.839        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0658      |\n",
      "|    mean_step_reward   | -0.006925632 |\n",
      "|    n_updates          | 2596         |\n",
      "|    policyGradLoss     | -0.00766     |\n",
      "|    value_loss         | 0.00768      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 768           |\n",
      "|    iterations         | 11            |\n",
      "|    time_elapsed       | 117           |\n",
      "|    total_timesteps    | 5332992       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0033272863  |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.866         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0686       |\n",
      "|    mean_step_reward   | -0.0073236534 |\n",
      "|    n_updates          | 2600          |\n",
      "|    policyGradLoss     | -0.00846      |\n",
      "|    value_loss         | 0.00432       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 761           |\n",
      "|    iterations         | 12            |\n",
      "|    time_elapsed       | 129           |\n",
      "|    total_timesteps    | 5341184       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004219809   |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.924         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0667       |\n",
      "|    mean_step_reward   | -0.0076857563 |\n",
      "|    n_updates          | 2604          |\n",
      "|    policyGradLoss     | -0.00606      |\n",
      "|    value_loss         | 0.00188       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 761          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 139          |\n",
      "|    total_timesteps    | 5349376      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027701347 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.821        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0624      |\n",
      "|    mean_step_reward   | -0.007676841 |\n",
      "|    n_updates          | 2608         |\n",
      "|    policyGradLoss     | -0.00518     |\n",
      "|    value_loss         | 0.00401      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 760           |\n",
      "|    iterations         | 14            |\n",
      "|    time_elapsed       | 150           |\n",
      "|    total_timesteps    | 5357568       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0035507127  |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.866         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0689       |\n",
      "|    mean_step_reward   | -0.0073054475 |\n",
      "|    n_updates          | 2612          |\n",
      "|    policyGradLoss     | -0.00783      |\n",
      "|    value_loss         | 0.00578       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 757           |\n",
      "|    iterations         | 15            |\n",
      "|    time_elapsed       | 162           |\n",
      "|    total_timesteps    | 5365760       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0033046696  |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.868         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0656       |\n",
      "|    mean_step_reward   | -0.0073397486 |\n",
      "|    n_updates          | 2616          |\n",
      "|    policyGradLoss     | -0.00752      |\n",
      "|    value_loss         | 0.00603       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 761          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 172          |\n",
      "|    total_timesteps    | 5373952      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0040154965 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.882        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0675      |\n",
      "|    mean_step_reward   | -0.007334554 |\n",
      "|    n_updates          | 2620         |\n",
      "|    policyGradLoss     | -0.00514     |\n",
      "|    value_loss         | 0.00521      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 757           |\n",
      "|    iterations         | 17            |\n",
      "|    time_elapsed       | 183           |\n",
      "|    total_timesteps    | 5382144       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0046642898  |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.883         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0672       |\n",
      "|    mean_step_reward   | -0.0069335653 |\n",
      "|    n_updates          | 2624          |\n",
      "|    policyGradLoss     | -0.00717      |\n",
      "|    value_loss         | 0.00586       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 195          |\n",
      "|    total_timesteps    | 5390336      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003934919  |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.882        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0686      |\n",
      "|    mean_step_reward   | -0.007777132 |\n",
      "|    n_updates          | 2628         |\n",
      "|    policyGradLoss     | -0.00818     |\n",
      "|    value_loss         | 0.00365      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 205          |\n",
      "|    total_timesteps    | 5398528      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025022442 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.85         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0621      |\n",
      "|    mean_step_reward   | -0.007564434 |\n",
      "|    n_updates          | 2632         |\n",
      "|    policyGradLoss     | -0.00493     |\n",
      "|    value_loss         | 0.00223      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 20            |\n",
      "|    time_elapsed       | 217           |\n",
      "|    total_timesteps    | 5406720       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0027461322  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.915         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0641       |\n",
      "|    mean_step_reward   | -0.0076829176 |\n",
      "|    n_updates          | 2636          |\n",
      "|    policyGradLoss     | -0.00517      |\n",
      "|    value_loss         | 0.00297       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 227          |\n",
      "|    total_timesteps    | 5414912      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0042561837 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.944        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0591      |\n",
      "|    mean_step_reward   | -0.006644681 |\n",
      "|    n_updates          | 2640         |\n",
      "|    policyGradLoss     | -0.00612     |\n",
      "|    value_loss         | 0.00376      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 239          |\n",
      "|    total_timesteps    | 5423104      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0050670807 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.84         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0639      |\n",
      "|    mean_step_reward   | -0.007825635 |\n",
      "|    n_updates          | 2644         |\n",
      "|    policyGradLoss     | -0.00747     |\n",
      "|    value_loss         | 0.00694      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 23            |\n",
      "|    time_elapsed       | 250           |\n",
      "|    total_timesteps    | 5431296       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.00500444    |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.937         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.067        |\n",
      "|    mean_step_reward   | -0.0069274316 |\n",
      "|    n_updates          | 2648          |\n",
      "|    policyGradLoss     | -0.00739      |\n",
      "|    value_loss         | 0.00316       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 260          |\n",
      "|    total_timesteps    | 5439488      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035563824 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.908        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0676      |\n",
      "|    mean_step_reward   | -0.007702858 |\n",
      "|    n_updates          | 2652         |\n",
      "|    policyGradLoss     | -0.00592     |\n",
      "|    value_loss         | 0.0023       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 25            |\n",
      "|    time_elapsed       | 272           |\n",
      "|    total_timesteps    | 5447680       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0031366178  |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.845         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0622       |\n",
      "|    mean_step_reward   | -0.0076049604 |\n",
      "|    n_updates          | 2656          |\n",
      "|    policyGradLoss     | -0.00396      |\n",
      "|    value_loss         | 0.0037        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 283          |\n",
      "|    total_timesteps    | 5455872      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003864452  |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.907        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.069       |\n",
      "|    mean_step_reward   | -0.007763547 |\n",
      "|    n_updates          | 2660         |\n",
      "|    policyGradLoss     | -0.00768     |\n",
      "|    value_loss         | 0.00191      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 27            |\n",
      "|    time_elapsed       | 294           |\n",
      "|    total_timesteps    | 5464064       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0031583328  |\n",
      "|    entropy_loss       | -2.19         |\n",
      "|    explained_variance | 0.932         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0665       |\n",
      "|    mean_step_reward   | -0.0069997283 |\n",
      "|    n_updates          | 2664          |\n",
      "|    policyGradLoss     | -0.00585      |\n",
      "|    value_loss         | 0.00535       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 306          |\n",
      "|    total_timesteps    | 5472256      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004276272  |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.897        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0692      |\n",
      "|    mean_step_reward   | -0.007942839 |\n",
      "|    n_updates          | 2668         |\n",
      "|    policyGradLoss     | -0.00936     |\n",
      "|    value_loss         | 0.00348      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 316          |\n",
      "|    total_timesteps    | 5480448      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035082712 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.9          |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0644      |\n",
      "|    mean_step_reward   | -0.006878251 |\n",
      "|    n_updates          | 2672         |\n",
      "|    policyGradLoss     | -0.00785     |\n",
      "|    value_loss         | 0.00543      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 327          |\n",
      "|    total_timesteps    | 5488640      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00297355   |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.892        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0632      |\n",
      "|    mean_step_reward   | -0.007495389 |\n",
      "|    n_updates          | 2676         |\n",
      "|    policyGradLoss     | -0.00584     |\n",
      "|    value_loss         | 0.00264      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 339          |\n",
      "|    total_timesteps    | 5496832      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038022993 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.787        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0648      |\n",
      "|    mean_step_reward   | -0.007612422 |\n",
      "|    n_updates          | 2680         |\n",
      "|    policyGradLoss     | -0.00668     |\n",
      "|    value_loss         | 0.00536      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 349          |\n",
      "|    total_timesteps    | 5505024      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004499674  |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.686        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0603      |\n",
      "|    mean_step_reward   | -0.008291969 |\n",
      "|    n_updates          | 2684         |\n",
      "|    policyGradLoss     | -0.00674     |\n",
      "|    value_loss         | 0.000702     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 360          |\n",
      "|    total_timesteps    | 5513216      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004543909  |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.627        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0652      |\n",
      "|    mean_step_reward   | -0.007567684 |\n",
      "|    n_updates          | 2688         |\n",
      "|    policyGradLoss     | -0.00793     |\n",
      "|    value_loss         | 0.0118       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 371          |\n",
      "|    total_timesteps    | 5521408      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004779708  |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.634        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0681      |\n",
      "|    mean_step_reward   | -0.007434682 |\n",
      "|    n_updates          | 2692         |\n",
      "|    policyGradLoss     | -0.00867     |\n",
      "|    value_loss         | 0.0143       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 35            |\n",
      "|    time_elapsed       | 382           |\n",
      "|    total_timesteps    | 5529600       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004192245   |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.689         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0628       |\n",
      "|    mean_step_reward   | -0.0070643527 |\n",
      "|    n_updates          | 2696          |\n",
      "|    policyGradLoss     | -0.00795      |\n",
      "|    value_loss         | 0.015         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 36            |\n",
      "|    time_elapsed       | 393           |\n",
      "|    total_timesteps    | 5537792       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0033846893  |\n",
      "|    entropy_loss       | -2.19         |\n",
      "|    explained_variance | 0.77          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0633       |\n",
      "|    mean_step_reward   | -0.0065212715 |\n",
      "|    n_updates          | 2700          |\n",
      "|    policyGradLoss     | -0.00896      |\n",
      "|    value_loss         | 0.00933       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 403          |\n",
      "|    total_timesteps    | 5545984      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003313011  |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.639        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0651      |\n",
      "|    mean_step_reward   | -0.007783188 |\n",
      "|    n_updates          | 2704         |\n",
      "|    policyGradLoss     | -0.00707     |\n",
      "|    value_loss         | 0.00791      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 415          |\n",
      "|    total_timesteps    | 5554176      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0036508788 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.803        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0684      |\n",
      "|    mean_step_reward   | -0.007664192 |\n",
      "|    n_updates          | 2708         |\n",
      "|    policyGradLoss     | -0.0053      |\n",
      "|    value_loss         | 0.00274      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 427          |\n",
      "|    total_timesteps    | 5562368      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0043283943 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.807        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0688      |\n",
      "|    mean_step_reward   | -0.007683869 |\n",
      "|    n_updates          | 2712         |\n",
      "|    policyGradLoss     | -0.0099      |\n",
      "|    value_loss         | 0.0116       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 40            |\n",
      "|    time_elapsed       | 437           |\n",
      "|    total_timesteps    | 5570560       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0036135637  |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.842         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0645       |\n",
      "|    mean_step_reward   | -0.0064079943 |\n",
      "|    n_updates          | 2716          |\n",
      "|    policyGradLoss     | -0.00795      |\n",
      "|    value_loss         | 0.0114        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_16.zip\n",
      "[EVAL] Mean Return: -61.995, Best Return: -58.279\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_16_-62.00.mp4\n",
      "\n",
      "=== Round 18 | Learn 327680 steps (Total trained: 5570560) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 970     |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 8       |\n",
      "|    total_timesteps | 5578752 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 902           |\n",
      "|    iterations         | 2             |\n",
      "|    time_elapsed       | 18            |\n",
      "|    total_timesteps    | 5586944       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003356682   |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.872         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0667       |\n",
      "|    mean_step_reward   | -0.0074014454 |\n",
      "|    n_updates          | 2724          |\n",
      "|    policyGradLoss     | -0.00627      |\n",
      "|    value_loss         | 0.00584       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 828           |\n",
      "|    iterations         | 3             |\n",
      "|    time_elapsed       | 29            |\n",
      "|    total_timesteps    | 5595136       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0041704876  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.897         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0658       |\n",
      "|    mean_step_reward   | -0.0083183125 |\n",
      "|    n_updates          | 2728          |\n",
      "|    policyGradLoss     | -0.00699      |\n",
      "|    value_loss         | 0.000244      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 804          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 40           |\n",
      "|    total_timesteps    | 5603328      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004411561  |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.958        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.08        |\n",
      "|    mean_step_reward   | -0.007889206 |\n",
      "|    n_updates          | 2732         |\n",
      "|    policyGradLoss     | -0.00998     |\n",
      "|    value_loss         | 0.000297     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 791          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 51           |\n",
      "|    total_timesteps    | 5611520      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0048037907 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.859        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0628      |\n",
      "|    mean_step_reward   | -0.00666563  |\n",
      "|    n_updates          | 2736         |\n",
      "|    policyGradLoss     | -0.00874     |\n",
      "|    value_loss         | 0.0121       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 777          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 63           |\n",
      "|    total_timesteps    | 5619712      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004319642  |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.894        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0681      |\n",
      "|    mean_step_reward   | -0.007219242 |\n",
      "|    n_updates          | 2740         |\n",
      "|    policyGradLoss     | -0.00593     |\n",
      "|    value_loss         | 0.00332      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 782          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 73           |\n",
      "|    total_timesteps    | 5627904      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004813443  |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.794        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0638      |\n",
      "|    mean_step_reward   | -0.007563142 |\n",
      "|    n_updates          | 2744         |\n",
      "|    policyGradLoss     | -0.00658     |\n",
      "|    value_loss         | 0.00889      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 770          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 85           |\n",
      "|    total_timesteps    | 5636096      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0045485757 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.838        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.07        |\n",
      "|    mean_step_reward   | -0.007351866 |\n",
      "|    n_updates          | 2748         |\n",
      "|    policyGradLoss     | -0.00892     |\n",
      "|    value_loss         | 0.00532      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 764          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 96           |\n",
      "|    total_timesteps    | 5644288      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0036111246 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.942        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0616      |\n",
      "|    mean_step_reward   | -0.008014167 |\n",
      "|    n_updates          | 2752         |\n",
      "|    policyGradLoss     | -0.00546     |\n",
      "|    value_loss         | 0.000568     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 769          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 106          |\n",
      "|    total_timesteps    | 5652480      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004208453  |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.919        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0652      |\n",
      "|    mean_step_reward   | -0.007834643 |\n",
      "|    n_updates          | 2756         |\n",
      "|    policyGradLoss     | -0.00716     |\n",
      "|    value_loss         | 0.000683     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 763          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 118          |\n",
      "|    total_timesteps    | 5660672      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005376474  |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.927        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0659      |\n",
      "|    mean_step_reward   | -0.006127687 |\n",
      "|    n_updates          | 2760         |\n",
      "|    policyGradLoss     | -0.00683     |\n",
      "|    value_loss         | 0.00642      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 764          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 128          |\n",
      "|    total_timesteps    | 5668864      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0047898893 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.959        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0622      |\n",
      "|    mean_step_reward   | -0.007603621 |\n",
      "|    n_updates          | 2764         |\n",
      "|    policyGradLoss     | -0.00541     |\n",
      "|    value_loss         | 0.00107      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 139         |\n",
      "|    total_timesteps    | 5677056     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003875264 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.06       |\n",
      "|    mean_step_reward   | -0.00731441 |\n",
      "|    n_updates          | 2768        |\n",
      "|    policyGradLoss     | -0.00651    |\n",
      "|    value_loss         | 0.00306     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 756           |\n",
      "|    iterations         | 14            |\n",
      "|    time_elapsed       | 151           |\n",
      "|    total_timesteps    | 5685248       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0037895949  |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.898         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0631       |\n",
      "|    mean_step_reward   | -0.0073121227 |\n",
      "|    n_updates          | 2772          |\n",
      "|    policyGradLoss     | -0.00614      |\n",
      "|    value_loss         | 0.00279       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 761          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 161          |\n",
      "|    total_timesteps    | 5693440      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004479085  |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.572        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.071       |\n",
      "|    mean_step_reward   | -0.008207004 |\n",
      "|    n_updates          | 2776         |\n",
      "|    policyGradLoss     | -0.0103      |\n",
      "|    value_loss         | 6.49e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 757          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 172          |\n",
      "|    total_timesteps    | 5701632      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0055361176 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.907        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0613      |\n",
      "|    mean_step_reward   | -0.007870054 |\n",
      "|    n_updates          | 2780         |\n",
      "|    policyGradLoss     | -0.00351     |\n",
      "|    value_loss         | 0.00133      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 184          |\n",
      "|    total_timesteps    | 5709824      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0048899716 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.887        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0691      |\n",
      "|    mean_step_reward   | -0.008079434 |\n",
      "|    n_updates          | 2784         |\n",
      "|    policyGradLoss     | -0.00925     |\n",
      "|    value_loss         | 0.00443      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 195          |\n",
      "|    total_timesteps    | 5718016      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0077615012 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.761        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0539      |\n",
      "|    mean_step_reward   | -0.006508163 |\n",
      "|    n_updates          | 2788         |\n",
      "|    policyGradLoss     | -0.00763     |\n",
      "|    value_loss         | 0.0165       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 206          |\n",
      "|    total_timesteps    | 5726208      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0049299207 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.902        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0648      |\n",
      "|    mean_step_reward   | -0.00667026  |\n",
      "|    n_updates          | 2792         |\n",
      "|    policyGradLoss     | -0.00582     |\n",
      "|    value_loss         | 0.0036       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 756           |\n",
      "|    iterations         | 20            |\n",
      "|    time_elapsed       | 216           |\n",
      "|    total_timesteps    | 5734400       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0051196925  |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.861         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.066        |\n",
      "|    mean_step_reward   | -0.0068814987 |\n",
      "|    n_updates          | 2796          |\n",
      "|    policyGradLoss     | -0.00709      |\n",
      "|    value_loss         | 0.00968       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 228          |\n",
      "|    total_timesteps    | 5742592      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004171963  |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.805        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0659      |\n",
      "|    mean_step_reward   | -0.007829012 |\n",
      "|    n_updates          | 2800         |\n",
      "|    policyGradLoss     | -0.00351     |\n",
      "|    value_loss         | 0.00263      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 239          |\n",
      "|    total_timesteps    | 5750784      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0051321937 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.811        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0699      |\n",
      "|    mean_step_reward   | -0.007859098 |\n",
      "|    n_updates          | 2804         |\n",
      "|    policyGradLoss     | -0.00688     |\n",
      "|    value_loss         | 0.00275      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 250          |\n",
      "|    total_timesteps    | 5758976      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0049189897 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.871        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0668      |\n",
      "|    mean_step_reward   | -0.007762595 |\n",
      "|    n_updates          | 2808         |\n",
      "|    policyGradLoss     | -0.00666     |\n",
      "|    value_loss         | 0.00537      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 261          |\n",
      "|    total_timesteps    | 5767168      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00582311   |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.881        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0712      |\n",
      "|    mean_step_reward   | -0.006468619 |\n",
      "|    n_updates          | 2812         |\n",
      "|    policyGradLoss     | -0.00723     |\n",
      "|    value_loss         | 0.0103       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 25            |\n",
      "|    time_elapsed       | 271           |\n",
      "|    total_timesteps    | 5775360       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0038735834  |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.845         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0681       |\n",
      "|    mean_step_reward   | -0.0069836513 |\n",
      "|    n_updates          | 2816          |\n",
      "|    policyGradLoss     | -0.00466      |\n",
      "|    value_loss         | 0.00296       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 283          |\n",
      "|    total_timesteps    | 5783552      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005009737  |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.876        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0658      |\n",
      "|    mean_step_reward   | -0.008028797 |\n",
      "|    n_updates          | 2820         |\n",
      "|    policyGradLoss     | -0.0066      |\n",
      "|    value_loss         | 0.00408      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 27            |\n",
      "|    time_elapsed       | 294           |\n",
      "|    total_timesteps    | 5791744       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0053036893  |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.825         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0657       |\n",
      "|    mean_step_reward   | -0.0072012483 |\n",
      "|    n_updates          | 2824          |\n",
      "|    policyGradLoss     | -0.00735      |\n",
      "|    value_loss         | 0.0078        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 28            |\n",
      "|    time_elapsed       | 305           |\n",
      "|    total_timesteps    | 5799936       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.00525121    |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.911         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0643       |\n",
      "|    mean_step_reward   | -0.0073744846 |\n",
      "|    n_updates          | 2828          |\n",
      "|    policyGradLoss     | -0.00782      |\n",
      "|    value_loss         | 0.00314       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 316          |\n",
      "|    total_timesteps    | 5808128      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0044172728 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.833        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0714      |\n",
      "|    mean_step_reward   | -0.008215205 |\n",
      "|    n_updates          | 2832         |\n",
      "|    policyGradLoss     | -0.0076      |\n",
      "|    value_loss         | 0.00382      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 327          |\n",
      "|    total_timesteps    | 5816320      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.006971102  |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.87         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0653      |\n",
      "|    mean_step_reward   | -0.005842575 |\n",
      "|    n_updates          | 2836         |\n",
      "|    policyGradLoss     | -0.00686     |\n",
      "|    value_loss         | 0.0114       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 338          |\n",
      "|    total_timesteps    | 5824512      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004477065  |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.887        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0685      |\n",
      "|    mean_step_reward   | -0.007224465 |\n",
      "|    n_updates          | 2840         |\n",
      "|    policyGradLoss     | -0.00766     |\n",
      "|    value_loss         | 0.00701      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 32            |\n",
      "|    time_elapsed       | 350           |\n",
      "|    total_timesteps    | 5832704       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005968413   |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.853         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0664       |\n",
      "|    mean_step_reward   | -0.0074221664 |\n",
      "|    n_updates          | 2844          |\n",
      "|    policyGradLoss     | -0.00764      |\n",
      "|    value_loss         | 0.00412       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 360          |\n",
      "|    total_timesteps    | 5840896      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003723396  |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.843        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.064       |\n",
      "|    mean_step_reward   | -0.007541935 |\n",
      "|    n_updates          | 2848         |\n",
      "|    policyGradLoss     | -0.00641     |\n",
      "|    value_loss         | 0.00555      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 371          |\n",
      "|    total_timesteps    | 5849088      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0048429864 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.891        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0635      |\n",
      "|    mean_step_reward   | -0.007591354 |\n",
      "|    n_updates          | 2852         |\n",
      "|    policyGradLoss     | -0.00583     |\n",
      "|    value_loss         | 0.00263      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 383          |\n",
      "|    total_timesteps    | 5857280      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034305833 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.795        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0635      |\n",
      "|    mean_step_reward   | -0.008214414 |\n",
      "|    n_updates          | 2856         |\n",
      "|    policyGradLoss     | -0.0077      |\n",
      "|    value_loss         | 0.00349      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 36            |\n",
      "|    time_elapsed       | 393           |\n",
      "|    total_timesteps    | 5865472       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004042782   |\n",
      "|    entropy_loss       | -2.19         |\n",
      "|    explained_variance | 0.906         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.067        |\n",
      "|    mean_step_reward   | -0.0062560323 |\n",
      "|    n_updates          | 2860          |\n",
      "|    policyGradLoss     | -0.00856      |\n",
      "|    value_loss         | 0.00556       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 37            |\n",
      "|    time_elapsed       | 405           |\n",
      "|    total_timesteps    | 5873664       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004506115   |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.934         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0624       |\n",
      "|    mean_step_reward   | -0.0071474016 |\n",
      "|    n_updates          | 2864          |\n",
      "|    policyGradLoss     | -0.0072       |\n",
      "|    value_loss         | 0.00266       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 415          |\n",
      "|    total_timesteps    | 5881856      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0040455167 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.941        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0656      |\n",
      "|    mean_step_reward   | -0.007559428 |\n",
      "|    n_updates          | 2868         |\n",
      "|    policyGradLoss     | -0.00476     |\n",
      "|    value_loss         | 0.00274      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 747           |\n",
      "|    iterations         | 39            |\n",
      "|    time_elapsed       | 427           |\n",
      "|    total_timesteps    | 5890048       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005492021   |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.974         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0688       |\n",
      "|    mean_step_reward   | -0.0071945353 |\n",
      "|    n_updates          | 2872          |\n",
      "|    policyGradLoss     | -0.00608      |\n",
      "|    value_loss         | 0.000995      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 746          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 438          |\n",
      "|    total_timesteps    | 5898240      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003831313  |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.978        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0622      |\n",
      "|    mean_step_reward   | -0.007310202 |\n",
      "|    n_updates          | 2876         |\n",
      "|    policyGradLoss     | -0.00756     |\n",
      "|    value_loss         | 0.00119      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_17.zip\n",
      "[EVAL] Mean Return: -19.909, Best Return: -16.286\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_17_-19.91.mp4\n",
      "\n",
      "=== Round 19 | Learn 327680 steps (Total trained: 5898240) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1000    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 8       |\n",
      "|    total_timesteps | 5906432 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 830          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 5914624      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005558746  |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.897        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0668      |\n",
      "|    mean_step_reward   | -0.005752301 |\n",
      "|    n_updates          | 2884         |\n",
      "|    policyGradLoss     | -0.00819     |\n",
      "|    value_loss         | 0.0102       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 832           |\n",
      "|    iterations         | 3             |\n",
      "|    time_elapsed       | 29            |\n",
      "|    total_timesteps    | 5922816       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003561355   |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.96          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0651       |\n",
      "|    mean_step_reward   | -0.0075520547 |\n",
      "|    n_updates          | 2888          |\n",
      "|    policyGradLoss     | -0.00619      |\n",
      "|    value_loss         | 0.000825      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 5931008     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004239446 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.065      |\n",
      "|    mean_step_reward   | -0.00812077 |\n",
      "|    n_updates          | 2892        |\n",
      "|    policyGradLoss     | -0.00633    |\n",
      "|    value_loss         | 0.000883    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 788           |\n",
      "|    iterations         | 5             |\n",
      "|    time_elapsed       | 51            |\n",
      "|    total_timesteps    | 5939200       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0044876556  |\n",
      "|    entropy_loss       | -2.19         |\n",
      "|    explained_variance | 0.921         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0656       |\n",
      "|    mean_step_reward   | -0.0067306813 |\n",
      "|    n_updates          | 2896          |\n",
      "|    policyGradLoss     | -0.00716      |\n",
      "|    value_loss         | 0.00423       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 779           |\n",
      "|    iterations         | 6             |\n",
      "|    time_elapsed       | 63            |\n",
      "|    total_timesteps    | 5947392       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0051372293  |\n",
      "|    entropy_loss       | -2.19         |\n",
      "|    explained_variance | 0.974         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0649       |\n",
      "|    mean_step_reward   | -0.0075305444 |\n",
      "|    n_updates          | 2900          |\n",
      "|    policyGradLoss     | -0.00641      |\n",
      "|    value_loss         | 0.000577      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 768           |\n",
      "|    iterations         | 7             |\n",
      "|    time_elapsed       | 74            |\n",
      "|    total_timesteps    | 5955584       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0037731985  |\n",
      "|    entropy_loss       | -2.17         |\n",
      "|    explained_variance | 0.963         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0674       |\n",
      "|    mean_step_reward   | -0.0079917535 |\n",
      "|    n_updates          | 2904          |\n",
      "|    policyGradLoss     | -0.00609      |\n",
      "|    value_loss         | 0.000547      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 774          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 84           |\n",
      "|    total_timesteps    | 5963776      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0059478357 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.923        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0642      |\n",
      "|    mean_step_reward   | -0.006423764 |\n",
      "|    n_updates          | 2908         |\n",
      "|    policyGradLoss     | -0.00584     |\n",
      "|    value_loss         | 0.00627      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 766          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 96           |\n",
      "|    total_timesteps    | 5971968      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004189873  |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.969        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0687      |\n",
      "|    mean_step_reward   | -0.007601782 |\n",
      "|    n_updates          | 2912         |\n",
      "|    policyGradLoss     | -0.00621     |\n",
      "|    value_loss         | 0.000679     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 760          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 107          |\n",
      "|    total_timesteps    | 5980160      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0044986564 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.959        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0626      |\n",
      "|    mean_step_reward   | -0.007860111 |\n",
      "|    n_updates          | 2916         |\n",
      "|    policyGradLoss     | -0.00644     |\n",
      "|    value_loss         | 0.000651     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 763           |\n",
      "|    iterations         | 11            |\n",
      "|    time_elapsed       | 117           |\n",
      "|    total_timesteps    | 5988352       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0086786095  |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.826         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.064        |\n",
      "|    mean_step_reward   | -0.0070678764 |\n",
      "|    n_updates          | 2920          |\n",
      "|    policyGradLoss     | -0.00626      |\n",
      "|    value_loss         | 0.00689       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 757          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 129          |\n",
      "|    total_timesteps    | 5996544      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0063977027 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.852        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0665      |\n",
      "|    mean_step_reward   | -0.008044989 |\n",
      "|    n_updates          | 2924         |\n",
      "|    policyGradLoss     | -0.00634     |\n",
      "|    value_loss         | 0.0032       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 759          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 140          |\n",
      "|    total_timesteps    | 6004736      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004671597  |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.973        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0655      |\n",
      "|    mean_step_reward   | -0.007848343 |\n",
      "|    n_updates          | 2928         |\n",
      "|    policyGradLoss     | -0.00625     |\n",
      "|    value_loss         | 0.000186     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 757           |\n",
      "|    iterations         | 14            |\n",
      "|    time_elapsed       | 151           |\n",
      "|    total_timesteps    | 6012928       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0075311735  |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.897         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0612       |\n",
      "|    mean_step_reward   | -0.0064213583 |\n",
      "|    n_updates          | 2932          |\n",
      "|    policyGradLoss     | -0.00723      |\n",
      "|    value_loss         | 0.00764       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 15            |\n",
      "|    time_elapsed       | 163           |\n",
      "|    total_timesteps    | 6021120       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0051808828  |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.915         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0657       |\n",
      "|    mean_step_reward   | -0.0075579435 |\n",
      "|    n_updates          | 2936          |\n",
      "|    policyGradLoss     | -0.00584      |\n",
      "|    value_loss         | 0.0023        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 757          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 172          |\n",
      "|    total_timesteps    | 6029312      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038281796 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.922        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0636      |\n",
      "|    mean_step_reward   | -0.007517381 |\n",
      "|    n_updates          | 2940         |\n",
      "|    policyGradLoss     | -0.00438     |\n",
      "|    value_loss         | 0.00107      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 754           |\n",
      "|    iterations         | 17            |\n",
      "|    time_elapsed       | 184           |\n",
      "|    total_timesteps    | 6037504       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0057836594  |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.832         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.064        |\n",
      "|    mean_step_reward   | -0.0075386213 |\n",
      "|    n_updates          | 2944          |\n",
      "|    policyGradLoss     | -0.00703      |\n",
      "|    value_loss         | 0.00659       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 195          |\n",
      "|    total_timesteps    | 6045696      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0058385627 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.865        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0698      |\n",
      "|    mean_step_reward   | -0.006843714 |\n",
      "|    n_updates          | 2948         |\n",
      "|    policyGradLoss     | -0.0073      |\n",
      "|    value_loss         | 0.00547      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 19            |\n",
      "|    time_elapsed       | 206           |\n",
      "|    total_timesteps    | 6053888       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003882716   |\n",
      "|    entropy_loss       | -2.17         |\n",
      "|    explained_variance | 0.929         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.066        |\n",
      "|    mean_step_reward   | -0.0077900514 |\n",
      "|    n_updates          | 2952          |\n",
      "|    policyGradLoss     | -0.00452      |\n",
      "|    value_loss         | 0.000788      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 20            |\n",
      "|    time_elapsed       | 218           |\n",
      "|    total_timesteps    | 6062080       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0062490366  |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.759         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0654       |\n",
      "|    mean_step_reward   | -0.0077760145 |\n",
      "|    n_updates          | 2956          |\n",
      "|    policyGradLoss     | -0.00905      |\n",
      "|    value_loss         | 0.0107        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 21            |\n",
      "|    time_elapsed       | 228           |\n",
      "|    total_timesteps    | 6070272       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0051414235  |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.922         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0655       |\n",
      "|    mean_step_reward   | -0.0064886804 |\n",
      "|    n_updates          | 2960          |\n",
      "|    policyGradLoss     | -0.00835      |\n",
      "|    value_loss         | 0.00363       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 22            |\n",
      "|    time_elapsed       | 239           |\n",
      "|    total_timesteps    | 6078464       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004194743   |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.908         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0648       |\n",
      "|    mean_step_reward   | -0.0074667637 |\n",
      "|    n_updates          | 2964          |\n",
      "|    policyGradLoss     | -0.00429      |\n",
      "|    value_loss         | 0.00193       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 251          |\n",
      "|    total_timesteps    | 6086656      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004544122  |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.864        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0636      |\n",
      "|    mean_step_reward   | -0.008062975 |\n",
      "|    n_updates          | 2968         |\n",
      "|    policyGradLoss     | -0.00631     |\n",
      "|    value_loss         | 0.00323      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 24            |\n",
      "|    time_elapsed       | 261           |\n",
      "|    total_timesteps    | 6094848       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0040528923  |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.854         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0612       |\n",
      "|    mean_step_reward   | -0.0068903985 |\n",
      "|    n_updates          | 2972          |\n",
      "|    policyGradLoss     | -0.00688      |\n",
      "|    value_loss         | 0.00814       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 273          |\n",
      "|    total_timesteps    | 6103040      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0037420408 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.946        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0622      |\n",
      "|    mean_step_reward   | -0.007683001 |\n",
      "|    n_updates          | 2976         |\n",
      "|    policyGradLoss     | -0.00549     |\n",
      "|    value_loss         | 0.000541     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 26            |\n",
      "|    time_elapsed       | 283           |\n",
      "|    total_timesteps    | 6111232       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0039794655  |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.889         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0654       |\n",
      "|    mean_step_reward   | -0.0075186705 |\n",
      "|    n_updates          | 2980          |\n",
      "|    policyGradLoss     | -0.0072       |\n",
      "|    value_loss         | 0.00482       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 27            |\n",
      "|    time_elapsed       | 295           |\n",
      "|    total_timesteps    | 6119424       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0036013732  |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.956         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0704       |\n",
      "|    mean_step_reward   | -0.0065181823 |\n",
      "|    n_updates          | 2984          |\n",
      "|    policyGradLoss     | -0.00587      |\n",
      "|    value_loss         | 0.00237       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 28            |\n",
      "|    time_elapsed       | 306           |\n",
      "|    total_timesteps    | 6127616       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004048913   |\n",
      "|    entropy_loss       | -2.19         |\n",
      "|    explained_variance | 0.949         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0665       |\n",
      "|    mean_step_reward   | -0.0076822317 |\n",
      "|    n_updates          | 2988          |\n",
      "|    policyGradLoss     | -0.00608      |\n",
      "|    value_loss         | 0.00179       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 6135808     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003400615 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.766       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0695     |\n",
      "|    mean_step_reward   | -0.00815284 |\n",
      "|    n_updates          | 2992        |\n",
      "|    policyGradLoss     | -0.00676    |\n",
      "|    value_loss         | 0.00356     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 30            |\n",
      "|    time_elapsed       | 328           |\n",
      "|    total_timesteps    | 6144000       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0043679755  |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.816         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0615       |\n",
      "|    mean_step_reward   | -0.0069239857 |\n",
      "|    n_updates          | 2996          |\n",
      "|    policyGradLoss     | -0.00653      |\n",
      "|    value_loss         | 0.011         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 339          |\n",
      "|    total_timesteps    | 6152192      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0031346357 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.924        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.066       |\n",
      "|    mean_step_reward   | -0.007563595 |\n",
      "|    n_updates          | 3000         |\n",
      "|    policyGradLoss     | -0.00592     |\n",
      "|    value_loss         | 0.00155      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 350          |\n",
      "|    total_timesteps    | 6160384      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0053793676 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.818        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0715      |\n",
      "|    mean_step_reward   | -0.007611761 |\n",
      "|    n_updates          | 3004         |\n",
      "|    policyGradLoss     | -0.00904     |\n",
      "|    value_loss         | 0.00665      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 747           |\n",
      "|    iterations         | 33            |\n",
      "|    time_elapsed       | 361           |\n",
      "|    total_timesteps    | 6168576       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0042549665  |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.886         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0675       |\n",
      "|    mean_step_reward   | -0.0064203553 |\n",
      "|    n_updates          | 3008          |\n",
      "|    policyGradLoss     | -0.00889      |\n",
      "|    value_loss         | 0.00759       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 34            |\n",
      "|    time_elapsed       | 372           |\n",
      "|    total_timesteps    | 6176768       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004937784   |\n",
      "|    entropy_loss       | -2.19         |\n",
      "|    explained_variance | 0.871         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0681       |\n",
      "|    mean_step_reward   | -0.0075166454 |\n",
      "|    n_updates          | 3012          |\n",
      "|    policyGradLoss     | -0.00783      |\n",
      "|    value_loss         | 0.00774       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 747           |\n",
      "|    iterations         | 35            |\n",
      "|    time_elapsed       | 383           |\n",
      "|    total_timesteps    | 6184960       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0028253144  |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.922         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0651       |\n",
      "|    mean_step_reward   | -0.0070777377 |\n",
      "|    n_updates          | 3016          |\n",
      "|    policyGradLoss     | -0.00483      |\n",
      "|    value_loss         | 0.00108       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 746          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 394          |\n",
      "|    total_timesteps    | 6193152      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0043953815 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.812        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0649      |\n",
      "|    mean_step_reward   | -0.007177402 |\n",
      "|    n_updates          | 3020         |\n",
      "|    policyGradLoss     | -0.00642     |\n",
      "|    value_loss         | 0.0108       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 404          |\n",
      "|    total_timesteps    | 6201344      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025331378 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.89         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0691      |\n",
      "|    mean_step_reward   | -0.007453512 |\n",
      "|    n_updates          | 3024         |\n",
      "|    policyGradLoss     | -0.00593     |\n",
      "|    value_loss         | 0.0024       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 38            |\n",
      "|    time_elapsed       | 416           |\n",
      "|    total_timesteps    | 6209536       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0037378413  |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.904         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0745       |\n",
      "|    mean_step_reward   | -0.0076505374 |\n",
      "|    n_updates          | 3028          |\n",
      "|    policyGradLoss     | -0.00699      |\n",
      "|    value_loss         | 0.00252       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 747           |\n",
      "|    iterations         | 39            |\n",
      "|    time_elapsed       | 427           |\n",
      "|    total_timesteps    | 6217728       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0036953343  |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.87          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0631       |\n",
      "|    mean_step_reward   | -0.0070047956 |\n",
      "|    n_updates          | 3032          |\n",
      "|    policyGradLoss     | -0.00735      |\n",
      "|    value_loss         | 0.00665       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 40            |\n",
      "|    time_elapsed       | 437           |\n",
      "|    total_timesteps    | 6225920       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004761613   |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.937         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0667       |\n",
      "|    mean_step_reward   | -0.0076238224 |\n",
      "|    n_updates          | 3036          |\n",
      "|    policyGradLoss     | -0.0068       |\n",
      "|    value_loss         | 0.00174       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_18.zip\n",
      "[EVAL] Mean Return: -20.436, Best Return: -16.693\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_18_-20.44.mp4\n",
      "\n",
      "=== Round 20 | Learn 327680 steps (Total trained: 6225920) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 997     |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 8       |\n",
      "|    total_timesteps | 6234112 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 871           |\n",
      "|    iterations         | 2             |\n",
      "|    time_elapsed       | 18            |\n",
      "|    total_timesteps    | 6242304       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0045519597  |\n",
      "|    entropy_loss       | -2.17         |\n",
      "|    explained_variance | 0.859         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0704       |\n",
      "|    mean_step_reward   | -0.0067232866 |\n",
      "|    n_updates          | 3044          |\n",
      "|    policyGradLoss     | -0.00664      |\n",
      "|    value_loss         | 0.00664       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 807           |\n",
      "|    iterations         | 3             |\n",
      "|    time_elapsed       | 30            |\n",
      "|    total_timesteps    | 6250496       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0049840575  |\n",
      "|    entropy_loss       | -2.19         |\n",
      "|    explained_variance | 0.824         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0649       |\n",
      "|    mean_step_reward   | -0.0074248705 |\n",
      "|    n_updates          | 3048          |\n",
      "|    policyGradLoss     | -0.00607      |\n",
      "|    value_loss         | 0.00674       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 797          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 41           |\n",
      "|    total_timesteps    | 6258688      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005035242  |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.819        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0612      |\n",
      "|    mean_step_reward   | -0.007848857 |\n",
      "|    n_updates          | 3052         |\n",
      "|    policyGradLoss     | -0.00776     |\n",
      "|    value_loss         | 0.00517      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 782           |\n",
      "|    iterations         | 5             |\n",
      "|    time_elapsed       | 52            |\n",
      "|    total_timesteps    | 6266880       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004587762   |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.852         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0637       |\n",
      "|    mean_step_reward   | -0.0069831675 |\n",
      "|    n_updates          | 3056          |\n",
      "|    policyGradLoss     | -0.00732      |\n",
      "|    value_loss         | 0.0108        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 770           |\n",
      "|    iterations         | 6             |\n",
      "|    time_elapsed       | 63            |\n",
      "|    total_timesteps    | 6275072       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0044474574  |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.802         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0712       |\n",
      "|    mean_step_reward   | -0.0066578146 |\n",
      "|    n_updates          | 3060          |\n",
      "|    policyGradLoss     | -0.00995      |\n",
      "|    value_loss         | 0.0146        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 779          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 73           |\n",
      "|    total_timesteps    | 6283264      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003576037  |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.868        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0648      |\n",
      "|    mean_step_reward   | -0.007402757 |\n",
      "|    n_updates          | 3064         |\n",
      "|    policyGradLoss     | -0.00571     |\n",
      "|    value_loss         | 0.00391      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 767          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 85           |\n",
      "|    total_timesteps    | 6291456      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004491684  |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.885        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0659      |\n",
      "|    mean_step_reward   | -0.008064913 |\n",
      "|    n_updates          | 3068         |\n",
      "|    policyGradLoss     | -0.0051      |\n",
      "|    value_loss         | 0.00183      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 763          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 96           |\n",
      "|    total_timesteps    | 6299648      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0043414505 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.601        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0675      |\n",
      "|    mean_step_reward   | -0.007942713 |\n",
      "|    n_updates          | 3072         |\n",
      "|    policyGradLoss     | -0.00647     |\n",
      "|    value_loss         | 0.00506      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 764          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 107          |\n",
      "|    total_timesteps    | 6307840      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004414119  |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.739        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0649      |\n",
      "|    mean_step_reward   | -0.006970127 |\n",
      "|    n_updates          | 3076         |\n",
      "|    policyGradLoss     | -0.00651     |\n",
      "|    value_loss         | 0.00666      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 758          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 118          |\n",
      "|    total_timesteps    | 6316032      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0052255196 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.762        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0673      |\n",
      "|    mean_step_reward   | -0.008092472 |\n",
      "|    n_updates          | 3080         |\n",
      "|    policyGradLoss     | -0.00747     |\n",
      "|    value_loss         | 0.00391      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 762          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 128          |\n",
      "|    total_timesteps    | 6324224      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0042055    |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.766        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0618      |\n",
      "|    mean_step_reward   | -0.005630878 |\n",
      "|    n_updates          | 3084         |\n",
      "|    policyGradLoss     | -0.00857     |\n",
      "|    value_loss         | 0.0171       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 140          |\n",
      "|    total_timesteps    | 6332416      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.002833625  |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.901        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0621      |\n",
      "|    mean_step_reward   | -0.007915661 |\n",
      "|    n_updates          | 3088         |\n",
      "|    policyGradLoss     | -0.00398     |\n",
      "|    value_loss         | 0.000806     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 14            |\n",
      "|    time_elapsed       | 152           |\n",
      "|    total_timesteps    | 6340608       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0038515395  |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.87          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0675       |\n",
      "|    mean_step_reward   | -0.0080476785 |\n",
      "|    n_updates          | 3092          |\n",
      "|    policyGradLoss     | -0.0051       |\n",
      "|    value_loss         | 0.00147       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 755           |\n",
      "|    iterations         | 15            |\n",
      "|    time_elapsed       | 162           |\n",
      "|    total_timesteps    | 6348800       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005099225   |\n",
      "|    entropy_loss       | -2.19         |\n",
      "|    explained_variance | 0.899         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.065        |\n",
      "|    mean_step_reward   | -0.0077138846 |\n",
      "|    n_updates          | 3096          |\n",
      "|    policyGradLoss     | -0.00674      |\n",
      "|    value_loss         | 0.00295       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 174          |\n",
      "|    total_timesteps    | 6356992      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005797716  |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.857        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0693      |\n",
      "|    mean_step_reward   | -0.007919382 |\n",
      "|    n_updates          | 3100         |\n",
      "|    policyGradLoss     | -0.00758     |\n",
      "|    value_loss         | 0.0052       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 17            |\n",
      "|    time_elapsed       | 184           |\n",
      "|    total_timesteps    | 6365184       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005905385   |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.811         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0588       |\n",
      "|    mean_step_reward   | -0.0065159355 |\n",
      "|    n_updates          | 3104          |\n",
      "|    policyGradLoss     | -0.0081       |\n",
      "|    value_loss         | 0.0124        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 195          |\n",
      "|    total_timesteps    | 6373376      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0054734554 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.846        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0641      |\n",
      "|    mean_step_reward   | -0.006311875 |\n",
      "|    n_updates          | 3108         |\n",
      "|    policyGradLoss     | -0.00859     |\n",
      "|    value_loss         | 0.0125       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 207          |\n",
      "|    total_timesteps    | 6381568      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004751619  |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.311        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0739      |\n",
      "|    mean_step_reward   | -0.008271436 |\n",
      "|    n_updates          | 3112         |\n",
      "|    policyGradLoss     | -0.00794     |\n",
      "|    value_loss         | 0.00203      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 216          |\n",
      "|    total_timesteps    | 6389760      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0037916675 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.743        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0651      |\n",
      "|    mean_step_reward   | -0.007235765 |\n",
      "|    n_updates          | 3116         |\n",
      "|    policyGradLoss     | -0.00681     |\n",
      "|    value_loss         | 0.00596      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 21            |\n",
      "|    time_elapsed       | 228           |\n",
      "|    total_timesteps    | 6397952       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004450379   |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.769         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0645       |\n",
      "|    mean_step_reward   | -0.0072317543 |\n",
      "|    n_updates          | 3120          |\n",
      "|    policyGradLoss     | -0.00672      |\n",
      "|    value_loss         | 0.00683       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 22            |\n",
      "|    time_elapsed       | 239           |\n",
      "|    total_timesteps    | 6406144       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0044043493  |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.859         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0655       |\n",
      "|    mean_step_reward   | -0.0077301804 |\n",
      "|    n_updates          | 3124          |\n",
      "|    policyGradLoss     | -0.00575      |\n",
      "|    value_loss         | 0.00305       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 23            |\n",
      "|    time_elapsed       | 250           |\n",
      "|    total_timesteps    | 6414336       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0036166501  |\n",
      "|    entropy_loss       | -2.19         |\n",
      "|    explained_variance | 0.824         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.071        |\n",
      "|    mean_step_reward   | -0.0077212453 |\n",
      "|    n_updates          | 3128          |\n",
      "|    policyGradLoss     | -0.00823      |\n",
      "|    value_loss         | 0.00495       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 24            |\n",
      "|    time_elapsed       | 261           |\n",
      "|    total_timesteps    | 6422528       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.006437025   |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.76          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0623       |\n",
      "|    mean_step_reward   | -0.0064804787 |\n",
      "|    n_updates          | 3132          |\n",
      "|    policyGradLoss     | -0.00864      |\n",
      "|    value_loss         | 0.0178        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 754           |\n",
      "|    iterations         | 25            |\n",
      "|    time_elapsed       | 271           |\n",
      "|    total_timesteps    | 6430720       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0056023523  |\n",
      "|    entropy_loss       | -2.19         |\n",
      "|    explained_variance | 0.819         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0647       |\n",
      "|    mean_step_reward   | -0.0071414625 |\n",
      "|    n_updates          | 3136          |\n",
      "|    policyGradLoss     | -0.00609      |\n",
      "|    value_loss         | 0.00598       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 283          |\n",
      "|    total_timesteps    | 6438912      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004121624  |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.726        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0632      |\n",
      "|    mean_step_reward   | -0.007261629 |\n",
      "|    n_updates          | 3140         |\n",
      "|    policyGradLoss     | -0.00632     |\n",
      "|    value_loss         | 0.00778      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 294          |\n",
      "|    total_timesteps    | 6447104      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004701376  |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.333        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0701      |\n",
      "|    mean_step_reward   | -0.008281207 |\n",
      "|    n_updates          | 3144         |\n",
      "|    policyGradLoss     | -0.00662     |\n",
      "|    value_loss         | 0.00148      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 304          |\n",
      "|    total_timesteps    | 6455296      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004515227  |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.794        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0658      |\n",
      "|    mean_step_reward   | -0.007859906 |\n",
      "|    n_updates          | 3148         |\n",
      "|    policyGradLoss     | -0.00677     |\n",
      "|    value_loss         | 0.004        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 6463488     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004688274 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.78        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0623     |\n",
      "|    mean_step_reward   | -0.00738932 |\n",
      "|    n_updates          | 3152        |\n",
      "|    policyGradLoss     | -0.00775    |\n",
      "|    value_loss         | 0.0104      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 326          |\n",
      "|    total_timesteps    | 6471680      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0036393723 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.87         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.067       |\n",
      "|    mean_step_reward   | -0.006003758 |\n",
      "|    n_updates          | 3156         |\n",
      "|    policyGradLoss     | -0.00785     |\n",
      "|    value_loss         | 0.00711      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 338          |\n",
      "|    total_timesteps    | 6479872      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005616405  |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.884        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0617      |\n",
      "|    mean_step_reward   | -0.007944011 |\n",
      "|    n_updates          | 3160         |\n",
      "|    policyGradLoss     | -0.00581     |\n",
      "|    value_loss         | 0.0017       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 32            |\n",
      "|    time_elapsed       | 349           |\n",
      "|    total_timesteps    | 6488064       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004352228   |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.907         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0663       |\n",
      "|    mean_step_reward   | -0.0069108135 |\n",
      "|    n_updates          | 3164          |\n",
      "|    policyGradLoss     | -0.0069       |\n",
      "|    value_loss         | 0.00315       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 359          |\n",
      "|    total_timesteps    | 6496256      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0042696972 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.946        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0594      |\n",
      "|    mean_step_reward   | -0.007952304 |\n",
      "|    n_updates          | 3168         |\n",
      "|    policyGradLoss     | -0.00716     |\n",
      "|    value_loss         | 0.000797     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 371          |\n",
      "|    total_timesteps    | 6504448      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0037756243 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.886        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0648      |\n",
      "|    mean_step_reward   | -0.008453362 |\n",
      "|    n_updates          | 3172         |\n",
      "|    policyGradLoss     | -0.00593     |\n",
      "|    value_loss         | 0.000182     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 382          |\n",
      "|    total_timesteps    | 6512640      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0053085713 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.916        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0617      |\n",
      "|    mean_step_reward   | -0.007008724 |\n",
      "|    n_updates          | 3176         |\n",
      "|    policyGradLoss     | -0.00733     |\n",
      "|    value_loss         | 0.00537      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 36            |\n",
      "|    time_elapsed       | 392           |\n",
      "|    total_timesteps    | 6520832       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005583653   |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.85          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0632       |\n",
      "|    mean_step_reward   | -0.0073822243 |\n",
      "|    n_updates          | 3180          |\n",
      "|    policyGradLoss     | -0.00772      |\n",
      "|    value_loss         | 0.00973       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 37            |\n",
      "|    time_elapsed       | 404           |\n",
      "|    total_timesteps    | 6529024       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0035227812  |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.9           |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0613       |\n",
      "|    mean_step_reward   | -0.0071671205 |\n",
      "|    n_updates          | 3184          |\n",
      "|    policyGradLoss     | -0.00547      |\n",
      "|    value_loss         | 0.00304       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 415          |\n",
      "|    total_timesteps    | 6537216      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0051253308 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.713        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0701      |\n",
      "|    mean_step_reward   | -0.007356998 |\n",
      "|    n_updates          | 3188         |\n",
      "|    policyGradLoss     | -0.00684     |\n",
      "|    value_loss         | 0.00994      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 39            |\n",
      "|    time_elapsed       | 426           |\n",
      "|    total_timesteps    | 6545408       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003112885   |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.916         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0628       |\n",
      "|    mean_step_reward   | -0.0075025205 |\n",
      "|    n_updates          | 3192          |\n",
      "|    policyGradLoss     | -0.00625      |\n",
      "|    value_loss         | 0.000892      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 438          |\n",
      "|    total_timesteps    | 6553600      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004573404  |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.763        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0745      |\n",
      "|    mean_step_reward   | -0.008175014 |\n",
      "|    n_updates          | 3196         |\n",
      "|    policyGradLoss     | -0.0109      |\n",
      "|    value_loss         | 9.01e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_19.zip\n",
      "[EVAL] Mean Return: -108.035, Best Return: -104.265\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_19_-108.03.mp4\n",
      "\n",
      "=== Round 21 | Learn 327680 steps (Total trained: 6553600) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 986     |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 8       |\n",
      "|    total_timesteps | 6561792 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 914           |\n",
      "|    iterations         | 2             |\n",
      "|    time_elapsed       | 17            |\n",
      "|    total_timesteps    | 6569984       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005004029   |\n",
      "|    entropy_loss       | -2.17         |\n",
      "|    explained_variance | 0.905         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0629       |\n",
      "|    mean_step_reward   | -0.0068939426 |\n",
      "|    n_updates          | 3204          |\n",
      "|    policyGradLoss     | -0.00865      |\n",
      "|    value_loss         | 0.00667       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 832           |\n",
      "|    iterations         | 3             |\n",
      "|    time_elapsed       | 29            |\n",
      "|    total_timesteps    | 6578176       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0035138838  |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.815         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.064        |\n",
      "|    mean_step_reward   | -0.0076211067 |\n",
      "|    n_updates          | 3208          |\n",
      "|    policyGradLoss     | -0.00517      |\n",
      "|    value_loss         | 0.00493       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 802          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 40           |\n",
      "|    total_timesteps    | 6586368      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0044575306 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.842        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.062       |\n",
      "|    mean_step_reward   | -0.006819989 |\n",
      "|    n_updates          | 3212         |\n",
      "|    policyGradLoss     | -0.00872     |\n",
      "|    value_loss         | 0.00858      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 799           |\n",
      "|    iterations         | 5             |\n",
      "|    time_elapsed       | 51            |\n",
      "|    total_timesteps    | 6594560       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0044237645  |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.905         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0645       |\n",
      "|    mean_step_reward   | -0.0078679845 |\n",
      "|    n_updates          | 3216          |\n",
      "|    policyGradLoss     | -0.00586      |\n",
      "|    value_loss         | 0.00123       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 781          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 62           |\n",
      "|    total_timesteps    | 6602752      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004617509  |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.327        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0786      |\n",
      "|    mean_step_reward   | -0.008130234 |\n",
      "|    n_updates          | 3220         |\n",
      "|    policyGradLoss     | -0.0137      |\n",
      "|    value_loss         | 4.04e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 784          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 73           |\n",
      "|    total_timesteps    | 6610944      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.006583728  |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.88         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0671      |\n",
      "|    mean_step_reward   | -0.006895094 |\n",
      "|    n_updates          | 3224         |\n",
      "|    policyGradLoss     | -0.0073      |\n",
      "|    value_loss         | 0.0066       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 774           |\n",
      "|    iterations         | 8             |\n",
      "|    time_elapsed       | 84            |\n",
      "|    total_timesteps    | 6619136       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0046361824  |\n",
      "|    entropy_loss       | -2.17         |\n",
      "|    explained_variance | 0.87          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0666       |\n",
      "|    mean_step_reward   | -0.0067591937 |\n",
      "|    n_updates          | 3228          |\n",
      "|    policyGradLoss     | -0.00653      |\n",
      "|    value_loss         | 0.00608       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 766          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 96           |\n",
      "|    total_timesteps    | 6627328      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033826642 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.95         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0596      |\n",
      "|    mean_step_reward   | -0.007531938 |\n",
      "|    n_updates          | 3232         |\n",
      "|    policyGradLoss     | -0.00482     |\n",
      "|    value_loss         | 0.00111      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 773          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 105          |\n",
      "|    total_timesteps    | 6635520      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0046771206 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.897        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0694      |\n",
      "|    mean_step_reward   | -0.007371464 |\n",
      "|    n_updates          | 3236         |\n",
      "|    policyGradLoss     | -0.00872     |\n",
      "|    value_loss         | 0.00324      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 766           |\n",
      "|    iterations         | 11            |\n",
      "|    time_elapsed       | 117           |\n",
      "|    total_timesteps    | 6643712       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004721421   |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.862         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0682       |\n",
      "|    mean_step_reward   | -0.0075349174 |\n",
      "|    n_updates          | 3240          |\n",
      "|    policyGradLoss     | -0.00593      |\n",
      "|    value_loss         | 0.00366       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 764          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 128          |\n",
      "|    total_timesteps    | 6651904      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003392328  |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.889        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0685      |\n",
      "|    mean_step_reward   | -0.007778832 |\n",
      "|    n_updates          | 3244         |\n",
      "|    policyGradLoss     | -0.00608     |\n",
      "|    value_loss         | 0.00127      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 763          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 139          |\n",
      "|    total_timesteps    | 6660096      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0066074976 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.911        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0689      |\n",
      "|    mean_step_reward   | -0.006964505 |\n",
      "|    n_updates          | 3248         |\n",
      "|    policyGradLoss     | -0.00878     |\n",
      "|    value_loss         | 0.00544      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 758          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 151          |\n",
      "|    total_timesteps    | 6668288      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00511072   |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.897        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0649      |\n",
      "|    mean_step_reward   | -0.008141044 |\n",
      "|    n_updates          | 3252         |\n",
      "|    policyGradLoss     | -0.00778     |\n",
      "|    value_loss         | 0.00453      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 764           |\n",
      "|    iterations         | 15            |\n",
      "|    time_elapsed       | 160           |\n",
      "|    total_timesteps    | 6676480       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.006661823   |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.812         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0602       |\n",
      "|    mean_step_reward   | -0.0059973034 |\n",
      "|    n_updates          | 3256          |\n",
      "|    policyGradLoss     | -0.00671      |\n",
      "|    value_loss         | 0.0105        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 760           |\n",
      "|    iterations         | 16            |\n",
      "|    time_elapsed       | 172           |\n",
      "|    total_timesteps    | 6684672       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0041605965  |\n",
      "|    entropy_loss       | -2.19         |\n",
      "|    explained_variance | 0.878         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0683       |\n",
      "|    mean_step_reward   | -0.0069913343 |\n",
      "|    n_updates          | 3260          |\n",
      "|    policyGradLoss     | -0.00673      |\n",
      "|    value_loss         | 0.00354       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 759           |\n",
      "|    iterations         | 17            |\n",
      "|    time_elapsed       | 183           |\n",
      "|    total_timesteps    | 6692864       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0032265312  |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.925         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0628       |\n",
      "|    mean_step_reward   | -0.0079287235 |\n",
      "|    n_updates          | 3264          |\n",
      "|    policyGradLoss     | -0.00724      |\n",
      "|    value_loss         | 0.00153       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 757           |\n",
      "|    iterations         | 18            |\n",
      "|    time_elapsed       | 194           |\n",
      "|    total_timesteps    | 6701056       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0053204633  |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.944         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0769       |\n",
      "|    mean_step_reward   | -0.0077421376 |\n",
      "|    n_updates          | 3268          |\n",
      "|    policyGradLoss     | -0.00843      |\n",
      "|    value_loss         | 0.0004        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 754           |\n",
      "|    iterations         | 19            |\n",
      "|    time_elapsed       | 206           |\n",
      "|    total_timesteps    | 6709248       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0052802484  |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.884         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.059        |\n",
      "|    mean_step_reward   | -0.0071088113 |\n",
      "|    n_updates          | 3272          |\n",
      "|    policyGradLoss     | -0.00687      |\n",
      "|    value_loss         | 0.00691       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 216          |\n",
      "|    total_timesteps    | 6717440      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0037259837 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.939        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0684      |\n",
      "|    mean_step_reward   | -0.008005702 |\n",
      "|    n_updates          | 3276         |\n",
      "|    policyGradLoss     | -0.0065      |\n",
      "|    value_loss         | 0.00149      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 754           |\n",
      "|    iterations         | 21            |\n",
      "|    time_elapsed       | 228           |\n",
      "|    total_timesteps    | 6725632       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004661467   |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.907         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0684       |\n",
      "|    mean_step_reward   | -0.0057853134 |\n",
      "|    n_updates          | 3280          |\n",
      "|    policyGradLoss     | -0.00851      |\n",
      "|    value_loss         | 0.00747       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 239         |\n",
      "|    total_timesteps    | 6733824     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004088931 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.806       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0689     |\n",
      "|    mean_step_reward   | -0.00816742 |\n",
      "|    n_updates          | 3284        |\n",
      "|    policyGradLoss     | -0.00717    |\n",
      "|    value_loss         | 0.00329     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 249          |\n",
      "|    total_timesteps    | 6742016      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0048624147 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.839        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0642      |\n",
      "|    mean_step_reward   | -0.007518104 |\n",
      "|    n_updates          | 3288         |\n",
      "|    policyGradLoss     | -0.00503     |\n",
      "|    value_loss         | 0.0033       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 24            |\n",
      "|    time_elapsed       | 260           |\n",
      "|    total_timesteps    | 6750208       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004751047   |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.937         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0588       |\n",
      "|    mean_step_reward   | -0.0077574253 |\n",
      "|    n_updates          | 3292          |\n",
      "|    policyGradLoss     | -0.00637      |\n",
      "|    value_loss         | 0.00052       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 25            |\n",
      "|    time_elapsed       | 271           |\n",
      "|    total_timesteps    | 6758400       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004396933   |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.803         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0649       |\n",
      "|    mean_step_reward   | -0.0082025025 |\n",
      "|    n_updates          | 3296          |\n",
      "|    policyGradLoss     | -0.00708      |\n",
      "|    value_loss         | 0.00457       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 282          |\n",
      "|    total_timesteps    | 6766592      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0048355376 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.918        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0653      |\n",
      "|    mean_step_reward   | -0.0066992   |\n",
      "|    n_updates          | 3300         |\n",
      "|    policyGradLoss     | -0.00635     |\n",
      "|    value_loss         | 0.00374      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 27            |\n",
      "|    time_elapsed       | 294           |\n",
      "|    total_timesteps    | 6774784       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0048971237  |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.924         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0644       |\n",
      "|    mean_step_reward   | -0.0064245174 |\n",
      "|    n_updates          | 3304          |\n",
      "|    policyGradLoss     | -0.00596      |\n",
      "|    value_loss         | 0.00735       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 304          |\n",
      "|    total_timesteps    | 6782976      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003943869  |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.961        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0672      |\n",
      "|    mean_step_reward   | -0.007522691 |\n",
      "|    n_updates          | 3308         |\n",
      "|    policyGradLoss     | -0.007       |\n",
      "|    value_loss         | 0.00125      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 316          |\n",
      "|    total_timesteps    | 6791168      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004123169  |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.532        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0628      |\n",
      "|    mean_step_reward   | -0.008328552 |\n",
      "|    n_updates          | 3312         |\n",
      "|    policyGradLoss     | -0.00665     |\n",
      "|    value_loss         | 0.00198      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 30            |\n",
      "|    time_elapsed       | 327           |\n",
      "|    total_timesteps    | 6799360       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0041135047  |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.801         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0658       |\n",
      "|    mean_step_reward   | -0.0075843437 |\n",
      "|    n_updates          | 3316          |\n",
      "|    policyGradLoss     | -0.00829      |\n",
      "|    value_loss         | 0.004         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 31            |\n",
      "|    time_elapsed       | 338           |\n",
      "|    total_timesteps    | 6807552       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0049795634  |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.859         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0529       |\n",
      "|    mean_step_reward   | -0.0069967792 |\n",
      "|    n_updates          | 3320          |\n",
      "|    policyGradLoss     | -0.00781      |\n",
      "|    value_loss         | 0.00774       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 32            |\n",
      "|    time_elapsed       | 350           |\n",
      "|    total_timesteps    | 6815744       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0039245905  |\n",
      "|    entropy_loss       | -2.17         |\n",
      "|    explained_variance | 0.857         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0598       |\n",
      "|    mean_step_reward   | -0.0066128564 |\n",
      "|    n_updates          | 3324          |\n",
      "|    policyGradLoss     | -0.00763      |\n",
      "|    value_loss         | 0.00931       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 33            |\n",
      "|    time_elapsed       | 360           |\n",
      "|    total_timesteps    | 6823936       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004972812   |\n",
      "|    entropy_loss       | -2.17         |\n",
      "|    explained_variance | 0.884         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0654       |\n",
      "|    mean_step_reward   | -0.0064731026 |\n",
      "|    n_updates          | 3328          |\n",
      "|    policyGradLoss     | -0.00907      |\n",
      "|    value_loss         | 0.0109        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 34            |\n",
      "|    time_elapsed       | 371           |\n",
      "|    total_timesteps    | 6832128       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0039970204  |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.923         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0641       |\n",
      "|    mean_step_reward   | -0.0077814204 |\n",
      "|    n_updates          | 3332          |\n",
      "|    policyGradLoss     | -0.00777      |\n",
      "|    value_loss         | 0.00231       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 383          |\n",
      "|    total_timesteps    | 6840320      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004878928  |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.916        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0602      |\n",
      "|    mean_step_reward   | -0.006256923 |\n",
      "|    n_updates          | 3336         |\n",
      "|    policyGradLoss     | -0.00808     |\n",
      "|    value_loss         | 0.00747      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 36            |\n",
      "|    time_elapsed       | 393           |\n",
      "|    total_timesteps    | 6848512       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004070848   |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.879         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0734       |\n",
      "|    mean_step_reward   | -0.0077316165 |\n",
      "|    n_updates          | 3340          |\n",
      "|    policyGradLoss     | -0.00833      |\n",
      "|    value_loss         | 0.00307       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 405          |\n",
      "|    total_timesteps    | 6856704      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0037676175 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.874        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0699      |\n",
      "|    mean_step_reward   | -0.007976796 |\n",
      "|    n_updates          | 3344         |\n",
      "|    policyGradLoss     | -0.00728     |\n",
      "|    value_loss         | 0.00143      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 38            |\n",
      "|    time_elapsed       | 415           |\n",
      "|    total_timesteps    | 6864896       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004636093   |\n",
      "|    entropy_loss       | -2.19         |\n",
      "|    explained_variance | 0.849         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0693       |\n",
      "|    mean_step_reward   | -0.0071671344 |\n",
      "|    n_updates          | 3348          |\n",
      "|    policyGradLoss     | -0.00685      |\n",
      "|    value_loss         | 0.00779       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 747         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 427         |\n",
      "|    total_timesteps    | 6873088     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004765786 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0681     |\n",
      "|    mean_step_reward   | -0.00714112 |\n",
      "|    n_updates          | 3352        |\n",
      "|    policyGradLoss     | -0.00732    |\n",
      "|    value_loss         | 0.00646     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 746          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 438          |\n",
      "|    total_timesteps    | 6881280      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0039292756 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.945        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0656      |\n",
      "|    mean_step_reward   | -0.006876293 |\n",
      "|    n_updates          | 3356         |\n",
      "|    policyGradLoss     | -0.00759     |\n",
      "|    value_loss         | 0.00272      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_20.zip\n",
      "[EVAL] Mean Return: -64.174, Best Return: -60.471\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_20_-64.17.mp4\n",
      "\n",
      "=== Round 22 | Learn 327680 steps (Total trained: 6881280) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1118    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 6889472 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 888           |\n",
      "|    iterations         | 2             |\n",
      "|    time_elapsed       | 18            |\n",
      "|    total_timesteps    | 6897664       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004008344   |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.927         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0661       |\n",
      "|    mean_step_reward   | -0.0072328793 |\n",
      "|    n_updates          | 3364          |\n",
      "|    policyGradLoss     | -0.00738      |\n",
      "|    value_loss         | 0.00327       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 817          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 30           |\n",
      "|    total_timesteps    | 6905856      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030182851 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.899        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0671      |\n",
      "|    mean_step_reward   | -0.007928901 |\n",
      "|    n_updates          | 3368         |\n",
      "|    policyGradLoss     | -0.00647     |\n",
      "|    value_loss         | 0.00158      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 6914048     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005589    |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.575       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0695     |\n",
      "|    mean_step_reward   | -0.00863817 |\n",
      "|    n_updates          | 3372        |\n",
      "|    policyGradLoss     | -0.00875    |\n",
      "|    value_loss         | 0.0102      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 794           |\n",
      "|    iterations         | 5             |\n",
      "|    time_elapsed       | 51            |\n",
      "|    total_timesteps    | 6922240       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0046393354  |\n",
      "|    entropy_loss       | -2.17         |\n",
      "|    explained_variance | 0.884         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0706       |\n",
      "|    mean_step_reward   | -0.0055876686 |\n",
      "|    n_updates          | 3376          |\n",
      "|    policyGradLoss     | -0.00816      |\n",
      "|    value_loss         | 0.00593       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 783           |\n",
      "|    iterations         | 6             |\n",
      "|    time_elapsed       | 62            |\n",
      "|    total_timesteps    | 6930432       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0037571285  |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.859         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0686       |\n",
      "|    mean_step_reward   | -0.0072495546 |\n",
      "|    n_updates          | 3380          |\n",
      "|    policyGradLoss     | -0.00554      |\n",
      "|    value_loss         | 0.00405       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 777          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 73           |\n",
      "|    total_timesteps    | 6938624      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0048733493 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.806        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0507      |\n",
      "|    mean_step_reward   | -0.007265898 |\n",
      "|    n_updates          | 3384         |\n",
      "|    policyGradLoss     | -0.00859     |\n",
      "|    value_loss         | 0.00564      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 766           |\n",
      "|    iterations         | 8             |\n",
      "|    time_elapsed       | 85            |\n",
      "|    total_timesteps    | 6946816       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0034668155  |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.933         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0597       |\n",
      "|    mean_step_reward   | -0.0076062023 |\n",
      "|    n_updates          | 3388          |\n",
      "|    policyGradLoss     | -0.00543      |\n",
      "|    value_loss         | 0.00219       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 773           |\n",
      "|    iterations         | 9             |\n",
      "|    time_elapsed       | 95            |\n",
      "|    total_timesteps    | 6955008       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0039020618  |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.857         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.062        |\n",
      "|    mean_step_reward   | -0.0074998625 |\n",
      "|    n_updates          | 3392          |\n",
      "|    policyGradLoss     | -0.0064       |\n",
      "|    value_loss         | 0.00255       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 765          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 106          |\n",
      "|    total_timesteps    | 6963200      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0045331363 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.925        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0694      |\n",
      "|    mean_step_reward   | -0.008349754 |\n",
      "|    n_updates          | 3396         |\n",
      "|    policyGradLoss     | -0.0095      |\n",
      "|    value_loss         | 0.000145     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 762           |\n",
      "|    iterations         | 11            |\n",
      "|    time_elapsed       | 118           |\n",
      "|    total_timesteps    | 6971392       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0057122214  |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.908         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0606       |\n",
      "|    mean_step_reward   | -0.0063184127 |\n",
      "|    n_updates          | 3400          |\n",
      "|    policyGradLoss     | -0.00649      |\n",
      "|    value_loss         | 0.00728       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 763          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 128          |\n",
      "|    total_timesteps    | 6979584      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004133072  |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.912        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0504      |\n",
      "|    mean_step_reward   | -0.007710451 |\n",
      "|    n_updates          | 3404         |\n",
      "|    policyGradLoss     | -0.00342     |\n",
      "|    value_loss         | 0.004        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 759           |\n",
      "|    iterations         | 13            |\n",
      "|    time_elapsed       | 140           |\n",
      "|    total_timesteps    | 6987776       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0038799837  |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.839         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0534       |\n",
      "|    mean_step_reward   | -0.0072209127 |\n",
      "|    n_updates          | 3408          |\n",
      "|    policyGradLoss     | -0.00671      |\n",
      "|    value_loss         | 0.00501       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 760          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 150          |\n",
      "|    total_timesteps    | 6995968      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0048612077 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.931        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0641      |\n",
      "|    mean_step_reward   | -0.00722709  |\n",
      "|    n_updates          | 3412         |\n",
      "|    policyGradLoss     | -0.00711     |\n",
      "|    value_loss         | 0.00241      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 757           |\n",
      "|    iterations         | 15            |\n",
      "|    time_elapsed       | 162           |\n",
      "|    total_timesteps    | 7004160       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004151051   |\n",
      "|    entropy_loss       | -2.19         |\n",
      "|    explained_variance | 0.945         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0659       |\n",
      "|    mean_step_reward   | -0.0074836733 |\n",
      "|    n_updates          | 3416          |\n",
      "|    policyGradLoss     | -0.00652      |\n",
      "|    value_loss         | 0.0014        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 173          |\n",
      "|    total_timesteps    | 7012352      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0043518622 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.626        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0758      |\n",
      "|    mean_step_reward   | -0.008147774 |\n",
      "|    n_updates          | 3420         |\n",
      "|    policyGradLoss     | -0.00997     |\n",
      "|    value_loss         | 8.25e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 758           |\n",
      "|    iterations         | 17            |\n",
      "|    time_elapsed       | 183           |\n",
      "|    total_timesteps    | 7020544       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004957215   |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.864         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0633       |\n",
      "|    mean_step_reward   | -0.0068104505 |\n",
      "|    n_updates          | 3424          |\n",
      "|    policyGradLoss     | -0.00538      |\n",
      "|    value_loss         | 0.0106        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 756           |\n",
      "|    iterations         | 18            |\n",
      "|    time_elapsed       | 195           |\n",
      "|    total_timesteps    | 7028736       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004088395   |\n",
      "|    entropy_loss       | -2.17         |\n",
      "|    explained_variance | 0.908         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0675       |\n",
      "|    mean_step_reward   | -0.0071892682 |\n",
      "|    n_updates          | 3428          |\n",
      "|    policyGradLoss     | -0.00682      |\n",
      "|    value_loss         | 0.00473       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 755           |\n",
      "|    iterations         | 19            |\n",
      "|    time_elapsed       | 206           |\n",
      "|    total_timesteps    | 7036928       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004925758   |\n",
      "|    entropy_loss       | -2.17         |\n",
      "|    explained_variance | 0.938         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0679       |\n",
      "|    mean_step_reward   | -0.0069374247 |\n",
      "|    n_updates          | 3432          |\n",
      "|    policyGradLoss     | -0.00652      |\n",
      "|    value_loss         | 0.0026        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 216          |\n",
      "|    total_timesteps    | 7045120      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005936909  |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.904        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0686      |\n",
      "|    mean_step_reward   | -0.007534156 |\n",
      "|    n_updates          | 3436         |\n",
      "|    policyGradLoss     | -0.00578     |\n",
      "|    value_loss         | 0.00267      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 228          |\n",
      "|    total_timesteps    | 7053312      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027882848 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.942        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0616      |\n",
      "|    mean_step_reward   | -0.007597573 |\n",
      "|    n_updates          | 3440         |\n",
      "|    policyGradLoss     | -0.00456     |\n",
      "|    value_loss         | 0.00129      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 238          |\n",
      "|    total_timesteps    | 7061504      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003949371  |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.949        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0649      |\n",
      "|    mean_step_reward   | -0.007700471 |\n",
      "|    n_updates          | 3444         |\n",
      "|    policyGradLoss     | -0.00601     |\n",
      "|    value_loss         | 0.000507     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 23            |\n",
      "|    time_elapsed       | 250           |\n",
      "|    total_timesteps    | 7069696       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0042537274  |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.964         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0648       |\n",
      "|    mean_step_reward   | -0.0065797586 |\n",
      "|    n_updates          | 3448          |\n",
      "|    policyGradLoss     | -0.00695      |\n",
      "|    value_loss         | 0.00295       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 24            |\n",
      "|    time_elapsed       | 261           |\n",
      "|    total_timesteps    | 7077888       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0039029657  |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.906         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0457       |\n",
      "|    mean_step_reward   | -0.0072985343 |\n",
      "|    n_updates          | 3452          |\n",
      "|    policyGradLoss     | -0.00819      |\n",
      "|    value_loss         | 0.00357       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 25            |\n",
      "|    time_elapsed       | 272           |\n",
      "|    total_timesteps    | 7086080       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0048874747  |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.922         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0742       |\n",
      "|    mean_step_reward   | -0.0069645764 |\n",
      "|    n_updates          | 3456          |\n",
      "|    policyGradLoss     | -0.00921      |\n",
      "|    value_loss         | 0.00531       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 283          |\n",
      "|    total_timesteps    | 7094272      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0029965742 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.931        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0647      |\n",
      "|    mean_step_reward   | -0.007377542 |\n",
      "|    n_updates          | 3460         |\n",
      "|    policyGradLoss     | -0.00684     |\n",
      "|    value_loss         | 0.00129      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 294          |\n",
      "|    total_timesteps    | 7102464      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004097274  |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.913        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0656      |\n",
      "|    mean_step_reward   | -0.007991042 |\n",
      "|    n_updates          | 3464         |\n",
      "|    policyGradLoss     | -0.00802     |\n",
      "|    value_loss         | 0.00118      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 305          |\n",
      "|    total_timesteps    | 7110656      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035775756 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.929        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0644      |\n",
      "|    mean_step_reward   | -0.007117453 |\n",
      "|    n_updates          | 3468         |\n",
      "|    policyGradLoss     | -0.00653     |\n",
      "|    value_loss         | 0.00178      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 317          |\n",
      "|    total_timesteps    | 7118848      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0048157154 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.761        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0645      |\n",
      "|    mean_step_reward   | -0.006930967 |\n",
      "|    n_updates          | 3472         |\n",
      "|    policyGradLoss     | -0.00882     |\n",
      "|    value_loss         | 0.0114       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 30            |\n",
      "|    time_elapsed       | 327           |\n",
      "|    total_timesteps    | 7127040       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0041553713  |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.896         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0666       |\n",
      "|    mean_step_reward   | -0.0064741597 |\n",
      "|    n_updates          | 3476          |\n",
      "|    policyGradLoss     | -0.00802      |\n",
      "|    value_loss         | 0.00656       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 338          |\n",
      "|    total_timesteps    | 7135232      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034932804 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.887        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0668      |\n",
      "|    mean_step_reward   | -0.007374118 |\n",
      "|    n_updates          | 3480         |\n",
      "|    policyGradLoss     | -0.00729     |\n",
      "|    value_loss         | 0.0046       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 32            |\n",
      "|    time_elapsed       | 349           |\n",
      "|    total_timesteps    | 7143424       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0035256213  |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.886         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0676       |\n",
      "|    mean_step_reward   | -0.0070707356 |\n",
      "|    n_updates          | 3484          |\n",
      "|    policyGradLoss     | -0.00567      |\n",
      "|    value_loss         | 0.00215       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 33            |\n",
      "|    time_elapsed       | 360           |\n",
      "|    total_timesteps    | 7151616       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0042702146  |\n",
      "|    entropy_loss       | -2.19         |\n",
      "|    explained_variance | 0.958         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0648       |\n",
      "|    mean_step_reward   | -0.0072257975 |\n",
      "|    n_updates          | 3488          |\n",
      "|    policyGradLoss     | -0.00662      |\n",
      "|    value_loss         | 0.00186       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 34            |\n",
      "|    time_elapsed       | 371           |\n",
      "|    total_timesteps    | 7159808       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004604256   |\n",
      "|    entropy_loss       | -2.19         |\n",
      "|    explained_variance | 0.871         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.062        |\n",
      "|    mean_step_reward   | -0.0076661776 |\n",
      "|    n_updates          | 3492          |\n",
      "|    policyGradLoss     | -0.00711      |\n",
      "|    value_loss         | 0.00316       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 35            |\n",
      "|    time_elapsed       | 382           |\n",
      "|    total_timesteps    | 7168000       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0037906577  |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.931         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0714       |\n",
      "|    mean_step_reward   | -0.0069810483 |\n",
      "|    n_updates          | 3496          |\n",
      "|    policyGradLoss     | -0.00564      |\n",
      "|    value_loss         | 0.00387       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 393          |\n",
      "|    total_timesteps    | 7176192      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0058066607 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.833        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0653      |\n",
      "|    mean_step_reward   | -0.007057759 |\n",
      "|    n_updates          | 3500         |\n",
      "|    policyGradLoss     | -0.00808     |\n",
      "|    value_loss         | 0.0105       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 404          |\n",
      "|    total_timesteps    | 7184384      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0042097755 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.784        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0683      |\n",
      "|    mean_step_reward   | -0.007748609 |\n",
      "|    n_updates          | 3504         |\n",
      "|    policyGradLoss     | -0.0093      |\n",
      "|    value_loss         | 0.00429      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 38            |\n",
      "|    time_elapsed       | 415           |\n",
      "|    total_timesteps    | 7192576       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0035426547  |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.857         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.061        |\n",
      "|    mean_step_reward   | -0.0077075167 |\n",
      "|    n_updates          | 3508          |\n",
      "|    policyGradLoss     | -0.00648      |\n",
      "|    value_loss         | 0.00255       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 427          |\n",
      "|    total_timesteps    | 7200768      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004968364  |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.855        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0677      |\n",
      "|    mean_step_reward   | -0.007189569 |\n",
      "|    n_updates          | 3512         |\n",
      "|    policyGradLoss     | -0.00694     |\n",
      "|    value_loss         | 0.00578      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 437          |\n",
      "|    total_timesteps    | 7208960      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0040352987 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.933        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0617      |\n",
      "|    mean_step_reward   | -0.007165822 |\n",
      "|    n_updates          | 3516         |\n",
      "|    policyGradLoss     | -0.0051      |\n",
      "|    value_loss         | 0.00243      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_21.zip\n",
      "[EVAL] Mean Return: -20.517, Best Return: -16.827\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_21_-20.52.mp4\n",
      "\n",
      "=== Round 23 | Learn 327680 steps (Total trained: 7208960) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 987     |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 8       |\n",
      "|    total_timesteps | 7217152 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 913           |\n",
      "|    iterations         | 2             |\n",
      "|    time_elapsed       | 17            |\n",
      "|    total_timesteps    | 7225344       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004614373   |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.82          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0678       |\n",
      "|    mean_step_reward   | -0.0062106904 |\n",
      "|    n_updates          | 3524          |\n",
      "|    policyGradLoss     | -0.00888      |\n",
      "|    value_loss         | 0.0119        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 829           |\n",
      "|    iterations         | 3             |\n",
      "|    time_elapsed       | 29            |\n",
      "|    total_timesteps    | 7233536       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004512541   |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.652         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0557       |\n",
      "|    mean_step_reward   | -0.0077260784 |\n",
      "|    n_updates          | 3528          |\n",
      "|    policyGradLoss     | -0.0055       |\n",
      "|    value_loss         | 0.0111        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 798           |\n",
      "|    iterations         | 4             |\n",
      "|    time_elapsed       | 41            |\n",
      "|    total_timesteps    | 7241728       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.00433918    |\n",
      "|    entropy_loss       | -2.19         |\n",
      "|    explained_variance | 0.706         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0668       |\n",
      "|    mean_step_reward   | -0.0071146283 |\n",
      "|    n_updates          | 3532          |\n",
      "|    policyGradLoss     | -0.00685      |\n",
      "|    value_loss         | 0.00946       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 794          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 51           |\n",
      "|    total_timesteps    | 7249920      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0040341793 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.82         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0688      |\n",
      "|    mean_step_reward   | -0.008200882 |\n",
      "|    n_updates          | 3536         |\n",
      "|    policyGradLoss     | -0.00648     |\n",
      "|    value_loss         | 0.00303      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 778           |\n",
      "|    iterations         | 6             |\n",
      "|    time_elapsed       | 63            |\n",
      "|    total_timesteps    | 7258112       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005236337   |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.704         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.064        |\n",
      "|    mean_step_reward   | -0.0072258897 |\n",
      "|    n_updates          | 3540          |\n",
      "|    policyGradLoss     | -0.00874      |\n",
      "|    value_loss         | 0.00984       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 779          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 73           |\n",
      "|    total_timesteps    | 7266304      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003522385  |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.845        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0635      |\n",
      "|    mean_step_reward   | -0.007796673 |\n",
      "|    n_updates          | 3544         |\n",
      "|    policyGradLoss     | -0.00695     |\n",
      "|    value_loss         | 0.0032       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 772           |\n",
      "|    iterations         | 8             |\n",
      "|    time_elapsed       | 84            |\n",
      "|    total_timesteps    | 7274496       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005548198   |\n",
      "|    entropy_loss       | -2.17         |\n",
      "|    explained_variance | 0.773         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0618       |\n",
      "|    mean_step_reward   | -0.0059246602 |\n",
      "|    n_updates          | 3548          |\n",
      "|    policyGradLoss     | -0.00888      |\n",
      "|    value_loss         | 0.0192        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 763          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 96           |\n",
      "|    total_timesteps    | 7282688      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0037137484 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.798        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0549      |\n",
      "|    mean_step_reward   | -0.00762681  |\n",
      "|    n_updates          | 3552         |\n",
      "|    policyGradLoss     | -0.00486     |\n",
      "|    value_loss         | 0.00531      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 770           |\n",
      "|    iterations         | 10            |\n",
      "|    time_elapsed       | 106           |\n",
      "|    total_timesteps    | 7290880       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0036084577  |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.728         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0637       |\n",
      "|    mean_step_reward   | -0.0074365935 |\n",
      "|    n_updates          | 3556          |\n",
      "|    policyGradLoss     | -0.00614      |\n",
      "|    value_loss         | 0.00603       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 764          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 117          |\n",
      "|    total_timesteps    | 7299072      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033623069 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.93         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0717      |\n",
      "|    mean_step_reward   | -0.007907424 |\n",
      "|    n_updates          | 3560         |\n",
      "|    policyGradLoss     | -0.00587     |\n",
      "|    value_loss         | 0.000867     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 763           |\n",
      "|    iterations         | 12            |\n",
      "|    time_elapsed       | 128           |\n",
      "|    total_timesteps    | 7307264       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004238993   |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.846         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0673       |\n",
      "|    mean_step_reward   | -0.0078360345 |\n",
      "|    n_updates          | 3564          |\n",
      "|    policyGradLoss     | -0.00731      |\n",
      "|    value_loss         | 0.00438       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 762          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 139          |\n",
      "|    total_timesteps    | 7315456      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038510226 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.908        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0646      |\n",
      "|    mean_step_reward   | -0.00729343  |\n",
      "|    n_updates          | 3568         |\n",
      "|    policyGradLoss     | -0.00723     |\n",
      "|    value_loss         | 0.00445      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 758          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 151          |\n",
      "|    total_timesteps    | 7323648      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0043311655 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.865        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0719      |\n",
      "|    mean_step_reward   | -0.006163016 |\n",
      "|    n_updates          | 3572         |\n",
      "|    policyGradLoss     | -0.00997     |\n",
      "|    value_loss         | 0.00989      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 761          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 161          |\n",
      "|    total_timesteps    | 7331840      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0044460185 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.785        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0651      |\n",
      "|    mean_step_reward   | -0.007627981 |\n",
      "|    n_updates          | 3576         |\n",
      "|    policyGradLoss     | -0.00668     |\n",
      "|    value_loss         | 0.00488      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 757          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 173          |\n",
      "|    total_timesteps    | 7340032      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0040231775 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.843        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0638      |\n",
      "|    mean_step_reward   | -0.007329734 |\n",
      "|    n_updates          | 3580         |\n",
      "|    policyGradLoss     | -0.00838     |\n",
      "|    value_loss         | 0.00601      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 184          |\n",
      "|    total_timesteps    | 7348224      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038414411 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.94         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0621      |\n",
      "|    mean_step_reward   | -0.007913662 |\n",
      "|    n_updates          | 3584         |\n",
      "|    policyGradLoss     | -0.0059      |\n",
      "|    value_loss         | 0.000686     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 756           |\n",
      "|    iterations         | 18            |\n",
      "|    time_elapsed       | 194           |\n",
      "|    total_timesteps    | 7356416       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005486715   |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.75          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.07         |\n",
      "|    mean_step_reward   | -0.0072941566 |\n",
      "|    n_updates          | 3588          |\n",
      "|    policyGradLoss     | -0.00888      |\n",
      "|    value_loss         | 0.0102        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 19            |\n",
      "|    time_elapsed       | 206           |\n",
      "|    total_timesteps    | 7364608       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0038248114  |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.902         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0696       |\n",
      "|    mean_step_reward   | -0.0077198436 |\n",
      "|    n_updates          | 3592          |\n",
      "|    policyGradLoss     | -0.00926      |\n",
      "|    value_loss         | 0.00333       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 217          |\n",
      "|    total_timesteps    | 7372800      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0050899526 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.809        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0623      |\n",
      "|    mean_step_reward   | -0.006184806 |\n",
      "|    n_updates          | 3596         |\n",
      "|    policyGradLoss     | -0.0101      |\n",
      "|    value_loss         | 0.0145       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 21            |\n",
      "|    time_elapsed       | 228           |\n",
      "|    total_timesteps    | 7380992       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003852266   |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.887         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0608       |\n",
      "|    mean_step_reward   | -0.0075895004 |\n",
      "|    n_updates          | 3600          |\n",
      "|    policyGradLoss     | -0.0077       |\n",
      "|    value_loss         | 0.00359       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 239          |\n",
      "|    total_timesteps    | 7389184      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035458973 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.934        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0649      |\n",
      "|    mean_step_reward   | -0.007463789 |\n",
      "|    n_updates          | 3604         |\n",
      "|    policyGradLoss     | -0.00517     |\n",
      "|    value_loss         | 0.00158      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 249          |\n",
      "|    total_timesteps    | 7397376      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0032346183 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.918        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.065       |\n",
      "|    mean_step_reward   | -0.007930522 |\n",
      "|    n_updates          | 3608         |\n",
      "|    policyGradLoss     | -0.00601     |\n",
      "|    value_loss         | 0.00115      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 24            |\n",
      "|    time_elapsed       | 261           |\n",
      "|    total_timesteps    | 7405568       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004678115   |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.879         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0614       |\n",
      "|    mean_step_reward   | -0.0073303897 |\n",
      "|    n_updates          | 3612          |\n",
      "|    policyGradLoss     | -0.00858      |\n",
      "|    value_loss         | 0.0052        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 25            |\n",
      "|    time_elapsed       | 272           |\n",
      "|    total_timesteps    | 7413760       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004990767   |\n",
      "|    entropy_loss       | -2.17         |\n",
      "|    explained_variance | 0.833         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.069        |\n",
      "|    mean_step_reward   | -0.0075538335 |\n",
      "|    n_updates          | 3616          |\n",
      "|    policyGradLoss     | -0.00781      |\n",
      "|    value_loss         | 0.00916       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 26            |\n",
      "|    time_elapsed       | 283           |\n",
      "|    total_timesteps    | 7421952       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004634358   |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.922         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0601       |\n",
      "|    mean_step_reward   | -0.0058221016 |\n",
      "|    n_updates          | 3620          |\n",
      "|    policyGradLoss     | -0.00631      |\n",
      "|    value_loss         | 0.00709       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 27            |\n",
      "|    time_elapsed       | 294           |\n",
      "|    total_timesteps    | 7430144       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0032108044  |\n",
      "|    entropy_loss       | -2.19         |\n",
      "|    explained_variance | 0.922         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0592       |\n",
      "|    mean_step_reward   | -0.0074077705 |\n",
      "|    n_updates          | 3624          |\n",
      "|    policyGradLoss     | -0.00503      |\n",
      "|    value_loss         | 0.00339       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 28            |\n",
      "|    time_elapsed       | 305           |\n",
      "|    total_timesteps    | 7438336       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0037468043  |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.787         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0563       |\n",
      "|    mean_step_reward   | -0.0077178674 |\n",
      "|    n_updates          | 3628          |\n",
      "|    policyGradLoss     | -0.00542      |\n",
      "|    value_loss         | 0.00271       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 316          |\n",
      "|    total_timesteps    | 7446528      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003807455  |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.815        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0647      |\n",
      "|    mean_step_reward   | -0.008331746 |\n",
      "|    n_updates          | 3632         |\n",
      "|    policyGradLoss     | -0.00554     |\n",
      "|    value_loss         | 0.000207     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 328          |\n",
      "|    total_timesteps    | 7454720      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0039684474 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.899        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0651      |\n",
      "|    mean_step_reward   | -0.007023244 |\n",
      "|    n_updates          | 3636         |\n",
      "|    policyGradLoss     | -0.00719     |\n",
      "|    value_loss         | 0.00592      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 337          |\n",
      "|    total_timesteps    | 7462912      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030165869 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.879        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0674      |\n",
      "|    mean_step_reward   | -0.00662465  |\n",
      "|    n_updates          | 3640         |\n",
      "|    policyGradLoss     | -0.00749     |\n",
      "|    value_loss         | 0.00654      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 349          |\n",
      "|    total_timesteps    | 7471104      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0043072123 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.854        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.066       |\n",
      "|    mean_step_reward   | -0.006073971 |\n",
      "|    n_updates          | 3644         |\n",
      "|    policyGradLoss     | -0.00943     |\n",
      "|    value_loss         | 0.015        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 33            |\n",
      "|    time_elapsed       | 361           |\n",
      "|    total_timesteps    | 7479296       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003733398   |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.868         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0693       |\n",
      "|    mean_step_reward   | -0.0070328387 |\n",
      "|    n_updates          | 3648          |\n",
      "|    policyGradLoss     | -0.00719      |\n",
      "|    value_loss         | 0.00928       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 34            |\n",
      "|    time_elapsed       | 371           |\n",
      "|    total_timesteps    | 7487488       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004079143   |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.869         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0635       |\n",
      "|    mean_step_reward   | -0.0061449213 |\n",
      "|    n_updates          | 3652          |\n",
      "|    policyGradLoss     | -0.00802      |\n",
      "|    value_loss         | 0.0101        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 383          |\n",
      "|    total_timesteps    | 7495680      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004126246  |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.853        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0644      |\n",
      "|    mean_step_reward   | -0.007860491 |\n",
      "|    n_updates          | 3656         |\n",
      "|    policyGradLoss     | -0.00694     |\n",
      "|    value_loss         | 0.00188      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 393          |\n",
      "|    total_timesteps    | 7503872      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003907688  |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.882        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.065       |\n",
      "|    mean_step_reward   | -0.007651954 |\n",
      "|    n_updates          | 3660         |\n",
      "|    policyGradLoss     | -0.00687     |\n",
      "|    value_loss         | 0.00384      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 37            |\n",
      "|    time_elapsed       | 404           |\n",
      "|    total_timesteps    | 7512064       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0043602656  |\n",
      "|    entropy_loss       | -2.19         |\n",
      "|    explained_variance | 0.865         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0672       |\n",
      "|    mean_step_reward   | -0.0075094476 |\n",
      "|    n_updates          | 3664          |\n",
      "|    policyGradLoss     | -0.00561      |\n",
      "|    value_loss         | 0.00489       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 416          |\n",
      "|    total_timesteps    | 7520256      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034902124 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.905        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0667      |\n",
      "|    mean_step_reward   | -0.007602207 |\n",
      "|    n_updates          | 3668         |\n",
      "|    policyGradLoss     | -0.00736     |\n",
      "|    value_loss         | 0.00416      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 39            |\n",
      "|    time_elapsed       | 426           |\n",
      "|    total_timesteps    | 7528448       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0036873638  |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.881         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0661       |\n",
      "|    mean_step_reward   | -0.0071648513 |\n",
      "|    n_updates          | 3672          |\n",
      "|    policyGradLoss     | -0.00786      |\n",
      "|    value_loss         | 0.00668       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 437          |\n",
      "|    total_timesteps    | 7536640      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0041057765 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.925        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0661      |\n",
      "|    mean_step_reward   | -0.006860853 |\n",
      "|    n_updates          | 3676         |\n",
      "|    policyGradLoss     | -0.00668     |\n",
      "|    value_loss         | 0.00374      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_22.zip\n",
      "[EVAL] Mean Return: -19.921, Best Return: -16.271\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_22_-19.92.mp4\n",
      "\n",
      "=== Round 24 | Learn 327680 steps (Total trained: 7536640) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 980     |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 8       |\n",
      "|    total_timesteps | 7544832 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 841           |\n",
      "|    iterations         | 2             |\n",
      "|    time_elapsed       | 19            |\n",
      "|    total_timesteps    | 7553024       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004592429   |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.9           |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0659       |\n",
      "|    mean_step_reward   | -0.0075575355 |\n",
      "|    n_updates          | 3684          |\n",
      "|    policyGradLoss     | -0.00639      |\n",
      "|    value_loss         | 0.00234       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 818           |\n",
      "|    iterations         | 3             |\n",
      "|    time_elapsed       | 30            |\n",
      "|    total_timesteps    | 7561216       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0064060227  |\n",
      "|    entropy_loss       | -2.17         |\n",
      "|    explained_variance | 0.816         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0689       |\n",
      "|    mean_step_reward   | -0.0071234577 |\n",
      "|    n_updates          | 3688          |\n",
      "|    policyGradLoss     | -0.00821      |\n",
      "|    value_loss         | 0.00678       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 792           |\n",
      "|    iterations         | 4             |\n",
      "|    time_elapsed       | 41            |\n",
      "|    total_timesteps    | 7569408       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0035974209  |\n",
      "|    entropy_loss       | -2.19         |\n",
      "|    explained_variance | 0.919         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0612       |\n",
      "|    mean_step_reward   | -0.0073152427 |\n",
      "|    n_updates          | 3692          |\n",
      "|    policyGradLoss     | -0.00563      |\n",
      "|    value_loss         | 0.00318       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 778          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 52           |\n",
      "|    total_timesteps    | 7577600      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003416845  |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.881        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.066       |\n",
      "|    mean_step_reward   | -0.007448665 |\n",
      "|    n_updates          | 3696         |\n",
      "|    policyGradLoss     | -0.00696     |\n",
      "|    value_loss         | 0.00378      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 773          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 63           |\n",
      "|    total_timesteps    | 7585792      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0045993794 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.887        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0715      |\n",
      "|    mean_step_reward   | -0.006899089 |\n",
      "|    n_updates          | 3700         |\n",
      "|    policyGradLoss     | -0.0106      |\n",
      "|    value_loss         | 0.00696      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 769          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 74           |\n",
      "|    total_timesteps    | 7593984      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0039115963 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.919        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0631      |\n",
      "|    mean_step_reward   | -0.007847559 |\n",
      "|    n_updates          | 3704         |\n",
      "|    policyGradLoss     | -0.00543     |\n",
      "|    value_loss         | 0.000694     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 765           |\n",
      "|    iterations         | 8             |\n",
      "|    time_elapsed       | 85            |\n",
      "|    total_timesteps    | 7602176       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0037413486  |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.929         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0692       |\n",
      "|    mean_step_reward   | -0.0074959304 |\n",
      "|    n_updates          | 3708          |\n",
      "|    policyGradLoss     | -0.0061       |\n",
      "|    value_loss         | 0.00176       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 758          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 97           |\n",
      "|    total_timesteps    | 7610368      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004653709  |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.699        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0686      |\n",
      "|    mean_step_reward   | -0.007681197 |\n",
      "|    n_updates          | 3712         |\n",
      "|    policyGradLoss     | -0.00897     |\n",
      "|    value_loss         | 0.00839      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 765           |\n",
      "|    iterations         | 10            |\n",
      "|    time_elapsed       | 107           |\n",
      "|    total_timesteps    | 7618560       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0045626797  |\n",
      "|    entropy_loss       | -2.17         |\n",
      "|    explained_variance | 0.869         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0669       |\n",
      "|    mean_step_reward   | -0.0072056013 |\n",
      "|    n_updates          | 3716          |\n",
      "|    policyGradLoss     | -0.00835      |\n",
      "|    value_loss         | 0.00633       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 758           |\n",
      "|    iterations         | 11            |\n",
      "|    time_elapsed       | 118           |\n",
      "|    total_timesteps    | 7626752       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004092627   |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.8           |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0662       |\n",
      "|    mean_step_reward   | -0.0075218896 |\n",
      "|    n_updates          | 3720          |\n",
      "|    policyGradLoss     | -0.00663      |\n",
      "|    value_loss         | 0.00305       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 130          |\n",
      "|    total_timesteps    | 7634944      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004525479  |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.812        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.062       |\n",
      "|    mean_step_reward   | -0.006282204 |\n",
      "|    n_updates          | 3724         |\n",
      "|    policyGradLoss     | -0.00742     |\n",
      "|    value_loss         | 0.0123       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 756           |\n",
      "|    iterations         | 13            |\n",
      "|    time_elapsed       | 140           |\n",
      "|    total_timesteps    | 7643136       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0033466583  |\n",
      "|    entropy_loss       | -2.19         |\n",
      "|    explained_variance | 0.857         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0661       |\n",
      "|    mean_step_reward   | -0.0074675265 |\n",
      "|    n_updates          | 3728          |\n",
      "|    policyGradLoss     | -0.00686      |\n",
      "|    value_loss         | 0.00279       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 14            |\n",
      "|    time_elapsed       | 152           |\n",
      "|    total_timesteps    | 7651328       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004068655   |\n",
      "|    entropy_loss       | -2.19         |\n",
      "|    explained_variance | 0.802         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0677       |\n",
      "|    mean_step_reward   | -0.0076373606 |\n",
      "|    n_updates          | 3732          |\n",
      "|    policyGradLoss     | -0.00691      |\n",
      "|    value_loss         | 0.00545       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 163          |\n",
      "|    total_timesteps    | 7659520      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034385098 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.821        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0687      |\n",
      "|    mean_step_reward   | -0.007773583 |\n",
      "|    n_updates          | 3736         |\n",
      "|    policyGradLoss     | -0.00812     |\n",
      "|    value_loss         | 0.0052       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 174          |\n",
      "|    total_timesteps    | 7667712      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0048356107 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.829        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0671      |\n",
      "|    mean_step_reward   | -0.007729281 |\n",
      "|    n_updates          | 3740         |\n",
      "|    policyGradLoss     | -0.00877     |\n",
      "|    value_loss         | 0.00552      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 186          |\n",
      "|    total_timesteps    | 7675904      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0040990966 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.837        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0668      |\n",
      "|    mean_step_reward   | -0.006409006 |\n",
      "|    n_updates          | 3744         |\n",
      "|    policyGradLoss     | -0.00656     |\n",
      "|    value_loss         | 0.00748      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 754           |\n",
      "|    iterations         | 18            |\n",
      "|    time_elapsed       | 195           |\n",
      "|    total_timesteps    | 7684096       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003935053   |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.872         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0688       |\n",
      "|    mean_step_reward   | -0.0073156236 |\n",
      "|    n_updates          | 3748          |\n",
      "|    policyGradLoss     | -0.00991      |\n",
      "|    value_loss         | 0.00747       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 19            |\n",
      "|    time_elapsed       | 207           |\n",
      "|    total_timesteps    | 7692288       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0033607532  |\n",
      "|    entropy_loss       | -2.19         |\n",
      "|    explained_variance | 0.856         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0698       |\n",
      "|    mean_step_reward   | -0.0061536008 |\n",
      "|    n_updates          | 3752          |\n",
      "|    policyGradLoss     | -0.00918      |\n",
      "|    value_loss         | 0.00855       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 218          |\n",
      "|    total_timesteps    | 7700480      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004067268  |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.826        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0687      |\n",
      "|    mean_step_reward   | -0.008066834 |\n",
      "|    n_updates          | 3756         |\n",
      "|    policyGradLoss     | -0.00639     |\n",
      "|    value_loss         | 0.0026       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 228          |\n",
      "|    total_timesteps    | 7708672      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0039616944 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.852        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.066       |\n",
      "|    mean_step_reward   | -0.006979064 |\n",
      "|    n_updates          | 3760         |\n",
      "|    policyGradLoss     | -0.00818     |\n",
      "|    value_loss         | 0.00786      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 240          |\n",
      "|    total_timesteps    | 7716864      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038229628 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.541        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0694      |\n",
      "|    mean_step_reward   | -0.008617041 |\n",
      "|    n_updates          | 3764         |\n",
      "|    policyGradLoss     | -0.00728     |\n",
      "|    value_loss         | 0.002        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 23            |\n",
      "|    time_elapsed       | 250           |\n",
      "|    total_timesteps    | 7725056       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0028144205  |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.727         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0652       |\n",
      "|    mean_step_reward   | -0.0070620114 |\n",
      "|    n_updates          | 3768          |\n",
      "|    policyGradLoss     | -0.00548      |\n",
      "|    value_loss         | 0.00341       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 262          |\n",
      "|    total_timesteps    | 7733248      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034860398 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.746        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0655      |\n",
      "|    mean_step_reward   | -0.00779228  |\n",
      "|    n_updates          | 3772         |\n",
      "|    policyGradLoss     | -0.00678     |\n",
      "|    value_loss         | 0.00696      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 25            |\n",
      "|    time_elapsed       | 273           |\n",
      "|    total_timesteps    | 7741440       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004683243   |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.912         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0684       |\n",
      "|    mean_step_reward   | -0.0064239576 |\n",
      "|    n_updates          | 3776          |\n",
      "|    policyGradLoss     | -0.00861      |\n",
      "|    value_loss         | 0.00604       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 283          |\n",
      "|    total_timesteps    | 7749632      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004103243  |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.825        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0726      |\n",
      "|    mean_step_reward   | -0.008078638 |\n",
      "|    n_updates          | 3780         |\n",
      "|    policyGradLoss     | -0.0069      |\n",
      "|    value_loss         | 0.00219      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 295          |\n",
      "|    total_timesteps    | 7757824      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035396654 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.896        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.066       |\n",
      "|    mean_step_reward   | -0.006983985 |\n",
      "|    n_updates          | 3784         |\n",
      "|    policyGradLoss     | -0.00655     |\n",
      "|    value_loss         | 0.00386      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 28            |\n",
      "|    time_elapsed       | 305           |\n",
      "|    total_timesteps    | 7766016       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0037202486  |\n",
      "|    entropy_loss       | -2.21         |\n",
      "|    explained_variance | 0.956         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0686       |\n",
      "|    mean_step_reward   | -0.0076624304 |\n",
      "|    n_updates          | 3788          |\n",
      "|    policyGradLoss     | -0.00671      |\n",
      "|    value_loss         | 0.00115       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 29            |\n",
      "|    time_elapsed       | 317           |\n",
      "|    total_timesteps    | 7774208       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0037778248  |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.92          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0667       |\n",
      "|    mean_step_reward   | -0.0074093677 |\n",
      "|    n_updates          | 3792          |\n",
      "|    policyGradLoss     | -0.00617      |\n",
      "|    value_loss         | 0.00195       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 328          |\n",
      "|    total_timesteps    | 7782400      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0061479136 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.896        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0596      |\n",
      "|    mean_step_reward   | -0.007307583 |\n",
      "|    n_updates          | 3796         |\n",
      "|    policyGradLoss     | -0.00587     |\n",
      "|    value_loss         | 0.00292      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 338          |\n",
      "|    total_timesteps    | 7790592      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0046926504 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.875        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0664      |\n",
      "|    mean_step_reward   | -0.006620136 |\n",
      "|    n_updates          | 3800         |\n",
      "|    policyGradLoss     | -0.00804     |\n",
      "|    value_loss         | 0.00822      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 350          |\n",
      "|    total_timesteps    | 7798784      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0040149307 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.86         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.07        |\n",
      "|    mean_step_reward   | -0.007973409 |\n",
      "|    n_updates          | 3804         |\n",
      "|    policyGradLoss     | -0.00752     |\n",
      "|    value_loss         | 0.00171      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 747           |\n",
      "|    iterations         | 33            |\n",
      "|    time_elapsed       | 361           |\n",
      "|    total_timesteps    | 7806976       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0065038577  |\n",
      "|    entropy_loss       | -2.19         |\n",
      "|    explained_variance | 0.911         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0651       |\n",
      "|    mean_step_reward   | -0.0069569047 |\n",
      "|    n_updates          | 3808          |\n",
      "|    policyGradLoss     | -0.00743      |\n",
      "|    value_loss         | 0.00474       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 34            |\n",
      "|    time_elapsed       | 371           |\n",
      "|    total_timesteps    | 7815168       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0038196906  |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.881         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0662       |\n",
      "|    mean_step_reward   | -0.0075489366 |\n",
      "|    n_updates          | 3812          |\n",
      "|    policyGradLoss     | -0.0063       |\n",
      "|    value_loss         | 0.00324       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 747           |\n",
      "|    iterations         | 35            |\n",
      "|    time_elapsed       | 383           |\n",
      "|    total_timesteps    | 7823360       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0041321935  |\n",
      "|    entropy_loss       | -2.2          |\n",
      "|    explained_variance | 0.931         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0622       |\n",
      "|    mean_step_reward   | -0.0075216973 |\n",
      "|    n_updates          | 3816          |\n",
      "|    policyGradLoss     | -0.00503      |\n",
      "|    value_loss         | 0.00147       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 393          |\n",
      "|    total_timesteps    | 7831552      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00369156   |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.964        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0645      |\n",
      "|    mean_step_reward   | -0.007919481 |\n",
      "|    n_updates          | 3820         |\n",
      "|    policyGradLoss     | -0.00643     |\n",
      "|    value_loss         | 0.000773     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 405          |\n",
      "|    total_timesteps    | 7839744      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004116717  |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.913        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0697      |\n",
      "|    mean_step_reward   | -0.006619237 |\n",
      "|    n_updates          | 3824         |\n",
      "|    policyGradLoss     | -0.00842     |\n",
      "|    value_loss         | 0.00592      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 745          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 417          |\n",
      "|    total_timesteps    | 7847936      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004372569  |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.95         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0693      |\n",
      "|    mean_step_reward   | -0.007586305 |\n",
      "|    n_updates          | 3828         |\n",
      "|    policyGradLoss     | -0.00572     |\n",
      "|    value_loss         | 0.00149      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 747           |\n",
      "|    iterations         | 39            |\n",
      "|    time_elapsed       | 427           |\n",
      "|    total_timesteps    | 7856128       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0038595258  |\n",
      "|    entropy_loss       | -2.17         |\n",
      "|    explained_variance | 0.934         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0666       |\n",
      "|    mean_step_reward   | -0.0067606373 |\n",
      "|    n_updates          | 3832          |\n",
      "|    policyGradLoss     | -0.00713      |\n",
      "|    value_loss         | 0.00386       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 746          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 438          |\n",
      "|    total_timesteps    | 7864320      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004418432  |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.91         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0712      |\n",
      "|    mean_step_reward   | -0.007980565 |\n",
      "|    n_updates          | 3836         |\n",
      "|    policyGradLoss     | -0.0057      |\n",
      "|    value_loss         | 0.0017       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_23.zip\n",
      "[EVAL] Mean Return: -21.911, Best Return: -18.275\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_23_-21.91.mp4\n",
      "\n",
      "=== Round 25 | Learn 327680 steps (Total trained: 7864320) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 987     |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 8       |\n",
      "|    total_timesteps | 7872512 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 875          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 7880704      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003466377  |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.948        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0689      |\n",
      "|    mean_step_reward   | -0.007889595 |\n",
      "|    n_updates          | 3844         |\n",
      "|    policyGradLoss     | -0.00635     |\n",
      "|    value_loss         | 0.000656     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 814          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 30           |\n",
      "|    total_timesteps    | 7888896      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0051705604 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.914        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0662      |\n",
      "|    mean_step_reward   | -0.007090078 |\n",
      "|    n_updates          | 3848         |\n",
      "|    policyGradLoss     | -0.00629     |\n",
      "|    value_loss         | 0.00472      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 785          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 41           |\n",
      "|    total_timesteps    | 7897088      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0047671366 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.855        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0618      |\n",
      "|    mean_step_reward   | -0.007058355 |\n",
      "|    n_updates          | 3852         |\n",
      "|    policyGradLoss     | -0.00827     |\n",
      "|    value_loss         | 0.00567      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 794           |\n",
      "|    iterations         | 5             |\n",
      "|    time_elapsed       | 51            |\n",
      "|    total_timesteps    | 7905280       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0037727838  |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.867         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0627       |\n",
      "|    mean_step_reward   | -0.0070551625 |\n",
      "|    n_updates          | 3856          |\n",
      "|    policyGradLoss     | -0.00843      |\n",
      "|    value_loss         | 0.00565       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 778          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 63           |\n",
      "|    total_timesteps    | 7913472      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0037666704 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.926        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0676      |\n",
      "|    mean_step_reward   | -0.007990482 |\n",
      "|    n_updates          | 3860         |\n",
      "|    policyGradLoss     | -0.00707     |\n",
      "|    value_loss         | 0.0011       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 774           |\n",
      "|    iterations         | 7             |\n",
      "|    time_elapsed       | 73            |\n",
      "|    total_timesteps    | 7921664       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0041265395  |\n",
      "|    entropy_loss       | -2.17         |\n",
      "|    explained_variance | 0.927         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0641       |\n",
      "|    mean_step_reward   | -0.0070620566 |\n",
      "|    n_updates          | 3864          |\n",
      "|    policyGradLoss     | -0.00841      |\n",
      "|    value_loss         | 0.00213       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 771          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 84           |\n",
      "|    total_timesteps    | 7929856      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0040198294 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.956        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0565      |\n",
      "|    mean_step_reward   | -0.008197044 |\n",
      "|    n_updates          | 3868         |\n",
      "|    policyGradLoss     | -0.00738     |\n",
      "|    value_loss         | 0.00019      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 763          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 96           |\n",
      "|    total_timesteps    | 7938048      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0054856734 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.871        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.063       |\n",
      "|    mean_step_reward   | -0.006941121 |\n",
      "|    n_updates          | 3872         |\n",
      "|    policyGradLoss     | -0.00699     |\n",
      "|    value_loss         | 0.00833      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 770          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 106          |\n",
      "|    total_timesteps    | 7946240      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0055736294 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.913        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0701      |\n",
      "|    mean_step_reward   | -0.006975543 |\n",
      "|    n_updates          | 3876         |\n",
      "|    policyGradLoss     | -0.00727     |\n",
      "|    value_loss         | 0.00357      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 764           |\n",
      "|    iterations         | 11            |\n",
      "|    time_elapsed       | 117           |\n",
      "|    total_timesteps    | 7954432       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.00504216    |\n",
      "|    entropy_loss       | -2.17         |\n",
      "|    explained_variance | 0.907         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0641       |\n",
      "|    mean_step_reward   | -0.0068998793 |\n",
      "|    n_updates          | 3880          |\n",
      "|    policyGradLoss     | -0.00613      |\n",
      "|    value_loss         | 0.00464       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 760          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 129          |\n",
      "|    total_timesteps    | 7962624      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034858712 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.926        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0626      |\n",
      "|    mean_step_reward   | -0.00784198  |\n",
      "|    n_updates          | 3884         |\n",
      "|    policyGradLoss     | -0.00556     |\n",
      "|    value_loss         | 0.000771     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 763           |\n",
      "|    iterations         | 13            |\n",
      "|    time_elapsed       | 139           |\n",
      "|    total_timesteps    | 7970816       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005123774   |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.827         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0681       |\n",
      "|    mean_step_reward   | -0.0071834084 |\n",
      "|    n_updates          | 3888          |\n",
      "|    policyGradLoss     | -0.00696      |\n",
      "|    value_loss         | 0.00632       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 758          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 151          |\n",
      "|    total_timesteps    | 7979008      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004733056  |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.937        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0666      |\n",
      "|    mean_step_reward   | -0.008279217 |\n",
      "|    n_updates          | 3892         |\n",
      "|    policyGradLoss     | -0.00896     |\n",
      "|    value_loss         | 0.000131     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 759          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 161          |\n",
      "|    total_timesteps    | 7987200      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004604383  |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.926        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0664      |\n",
      "|    mean_step_reward   | -0.006873374 |\n",
      "|    n_updates          | 3896         |\n",
      "|    policyGradLoss     | -0.00841     |\n",
      "|    value_loss         | 0.00466      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 758           |\n",
      "|    iterations         | 16            |\n",
      "|    time_elapsed       | 172           |\n",
      "|    total_timesteps    | 7995392       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004515741   |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.806         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0536       |\n",
      "|    mean_step_reward   | -0.0067582703 |\n",
      "|    n_updates          | 3900          |\n",
      "|    policyGradLoss     | -0.00843      |\n",
      "|    value_loss         | 0.0097        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 754           |\n",
      "|    iterations         | 17            |\n",
      "|    time_elapsed       | 184           |\n",
      "|    total_timesteps    | 8003584       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004331181   |\n",
      "|    entropy_loss       | -2.17         |\n",
      "|    explained_variance | 0.842         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0661       |\n",
      "|    mean_step_reward   | -0.0069333855 |\n",
      "|    n_updates          | 3904          |\n",
      "|    policyGradLoss     | -0.00776      |\n",
      "|    value_loss         | 0.00642       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 758          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 194          |\n",
      "|    total_timesteps    | 8011776      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0032167872 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.913        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0636      |\n",
      "|    mean_step_reward   | -0.007941922 |\n",
      "|    n_updates          | 3908         |\n",
      "|    policyGradLoss     | -0.00559     |\n",
      "|    value_loss         | 0.000755     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 755           |\n",
      "|    iterations         | 19            |\n",
      "|    time_elapsed       | 206           |\n",
      "|    total_timesteps    | 8019968       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005387104   |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.928         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0666       |\n",
      "|    mean_step_reward   | -0.0072181383 |\n",
      "|    n_updates          | 3912          |\n",
      "|    policyGradLoss     | -0.00922      |\n",
      "|    value_loss         | 0.00326       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 217          |\n",
      "|    total_timesteps    | 8028160      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038390036 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.474        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0755      |\n",
      "|    mean_step_reward   | -0.008127264 |\n",
      "|    n_updates          | 3916         |\n",
      "|    policyGradLoss     | -0.0107      |\n",
      "|    value_loss         | 5.13e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 755           |\n",
      "|    iterations         | 21            |\n",
      "|    time_elapsed       | 227           |\n",
      "|    total_timesteps    | 8036352       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003799778   |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.901         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0601       |\n",
      "|    mean_step_reward   | -0.0075983303 |\n",
      "|    n_updates          | 3920          |\n",
      "|    policyGradLoss     | -0.00666      |\n",
      "|    value_loss         | 0.00448       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 239          |\n",
      "|    total_timesteps    | 8044544      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00540326   |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.873        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0678      |\n",
      "|    mean_step_reward   | -0.006515066 |\n",
      "|    n_updates          | 3924         |\n",
      "|    policyGradLoss     | -0.00836     |\n",
      "|    value_loss         | 0.00839      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 249          |\n",
      "|    total_timesteps    | 8052736      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0051502967 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.802        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0721      |\n",
      "|    mean_step_reward   | -0.008029877 |\n",
      "|    n_updates          | 3928         |\n",
      "|    policyGradLoss     | -0.0109      |\n",
      "|    value_loss         | 0.00347      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 260          |\n",
      "|    total_timesteps    | 8060928      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003938217  |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.873        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.07        |\n",
      "|    mean_step_reward   | -0.006647408 |\n",
      "|    n_updates          | 3932         |\n",
      "|    policyGradLoss     | -0.00756     |\n",
      "|    value_loss         | 0.00479      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 272          |\n",
      "|    total_timesteps    | 8069120      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0032993734 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.874        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0636      |\n",
      "|    mean_step_reward   | -0.007356899 |\n",
      "|    n_updates          | 3936         |\n",
      "|    policyGradLoss     | -0.0058      |\n",
      "|    value_loss         | 0.00231      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 283          |\n",
      "|    total_timesteps    | 8077312      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005085091  |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | -0.64        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0729      |\n",
      "|    mean_step_reward   | -0.008114258 |\n",
      "|    n_updates          | 3940         |\n",
      "|    policyGradLoss     | -0.0131      |\n",
      "|    value_loss         | 0.000158     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 294          |\n",
      "|    total_timesteps    | 8085504      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003935368  |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.964        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.064       |\n",
      "|    mean_step_reward   | -0.007317364 |\n",
      "|    n_updates          | 3944         |\n",
      "|    policyGradLoss     | -0.00727     |\n",
      "|    value_loss         | 0.00123      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 28            |\n",
      "|    time_elapsed       | 305           |\n",
      "|    total_timesteps    | 8093696       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0040302286  |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.965         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0676       |\n",
      "|    mean_step_reward   | -0.0065088123 |\n",
      "|    n_updates          | 3948          |\n",
      "|    policyGradLoss     | -0.00551      |\n",
      "|    value_loss         | 0.00258       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 29            |\n",
      "|    time_elapsed       | 317           |\n",
      "|    total_timesteps    | 8101888       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0045867427  |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.984         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0662       |\n",
      "|    mean_step_reward   | -0.0068890275 |\n",
      "|    n_updates          | 3952          |\n",
      "|    policyGradLoss     | -0.00849      |\n",
      "|    value_loss         | 0.00106       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 327          |\n",
      "|    total_timesteps    | 8110080      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004310459  |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.945        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0658      |\n",
      "|    mean_step_reward   | -0.007437243 |\n",
      "|    n_updates          | 3956         |\n",
      "|    policyGradLoss     | -0.00498     |\n",
      "|    value_loss         | 0.00141      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 31            |\n",
      "|    time_elapsed       | 339           |\n",
      "|    total_timesteps    | 8118272       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005325872   |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.857         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0636       |\n",
      "|    mean_step_reward   | -0.0076714978 |\n",
      "|    n_updates          | 3960          |\n",
      "|    policyGradLoss     | -0.00691      |\n",
      "|    value_loss         | 0.00438       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 349         |\n",
      "|    total_timesteps    | 8126464     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004125877 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.716       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0548     |\n",
      "|    mean_step_reward   | -0.00767663 |\n",
      "|    n_updates          | 3964        |\n",
      "|    policyGradLoss     | -0.00505    |\n",
      "|    value_loss         | 0.00349     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 33            |\n",
      "|    time_elapsed       | 360           |\n",
      "|    total_timesteps    | 8134656       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003713133   |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.908         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.06         |\n",
      "|    mean_step_reward   | -0.0072279526 |\n",
      "|    n_updates          | 3968          |\n",
      "|    policyGradLoss     | -0.00627      |\n",
      "|    value_loss         | 0.00122       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 372          |\n",
      "|    total_timesteps    | 8142848      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005435699  |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.934        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0597      |\n",
      "|    mean_step_reward   | -0.006863837 |\n",
      "|    n_updates          | 3972         |\n",
      "|    policyGradLoss     | -0.00741     |\n",
      "|    value_loss         | 0.00593      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 382          |\n",
      "|    total_timesteps    | 8151040      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004080272  |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.962        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0577      |\n",
      "|    mean_step_reward   | -0.007421762 |\n",
      "|    n_updates          | 3976         |\n",
      "|    policyGradLoss     | -0.00641     |\n",
      "|    value_loss         | 0.00139      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 394          |\n",
      "|    total_timesteps    | 8159232      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0046338504 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.986        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0606      |\n",
      "|    mean_step_reward   | -0.007047045 |\n",
      "|    n_updates          | 3980         |\n",
      "|    policyGradLoss     | -0.00571     |\n",
      "|    value_loss         | 0.000646     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 37            |\n",
      "|    time_elapsed       | 405           |\n",
      "|    total_timesteps    | 8167424       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004950866   |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.985         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0633       |\n",
      "|    mean_step_reward   | -0.0071687317 |\n",
      "|    n_updates          | 3984          |\n",
      "|    policyGradLoss     | -0.00908      |\n",
      "|    value_loss         | 0.000675      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 415          |\n",
      "|    total_timesteps    | 8175616      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0052498016 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | -0.483       |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0748      |\n",
      "|    mean_step_reward   | -0.008096704 |\n",
      "|    n_updates          | 3988         |\n",
      "|    policyGradLoss     | -0.0121      |\n",
      "|    value_loss         | 5.41e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 747           |\n",
      "|    iterations         | 39            |\n",
      "|    time_elapsed       | 427           |\n",
      "|    total_timesteps    | 8183808       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004664527   |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.824         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0656       |\n",
      "|    mean_step_reward   | -0.0074027823 |\n",
      "|    n_updates          | 3992          |\n",
      "|    policyGradLoss     | -0.00908      |\n",
      "|    value_loss         | 0.00496       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 437          |\n",
      "|    total_timesteps    | 8192000      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0049972655 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.849        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0563      |\n",
      "|    mean_step_reward   | -0.007457717 |\n",
      "|    n_updates          | 3996         |\n",
      "|    policyGradLoss     | -0.0082      |\n",
      "|    value_loss         | 0.00688      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_24.zip\n",
      "[EVAL] Mean Return: -20.010, Best Return: -16.480\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_24_-20.01.mp4\n",
      "\n",
      "=== Round 26 | Learn 327680 steps (Total trained: 8192000) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1162    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 8200192 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 883           |\n",
      "|    iterations         | 2             |\n",
      "|    time_elapsed       | 18            |\n",
      "|    total_timesteps    | 8208384       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0039495346  |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.903         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0676       |\n",
      "|    mean_step_reward   | -0.0072077466 |\n",
      "|    n_updates          | 4004          |\n",
      "|    policyGradLoss     | -0.00694      |\n",
      "|    value_loss         | 0.00327       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 863          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 8216576      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0037751289 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.785        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.065       |\n",
      "|    mean_step_reward   | -0.008019693 |\n",
      "|    n_updates          | 4008         |\n",
      "|    policyGradLoss     | -0.00616     |\n",
      "|    value_loss         | 0.00379      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 819           |\n",
      "|    iterations         | 4             |\n",
      "|    time_elapsed       | 39            |\n",
      "|    total_timesteps    | 8224768       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0037496104  |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.888         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0573       |\n",
      "|    mean_step_reward   | -0.0073669613 |\n",
      "|    n_updates          | 4012          |\n",
      "|    policyGradLoss     | -0.0055       |\n",
      "|    value_loss         | 0.00216       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 795          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 51           |\n",
      "|    total_timesteps    | 8232960      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0040782345 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.899        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.064       |\n",
      "|    mean_step_reward   | -0.007565299 |\n",
      "|    n_updates          | 4016         |\n",
      "|    policyGradLoss     | -0.00829     |\n",
      "|    value_loss         | 0.00305      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 800           |\n",
      "|    iterations         | 6             |\n",
      "|    time_elapsed       | 61            |\n",
      "|    total_timesteps    | 8241152       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004476673   |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.91          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0604       |\n",
      "|    mean_step_reward   | -0.0069384295 |\n",
      "|    n_updates          | 4020          |\n",
      "|    policyGradLoss     | -0.00704      |\n",
      "|    value_loss         | 0.00379       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 785           |\n",
      "|    iterations         | 7             |\n",
      "|    time_elapsed       | 72            |\n",
      "|    total_timesteps    | 8249344       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0039261575  |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.954         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0658       |\n",
      "|    mean_step_reward   | -0.0067471573 |\n",
      "|    n_updates          | 4024          |\n",
      "|    policyGradLoss     | -0.00463      |\n",
      "|    value_loss         | 0.00194       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 781          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 83           |\n",
      "|    total_timesteps    | 8257536      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005773522  |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.906        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0602      |\n",
      "|    mean_step_reward   | -0.006667667 |\n",
      "|    n_updates          | 4028         |\n",
      "|    policyGradLoss     | -0.00742     |\n",
      "|    value_loss         | 0.00673      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 777           |\n",
      "|    iterations         | 9             |\n",
      "|    time_elapsed       | 94            |\n",
      "|    total_timesteps    | 8265728       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0036201812  |\n",
      "|    entropy_loss       | -2.17         |\n",
      "|    explained_variance | 0.938         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0651       |\n",
      "|    mean_step_reward   | -0.0074795852 |\n",
      "|    n_updates          | 4032          |\n",
      "|    policyGradLoss     | -0.00717      |\n",
      "|    value_loss         | 0.00262       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 770          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 106          |\n",
      "|    total_timesteps    | 8273920      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003947315  |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.964        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0685      |\n",
      "|    mean_step_reward   | -0.007389282 |\n",
      "|    n_updates          | 4036         |\n",
      "|    policyGradLoss     | -0.00658     |\n",
      "|    value_loss         | 0.000578     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 775          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 116          |\n",
      "|    total_timesteps    | 8282112      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038532643 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.899        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0601      |\n",
      "|    mean_step_reward   | -0.008005847 |\n",
      "|    n_updates          | 4040         |\n",
      "|    policyGradLoss     | -0.0053      |\n",
      "|    value_loss         | 0.0019       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 768          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 127          |\n",
      "|    total_timesteps    | 8290304      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0061273994 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.796        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0713      |\n",
      "|    mean_step_reward   | -0.007156839 |\n",
      "|    n_updates          | 4044         |\n",
      "|    policyGradLoss     | -0.00961     |\n",
      "|    value_loss         | 0.00649      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 763          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 139          |\n",
      "|    total_timesteps    | 8298496      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0041955104 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.914        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0643      |\n",
      "|    mean_step_reward   | -0.006744717 |\n",
      "|    n_updates          | 4048         |\n",
      "|    policyGradLoss     | -0.00582     |\n",
      "|    value_loss         | 0.00487      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 764           |\n",
      "|    iterations         | 14            |\n",
      "|    time_elapsed       | 150           |\n",
      "|    total_timesteps    | 8306688       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0057030725  |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.944         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0668       |\n",
      "|    mean_step_reward   | -0.0063419584 |\n",
      "|    n_updates          | 4052          |\n",
      "|    policyGradLoss     | -0.00724      |\n",
      "|    value_loss         | 0.00483       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 759          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 161          |\n",
      "|    total_timesteps    | 8314880      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034001314 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.972        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0699      |\n",
      "|    mean_step_reward   | -0.006487595 |\n",
      "|    n_updates          | 4056         |\n",
      "|    policyGradLoss     | -0.00637     |\n",
      "|    value_loss         | 0.00122      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 760          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 172          |\n",
      "|    total_timesteps    | 8323072      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0050091473 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.943        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.063       |\n",
      "|    mean_step_reward   | -0.007515359 |\n",
      "|    n_updates          | 4060         |\n",
      "|    policyGradLoss     | -0.00609     |\n",
      "|    value_loss         | 0.00185      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 758          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 183          |\n",
      "|    total_timesteps    | 8331264      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004937125  |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.971        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0673      |\n",
      "|    mean_step_reward   | -0.007816357 |\n",
      "|    n_updates          | 4064         |\n",
      "|    policyGradLoss     | -0.0068      |\n",
      "|    value_loss         | 0.000436     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 754           |\n",
      "|    iterations         | 18            |\n",
      "|    time_elapsed       | 195           |\n",
      "|    total_timesteps    | 8339456       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0039799633  |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.982         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0633       |\n",
      "|    mean_step_reward   | -0.0068244627 |\n",
      "|    n_updates          | 4068          |\n",
      "|    policyGradLoss     | -0.00589      |\n",
      "|    value_loss         | 0.000942      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 759          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 204          |\n",
      "|    total_timesteps    | 8347648      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0053347796 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.911        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0716      |\n",
      "|    mean_step_reward   | -0.007499907 |\n",
      "|    n_updates          | 4072         |\n",
      "|    policyGradLoss     | -0.00563     |\n",
      "|    value_loss         | 0.00206      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 216          |\n",
      "|    total_timesteps    | 8355840      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004676339  |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.849        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0599      |\n",
      "|    mean_step_reward   | -0.007596735 |\n",
      "|    n_updates          | 4076         |\n",
      "|    policyGradLoss     | -0.00848     |\n",
      "|    value_loss         | 0.0039       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 756           |\n",
      "|    iterations         | 21            |\n",
      "|    time_elapsed       | 227           |\n",
      "|    total_timesteps    | 8364032       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005195996   |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.904         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0638       |\n",
      "|    mean_step_reward   | -0.0072313817 |\n",
      "|    n_updates          | 4080          |\n",
      "|    policyGradLoss     | -0.00761      |\n",
      "|    value_loss         | 0.00468       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 756           |\n",
      "|    iterations         | 22            |\n",
      "|    time_elapsed       | 238           |\n",
      "|    total_timesteps    | 8372224       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0060975286  |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.893         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0656       |\n",
      "|    mean_step_reward   | -0.0068069985 |\n",
      "|    n_updates          | 4084          |\n",
      "|    policyGradLoss     | -0.00636      |\n",
      "|    value_loss         | 0.00585       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 249          |\n",
      "|    total_timesteps    | 8380416      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004054721  |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.973        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0652      |\n",
      "|    mean_step_reward   | -0.008169629 |\n",
      "|    n_updates          | 4088         |\n",
      "|    policyGradLoss     | -0.00712     |\n",
      "|    value_loss         | 0.00022      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 260          |\n",
      "|    total_timesteps    | 8388608      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0050905957 |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.889        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0665      |\n",
      "|    mean_step_reward   | -0.006821446 |\n",
      "|    n_updates          | 4092         |\n",
      "|    policyGradLoss     | -0.00741     |\n",
      "|    value_loss         | 0.00689      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 271          |\n",
      "|    total_timesteps    | 8396800      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0049689915 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.869        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0641      |\n",
      "|    mean_step_reward   | -0.007096535 |\n",
      "|    n_updates          | 4096         |\n",
      "|    policyGradLoss     | -0.0066      |\n",
      "|    value_loss         | 0.00456      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 283          |\n",
      "|    total_timesteps    | 8404992      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0043633925 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.887        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0715      |\n",
      "|    mean_step_reward   | -0.007532869 |\n",
      "|    n_updates          | 4100         |\n",
      "|    policyGradLoss     | -0.00675     |\n",
      "|    value_loss         | 0.00367      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 27            |\n",
      "|    time_elapsed       | 293           |\n",
      "|    total_timesteps    | 8413184       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004820015   |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.912         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0647       |\n",
      "|    mean_step_reward   | -0.0074101053 |\n",
      "|    n_updates          | 4104          |\n",
      "|    policyGradLoss     | -0.00498      |\n",
      "|    value_loss         | 0.00356       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 28            |\n",
      "|    time_elapsed       | 305           |\n",
      "|    total_timesteps    | 8421376       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0040085125  |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.913         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0665       |\n",
      "|    mean_step_reward   | -0.0069154687 |\n",
      "|    n_updates          | 4108          |\n",
      "|    policyGradLoss     | -0.00893      |\n",
      "|    value_loss         | 0.0045        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 316          |\n",
      "|    total_timesteps    | 8429568      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0044560726 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.922        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0638      |\n",
      "|    mean_step_reward   | -0.008292514 |\n",
      "|    n_updates          | 4112         |\n",
      "|    policyGradLoss     | -0.00663     |\n",
      "|    value_loss         | 0.000158     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 327          |\n",
      "|    total_timesteps    | 8437760      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0043405136 |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.895        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0641      |\n",
      "|    mean_step_reward   | -0.006769728 |\n",
      "|    n_updates          | 4116         |\n",
      "|    policyGradLoss     | -0.00751     |\n",
      "|    value_loss         | 0.0062       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 339          |\n",
      "|    total_timesteps    | 8445952      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004327204  |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.84         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0626      |\n",
      "|    mean_step_reward   | -0.007753522 |\n",
      "|    n_updates          | 4120         |\n",
      "|    policyGradLoss     | -0.00645     |\n",
      "|    value_loss         | 0.00463      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 348          |\n",
      "|    total_timesteps    | 8454144      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0041536847 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.742        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.065       |\n",
      "|    mean_step_reward   | -0.008034624 |\n",
      "|    n_updates          | 4124         |\n",
      "|    policyGradLoss     | -0.00474     |\n",
      "|    value_loss         | 0.00308      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 360          |\n",
      "|    total_timesteps    | 8462336      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0055736904 |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.802        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0713      |\n",
      "|    mean_step_reward   | -0.006714097 |\n",
      "|    n_updates          | 4128         |\n",
      "|    policyGradLoss     | -0.00914     |\n",
      "|    value_loss         | 0.013        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 371          |\n",
      "|    total_timesteps    | 8470528      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004193021  |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.85         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0636      |\n",
      "|    mean_step_reward   | -0.006370779 |\n",
      "|    n_updates          | 4132         |\n",
      "|    policyGradLoss     | -0.00691     |\n",
      "|    value_loss         | 0.00605      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 382          |\n",
      "|    total_timesteps    | 8478720      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0047036824 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.789        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0724      |\n",
      "|    mean_step_reward   | -0.008165482 |\n",
      "|    n_updates          | 4136         |\n",
      "|    policyGradLoss     | -0.0113      |\n",
      "|    value_loss         | 6.6e-05      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 36            |\n",
      "|    time_elapsed       | 393           |\n",
      "|    total_timesteps    | 8486912       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004461064   |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.909         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0642       |\n",
      "|    mean_step_reward   | -0.0067725177 |\n",
      "|    n_updates          | 4140          |\n",
      "|    policyGradLoss     | -0.008        |\n",
      "|    value_loss         | 0.00611       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 37            |\n",
      "|    time_elapsed       | 403           |\n",
      "|    total_timesteps    | 8495104       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004438195   |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.935         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0642       |\n",
      "|    mean_step_reward   | -0.0069405804 |\n",
      "|    n_updates          | 4144          |\n",
      "|    policyGradLoss     | -0.00743      |\n",
      "|    value_loss         | 0.0017        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 415          |\n",
      "|    total_timesteps    | 8503296      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003757498  |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.975        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0585      |\n",
      "|    mean_step_reward   | -0.007869088 |\n",
      "|    n_updates          | 4148         |\n",
      "|    policyGradLoss     | -0.00587     |\n",
      "|    value_loss         | 0.00043      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 427          |\n",
      "|    total_timesteps    | 8511488      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0049037593 |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.875        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0618      |\n",
      "|    mean_step_reward   | -0.006867046 |\n",
      "|    n_updates          | 4152         |\n",
      "|    policyGradLoss     | -0.00696     |\n",
      "|    value_loss         | 0.00651      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 437         |\n",
      "|    total_timesteps    | 8519680     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004102354 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0503     |\n",
      "|    mean_step_reward   | -0.00644283 |\n",
      "|    n_updates          | 4156        |\n",
      "|    policyGradLoss     | -0.00615    |\n",
      "|    value_loss         | 0.00197     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_25.zip\n",
      "[EVAL] Mean Return: -107.441, Best Return: -103.871\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_25_-107.44.mp4\n",
      "\n",
      "=== Round 27 | Learn 327680 steps (Total trained: 8519680) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1075    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 8527872 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 865          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 8536064      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.006065361  |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.947        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0663      |\n",
      "|    mean_step_reward   | -0.006912594 |\n",
      "|    n_updates          | 4164         |\n",
      "|    policyGradLoss     | -0.00664     |\n",
      "|    value_loss         | 0.00359      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 808           |\n",
      "|    iterations         | 3             |\n",
      "|    time_elapsed       | 30            |\n",
      "|    total_timesteps    | 8544256       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0060534338  |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.887         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0669       |\n",
      "|    mean_step_reward   | -0.0070974776 |\n",
      "|    n_updates          | 4168          |\n",
      "|    policyGradLoss     | -0.00911      |\n",
      "|    value_loss         | 0.00492       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 819          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 40           |\n",
      "|    total_timesteps    | 8552448      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0039655752 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.904        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0653      |\n",
      "|    mean_step_reward   | -0.007916429 |\n",
      "|    n_updates          | 4172         |\n",
      "|    policyGradLoss     | -0.00742     |\n",
      "|    value_loss         | 0.00132      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 792           |\n",
      "|    iterations         | 5             |\n",
      "|    time_elapsed       | 51            |\n",
      "|    total_timesteps    | 8560640       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0041530803  |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.932         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0599       |\n",
      "|    mean_step_reward   | -0.0071685603 |\n",
      "|    n_updates          | 4176          |\n",
      "|    policyGradLoss     | -0.00456      |\n",
      "|    value_loss         | 0.00143       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 781           |\n",
      "|    iterations         | 6             |\n",
      "|    time_elapsed       | 62            |\n",
      "|    total_timesteps    | 8568832       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0058816243  |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.918         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0612       |\n",
      "|    mean_step_reward   | -0.0064126346 |\n",
      "|    n_updates          | 4180          |\n",
      "|    policyGradLoss     | -0.0078       |\n",
      "|    value_loss         | 0.00553       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 779          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 73           |\n",
      "|    total_timesteps    | 8577024      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0042527206 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | -0.0366      |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0796      |\n",
      "|    mean_step_reward   | -0.008110359 |\n",
      "|    n_updates          | 4184         |\n",
      "|    policyGradLoss     | -0.014       |\n",
      "|    value_loss         | 4.69e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 770          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 85           |\n",
      "|    total_timesteps    | 8585216      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00545279   |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.836        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0643      |\n",
      "|    mean_step_reward   | -0.007652631 |\n",
      "|    n_updates          | 4188         |\n",
      "|    policyGradLoss     | -0.00845     |\n",
      "|    value_loss         | 0.00601      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 773           |\n",
      "|    iterations         | 9             |\n",
      "|    time_elapsed       | 95            |\n",
      "|    total_timesteps    | 8593408       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0068660276  |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.747         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0657       |\n",
      "|    mean_step_reward   | -0.0064966395 |\n",
      "|    n_updates          | 4192          |\n",
      "|    policyGradLoss     | -0.00908      |\n",
      "|    value_loss         | 0.013         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 766           |\n",
      "|    iterations         | 10            |\n",
      "|    time_elapsed       | 106           |\n",
      "|    total_timesteps    | 8601600       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003468284   |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.898         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0625       |\n",
      "|    mean_step_reward   | -0.0074590896 |\n",
      "|    n_updates          | 4196          |\n",
      "|    policyGradLoss     | -0.00499      |\n",
      "|    value_loss         | 0.00103       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 760          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 118          |\n",
      "|    total_timesteps    | 8609792      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0046318853 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.969        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0698      |\n",
      "|    mean_step_reward   | -0.007205384 |\n",
      "|    n_updates          | 4200         |\n",
      "|    policyGradLoss     | -0.00614     |\n",
      "|    value_loss         | 0.00129      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 128         |\n",
      "|    total_timesteps    | 8617984     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004160014 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0617     |\n",
      "|    mean_step_reward   | -0.00697253 |\n",
      "|    n_updates          | 4204        |\n",
      "|    policyGradLoss     | -0.0071     |\n",
      "|    value_loss         | 0.00349     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 761          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 139          |\n",
      "|    total_timesteps    | 8626176      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0032255491 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.836        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0659      |\n",
      "|    mean_step_reward   | -0.007481303 |\n",
      "|    n_updates          | 4208         |\n",
      "|    policyGradLoss     | -0.00426     |\n",
      "|    value_loss         | 0.00355      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 760          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 150          |\n",
      "|    total_timesteps    | 8634368      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0042528184 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.949        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0671      |\n",
      "|    mean_step_reward   | -0.007901579 |\n",
      "|    n_updates          | 4212         |\n",
      "|    policyGradLoss     | -0.00641     |\n",
      "|    value_loss         | 0.00213      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 759           |\n",
      "|    iterations         | 15            |\n",
      "|    time_elapsed       | 161           |\n",
      "|    total_timesteps    | 8642560       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004575454   |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.87          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0676       |\n",
      "|    mean_step_reward   | -0.0062778117 |\n",
      "|    n_updates          | 4216          |\n",
      "|    policyGradLoss     | -0.00963      |\n",
      "|    value_loss         | 0.00662       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 755           |\n",
      "|    iterations         | 16            |\n",
      "|    time_elapsed       | 173           |\n",
      "|    total_timesteps    | 8650752       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003459361   |\n",
      "|    entropy_loss       | -2.18         |\n",
      "|    explained_variance | 0.963         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0613       |\n",
      "|    mean_step_reward   | -0.0075262208 |\n",
      "|    n_updates          | 4220          |\n",
      "|    policyGradLoss     | -0.00605      |\n",
      "|    value_loss         | 0.000824      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 760          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 183          |\n",
      "|    total_timesteps    | 8658944      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0051597254 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.986        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.063       |\n",
      "|    mean_step_reward   | -0.007198449 |\n",
      "|    n_updates          | 4224         |\n",
      "|    policyGradLoss     | -0.00756     |\n",
      "|    value_loss         | 0.000653     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 757           |\n",
      "|    iterations         | 18            |\n",
      "|    time_elapsed       | 194           |\n",
      "|    total_timesteps    | 8667136       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.00617643    |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.9           |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0691       |\n",
      "|    mean_step_reward   | -0.0070353793 |\n",
      "|    n_updates          | 4228          |\n",
      "|    policyGradLoss     | -0.00756      |\n",
      "|    value_loss         | 0.00534       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 206          |\n",
      "|    total_timesteps    | 8675328      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0048928075 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.825        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.072       |\n",
      "|    mean_step_reward   | -0.007460166 |\n",
      "|    n_updates          | 4232         |\n",
      "|    policyGradLoss     | -0.00947     |\n",
      "|    value_loss         | 0.00437      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 216          |\n",
      "|    total_timesteps    | 8683520      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0041084625 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.96         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0651      |\n",
      "|    mean_step_reward   | -0.007989509 |\n",
      "|    n_updates          | 4236         |\n",
      "|    policyGradLoss     | -0.00697     |\n",
      "|    value_loss         | 0.000508     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 228          |\n",
      "|    total_timesteps    | 8691712      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0047468096 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.978        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0648      |\n",
      "|    mean_step_reward   | -0.006672018 |\n",
      "|    n_updates          | 4240         |\n",
      "|    policyGradLoss     | -0.00822     |\n",
      "|    value_loss         | 0.00123      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 238          |\n",
      "|    total_timesteps    | 8699904      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004229547  |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.83         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0638      |\n",
      "|    mean_step_reward   | -0.007544873 |\n",
      "|    n_updates          | 4244         |\n",
      "|    policyGradLoss     | -0.00467     |\n",
      "|    value_loss         | 0.00471      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 23            |\n",
      "|    time_elapsed       | 249           |\n",
      "|    total_timesteps    | 8708096       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.00356153    |\n",
      "|    entropy_loss       | -2.17         |\n",
      "|    explained_variance | 0.949         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0697       |\n",
      "|    mean_step_reward   | -0.0075399703 |\n",
      "|    n_updates          | 4248          |\n",
      "|    policyGradLoss     | -0.0055       |\n",
      "|    value_loss         | 0.00107       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 24            |\n",
      "|    time_elapsed       | 261           |\n",
      "|    total_timesteps    | 8716288       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0056632822  |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.898         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0667       |\n",
      "|    mean_step_reward   | -0.0063613337 |\n",
      "|    n_updates          | 4252          |\n",
      "|    policyGradLoss     | -0.00763      |\n",
      "|    value_loss         | 0.00736       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 8724480     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004345432 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0736     |\n",
      "|    mean_step_reward   | -0.00781968 |\n",
      "|    n_updates          | 4256        |\n",
      "|    policyGradLoss     | -0.00744    |\n",
      "|    value_loss         | 0.000456    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 26            |\n",
      "|    time_elapsed       | 283           |\n",
      "|    total_timesteps    | 8732672       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0048044026  |\n",
      "|    entropy_loss       | -2.17         |\n",
      "|    explained_variance | 0.976         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0648       |\n",
      "|    mean_step_reward   | -0.0077568507 |\n",
      "|    n_updates          | 4260          |\n",
      "|    policyGradLoss     | -0.00646      |\n",
      "|    value_loss         | 0.000323      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 294          |\n",
      "|    total_timesteps    | 8740864      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0051099374 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.749        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0551      |\n",
      "|    mean_step_reward   | -0.006904484 |\n",
      "|    n_updates          | 4264         |\n",
      "|    policyGradLoss     | -0.00638     |\n",
      "|    value_loss         | 0.0141       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 305          |\n",
      "|    total_timesteps    | 8749056      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004546498  |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.912        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0663      |\n",
      "|    mean_step_reward   | -0.007167558 |\n",
      "|    n_updates          | 4268         |\n",
      "|    policyGradLoss     | -0.00592     |\n",
      "|    value_loss         | 0.00242      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 316          |\n",
      "|    total_timesteps    | 8757248      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038342718 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.973        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0623      |\n",
      "|    mean_step_reward   | -0.007616454 |\n",
      "|    n_updates          | 4272         |\n",
      "|    policyGradLoss     | -0.00686     |\n",
      "|    value_loss         | 0.000651     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 30            |\n",
      "|    time_elapsed       | 327           |\n",
      "|    total_timesteps    | 8765440       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0051330803  |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.923         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0606       |\n",
      "|    mean_step_reward   | -0.0062522003 |\n",
      "|    n_updates          | 4276          |\n",
      "|    policyGradLoss     | -0.00783      |\n",
      "|    value_loss         | 0.00764       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 338          |\n",
      "|    total_timesteps    | 8773632      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0037622545 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.976        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0665      |\n",
      "|    mean_step_reward   | -0.007799119 |\n",
      "|    n_updates          | 4280         |\n",
      "|    policyGradLoss     | -0.00616     |\n",
      "|    value_loss         | 0.000303     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 350          |\n",
      "|    total_timesteps    | 8781824      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038024783 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.966        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0637      |\n",
      "|    mean_step_reward   | -0.007763557 |\n",
      "|    n_updates          | 4284         |\n",
      "|    policyGradLoss     | -0.00653     |\n",
      "|    value_loss         | 0.00053      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 33            |\n",
      "|    time_elapsed       | 360           |\n",
      "|    total_timesteps    | 8790016       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0042553195  |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.98          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0683       |\n",
      "|    mean_step_reward   | -0.0070014475 |\n",
      "|    n_updates          | 4288          |\n",
      "|    policyGradLoss     | -0.00622      |\n",
      "|    value_loss         | 0.00105       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 34            |\n",
      "|    time_elapsed       | 371           |\n",
      "|    total_timesteps    | 8798208       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0047783884  |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.962         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.065        |\n",
      "|    mean_step_reward   | -0.0078319125 |\n",
      "|    n_updates          | 4292          |\n",
      "|    policyGradLoss     | -0.00794      |\n",
      "|    value_loss         | 0.000693      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 382         |\n",
      "|    total_timesteps    | 8806400     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004218452 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0643     |\n",
      "|    mean_step_reward   | -0.00708559 |\n",
      "|    n_updates          | 4296        |\n",
      "|    policyGradLoss     | -0.00622    |\n",
      "|    value_loss         | 0.00338     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 36            |\n",
      "|    time_elapsed       | 393           |\n",
      "|    total_timesteps    | 8814592       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.00665774    |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.834         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0622       |\n",
      "|    mean_step_reward   | -0.0070655523 |\n",
      "|    n_updates          | 4300          |\n",
      "|    policyGradLoss     | -0.00866      |\n",
      "|    value_loss         | 0.0107        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 37            |\n",
      "|    time_elapsed       | 405           |\n",
      "|    total_timesteps    | 8822784       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004042592   |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.946         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.063        |\n",
      "|    mean_step_reward   | -0.0070135174 |\n",
      "|    n_updates          | 4304          |\n",
      "|    policyGradLoss     | -0.00662      |\n",
      "|    value_loss         | 0.00164       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 38            |\n",
      "|    time_elapsed       | 415           |\n",
      "|    total_timesteps    | 8830976       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0038993382  |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.913         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0652       |\n",
      "|    mean_step_reward   | -0.0077375444 |\n",
      "|    n_updates          | 4308          |\n",
      "|    policyGradLoss     | -0.00613      |\n",
      "|    value_loss         | 0.000962      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 39            |\n",
      "|    time_elapsed       | 426           |\n",
      "|    total_timesteps    | 8839168       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0057201306  |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.803         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.062        |\n",
      "|    mean_step_reward   | -0.0068607545 |\n",
      "|    n_updates          | 4312          |\n",
      "|    policyGradLoss     | -0.0085       |\n",
      "|    value_loss         | 0.0108        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 747           |\n",
      "|    iterations         | 40            |\n",
      "|    time_elapsed       | 438           |\n",
      "|    total_timesteps    | 8847360       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003731064   |\n",
      "|    entropy_loss       | -2.17         |\n",
      "|    explained_variance | 0.957         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0617       |\n",
      "|    mean_step_reward   | -0.0078070005 |\n",
      "|    n_updates          | 4316          |\n",
      "|    policyGradLoss     | -0.00604      |\n",
      "|    value_loss         | 0.000406      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_26.zip\n",
      "[EVAL] Mean Return: -20.055, Best Return: -16.472\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_26_-20.06.mp4\n",
      "\n",
      "=== Round 28 | Learn 327680 steps (Total trained: 8847360) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 982     |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 8       |\n",
      "|    total_timesteps | 8855552 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 919          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 8863744      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0047173956 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.898        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0691      |\n",
      "|    mean_step_reward   | -0.007476261 |\n",
      "|    n_updates          | 4324         |\n",
      "|    policyGradLoss     | -0.0087      |\n",
      "|    value_loss         | 0.00509      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 832           |\n",
      "|    iterations         | 3             |\n",
      "|    time_elapsed       | 29            |\n",
      "|    total_timesteps    | 8871936       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0040423153  |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.871         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0615       |\n",
      "|    mean_step_reward   | -0.0065964237 |\n",
      "|    n_updates          | 4328          |\n",
      "|    policyGradLoss     | -0.00715      |\n",
      "|    value_loss         | 0.00489       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 798           |\n",
      "|    iterations         | 4             |\n",
      "|    time_elapsed       | 41            |\n",
      "|    total_timesteps    | 8880128       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0038228363  |\n",
      "|    entropy_loss       | -2.17         |\n",
      "|    explained_variance | 0.951         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0634       |\n",
      "|    mean_step_reward   | -0.0077961884 |\n",
      "|    n_updates          | 4332          |\n",
      "|    policyGradLoss     | -0.00442      |\n",
      "|    value_loss         | 0.000474      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 796           |\n",
      "|    iterations         | 5             |\n",
      "|    time_elapsed       | 51            |\n",
      "|    total_timesteps    | 8888320       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004359518   |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.96          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0572       |\n",
      "|    mean_step_reward   | -0.0068653906 |\n",
      "|    n_updates          | 4336          |\n",
      "|    policyGradLoss     | -0.0069       |\n",
      "|    value_loss         | 0.0025        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 778          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 63           |\n",
      "|    total_timesteps    | 8896512      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0045864573 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.971        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0694      |\n",
      "|    mean_step_reward   | -0.007710345 |\n",
      "|    n_updates          | 4340         |\n",
      "|    policyGradLoss     | -0.00684     |\n",
      "|    value_loss         | 0.00045      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 777           |\n",
      "|    iterations         | 7             |\n",
      "|    time_elapsed       | 73            |\n",
      "|    total_timesteps    | 8904704       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.006117166   |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.857         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0655       |\n",
      "|    mean_step_reward   | -0.0076431567 |\n",
      "|    n_updates          | 4344          |\n",
      "|    policyGradLoss     | -0.00714      |\n",
      "|    value_loss         | 0.00331       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 769           |\n",
      "|    iterations         | 8             |\n",
      "|    time_elapsed       | 85            |\n",
      "|    total_timesteps    | 8912896       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.00406663    |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.955         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0645       |\n",
      "|    mean_step_reward   | -0.0060856687 |\n",
      "|    n_updates          | 4348          |\n",
      "|    policyGradLoss     | -0.00666      |\n",
      "|    value_loss         | 0.00176       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 762           |\n",
      "|    iterations         | 9             |\n",
      "|    time_elapsed       | 96            |\n",
      "|    total_timesteps    | 8921088       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005186774   |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.94          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0678       |\n",
      "|    mean_step_reward   | -0.0074630803 |\n",
      "|    n_updates          | 4352          |\n",
      "|    policyGradLoss     | -0.00491      |\n",
      "|    value_loss         | 0.00154       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 770           |\n",
      "|    iterations         | 10            |\n",
      "|    time_elapsed       | 106           |\n",
      "|    total_timesteps    | 8929280       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.00468007    |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.978         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0662       |\n",
      "|    mean_step_reward   | -0.0073821032 |\n",
      "|    n_updates          | 4356          |\n",
      "|    policyGradLoss     | -0.00697      |\n",
      "|    value_loss         | 0.000413      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 761           |\n",
      "|    iterations         | 11            |\n",
      "|    time_elapsed       | 118           |\n",
      "|    total_timesteps    | 8937472       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005247852   |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.939         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0701       |\n",
      "|    mean_step_reward   | -0.0067791627 |\n",
      "|    n_updates          | 4360          |\n",
      "|    policyGradLoss     | -0.00885      |\n",
      "|    value_loss         | 0.00407       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 759           |\n",
      "|    iterations         | 12            |\n",
      "|    time_elapsed       | 129           |\n",
      "|    total_timesteps    | 8945664       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004371969   |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.973         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0677       |\n",
      "|    mean_step_reward   | -0.0077630975 |\n",
      "|    n_updates          | 4364          |\n",
      "|    policyGradLoss     | -0.00713      |\n",
      "|    value_loss         | 0.000412      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 760          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 140          |\n",
      "|    total_timesteps    | 8953856      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0046433546 |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.983        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0636      |\n",
      "|    mean_step_reward   | -0.007828418 |\n",
      "|    n_updates          | 4368         |\n",
      "|    policyGradLoss     | -0.00689     |\n",
      "|    value_loss         | 0.000381     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 151          |\n",
      "|    total_timesteps    | 8962048      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004462374  |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.969        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0591      |\n",
      "|    mean_step_reward   | -0.006639433 |\n",
      "|    n_updates          | 4372         |\n",
      "|    policyGradLoss     | -0.00667     |\n",
      "|    value_loss         | 0.00275      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 759          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 161          |\n",
      "|    total_timesteps    | 8970240      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005043655  |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.887        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0557      |\n",
      "|    mean_step_reward   | -0.006658019 |\n",
      "|    n_updates          | 4376         |\n",
      "|    policyGradLoss     | -0.00571     |\n",
      "|    value_loss         | 0.00649      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 758           |\n",
      "|    iterations         | 16            |\n",
      "|    time_elapsed       | 172           |\n",
      "|    total_timesteps    | 8978432       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0045420025  |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.895         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0663       |\n",
      "|    mean_step_reward   | -0.0073988037 |\n",
      "|    n_updates          | 4380          |\n",
      "|    policyGradLoss     | -0.00713      |\n",
      "|    value_loss         | 0.00239       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 757           |\n",
      "|    iterations         | 17            |\n",
      "|    time_elapsed       | 183           |\n",
      "|    total_timesteps    | 8986624       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005702764   |\n",
      "|    entropy_loss       | -2.12         |\n",
      "|    explained_variance | 0.944         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0536       |\n",
      "|    mean_step_reward   | -0.0064632623 |\n",
      "|    n_updates          | 4384          |\n",
      "|    policyGradLoss     | -0.00594      |\n",
      "|    value_loss         | 0.00282       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 756           |\n",
      "|    iterations         | 18            |\n",
      "|    time_elapsed       | 194           |\n",
      "|    total_timesteps    | 8994816       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0044346256  |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.985         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.067        |\n",
      "|    mean_step_reward   | -0.0077291713 |\n",
      "|    n_updates          | 4388          |\n",
      "|    policyGradLoss     | -0.00832      |\n",
      "|    value_loss         | 0.000226      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 206          |\n",
      "|    total_timesteps    | 9003008      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0047681453 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.988        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.07        |\n",
      "|    mean_step_reward   | -0.007722745 |\n",
      "|    n_updates          | 4392         |\n",
      "|    policyGradLoss     | -0.00691     |\n",
      "|    value_loss         | 0.000235     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 20            |\n",
      "|    time_elapsed       | 217           |\n",
      "|    total_timesteps    | 9011200       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0049348995  |\n",
      "|    entropy_loss       | -2.11         |\n",
      "|    explained_variance | 0.966         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0624       |\n",
      "|    mean_step_reward   | -0.0069567417 |\n",
      "|    n_updates          | 4396          |\n",
      "|    policyGradLoss     | -0.00574      |\n",
      "|    value_loss         | 0.00256       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 755           |\n",
      "|    iterations         | 21            |\n",
      "|    time_elapsed       | 227           |\n",
      "|    total_timesteps    | 9019392       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005639324   |\n",
      "|    entropy_loss       | -2.12         |\n",
      "|    explained_variance | 0.934         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0515       |\n",
      "|    mean_step_reward   | -0.0070169885 |\n",
      "|    n_updates          | 4400          |\n",
      "|    policyGradLoss     | -0.00348      |\n",
      "|    value_loss         | 0.00366       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 239          |\n",
      "|    total_timesteps    | 9027584      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0039264904 |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.992        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0689      |\n",
      "|    mean_step_reward   | -0.007611137 |\n",
      "|    n_updates          | 4404         |\n",
      "|    policyGradLoss     | -0.0104      |\n",
      "|    value_loss         | 0.000119     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 251          |\n",
      "|    total_timesteps    | 9035776      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004070454  |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.987        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0626      |\n",
      "|    mean_step_reward   | -0.006513072 |\n",
      "|    n_updates          | 4408         |\n",
      "|    policyGradLoss     | -0.00634     |\n",
      "|    value_loss         | 0.000842     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 261          |\n",
      "|    total_timesteps    | 9043968      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0050782817 |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.993        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0691      |\n",
      "|    mean_step_reward   | -0.007716613 |\n",
      "|    n_updates          | 4412         |\n",
      "|    policyGradLoss     | -0.00873     |\n",
      "|    value_loss         | 0.000151     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 25            |\n",
      "|    time_elapsed       | 272           |\n",
      "|    total_timesteps    | 9052160       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0056034634  |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.815         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0606       |\n",
      "|    mean_step_reward   | -0.0077072764 |\n",
      "|    n_updates          | 4416          |\n",
      "|    policyGradLoss     | -0.00575      |\n",
      "|    value_loss         | 0.00236       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 283          |\n",
      "|    total_timesteps    | 9060352      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0063383654 |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.898        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0684      |\n",
      "|    mean_step_reward   | -0.007262768 |\n",
      "|    n_updates          | 4420         |\n",
      "|    policyGradLoss     | -0.00699     |\n",
      "|    value_loss         | 0.00398      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 27            |\n",
      "|    time_elapsed       | 294           |\n",
      "|    total_timesteps    | 9068544       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004962866   |\n",
      "|    entropy_loss       | -2.1          |\n",
      "|    explained_variance | 0.923         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0551       |\n",
      "|    mean_step_reward   | -0.0063760355 |\n",
      "|    n_updates          | 4424          |\n",
      "|    policyGradLoss     | -0.00547      |\n",
      "|    value_loss         | 0.00298       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 28            |\n",
      "|    time_elapsed       | 306           |\n",
      "|    total_timesteps    | 9076736       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0042989645  |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.982         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0647       |\n",
      "|    mean_step_reward   | -0.0077569354 |\n",
      "|    n_updates          | 4428          |\n",
      "|    policyGradLoss     | -0.00716      |\n",
      "|    value_loss         | 0.000234      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 29            |\n",
      "|    time_elapsed       | 316           |\n",
      "|    total_timesteps    | 9084928       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.007106538   |\n",
      "|    entropy_loss       | -2.1          |\n",
      "|    explained_variance | 0.773         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0673       |\n",
      "|    mean_step_reward   | -0.0077370885 |\n",
      "|    n_updates          | 4432          |\n",
      "|    policyGradLoss     | -0.00766      |\n",
      "|    value_loss         | 0.00756       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 328          |\n",
      "|    total_timesteps    | 9093120      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004857952  |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.919        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0613      |\n",
      "|    mean_step_reward   | -0.006636973 |\n",
      "|    n_updates          | 4436         |\n",
      "|    policyGradLoss     | -0.00499     |\n",
      "|    value_loss         | 0.00321      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 747           |\n",
      "|    iterations         | 31            |\n",
      "|    time_elapsed       | 339           |\n",
      "|    total_timesteps    | 9101312       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004960673   |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.974         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0684       |\n",
      "|    mean_step_reward   | -0.0077261114 |\n",
      "|    n_updates          | 4440          |\n",
      "|    policyGradLoss     | -0.00619      |\n",
      "|    value_loss         | 0.000333      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 32            |\n",
      "|    time_elapsed       | 349           |\n",
      "|    total_timesteps    | 9109504       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0061099622  |\n",
      "|    entropy_loss       | -2.12         |\n",
      "|    explained_variance | 0.922         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0642       |\n",
      "|    mean_step_reward   | -0.0071992474 |\n",
      "|    n_updates          | 4444          |\n",
      "|    policyGradLoss     | -0.00568      |\n",
      "|    value_loss         | 0.0044        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 33            |\n",
      "|    time_elapsed       | 361           |\n",
      "|    total_timesteps    | 9117696       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0049421345  |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.926         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0661       |\n",
      "|    mean_step_reward   | -0.0064260117 |\n",
      "|    n_updates          | 4448          |\n",
      "|    policyGradLoss     | -0.00802      |\n",
      "|    value_loss         | 0.00528       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 371          |\n",
      "|    total_timesteps    | 9125888      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004406196  |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.982        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0656      |\n",
      "|    mean_step_reward   | -0.007751815 |\n",
      "|    n_updates          | 4452         |\n",
      "|    policyGradLoss     | -0.00688     |\n",
      "|    value_loss         | 0.000229     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 382          |\n",
      "|    total_timesteps    | 9134080      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005636482  |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.928        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0641      |\n",
      "|    mean_step_reward   | -0.006938737 |\n",
      "|    n_updates          | 4456         |\n",
      "|    policyGradLoss     | -0.00666     |\n",
      "|    value_loss         | 0.00436      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 394          |\n",
      "|    total_timesteps    | 9142272      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005547888  |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.969        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0622      |\n",
      "|    mean_step_reward   | -0.007756344 |\n",
      "|    n_updates          | 4460         |\n",
      "|    policyGradLoss     | -0.00625     |\n",
      "|    value_loss         | 0.000408     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 37            |\n",
      "|    time_elapsed       | 404           |\n",
      "|    total_timesteps    | 9150464       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0044057695  |\n",
      "|    entropy_loss       | -2.12         |\n",
      "|    explained_variance | 0.989         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0653       |\n",
      "|    mean_step_reward   | -0.0073426887 |\n",
      "|    n_updates          | 4464          |\n",
      "|    policyGradLoss     | -0.00684      |\n",
      "|    value_loss         | 0.00024       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 747           |\n",
      "|    iterations         | 38            |\n",
      "|    time_elapsed       | 416           |\n",
      "|    total_timesteps    | 9158656       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004753616   |\n",
      "|    entropy_loss       | -2.11         |\n",
      "|    explained_variance | 0.808         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0597       |\n",
      "|    mean_step_reward   | -0.0074975835 |\n",
      "|    n_updates          | 4468          |\n",
      "|    policyGradLoss     | -0.00532      |\n",
      "|    value_loss         | 0.00525       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 746           |\n",
      "|    iterations         | 39            |\n",
      "|    time_elapsed       | 427           |\n",
      "|    total_timesteps    | 9166848       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005149624   |\n",
      "|    entropy_loss       | -2.1          |\n",
      "|    explained_variance | 0.871         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.064        |\n",
      "|    mean_step_reward   | -0.0062547885 |\n",
      "|    n_updates          | 4472          |\n",
      "|    policyGradLoss     | -0.00705      |\n",
      "|    value_loss         | 0.0102        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 438          |\n",
      "|    total_timesteps    | 9175040      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0048636254 |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.974        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0673      |\n",
      "|    mean_step_reward   | -0.00776114  |\n",
      "|    n_updates          | 4476         |\n",
      "|    policyGradLoss     | -0.00791     |\n",
      "|    value_loss         | 0.000331     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_27.zip\n",
      "[EVAL] Mean Return: -20.255, Best Return: -16.872\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_27_-20.26.mp4\n",
      "\n",
      "=== Round 29 | Learn 327680 steps (Total trained: 9175040) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1022    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 8       |\n",
      "|    total_timesteps | 9183232 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 832          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 9191424      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.006542147  |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.865        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0692      |\n",
      "|    mean_step_reward   | -0.007073637 |\n",
      "|    n_updates          | 4484         |\n",
      "|    policyGradLoss     | -0.00977     |\n",
      "|    value_loss         | 0.00502      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 827         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 9199616     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004874996 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.9         |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0585     |\n",
      "|    mean_step_reward   | -0.00726832 |\n",
      "|    n_updates          | 4488        |\n",
      "|    policyGradLoss     | -0.00729    |\n",
      "|    value_loss         | 0.00283     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 790          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 41           |\n",
      "|    total_timesteps    | 9207808      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0040175933 |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.932        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0628      |\n",
      "|    mean_step_reward   | -0.007024637 |\n",
      "|    n_updates          | 4492         |\n",
      "|    policyGradLoss     | -0.00707     |\n",
      "|    value_loss         | 0.00226      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 789           |\n",
      "|    iterations         | 5             |\n",
      "|    time_elapsed       | 51            |\n",
      "|    total_timesteps    | 9216000       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0051622293  |\n",
      "|    entropy_loss       | -2.11         |\n",
      "|    explained_variance | 0.949         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0641       |\n",
      "|    mean_step_reward   | -0.0065804366 |\n",
      "|    n_updates          | 4496          |\n",
      "|    policyGradLoss     | -0.00916      |\n",
      "|    value_loss         | 0.00404       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 776          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 63           |\n",
      "|    total_timesteps    | 9224192      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0042424174 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.706        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0646      |\n",
      "|    mean_step_reward   | -0.0078242   |\n",
      "|    n_updates          | 4500         |\n",
      "|    policyGradLoss     | -0.0069      |\n",
      "|    value_loss         | 0.00345      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 765          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 74           |\n",
      "|    total_timesteps    | 9232384      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0042754076 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.925        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0615      |\n",
      "|    mean_step_reward   | -0.008013764 |\n",
      "|    n_updates          | 4504         |\n",
      "|    policyGradLoss     | -0.00566     |\n",
      "|    value_loss         | 0.00175      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 776           |\n",
      "|    iterations         | 8             |\n",
      "|    time_elapsed       | 84            |\n",
      "|    total_timesteps    | 9240576       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0043308106  |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.921         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0673       |\n",
      "|    mean_step_reward   | -0.0065261475 |\n",
      "|    n_updates          | 4508          |\n",
      "|    policyGradLoss     | -0.0074       |\n",
      "|    value_loss         | 0.00355       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 768           |\n",
      "|    iterations         | 9             |\n",
      "|    time_elapsed       | 95            |\n",
      "|    total_timesteps    | 9248768       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0031477096  |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.917         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0633       |\n",
      "|    mean_step_reward   | -0.0074243313 |\n",
      "|    n_updates          | 4512          |\n",
      "|    policyGradLoss     | -0.00732      |\n",
      "|    value_loss         | 0.00277       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 764           |\n",
      "|    iterations         | 10            |\n",
      "|    time_elapsed       | 107           |\n",
      "|    total_timesteps    | 9256960       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004544612   |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.952         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0659       |\n",
      "|    mean_step_reward   | -0.0072224108 |\n",
      "|    n_updates          | 4516          |\n",
      "|    policyGradLoss     | -0.00629      |\n",
      "|    value_loss         | 0.00114       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 764           |\n",
      "|    iterations         | 11            |\n",
      "|    time_elapsed       | 117           |\n",
      "|    total_timesteps    | 9265152       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005073632   |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.944         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0635       |\n",
      "|    mean_step_reward   | -0.0070122713 |\n",
      "|    n_updates          | 4520          |\n",
      "|    policyGradLoss     | -0.00649      |\n",
      "|    value_loss         | 0.00352       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 760           |\n",
      "|    iterations         | 12            |\n",
      "|    time_elapsed       | 129           |\n",
      "|    total_timesteps    | 9273344       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004670971   |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.981         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0628       |\n",
      "|    mean_step_reward   | -0.0073874714 |\n",
      "|    n_updates          | 4524          |\n",
      "|    policyGradLoss     | -0.00594      |\n",
      "|    value_loss         | 0.000392      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 762          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 139          |\n",
      "|    total_timesteps    | 9281536      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0055656396 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.669        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0663      |\n",
      "|    mean_step_reward   | -0.008170318 |\n",
      "|    n_updates          | 4528         |\n",
      "|    policyGradLoss     | -0.0064      |\n",
      "|    value_loss         | 0.00119      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 757           |\n",
      "|    iterations         | 14            |\n",
      "|    time_elapsed       | 151           |\n",
      "|    total_timesteps    | 9289728       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005035135   |\n",
      "|    entropy_loss       | -2.12         |\n",
      "|    explained_variance | 0.894         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0716       |\n",
      "|    mean_step_reward   | -0.0064454926 |\n",
      "|    n_updates          | 4532          |\n",
      "|    policyGradLoss     | -0.00739      |\n",
      "|    value_loss         | 0.00619       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 162          |\n",
      "|    total_timesteps    | 9297920      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0058276188 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.96         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0673      |\n",
      "|    mean_step_reward   | -0.007507514 |\n",
      "|    n_updates          | 4536         |\n",
      "|    policyGradLoss     | -0.00628     |\n",
      "|    value_loss         | 0.00101      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 757          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 172          |\n",
      "|    total_timesteps    | 9306112      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0047614677 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.933        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0648      |\n",
      "|    mean_step_reward   | -0.007906461 |\n",
      "|    n_updates          | 4540         |\n",
      "|    policyGradLoss     | -0.00441     |\n",
      "|    value_loss         | 0.00197      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 754           |\n",
      "|    iterations         | 17            |\n",
      "|    time_elapsed       | 184           |\n",
      "|    total_timesteps    | 9314304       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0047290074  |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.946         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0625       |\n",
      "|    mean_step_reward   | -0.0060148602 |\n",
      "|    n_updates          | 4544          |\n",
      "|    policyGradLoss     | -0.00682      |\n",
      "|    value_loss         | 0.00466       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 754           |\n",
      "|    iterations         | 18            |\n",
      "|    time_elapsed       | 195           |\n",
      "|    total_timesteps    | 9322496       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0040057865  |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.91          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.063        |\n",
      "|    mean_step_reward   | -0.0076075047 |\n",
      "|    n_updates          | 4548          |\n",
      "|    policyGradLoss     | -0.00591      |\n",
      "|    value_loss         | 0.00295       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 206          |\n",
      "|    total_timesteps    | 9330688      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00520024   |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.977        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0604      |\n",
      "|    mean_step_reward   | -0.007754536 |\n",
      "|    n_updates          | 4552         |\n",
      "|    policyGradLoss     | -0.0061      |\n",
      "|    value_loss         | 0.000287     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 20            |\n",
      "|    time_elapsed       | 217           |\n",
      "|    total_timesteps    | 9338880       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004583938   |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.974         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0611       |\n",
      "|    mean_step_reward   | -0.0070056235 |\n",
      "|    n_updates          | 4556          |\n",
      "|    policyGradLoss     | -0.00542      |\n",
      "|    value_loss         | 0.00156       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 227          |\n",
      "|    total_timesteps    | 9347072      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0050567193 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.983        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0671      |\n",
      "|    mean_step_reward   | -0.00758262  |\n",
      "|    n_updates          | 4560         |\n",
      "|    policyGradLoss     | -0.00638     |\n",
      "|    value_loss         | 0.000477     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 239          |\n",
      "|    total_timesteps    | 9355264      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00548033   |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.99         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0641      |\n",
      "|    mean_step_reward   | -0.007846314 |\n",
      "|    n_updates          | 4564         |\n",
      "|    policyGradLoss     | -0.0078      |\n",
      "|    value_loss         | 0.000232     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 23            |\n",
      "|    time_elapsed       | 251           |\n",
      "|    total_timesteps    | 9363456       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005279446   |\n",
      "|    entropy_loss       | -2.08         |\n",
      "|    explained_variance | 0.924         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0643       |\n",
      "|    mean_step_reward   | -0.0064716367 |\n",
      "|    n_updates          | 4568          |\n",
      "|    policyGradLoss     | -0.00807      |\n",
      "|    value_loss         | 0.00548       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 261          |\n",
      "|    total_timesteps    | 9371648      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004387068  |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.813        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0637      |\n",
      "|    mean_step_reward   | -0.007608063 |\n",
      "|    n_updates          | 4572         |\n",
      "|    policyGradLoss     | -0.00688     |\n",
      "|    value_loss         | 0.00345      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 25            |\n",
      "|    time_elapsed       | 272           |\n",
      "|    total_timesteps    | 9379840       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0039609596  |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.768         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0609       |\n",
      "|    mean_step_reward   | -0.0077429703 |\n",
      "|    n_updates          | 4576          |\n",
      "|    policyGradLoss     | -0.00521      |\n",
      "|    value_loss         | 0.00247       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 26            |\n",
      "|    time_elapsed       | 283           |\n",
      "|    total_timesteps    | 9388032       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0068884445  |\n",
      "|    entropy_loss       | -2.12         |\n",
      "|    explained_variance | 0.875         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0644       |\n",
      "|    mean_step_reward   | -0.0067104334 |\n",
      "|    n_updates          | 4580          |\n",
      "|    policyGradLoss     | -0.00777      |\n",
      "|    value_loss         | 0.00409       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 27            |\n",
      "|    time_elapsed       | 294           |\n",
      "|    total_timesteps    | 9396224       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0037070524  |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.969         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0676       |\n",
      "|    mean_step_reward   | -0.0077970936 |\n",
      "|    n_updates          | 4584          |\n",
      "|    policyGradLoss     | -0.00586      |\n",
      "|    value_loss         | 0.000385      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 9404416     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008169537 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.783       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.07       |\n",
      "|    mean_step_reward   | -0.00776465 |\n",
      "|    n_updates          | 4588        |\n",
      "|    policyGradLoss     | -0.00834    |\n",
      "|    value_loss         | 0.00354     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 29            |\n",
      "|    time_elapsed       | 315           |\n",
      "|    total_timesteps    | 9412608       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.006120827   |\n",
      "|    entropy_loss       | -2.1          |\n",
      "|    explained_variance | 0.875         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0613       |\n",
      "|    mean_step_reward   | -0.0062654153 |\n",
      "|    n_updates          | 4592          |\n",
      "|    policyGradLoss     | -0.00773      |\n",
      "|    value_loss         | 0.0112        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 327          |\n",
      "|    total_timesteps    | 9420800      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0043683983 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.928        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0645      |\n",
      "|    mean_step_reward   | -0.007084137 |\n",
      "|    n_updates          | 4596         |\n",
      "|    policyGradLoss     | -0.00605     |\n",
      "|    value_loss         | 0.00214      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 338          |\n",
      "|    total_timesteps    | 9428992      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005277645  |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.574        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.062       |\n",
      "|    mean_step_reward   | -0.008187418 |\n",
      "|    n_updates          | 4600         |\n",
      "|    policyGradLoss     | -0.00742     |\n",
      "|    value_loss         | 0.000362     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 32            |\n",
      "|    time_elapsed       | 349           |\n",
      "|    total_timesteps    | 9437184       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0064398013  |\n",
      "|    entropy_loss       | -2.12         |\n",
      "|    explained_variance | 0.901         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0628       |\n",
      "|    mean_step_reward   | -0.0065018423 |\n",
      "|    n_updates          | 4604          |\n",
      "|    policyGradLoss     | -0.00543      |\n",
      "|    value_loss         | 0.00488       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 361          |\n",
      "|    total_timesteps    | 9445376      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004797627  |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.969        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0655      |\n",
      "|    mean_step_reward   | -0.007799688 |\n",
      "|    n_updates          | 4608         |\n",
      "|    policyGradLoss     | -0.00698     |\n",
      "|    value_loss         | 0.000378     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 371          |\n",
      "|    total_timesteps    | 9453568      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0042993175 |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.985        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0666      |\n",
      "|    mean_step_reward   | -0.007766751 |\n",
      "|    n_updates          | 4612         |\n",
      "|    policyGradLoss     | -0.00592     |\n",
      "|    value_loss         | 0.000319     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 382          |\n",
      "|    total_timesteps    | 9461760      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0062388675 |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.967        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0668      |\n",
      "|    mean_step_reward   | -0.006335863 |\n",
      "|    n_updates          | 4616         |\n",
      "|    policyGradLoss     | -0.00584     |\n",
      "|    value_loss         | 0.00323      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 393          |\n",
      "|    total_timesteps    | 9469952      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003966962  |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.947        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.057       |\n",
      "|    mean_step_reward   | -0.007360356 |\n",
      "|    n_updates          | 4620         |\n",
      "|    policyGradLoss     | -0.00578     |\n",
      "|    value_loss         | 0.00232      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 404          |\n",
      "|    total_timesteps    | 9478144      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0066290926 |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.683        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0657      |\n",
      "|    mean_step_reward   | -0.007667616 |\n",
      "|    n_updates          | 4624         |\n",
      "|    policyGradLoss     | -0.00652     |\n",
      "|    value_loss         | 0.00359      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 38            |\n",
      "|    time_elapsed       | 415           |\n",
      "|    total_timesteps    | 9486336       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.008794809   |\n",
      "|    entropy_loss       | -2.1          |\n",
      "|    explained_variance | 0.849         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0647       |\n",
      "|    mean_step_reward   | -0.0066375844 |\n",
      "|    n_updates          | 4628          |\n",
      "|    policyGradLoss     | -0.0066       |\n",
      "|    value_loss         | 0.0107        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 39            |\n",
      "|    time_elapsed       | 427           |\n",
      "|    total_timesteps    | 9494528       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0052311793  |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.836         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0685       |\n",
      "|    mean_step_reward   | -0.0077696033 |\n",
      "|    n_updates          | 4632          |\n",
      "|    policyGradLoss     | -0.00688      |\n",
      "|    value_loss         | 0.00254       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 437          |\n",
      "|    total_timesteps    | 9502720      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0054391203 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.857        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0656      |\n",
      "|    mean_step_reward   | -0.007871054 |\n",
      "|    n_updates          | 4636         |\n",
      "|    policyGradLoss     | -0.00545     |\n",
      "|    value_loss         | 0.00191      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_28.zip\n",
      "[EVAL] Mean Return: -64.092, Best Return: -60.602\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_28_-64.09.mp4\n",
      "\n",
      "=== Round 30 | Learn 327680 steps (Total trained: 9502720) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 993     |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 8       |\n",
      "|    total_timesteps | 9510912 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 834           |\n",
      "|    iterations         | 2             |\n",
      "|    time_elapsed       | 19            |\n",
      "|    total_timesteps    | 9519104       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0059357784  |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.801         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0643       |\n",
      "|    mean_step_reward   | -0.0069226427 |\n",
      "|    n_updates          | 4644          |\n",
      "|    policyGradLoss     | -0.00904      |\n",
      "|    value_loss         | 0.00691       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 817           |\n",
      "|    iterations         | 3             |\n",
      "|    time_elapsed       | 30            |\n",
      "|    total_timesteps    | 9527296       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0054666055  |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.845         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.067        |\n",
      "|    mean_step_reward   | -0.0076944404 |\n",
      "|    n_updates          | 4648          |\n",
      "|    policyGradLoss     | -0.0043       |\n",
      "|    value_loss         | 0.0017        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 788           |\n",
      "|    iterations         | 4             |\n",
      "|    time_elapsed       | 41            |\n",
      "|    total_timesteps    | 9535488       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0072467863  |\n",
      "|    entropy_loss       | -2.11         |\n",
      "|    explained_variance | 0.79          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0664       |\n",
      "|    mean_step_reward   | -0.0073793167 |\n",
      "|    n_updates          | 4652          |\n",
      "|    policyGradLoss     | -0.00655      |\n",
      "|    value_loss         | 0.0105        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 788          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 51           |\n",
      "|    total_timesteps    | 9543680      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0041065253 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.888        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0665      |\n",
      "|    mean_step_reward   | -0.007037578 |\n",
      "|    n_updates          | 4656         |\n",
      "|    policyGradLoss     | -0.0053      |\n",
      "|    value_loss         | 0.00117      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 774           |\n",
      "|    iterations         | 6             |\n",
      "|    time_elapsed       | 63            |\n",
      "|    total_timesteps    | 9551872       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.00417013    |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.929         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.063        |\n",
      "|    mean_step_reward   | -0.0077717053 |\n",
      "|    n_updates          | 4660          |\n",
      "|    policyGradLoss     | -0.00759      |\n",
      "|    value_loss         | 0.000886      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 766          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 74           |\n",
      "|    total_timesteps    | 9560064      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0053030327 |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.847        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0611      |\n",
      "|    mean_step_reward   | -0.007927718 |\n",
      "|    n_updates          | 4664         |\n",
      "|    policyGradLoss     | -0.00775     |\n",
      "|    value_loss         | 0.00854      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 774          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 84           |\n",
      "|    total_timesteps    | 9568256      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0053548245 |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.88         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0625      |\n",
      "|    mean_step_reward   | -0.006410841 |\n",
      "|    n_updates          | 4668         |\n",
      "|    policyGradLoss     | -0.00836     |\n",
      "|    value_loss         | 0.00709      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 767          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 96           |\n",
      "|    total_timesteps    | 9576448      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003857802  |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.789        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0632      |\n",
      "|    mean_step_reward   | -0.007714054 |\n",
      "|    n_updates          | 4672         |\n",
      "|    policyGradLoss     | -0.00543     |\n",
      "|    value_loss         | 0.00207      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 765          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 107          |\n",
      "|    total_timesteps    | 9584640      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004681176  |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.908        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0642      |\n",
      "|    mean_step_reward   | -0.006533413 |\n",
      "|    n_updates          | 4676         |\n",
      "|    policyGradLoss     | -0.00603     |\n",
      "|    value_loss         | 0.00361      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 766          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 117          |\n",
      "|    total_timesteps    | 9592832      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005584647  |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.975        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0655      |\n",
      "|    mean_step_reward   | -0.007855699 |\n",
      "|    n_updates          | 4680         |\n",
      "|    policyGradLoss     | -0.00677     |\n",
      "|    value_loss         | 0.000332     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 761           |\n",
      "|    iterations         | 12            |\n",
      "|    time_elapsed       | 129           |\n",
      "|    total_timesteps    | 9601024       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0045248396  |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.895         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0647       |\n",
      "|    mean_step_reward   | -0.0077586705 |\n",
      "|    n_updates          | 4684          |\n",
      "|    policyGradLoss     | -0.00517      |\n",
      "|    value_loss         | 0.0015        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 766          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 138          |\n",
      "|    total_timesteps    | 9609216      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005469039  |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.902        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0613      |\n",
      "|    mean_step_reward   | -0.007105973 |\n",
      "|    n_updates          | 4688         |\n",
      "|    policyGradLoss     | -0.00615     |\n",
      "|    value_loss         | 0.00566      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 762          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 150          |\n",
      "|    total_timesteps    | 9617408      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.007541223  |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.924        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0617      |\n",
      "|    mean_step_reward   | -0.007489382 |\n",
      "|    n_updates          | 4692         |\n",
      "|    policyGradLoss     | -0.00665     |\n",
      "|    value_loss         | 0.00221      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 758           |\n",
      "|    iterations         | 15            |\n",
      "|    time_elapsed       | 161           |\n",
      "|    total_timesteps    | 9625600       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0049732174  |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.896         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.064        |\n",
      "|    mean_step_reward   | -0.0074265106 |\n",
      "|    n_updates          | 4696          |\n",
      "|    policyGradLoss     | -0.00555      |\n",
      "|    value_loss         | 0.00287       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 763           |\n",
      "|    iterations         | 16            |\n",
      "|    time_elapsed       | 171           |\n",
      "|    total_timesteps    | 9633792       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0048058527  |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.942         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0608       |\n",
      "|    mean_step_reward   | -0.0071089095 |\n",
      "|    n_updates          | 4700          |\n",
      "|    policyGradLoss     | -0.00551      |\n",
      "|    value_loss         | 0.0035        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 759          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 183          |\n",
      "|    total_timesteps    | 9641984      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00474994   |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.876        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0639      |\n",
      "|    mean_step_reward   | -0.007958158 |\n",
      "|    n_updates          | 4704         |\n",
      "|    policyGradLoss     | -0.00564     |\n",
      "|    value_loss         | 0.00237      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 759           |\n",
      "|    iterations         | 18            |\n",
      "|    time_elapsed       | 194           |\n",
      "|    total_timesteps    | 9650176       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0031129825  |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.946         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.066        |\n",
      "|    mean_step_reward   | -0.0073731486 |\n",
      "|    n_updates          | 4708          |\n",
      "|    policyGradLoss     | -0.00543      |\n",
      "|    value_loss         | 0.00106       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 759          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 205          |\n",
      "|    total_timesteps    | 9658368      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038648658 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.913        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0664      |\n",
      "|    mean_step_reward   | -0.007845575 |\n",
      "|    n_updates          | 4712         |\n",
      "|    policyGradLoss     | -0.00524     |\n",
      "|    value_loss         | 0.00231      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 216          |\n",
      "|    total_timesteps    | 9666560      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0043096803 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.942        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0674      |\n",
      "|    mean_step_reward   | -0.006723719 |\n",
      "|    n_updates          | 4716         |\n",
      "|    policyGradLoss     | -0.00813     |\n",
      "|    value_loss         | 0.00398      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 760          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 226          |\n",
      "|    total_timesteps    | 9674752      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0045896396 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.914        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0635      |\n",
      "|    mean_step_reward   | -0.007509628 |\n",
      "|    n_updates          | 4720         |\n",
      "|    policyGradLoss     | -0.00741     |\n",
      "|    value_loss         | 0.00257      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 238          |\n",
      "|    total_timesteps    | 9682944      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034798887 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.871        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0668      |\n",
      "|    mean_step_reward   | -0.007838659 |\n",
      "|    n_updates          | 4724         |\n",
      "|    policyGradLoss     | -0.00647     |\n",
      "|    value_loss         | 0.00315      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 754           |\n",
      "|    iterations         | 23            |\n",
      "|    time_elapsed       | 249           |\n",
      "|    total_timesteps    | 9691136       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0043157954  |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.976         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0683       |\n",
      "|    mean_step_reward   | -0.0071283444 |\n",
      "|    n_updates          | 4728          |\n",
      "|    policyGradLoss     | -0.00591      |\n",
      "|    value_loss         | 0.000642      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 756           |\n",
      "|    iterations         | 24            |\n",
      "|    time_elapsed       | 259           |\n",
      "|    total_timesteps    | 9699328       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0041211545  |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.977         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0657       |\n",
      "|    mean_step_reward   | -0.0074404646 |\n",
      "|    n_updates          | 4732          |\n",
      "|    policyGradLoss     | -0.00713      |\n",
      "|    value_loss         | 0.000606      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 271          |\n",
      "|    total_timesteps    | 9707520      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0053741513 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.955        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0602      |\n",
      "|    mean_step_reward   | -0.007461601 |\n",
      "|    n_updates          | 4736         |\n",
      "|    policyGradLoss     | -0.00649     |\n",
      "|    value_loss         | 0.00159      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 282          |\n",
      "|    total_timesteps    | 9715712      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0064098565 |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.911        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0653      |\n",
      "|    mean_step_reward   | -0.006692897 |\n",
      "|    n_updates          | 4740         |\n",
      "|    policyGradLoss     | -0.00896     |\n",
      "|    value_loss         | 0.0064       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 293          |\n",
      "|    total_timesteps    | 9723904      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0039833747 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.931        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.065       |\n",
      "|    mean_step_reward   | -0.006995262 |\n",
      "|    n_updates          | 4744         |\n",
      "|    policyGradLoss     | -0.00718     |\n",
      "|    value_loss         | 0.00286      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 28            |\n",
      "|    time_elapsed       | 305           |\n",
      "|    total_timesteps    | 9732096       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004911805   |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.943         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0677       |\n",
      "|    mean_step_reward   | -0.0075278673 |\n",
      "|    n_updates          | 4748          |\n",
      "|    policyGradLoss     | -0.00725      |\n",
      "|    value_loss         | 0.00191       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 314          |\n",
      "|    total_timesteps    | 9740288      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00449316   |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.903        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0642      |\n",
      "|    mean_step_reward   | -0.007329718 |\n",
      "|    n_updates          | 4752         |\n",
      "|    policyGradLoss     | -0.00745     |\n",
      "|    value_loss         | 0.00302      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 326          |\n",
      "|    total_timesteps    | 9748480      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0060703596 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.788        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0639      |\n",
      "|    mean_step_reward   | -0.007594702 |\n",
      "|    n_updates          | 4756         |\n",
      "|    policyGradLoss     | -0.00689     |\n",
      "|    value_loss         | 0.0059       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 337          |\n",
      "|    total_timesteps    | 9756672      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0039756224 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.948        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0666      |\n",
      "|    mean_step_reward   | -0.00749053  |\n",
      "|    n_updates          | 4760         |\n",
      "|    policyGradLoss     | -0.00715     |\n",
      "|    value_loss         | 0.000754     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 32            |\n",
      "|    time_elapsed       | 347           |\n",
      "|    total_timesteps    | 9764864       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0029932014  |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.947         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0635       |\n",
      "|    mean_step_reward   | -0.0071135294 |\n",
      "|    n_updates          | 4764          |\n",
      "|    policyGradLoss     | -0.00447      |\n",
      "|    value_loss         | 0.00215       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 33            |\n",
      "|    time_elapsed       | 359           |\n",
      "|    total_timesteps    | 9773056       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.006872794   |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.898         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.064        |\n",
      "|    mean_step_reward   | -0.0073279636 |\n",
      "|    n_updates          | 4768          |\n",
      "|    policyGradLoss     | -0.00631      |\n",
      "|    value_loss         | 0.0054        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 369          |\n",
      "|    total_timesteps    | 9781248      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004026674  |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.94         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.067       |\n",
      "|    mean_step_reward   | -0.008085357 |\n",
      "|    n_updates          | 4772         |\n",
      "|    policyGradLoss     | -0.00638     |\n",
      "|    value_loss         | 0.00137      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 35            |\n",
      "|    time_elapsed       | 381           |\n",
      "|    total_timesteps    | 9789440       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0045557073  |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.955         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0675       |\n",
      "|    mean_step_reward   | -0.0070119803 |\n",
      "|    n_updates          | 4776          |\n",
      "|    policyGradLoss     | -0.00741      |\n",
      "|    value_loss         | 0.00226       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 36            |\n",
      "|    time_elapsed       | 393           |\n",
      "|    total_timesteps    | 9797632       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004297663   |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.962         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0638       |\n",
      "|    mean_step_reward   | -0.0068818186 |\n",
      "|    n_updates          | 4780          |\n",
      "|    policyGradLoss     | -0.00724      |\n",
      "|    value_loss         | 0.00167       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 403          |\n",
      "|    total_timesteps    | 9805824      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0044373143 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.97         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0656      |\n",
      "|    mean_step_reward   | -0.007609294 |\n",
      "|    n_updates          | 4784         |\n",
      "|    policyGradLoss     | -0.00674     |\n",
      "|    value_loss         | 0.00107      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 414          |\n",
      "|    total_timesteps    | 9814016      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0053230133 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.885        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0638      |\n",
      "|    mean_step_reward   | -0.007893    |\n",
      "|    n_updates          | 4788         |\n",
      "|    policyGradLoss     | -0.00649     |\n",
      "|    value_loss         | 0.00432      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 425          |\n",
      "|    total_timesteps    | 9822208      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004127533  |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.959        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0676      |\n",
      "|    mean_step_reward   | -0.006180097 |\n",
      "|    n_updates          | 4792         |\n",
      "|    policyGradLoss     | -0.00687     |\n",
      "|    value_loss         | 0.00183      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 436          |\n",
      "|    total_timesteps    | 9830400      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0032766126 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.701        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0609      |\n",
      "|    mean_step_reward   | -0.008344986 |\n",
      "|    n_updates          | 4796         |\n",
      "|    policyGradLoss     | -0.00493     |\n",
      "|    value_loss         | 0.0017       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_29.zip\n",
      "[EVAL] Mean Return: -20.239, Best Return: -16.789\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_29_-20.24.mp4\n",
      "\n",
      "=== Round 31 | Learn 327680 steps (Total trained: 9830400) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1044    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 9838592 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 845           |\n",
      "|    iterations         | 2             |\n",
      "|    time_elapsed       | 19            |\n",
      "|    total_timesteps    | 9846784       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0035274522  |\n",
      "|    entropy_loss       | -2.17         |\n",
      "|    explained_variance | 0.971         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0566       |\n",
      "|    mean_step_reward   | -0.0073224828 |\n",
      "|    n_updates          | 4804          |\n",
      "|    policyGradLoss     | -0.00481      |\n",
      "|    value_loss         | 0.00117       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 842          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 29           |\n",
      "|    total_timesteps    | 9854976      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004599221  |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.75         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0661      |\n",
      "|    mean_step_reward   | -0.008271469 |\n",
      "|    n_updates          | 4808         |\n",
      "|    policyGradLoss     | -0.00499     |\n",
      "|    value_loss         | 0.00163      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 810          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 40           |\n",
      "|    total_timesteps    | 9863168      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005987185  |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.836        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0682      |\n",
      "|    mean_step_reward   | -0.007125303 |\n",
      "|    n_updates          | 4812         |\n",
      "|    policyGradLoss     | -0.00972     |\n",
      "|    value_loss         | 0.00753      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 790          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 51           |\n",
      "|    total_timesteps    | 9871360      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0045760237 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.914        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0644      |\n",
      "|    mean_step_reward   | -0.00656097  |\n",
      "|    n_updates          | 4816         |\n",
      "|    policyGradLoss     | -0.00584     |\n",
      "|    value_loss         | 0.00506      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 784          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 62           |\n",
      "|    total_timesteps    | 9879552      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0042877253 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.926        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0643      |\n",
      "|    mean_step_reward   | -0.008162409 |\n",
      "|    n_updates          | 4820         |\n",
      "|    policyGradLoss     | -0.00683     |\n",
      "|    value_loss         | 0.000209     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 779           |\n",
      "|    iterations         | 7             |\n",
      "|    time_elapsed       | 73            |\n",
      "|    total_timesteps    | 9887744       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005370655   |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.898         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0653       |\n",
      "|    mean_step_reward   | -0.0066235177 |\n",
      "|    n_updates          | 4824          |\n",
      "|    policyGradLoss     | -0.00706      |\n",
      "|    value_loss         | 0.00685       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 768          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 85           |\n",
      "|    total_timesteps    | 9895936      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0040827896 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.935        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0642      |\n",
      "|    mean_step_reward   | -0.007266167 |\n",
      "|    n_updates          | 4828         |\n",
      "|    policyGradLoss     | -0.00651     |\n",
      "|    value_loss         | 0.00255      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 763          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 96           |\n",
      "|    total_timesteps    | 9904128      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0046064556 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.977        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0656      |\n",
      "|    mean_step_reward   | -0.00780489  |\n",
      "|    n_updates          | 4832         |\n",
      "|    policyGradLoss     | -0.00781     |\n",
      "|    value_loss         | 0.000263     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 764          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 107          |\n",
      "|    total_timesteps    | 9912320      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0051985425 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.872        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0695      |\n",
      "|    mean_step_reward   | -0.00714566  |\n",
      "|    n_updates          | 4836         |\n",
      "|    policyGradLoss     | -0.00903     |\n",
      "|    value_loss         | 0.00552      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 758           |\n",
      "|    iterations         | 11            |\n",
      "|    time_elapsed       | 118           |\n",
      "|    total_timesteps    | 9920512       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0051601585  |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.875         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0693       |\n",
      "|    mean_step_reward   | -0.0070777633 |\n",
      "|    n_updates          | 4840          |\n",
      "|    policyGradLoss     | -0.00792      |\n",
      "|    value_loss         | 0.00716       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 763           |\n",
      "|    iterations         | 12            |\n",
      "|    time_elapsed       | 128           |\n",
      "|    total_timesteps    | 9928704       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0041659684  |\n",
      "|    entropy_loss       | -2.17         |\n",
      "|    explained_variance | 0.949         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0681       |\n",
      "|    mean_step_reward   | -0.0078459475 |\n",
      "|    n_updates          | 4844          |\n",
      "|    policyGradLoss     | -0.00612      |\n",
      "|    value_loss         | 0.000554      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 758          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 140          |\n",
      "|    total_timesteps    | 9936896      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0045947116 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.951        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0689      |\n",
      "|    mean_step_reward   | -0.006541089 |\n",
      "|    n_updates          | 4848         |\n",
      "|    policyGradLoss     | -0.00691     |\n",
      "|    value_loss         | 0.0018       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 152          |\n",
      "|    total_timesteps    | 9945088      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004238031  |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.973        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0672      |\n",
      "|    mean_step_reward   | -0.008016302 |\n",
      "|    n_updates          | 4852         |\n",
      "|    policyGradLoss     | -0.00743     |\n",
      "|    value_loss         | 0.000563     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 757          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 162          |\n",
      "|    total_timesteps    | 9953280      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0042908974 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.994        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0721      |\n",
      "|    mean_step_reward   | -0.007366023 |\n",
      "|    n_updates          | 4856         |\n",
      "|    policyGradLoss     | -0.00922     |\n",
      "|    value_loss         | 0.000174     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 173          |\n",
      "|    total_timesteps    | 9961472      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0046857    |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.953        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0647      |\n",
      "|    mean_step_reward   | -0.006501144 |\n",
      "|    n_updates          | 4860         |\n",
      "|    policyGradLoss     | -0.0057      |\n",
      "|    value_loss         | 0.00355      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 755           |\n",
      "|    iterations         | 17            |\n",
      "|    time_elapsed       | 184           |\n",
      "|    total_timesteps    | 9969664       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0069618034  |\n",
      "|    entropy_loss       | -2.12         |\n",
      "|    explained_variance | 0.906         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0696       |\n",
      "|    mean_step_reward   | -0.0070018247 |\n",
      "|    n_updates          | 4864          |\n",
      "|    policyGradLoss     | -0.00969      |\n",
      "|    value_loss         | 0.00518       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 195          |\n",
      "|    total_timesteps    | 9977856      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0043915873 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.865        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0661      |\n",
      "|    mean_step_reward   | -0.007283831 |\n",
      "|    n_updates          | 4868         |\n",
      "|    policyGradLoss     | -0.00555     |\n",
      "|    value_loss         | 0.00289      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 19            |\n",
      "|    time_elapsed       | 207           |\n",
      "|    total_timesteps    | 9986048       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0055407835  |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.94          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0651       |\n",
      "|    mean_step_reward   | -0.0069262595 |\n",
      "|    n_updates          | 4872          |\n",
      "|    policyGradLoss     | -0.00551      |\n",
      "|    value_loss         | 0.0038        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 756           |\n",
      "|    iterations         | 20            |\n",
      "|    time_elapsed       | 216           |\n",
      "|    total_timesteps    | 9994240       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0040707453  |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.809         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0636       |\n",
      "|    mean_step_reward   | -0.0076264865 |\n",
      "|    n_updates          | 4876          |\n",
      "|    policyGradLoss     | -0.00627      |\n",
      "|    value_loss         | 0.00298       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 228          |\n",
      "|    total_timesteps    | 10002432     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038727403 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.943        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0653      |\n",
      "|    mean_step_reward   | -0.006931187 |\n",
      "|    n_updates          | 4880         |\n",
      "|    policyGradLoss     | -0.00509     |\n",
      "|    value_loss         | 0.00147      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 22            |\n",
      "|    time_elapsed       | 239           |\n",
      "|    total_timesteps    | 10010624      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0040694224  |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.982         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0661       |\n",
      "|    mean_step_reward   | -0.0071625877 |\n",
      "|    n_updates          | 4884          |\n",
      "|    policyGradLoss     | -0.00711      |\n",
      "|    value_loss         | 0.000824      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 23            |\n",
      "|    time_elapsed       | 250           |\n",
      "|    total_timesteps    | 10018816      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004426694   |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.987         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0612       |\n",
      "|    mean_step_reward   | -0.0069362107 |\n",
      "|    n_updates          | 4888          |\n",
      "|    policyGradLoss     | -0.00773      |\n",
      "|    value_loss         | 0.00107       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 24            |\n",
      "|    time_elapsed       | 261           |\n",
      "|    total_timesteps    | 10027008      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005135311   |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.992         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0731       |\n",
      "|    mean_step_reward   | -0.0076814517 |\n",
      "|    n_updates          | 4892          |\n",
      "|    policyGradLoss     | -0.00914      |\n",
      "|    value_loss         | 9.73e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 271          |\n",
      "|    total_timesteps    | 10035200     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0044263625 |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.98         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0691      |\n",
      "|    mean_step_reward   | -0.006648247 |\n",
      "|    n_updates          | 4896         |\n",
      "|    policyGradLoss     | -0.00677     |\n",
      "|    value_loss         | 0.00168      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 283          |\n",
      "|    total_timesteps    | 10043392     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0050694034 |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.99         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0673      |\n",
      "|    mean_step_reward   | -0.007790434 |\n",
      "|    n_updates          | 4900         |\n",
      "|    policyGradLoss     | -0.00867     |\n",
      "|    value_loss         | 0.000252     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 295          |\n",
      "|    total_timesteps    | 10051584     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0045253867 |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.991        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0691      |\n",
      "|    mean_step_reward   | -0.007339203 |\n",
      "|    n_updates          | 4904         |\n",
      "|    policyGradLoss     | -0.00737     |\n",
      "|    value_loss         | 0.000149     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 305          |\n",
      "|    total_timesteps    | 10059776     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005110103  |\n",
      "|    entropy_loss       | -2.09        |\n",
      "|    explained_variance | 0.958        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.065       |\n",
      "|    mean_step_reward   | -0.007080069 |\n",
      "|    n_updates          | 4908         |\n",
      "|    policyGradLoss     | -0.0069      |\n",
      "|    value_loss         | 0.00218      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 316          |\n",
      "|    total_timesteps    | 10067968     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0058082156 |\n",
      "|    entropy_loss       | -2.09        |\n",
      "|    explained_variance | 0.865        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0621      |\n",
      "|    mean_step_reward   | -0.007293776 |\n",
      "|    n_updates          | 4912         |\n",
      "|    policyGradLoss     | -0.00868     |\n",
      "|    value_loss         | 0.00545      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 30            |\n",
      "|    time_elapsed       | 327           |\n",
      "|    total_timesteps    | 10076160      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005822338   |\n",
      "|    entropy_loss       | -2.11         |\n",
      "|    explained_variance | 0.943         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0642       |\n",
      "|    mean_step_reward   | -0.0072132796 |\n",
      "|    n_updates          | 4916          |\n",
      "|    policyGradLoss     | -0.00642      |\n",
      "|    value_loss         | 0.00154       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 31            |\n",
      "|    time_elapsed       | 338           |\n",
      "|    total_timesteps    | 10084352      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005914861   |\n",
      "|    entropy_loss       | -2.1          |\n",
      "|    explained_variance | 0.935         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0673       |\n",
      "|    mean_step_reward   | -0.0072879326 |\n",
      "|    n_updates          | 4920          |\n",
      "|    policyGradLoss     | -0.00654      |\n",
      "|    value_loss         | 0.00315       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 32            |\n",
      "|    time_elapsed       | 350           |\n",
      "|    total_timesteps    | 10092544      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.006057703   |\n",
      "|    entropy_loss       | -2.12         |\n",
      "|    explained_variance | 0.987         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0652       |\n",
      "|    mean_step_reward   | -0.0070401775 |\n",
      "|    n_updates          | 4924          |\n",
      "|    policyGradLoss     | -0.00664      |\n",
      "|    value_loss         | 0.000343      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 33            |\n",
      "|    time_elapsed       | 359           |\n",
      "|    total_timesteps    | 10100736      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004107247   |\n",
      "|    entropy_loss       | -2.11         |\n",
      "|    explained_variance | 0.988         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0674       |\n",
      "|    mean_step_reward   | -0.0074094264 |\n",
      "|    n_updates          | 4928          |\n",
      "|    policyGradLoss     | -0.0071       |\n",
      "|    value_loss         | 0.000357      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 371          |\n",
      "|    total_timesteps    | 10108928     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0040282663 |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.958        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0606      |\n",
      "|    mean_step_reward   | -0.007214976 |\n",
      "|    n_updates          | 4932         |\n",
      "|    policyGradLoss     | -0.00449     |\n",
      "|    value_loss         | 0.00147      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 35            |\n",
      "|    time_elapsed       | 382           |\n",
      "|    total_timesteps    | 10117120      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0054808445  |\n",
      "|    entropy_loss       | -2.1          |\n",
      "|    explained_variance | 0.883         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0669       |\n",
      "|    mean_step_reward   | -0.0071319123 |\n",
      "|    n_updates          | 4936          |\n",
      "|    policyGradLoss     | -0.00645      |\n",
      "|    value_loss         | 0.00514       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 36            |\n",
      "|    time_elapsed       | 393           |\n",
      "|    total_timesteps    | 10125312      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0047386475  |\n",
      "|    entropy_loss       | -2.11         |\n",
      "|    explained_variance | 0.977         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0621       |\n",
      "|    mean_step_reward   | -0.0073399898 |\n",
      "|    n_updates          | 4940          |\n",
      "|    policyGradLoss     | -0.0065       |\n",
      "|    value_loss         | 0.000603      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 405          |\n",
      "|    total_timesteps    | 10133504     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004783142  |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.94         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0636      |\n",
      "|    mean_step_reward   | -0.007395591 |\n",
      "|    n_updates          | 4944         |\n",
      "|    policyGradLoss     | -0.00706     |\n",
      "|    value_loss         | 0.00299      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 415          |\n",
      "|    total_timesteps    | 10141696     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005225027  |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.938        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0623      |\n",
      "|    mean_step_reward   | -0.006573376 |\n",
      "|    n_updates          | 4948         |\n",
      "|    policyGradLoss     | -0.0066      |\n",
      "|    value_loss         | 0.00379      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 426          |\n",
      "|    total_timesteps    | 10149888     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0056016077 |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.964        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0673      |\n",
      "|    mean_step_reward   | -0.007510679 |\n",
      "|    n_updates          | 4952         |\n",
      "|    policyGradLoss     | -0.00731     |\n",
      "|    value_loss         | 0.000987     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 438          |\n",
      "|    total_timesteps    | 10158080     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0040715095 |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.977        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0552      |\n",
      "|    mean_step_reward   | -0.007834084 |\n",
      "|    n_updates          | 4956         |\n",
      "|    policyGradLoss     | -0.00529     |\n",
      "|    value_loss         | 0.000552     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_30.zip\n",
      "[EVAL] Mean Return: -20.932, Best Return: -17.522\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_30_-20.93.mp4\n",
      "\n",
      "=== Round 32 | Learn 327680 steps (Total trained: 10158080) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1252     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 10166272 |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 896          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 10174464     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0047856756 |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.993        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0656      |\n",
      "|    mean_step_reward   | -0.006960174 |\n",
      "|    n_updates          | 4964         |\n",
      "|    policyGradLoss     | -0.00758     |\n",
      "|    value_loss         | 0.000282     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 837          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 29           |\n",
      "|    total_timesteps    | 10182656     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004620905  |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.92         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0622      |\n",
      "|    mean_step_reward   | -0.007443999 |\n",
      "|    n_updates          | 4968         |\n",
      "|    policyGradLoss     | -0.00534     |\n",
      "|    value_loss         | 0.0031       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 822          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 39           |\n",
      "|    total_timesteps    | 10190848     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0047482606 |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.981        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0644      |\n",
      "|    mean_step_reward   | -0.006713672 |\n",
      "|    n_updates          | 4972         |\n",
      "|    policyGradLoss     | -0.00614     |\n",
      "|    value_loss         | 0.000779     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 797           |\n",
      "|    iterations         | 5             |\n",
      "|    time_elapsed       | 51            |\n",
      "|    total_timesteps    | 10199040      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005139414   |\n",
      "|    entropy_loss       | -2.1          |\n",
      "|    explained_variance | 0.915         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0632       |\n",
      "|    mean_step_reward   | -0.0077757193 |\n",
      "|    n_updates          | 4976          |\n",
      "|    policyGradLoss     | -0.00567      |\n",
      "|    value_loss         | 0.00168       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 796           |\n",
      "|    iterations         | 6             |\n",
      "|    time_elapsed       | 61            |\n",
      "|    total_timesteps    | 10207232      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004491083   |\n",
      "|    entropy_loss       | -2.11         |\n",
      "|    explained_variance | 0.947         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.064        |\n",
      "|    mean_step_reward   | -0.0076010786 |\n",
      "|    n_updates          | 4980          |\n",
      "|    policyGradLoss     | -0.00755      |\n",
      "|    value_loss         | 0.00172       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 786           |\n",
      "|    iterations         | 7             |\n",
      "|    time_elapsed       | 72            |\n",
      "|    total_timesteps    | 10215424      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005593135   |\n",
      "|    entropy_loss       | -2.1          |\n",
      "|    explained_variance | 0.975         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0678       |\n",
      "|    mean_step_reward   | -0.0066407984 |\n",
      "|    n_updates          | 4984          |\n",
      "|    policyGradLoss     | -0.00752      |\n",
      "|    value_loss         | 0.00108       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 775           |\n",
      "|    iterations         | 8             |\n",
      "|    time_elapsed       | 84            |\n",
      "|    total_timesteps    | 10223616      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0061257496  |\n",
      "|    entropy_loss       | -2.09         |\n",
      "|    explained_variance | 0.868         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0618       |\n",
      "|    mean_step_reward   | -0.0070251888 |\n",
      "|    n_updates          | 4988          |\n",
      "|    policyGradLoss     | -0.0103       |\n",
      "|    value_loss         | 0.00498       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 785          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 93           |\n",
      "|    total_timesteps    | 10231808     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004415339  |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.903        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.07        |\n",
      "|    mean_step_reward   | -0.008029918 |\n",
      "|    n_updates          | 4992         |\n",
      "|    policyGradLoss     | -0.00481     |\n",
      "|    value_loss         | 0.00171      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 775           |\n",
      "|    iterations         | 10            |\n",
      "|    time_elapsed       | 105           |\n",
      "|    total_timesteps    | 10240000      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.007255989   |\n",
      "|    entropy_loss       | -2.1          |\n",
      "|    explained_variance | 0.906         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.064        |\n",
      "|    mean_step_reward   | -0.0062930393 |\n",
      "|    n_updates          | 4996          |\n",
      "|    policyGradLoss     | -0.0111       |\n",
      "|    value_loss         | 0.00586       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 770          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 116          |\n",
      "|    total_timesteps    | 10248192     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0046669682 |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.956        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0666      |\n",
      "|    mean_step_reward   | -0.007874759 |\n",
      "|    n_updates          | 5000         |\n",
      "|    policyGradLoss     | -0.00679     |\n",
      "|    value_loss         | 0.000704     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 768           |\n",
      "|    iterations         | 12            |\n",
      "|    time_elapsed       | 127           |\n",
      "|    total_timesteps    | 10256384      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0054708924  |\n",
      "|    entropy_loss       | -2.12         |\n",
      "|    explained_variance | 0.859         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0596       |\n",
      "|    mean_step_reward   | -0.0075292634 |\n",
      "|    n_updates          | 5004          |\n",
      "|    policyGradLoss     | -0.00787      |\n",
      "|    value_loss         | 0.00417       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 762          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 139          |\n",
      "|    total_timesteps    | 10264576     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0051907822 |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.932        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0674      |\n",
      "|    mean_step_reward   | -0.007005028 |\n",
      "|    n_updates          | 5008         |\n",
      "|    policyGradLoss     | -0.00715     |\n",
      "|    value_loss         | 0.00401      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 766           |\n",
      "|    iterations         | 14            |\n",
      "|    time_elapsed       | 149           |\n",
      "|    total_timesteps    | 10272768      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005707563   |\n",
      "|    entropy_loss       | -2.11         |\n",
      "|    explained_variance | 0.741         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0663       |\n",
      "|    mean_step_reward   | -0.0074785682 |\n",
      "|    n_updates          | 5012          |\n",
      "|    policyGradLoss     | -0.00814      |\n",
      "|    value_loss         | 0.006         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 761          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 161          |\n",
      "|    total_timesteps    | 10280960     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0043631783 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.812        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0649      |\n",
      "|    mean_step_reward   | -0.007615039 |\n",
      "|    n_updates          | 5016         |\n",
      "|    policyGradLoss     | -0.0071      |\n",
      "|    value_loss         | 0.00558      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 757           |\n",
      "|    iterations         | 16            |\n",
      "|    time_elapsed       | 173           |\n",
      "|    total_timesteps    | 10289152      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005131089   |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.897         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0622       |\n",
      "|    mean_step_reward   | -0.0064528007 |\n",
      "|    n_updates          | 5020          |\n",
      "|    policyGradLoss     | -0.00874      |\n",
      "|    value_loss         | 0.00671       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 758           |\n",
      "|    iterations         | 17            |\n",
      "|    time_elapsed       | 183           |\n",
      "|    total_timesteps    | 10297344      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0051053856  |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.956         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0651       |\n",
      "|    mean_step_reward   | -0.0077200485 |\n",
      "|    n_updates          | 5024          |\n",
      "|    policyGradLoss     | -0.00604      |\n",
      "|    value_loss         | 0.000671      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 195          |\n",
      "|    total_timesteps    | 10305536     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005163696  |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.82         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0673      |\n",
      "|    mean_step_reward   | -0.007867287 |\n",
      "|    n_updates          | 5028         |\n",
      "|    policyGradLoss     | -0.00752     |\n",
      "|    value_loss         | 0.00209      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 205          |\n",
      "|    total_timesteps    | 10313728     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0054113735 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.868        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0675      |\n",
      "|    mean_step_reward   | -0.007410622 |\n",
      "|    n_updates          | 5032         |\n",
      "|    policyGradLoss     | -0.00749     |\n",
      "|    value_loss         | 0.00584      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 216          |\n",
      "|    total_timesteps    | 10321920     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0051708147 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.875        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0656      |\n",
      "|    mean_step_reward   | -0.006202464 |\n",
      "|    n_updates          | 5036         |\n",
      "|    policyGradLoss     | -0.00766     |\n",
      "|    value_loss         | 0.00737      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 228          |\n",
      "|    total_timesteps    | 10330112     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0039093355 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.811        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0617      |\n",
      "|    mean_step_reward   | -0.008270813 |\n",
      "|    n_updates          | 5040         |\n",
      "|    policyGradLoss     | -0.00602     |\n",
      "|    value_loss         | 0.000615     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 238          |\n",
      "|    total_timesteps    | 10338304     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0076858345 |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.907        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0637      |\n",
      "|    mean_step_reward   | -0.006243934 |\n",
      "|    n_updates          | 5044         |\n",
      "|    policyGradLoss     | -0.01        |\n",
      "|    value_loss         | 0.00964      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 249          |\n",
      "|    total_timesteps    | 10346496     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004323571  |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.925        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0661      |\n",
      "|    mean_step_reward   | -0.006338621 |\n",
      "|    n_updates          | 5048         |\n",
      "|    policyGradLoss     | -0.00601     |\n",
      "|    value_loss         | 0.00403      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 260          |\n",
      "|    total_timesteps    | 10354688     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.007640805  |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.971        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.071       |\n",
      "|    mean_step_reward   | -0.007749593 |\n",
      "|    n_updates          | 5052         |\n",
      "|    policyGradLoss     | -0.00876     |\n",
      "|    value_loss         | 0.000492     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 271          |\n",
      "|    total_timesteps    | 10362880     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005165608  |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.984        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0635      |\n",
      "|    mean_step_reward   | -0.007205962 |\n",
      "|    n_updates          | 5056         |\n",
      "|    policyGradLoss     | -0.00614     |\n",
      "|    value_loss         | 0.000669     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 281          |\n",
      "|    total_timesteps    | 10371072     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0056216987 |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.905        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0637      |\n",
      "|    mean_step_reward   | -0.006972508 |\n",
      "|    n_updates          | 5060         |\n",
      "|    policyGradLoss     | -0.00741     |\n",
      "|    value_loss         | 0.00492      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 293          |\n",
      "|    total_timesteps    | 10379264     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0057182135 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.937        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0723      |\n",
      "|    mean_step_reward   | -0.008200203 |\n",
      "|    n_updates          | 5064         |\n",
      "|    policyGradLoss     | -0.0116      |\n",
      "|    value_loss         | 9.84e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 304          |\n",
      "|    total_timesteps    | 10387456     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.006168788  |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.873        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0661      |\n",
      "|    mean_step_reward   | -0.007119446 |\n",
      "|    n_updates          | 5068         |\n",
      "|    policyGradLoss     | -0.00966     |\n",
      "|    value_loss         | 0.00927      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 315          |\n",
      "|    total_timesteps    | 10395648     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0041124765 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.958        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0679      |\n",
      "|    mean_step_reward   | -0.007140072 |\n",
      "|    n_updates          | 5072         |\n",
      "|    policyGradLoss     | -0.00836     |\n",
      "|    value_loss         | 0.00137      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 326          |\n",
      "|    total_timesteps    | 10403840     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004218352  |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.962        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0739      |\n",
      "|    mean_step_reward   | -0.007562616 |\n",
      "|    n_updates          | 5076         |\n",
      "|    policyGradLoss     | -0.00796     |\n",
      "|    value_loss         | 0.0011       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 337          |\n",
      "|    total_timesteps    | 10412032     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0050767814 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.927        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0665      |\n",
      "|    mean_step_reward   | -0.007154241 |\n",
      "|    n_updates          | 5080         |\n",
      "|    policyGradLoss     | -0.00701     |\n",
      "|    value_loss         | 0.00311      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 347          |\n",
      "|    total_timesteps    | 10420224     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005063831  |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.935        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0644      |\n",
      "|    mean_step_reward   | -0.006865139 |\n",
      "|    n_updates          | 5084         |\n",
      "|    policyGradLoss     | -0.00602     |\n",
      "|    value_loss         | 0.00416      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 359          |\n",
      "|    total_timesteps    | 10428416     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0047563    |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.707        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0775      |\n",
      "|    mean_step_reward   | -0.008078081 |\n",
      "|    n_updates          | 5088         |\n",
      "|    policyGradLoss     | -0.0143      |\n",
      "|    value_loss         | 5.18e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 34            |\n",
      "|    time_elapsed       | 370           |\n",
      "|    total_timesteps    | 10436608      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0046655624  |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.946         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0596       |\n",
      "|    mean_step_reward   | -0.0075165904 |\n",
      "|    n_updates          | 5092          |\n",
      "|    policyGradLoss     | -0.00565      |\n",
      "|    value_loss         | 0.00242       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 35            |\n",
      "|    time_elapsed       | 381           |\n",
      "|    total_timesteps    | 10444800      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.009691456   |\n",
      "|    entropy_loss       | -2.12         |\n",
      "|    explained_variance | 0.922         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0642       |\n",
      "|    mean_step_reward   | -0.0063320864 |\n",
      "|    n_updates          | 5096          |\n",
      "|    policyGradLoss     | -0.00648      |\n",
      "|    value_loss         | 0.00615       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 392          |\n",
      "|    total_timesteps    | 10452992     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003729877  |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.961        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0524      |\n",
      "|    mean_step_reward   | -0.007203254 |\n",
      "|    n_updates          | 5100         |\n",
      "|    policyGradLoss     | -0.00514     |\n",
      "|    value_loss         | 0.00121      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 403          |\n",
      "|    total_timesteps    | 10461184     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005986036  |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.888        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0642      |\n",
      "|    mean_step_reward   | -0.007275451 |\n",
      "|    n_updates          | 5104         |\n",
      "|    policyGradLoss     | -0.00569     |\n",
      "|    value_loss         | 0.00565      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 38            |\n",
      "|    time_elapsed       | 414           |\n",
      "|    total_timesteps    | 10469376      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0054132016  |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.939         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0658       |\n",
      "|    mean_step_reward   | -0.0068409806 |\n",
      "|    n_updates          | 5108          |\n",
      "|    policyGradLoss     | -0.00607      |\n",
      "|    value_loss         | 0.00389       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 426          |\n",
      "|    total_timesteps    | 10477568     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0050847568 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.169        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0803      |\n",
      "|    mean_step_reward   | -0.008063282 |\n",
      "|    n_updates          | 5112         |\n",
      "|    policyGradLoss     | -0.017       |\n",
      "|    value_loss         | 3.32e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 435          |\n",
      "|    total_timesteps    | 10485760     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0055059325 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.894        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0631      |\n",
      "|    mean_step_reward   | -0.007365234 |\n",
      "|    n_updates          | 5116         |\n",
      "|    policyGradLoss     | -0.00856     |\n",
      "|    value_loss         | 0.00548      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_31.zip\n",
      "[EVAL] Mean Return: -19.804, Best Return: -16.420\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_31_-19.80.mp4\n",
      "\n",
      "=== Round 33 | Learn 327680 steps (Total trained: 10485760) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1012     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 10493952 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 834           |\n",
      "|    iterations         | 2             |\n",
      "|    time_elapsed       | 19            |\n",
      "|    total_timesteps    | 10502144      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0038890382  |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.967         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.059        |\n",
      "|    mean_step_reward   | -0.0071098404 |\n",
      "|    n_updates          | 5124          |\n",
      "|    policyGradLoss     | -0.00471      |\n",
      "|    value_loss         | 0.00141       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 826           |\n",
      "|    iterations         | 3             |\n",
      "|    time_elapsed       | 29            |\n",
      "|    total_timesteps    | 10510336      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004601538   |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.955         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0657       |\n",
      "|    mean_step_reward   | -0.0069501577 |\n",
      "|    n_updates          | 5128          |\n",
      "|    policyGradLoss     | -0.00706      |\n",
      "|    value_loss         | 0.00282       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 796          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 41           |\n",
      "|    total_timesteps    | 10518528     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0042900387 |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.971        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0708      |\n",
      "|    mean_step_reward   | -0.007002329 |\n",
      "|    n_updates          | 5132         |\n",
      "|    policyGradLoss     | -0.00756     |\n",
      "|    value_loss         | 0.00272      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 791           |\n",
      "|    iterations         | 5             |\n",
      "|    time_elapsed       | 51            |\n",
      "|    total_timesteps    | 10526720      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0054964893  |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.985         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0822       |\n",
      "|    mean_step_reward   | -0.0076768333 |\n",
      "|    n_updates          | 5136          |\n",
      "|    policyGradLoss     | -0.0173       |\n",
      "|    value_loss         | 3.67e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 782          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 62           |\n",
      "|    total_timesteps    | 10534912     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.007334766  |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.84         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0661      |\n",
      "|    mean_step_reward   | -0.007293242 |\n",
      "|    n_updates          | 5140         |\n",
      "|    policyGradLoss     | -0.0091      |\n",
      "|    value_loss         | 0.00745      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 770           |\n",
      "|    iterations         | 7             |\n",
      "|    time_elapsed       | 74            |\n",
      "|    total_timesteps    | 10543104      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.00592425    |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.898         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0703       |\n",
      "|    mean_step_reward   | -0.0071276077 |\n",
      "|    n_updates          | 5144          |\n",
      "|    policyGradLoss     | -0.00846      |\n",
      "|    value_loss         | 0.00394       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 778           |\n",
      "|    iterations         | 8             |\n",
      "|    time_elapsed       | 84            |\n",
      "|    total_timesteps    | 10551296      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0056488253  |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.929         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0684       |\n",
      "|    mean_step_reward   | -0.0069683576 |\n",
      "|    n_updates          | 5148          |\n",
      "|    policyGradLoss     | -0.00912      |\n",
      "|    value_loss         | 0.00445       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 769           |\n",
      "|    iterations         | 9             |\n",
      "|    time_elapsed       | 95            |\n",
      "|    total_timesteps    | 10559488      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005017621   |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.943         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0657       |\n",
      "|    mean_step_reward   | -0.0074327174 |\n",
      "|    n_updates          | 5152          |\n",
      "|    policyGradLoss     | -0.00727      |\n",
      "|    value_loss         | 0.00189       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 764           |\n",
      "|    iterations         | 10            |\n",
      "|    time_elapsed       | 107           |\n",
      "|    total_timesteps    | 10567680      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004863511   |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.958         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0605       |\n",
      "|    mean_step_reward   | -0.0071126996 |\n",
      "|    n_updates          | 5156          |\n",
      "|    policyGradLoss     | -0.00548      |\n",
      "|    value_loss         | 0.00254       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 765           |\n",
      "|    iterations         | 11            |\n",
      "|    time_elapsed       | 117           |\n",
      "|    total_timesteps    | 10575872      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005175371   |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.908         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0685       |\n",
      "|    mean_step_reward   | -0.0076679573 |\n",
      "|    n_updates          | 5160          |\n",
      "|    policyGradLoss     | -0.00615      |\n",
      "|    value_loss         | 0.00124       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 760           |\n",
      "|    iterations         | 12            |\n",
      "|    time_elapsed       | 129           |\n",
      "|    total_timesteps    | 10584064      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003690868   |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.927         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0591       |\n",
      "|    mean_step_reward   | -0.0072586294 |\n",
      "|    n_updates          | 5164          |\n",
      "|    policyGradLoss     | -0.00751      |\n",
      "|    value_loss         | 0.0035        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 763           |\n",
      "|    iterations         | 13            |\n",
      "|    time_elapsed       | 139           |\n",
      "|    total_timesteps    | 10592256      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0048338925  |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.976         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0718       |\n",
      "|    mean_step_reward   | -0.0071870806 |\n",
      "|    n_updates          | 5168          |\n",
      "|    policyGradLoss     | -0.00715      |\n",
      "|    value_loss         | 0.000657      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 759           |\n",
      "|    iterations         | 14            |\n",
      "|    time_elapsed       | 150           |\n",
      "|    total_timesteps    | 10600448      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0059876395  |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.851         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0684       |\n",
      "|    mean_step_reward   | -0.0069485568 |\n",
      "|    n_updates          | 5172          |\n",
      "|    policyGradLoss     | -0.00972      |\n",
      "|    value_loss         | 0.00778       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 162          |\n",
      "|    total_timesteps    | 10608640     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0044466527 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.969        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0666      |\n",
      "|    mean_step_reward   | -0.007451499 |\n",
      "|    n_updates          | 5176         |\n",
      "|    policyGradLoss     | -0.00576     |\n",
      "|    value_loss         | 0.000577     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 759          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 172          |\n",
      "|    total_timesteps    | 10616832     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0049011298 |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.94         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0665      |\n",
      "|    mean_step_reward   | -0.006938909 |\n",
      "|    n_updates          | 5180         |\n",
      "|    policyGradLoss     | -0.00722     |\n",
      "|    value_loss         | 0.00474      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 184          |\n",
      "|    total_timesteps    | 10625024     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.006046543  |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.715        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0704      |\n",
      "|    mean_step_reward   | -0.007451877 |\n",
      "|    n_updates          | 5184         |\n",
      "|    policyGradLoss     | -0.0087      |\n",
      "|    value_loss         | 0.00736      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 195          |\n",
      "|    total_timesteps    | 10633216     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0053377748 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.926        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0687      |\n",
      "|    mean_step_reward   | -0.007075992 |\n",
      "|    n_updates          | 5188         |\n",
      "|    policyGradLoss     | -0.00829     |\n",
      "|    value_loss         | 0.00432      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 755           |\n",
      "|    iterations         | 19            |\n",
      "|    time_elapsed       | 205           |\n",
      "|    total_timesteps    | 10641408      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0055145808  |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.892         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0681       |\n",
      "|    mean_step_reward   | -0.0065851617 |\n",
      "|    n_updates          | 5192          |\n",
      "|    policyGradLoss     | -0.00944      |\n",
      "|    value_loss         | 0.00744       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 217          |\n",
      "|    total_timesteps    | 10649600     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005517125  |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.908        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0641      |\n",
      "|    mean_step_reward   | -0.007027517 |\n",
      "|    n_updates          | 5196         |\n",
      "|    policyGradLoss     | -0.00785     |\n",
      "|    value_loss         | 0.00331      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 227          |\n",
      "|    total_timesteps    | 10657792     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004253431  |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.935        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0669      |\n",
      "|    mean_step_reward   | -0.008177105 |\n",
      "|    n_updates          | 5200         |\n",
      "|    policyGradLoss     | -0.0065      |\n",
      "|    value_loss         | 0.000578     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 239          |\n",
      "|    total_timesteps    | 10665984     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0053757736 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.965        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0567      |\n",
      "|    mean_step_reward   | -0.006543153 |\n",
      "|    n_updates          | 5204         |\n",
      "|    policyGradLoss     | -0.00693     |\n",
      "|    value_loss         | 0.00157      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 250          |\n",
      "|    total_timesteps    | 10674176     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0042089275 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.979        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0688      |\n",
      "|    mean_step_reward   | -0.00740226  |\n",
      "|    n_updates          | 5208         |\n",
      "|    policyGradLoss     | -0.006       |\n",
      "|    value_loss         | 0.000441     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 261          |\n",
      "|    total_timesteps    | 10682368     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00468216   |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.943        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0637      |\n",
      "|    mean_step_reward   | -0.007224645 |\n",
      "|    n_updates          | 5212         |\n",
      "|    policyGradLoss     | -0.00602     |\n",
      "|    value_loss         | 0.00285      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 25            |\n",
      "|    time_elapsed       | 272           |\n",
      "|    total_timesteps    | 10690560      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.006439741   |\n",
      "|    entropy_loss       | -2.12         |\n",
      "|    explained_variance | 0.92          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0689       |\n",
      "|    mean_step_reward   | -0.0067055896 |\n",
      "|    n_updates          | 5216          |\n",
      "|    policyGradLoss     | -0.0087       |\n",
      "|    value_loss         | 0.00691       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 26            |\n",
      "|    time_elapsed       | 283           |\n",
      "|    total_timesteps    | 10698752      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0052091186  |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.961         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0611       |\n",
      "|    mean_step_reward   | -0.0055150604 |\n",
      "|    n_updates          | 5220          |\n",
      "|    policyGradLoss     | -0.00709      |\n",
      "|    value_loss         | 0.0045        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 27            |\n",
      "|    time_elapsed       | 294           |\n",
      "|    total_timesteps    | 10706944      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0041798158  |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.972         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0678       |\n",
      "|    mean_step_reward   | -0.0077664666 |\n",
      "|    n_updates          | 5224          |\n",
      "|    policyGradLoss     | -0.0072       |\n",
      "|    value_loss         | 0.000619      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 28            |\n",
      "|    time_elapsed       | 305           |\n",
      "|    total_timesteps    | 10715136      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005004285   |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.978         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.066        |\n",
      "|    mean_step_reward   | -0.0072337096 |\n",
      "|    n_updates          | 5228          |\n",
      "|    policyGradLoss     | -0.00775      |\n",
      "|    value_loss         | 0.00101       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 29            |\n",
      "|    time_elapsed       | 315           |\n",
      "|    total_timesteps    | 10723328      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0071732095  |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.912         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0635       |\n",
      "|    mean_step_reward   | -0.0072521637 |\n",
      "|    n_updates          | 5232          |\n",
      "|    policyGradLoss     | -0.00718      |\n",
      "|    value_loss         | 0.00234       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 30            |\n",
      "|    time_elapsed       | 327           |\n",
      "|    total_timesteps    | 10731520      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0045451815  |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.942         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0626       |\n",
      "|    mean_step_reward   | -0.0075656828 |\n",
      "|    n_updates          | 5236          |\n",
      "|    policyGradLoss     | -0.0053       |\n",
      "|    value_loss         | 0.00146       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 31            |\n",
      "|    time_elapsed       | 338           |\n",
      "|    total_timesteps    | 10739712      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0053410456  |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.959         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.067        |\n",
      "|    mean_step_reward   | -0.0071840743 |\n",
      "|    n_updates          | 5240          |\n",
      "|    policyGradLoss     | -0.00723      |\n",
      "|    value_loss         | 0.002         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 32            |\n",
      "|    time_elapsed       | 349           |\n",
      "|    total_timesteps    | 10747904      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0054389588  |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.943         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.065        |\n",
      "|    mean_step_reward   | -0.0068233954 |\n",
      "|    n_updates          | 5244          |\n",
      "|    policyGradLoss     | -0.00854      |\n",
      "|    value_loss         | 0.00329       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 361          |\n",
      "|    total_timesteps    | 10756096     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005582523  |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.965        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0606      |\n",
      "|    mean_step_reward   | -0.007500493 |\n",
      "|    n_updates          | 5248         |\n",
      "|    policyGradLoss     | -0.00674     |\n",
      "|    value_loss         | 0.000832     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 371          |\n",
      "|    total_timesteps    | 10764288     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0048031537 |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.982        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0696      |\n",
      "|    mean_step_reward   | -0.006966393 |\n",
      "|    n_updates          | 5252         |\n",
      "|    policyGradLoss     | -0.00656     |\n",
      "|    value_loss         | 0.000624     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 382          |\n",
      "|    total_timesteps    | 10772480     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00787339   |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.835        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0639      |\n",
      "|    mean_step_reward   | -0.007451413 |\n",
      "|    n_updates          | 5256         |\n",
      "|    policyGradLoss     | -0.00872     |\n",
      "|    value_loss         | 0.00432      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 747           |\n",
      "|    iterations         | 36            |\n",
      "|    time_elapsed       | 394           |\n",
      "|    total_timesteps    | 10780672      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0049644867  |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.94          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0644       |\n",
      "|    mean_step_reward   | -0.0074332193 |\n",
      "|    n_updates          | 5260          |\n",
      "|    policyGradLoss     | -0.00633      |\n",
      "|    value_loss         | 0.00117       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 37            |\n",
      "|    time_elapsed       | 404           |\n",
      "|    total_timesteps    | 10788864      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004616555   |\n",
      "|    entropy_loss       | -2.12         |\n",
      "|    explained_variance | 0.989         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0672       |\n",
      "|    mean_step_reward   | -0.0068511097 |\n",
      "|    n_updates          | 5264          |\n",
      "|    policyGradLoss     | -0.00694      |\n",
      "|    value_loss         | 0.000516      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 415          |\n",
      "|    total_timesteps    | 10797056     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00529026   |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.892        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.065       |\n",
      "|    mean_step_reward   | -0.006822462 |\n",
      "|    n_updates          | 5268         |\n",
      "|    policyGradLoss     | -0.00786     |\n",
      "|    value_loss         | 0.00607      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 426          |\n",
      "|    total_timesteps    | 10805248     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0045716823 |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.925        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0621      |\n",
      "|    mean_step_reward   | -0.007352416 |\n",
      "|    n_updates          | 5272         |\n",
      "|    policyGradLoss     | -0.00599     |\n",
      "|    value_loss         | 0.00191      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 437          |\n",
      "|    total_timesteps    | 10813440     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0054880264 |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.942        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0647      |\n",
      "|    mean_step_reward   | -0.007554128 |\n",
      "|    n_updates          | 5276         |\n",
      "|    policyGradLoss     | -0.00785     |\n",
      "|    value_loss         | 0.00182      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_32.zip\n",
      "[EVAL] Mean Return: -121.385, Best Return: -119.932\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_32_-121.39.mp4\n",
      "\n",
      "=== Round 34 | Learn 327680 steps (Total trained: 10813440) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 984      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 10821632 |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 881          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 10829824     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0050168196 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.836        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0652      |\n",
      "|    mean_step_reward   | -0.00820215  |\n",
      "|    n_updates          | 5284         |\n",
      "|    policyGradLoss     | -0.00652     |\n",
      "|    value_loss         | 0.000846     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 818           |\n",
      "|    iterations         | 3             |\n",
      "|    time_elapsed       | 30            |\n",
      "|    total_timesteps    | 10838016      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0067874333  |\n",
      "|    entropy_loss       | -2.11         |\n",
      "|    explained_variance | 0.795         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0655       |\n",
      "|    mean_step_reward   | -0.0066460725 |\n",
      "|    n_updates          | 5288          |\n",
      "|    policyGradLoss     | -0.00526      |\n",
      "|    value_loss         | 0.00971       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 787          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 41           |\n",
      "|    total_timesteps    | 10846208     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0065121693 |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.866        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.067       |\n",
      "|    mean_step_reward   | -0.007647605 |\n",
      "|    n_updates          | 5292         |\n",
      "|    policyGradLoss     | -0.00546     |\n",
      "|    value_loss         | 0.00616      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 798           |\n",
      "|    iterations         | 5             |\n",
      "|    time_elapsed       | 51            |\n",
      "|    total_timesteps    | 10854400      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0063021793  |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.835         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0612       |\n",
      "|    mean_step_reward   | -0.0063299467 |\n",
      "|    n_updates          | 5296          |\n",
      "|    policyGradLoss     | -0.00501      |\n",
      "|    value_loss         | 0.00844       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 780           |\n",
      "|    iterations         | 6             |\n",
      "|    time_elapsed       | 62            |\n",
      "|    total_timesteps    | 10862592      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0048047216  |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.932         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0658       |\n",
      "|    mean_step_reward   | -0.0075207176 |\n",
      "|    n_updates          | 5300          |\n",
      "|    policyGradLoss     | -0.00661      |\n",
      "|    value_loss         | 0.00185       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 774           |\n",
      "|    iterations         | 7             |\n",
      "|    time_elapsed       | 74            |\n",
      "|    total_timesteps    | 10870784      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004185628   |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.917         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0637       |\n",
      "|    mean_step_reward   | -0.0076496373 |\n",
      "|    n_updates          | 5304          |\n",
      "|    policyGradLoss     | -0.00382      |\n",
      "|    value_loss         | 0.00242       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 773          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 84           |\n",
      "|    total_timesteps    | 10878976     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0057595074 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.826        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0662      |\n",
      "|    mean_step_reward   | -0.007514305 |\n",
      "|    n_updates          | 5308         |\n",
      "|    policyGradLoss     | -0.00757     |\n",
      "|    value_loss         | 0.00676      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 764          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 96           |\n",
      "|    total_timesteps    | 10887168     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005897334  |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.887        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0671      |\n",
      "|    mean_step_reward   | -0.006978981 |\n",
      "|    n_updates          | 5312         |\n",
      "|    policyGradLoss     | -0.00986     |\n",
      "|    value_loss         | 0.00445      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 769          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 106          |\n",
      "|    total_timesteps    | 10895360     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004734005  |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.943        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0647      |\n",
      "|    mean_step_reward   | -0.006870097 |\n",
      "|    n_updates          | 5316         |\n",
      "|    policyGradLoss     | -0.0072      |\n",
      "|    value_loss         | 0.0026       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 762           |\n",
      "|    iterations         | 11            |\n",
      "|    time_elapsed       | 118           |\n",
      "|    total_timesteps    | 10903552      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004925385   |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.888         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0713       |\n",
      "|    mean_step_reward   | -0.0069175414 |\n",
      "|    n_updates          | 5320          |\n",
      "|    policyGradLoss     | -0.00701      |\n",
      "|    value_loss         | 0.00569       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 129          |\n",
      "|    total_timesteps    | 10911744     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00484053   |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.881        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0606      |\n",
      "|    mean_step_reward   | -0.007838694 |\n",
      "|    n_updates          | 5324         |\n",
      "|    policyGradLoss     | -0.00636     |\n",
      "|    value_loss         | 0.00222      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 759          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 140          |\n",
      "|    total_timesteps    | 10919936     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0052064667 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.929        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0669      |\n",
      "|    mean_step_reward   | -0.007131528 |\n",
      "|    n_updates          | 5328         |\n",
      "|    policyGradLoss     | -0.0059      |\n",
      "|    value_loss         | 0.00292      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 151          |\n",
      "|    total_timesteps    | 10928128     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004384106  |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.94         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0663      |\n",
      "|    mean_step_reward   | -0.007902743 |\n",
      "|    n_updates          | 5332         |\n",
      "|    policyGradLoss     | -0.00668     |\n",
      "|    value_loss         | 0.000893     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 757           |\n",
      "|    iterations         | 15            |\n",
      "|    time_elapsed       | 162           |\n",
      "|    total_timesteps    | 10936320      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0041136793  |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.94          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0677       |\n",
      "|    mean_step_reward   | -0.0068231467 |\n",
      "|    n_updates          | 5336          |\n",
      "|    policyGradLoss     | -0.00559      |\n",
      "|    value_loss         | 0.00209       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 754           |\n",
      "|    iterations         | 16            |\n",
      "|    time_elapsed       | 173           |\n",
      "|    total_timesteps    | 10944512      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.006321405   |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.973         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0662       |\n",
      "|    mean_step_reward   | -0.0071313716 |\n",
      "|    n_updates          | 5340          |\n",
      "|    policyGradLoss     | -0.00885      |\n",
      "|    value_loss         | 0.00113       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 185          |\n",
      "|    total_timesteps    | 10952704     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0063115912 |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.967        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.066       |\n",
      "|    mean_step_reward   | -0.006514319 |\n",
      "|    n_updates          | 5344         |\n",
      "|    policyGradLoss     | -0.00889     |\n",
      "|    value_loss         | 0.00289      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 195          |\n",
      "|    total_timesteps    | 10960896     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005808281  |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.975        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0666      |\n",
      "|    mean_step_reward   | -0.007818916 |\n",
      "|    n_updates          | 5348         |\n",
      "|    policyGradLoss     | -0.00681     |\n",
      "|    value_loss         | 0.000549     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 19            |\n",
      "|    time_elapsed       | 206           |\n",
      "|    total_timesteps    | 10969088      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0044155642  |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.99          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0637       |\n",
      "|    mean_step_reward   | -0.0070625534 |\n",
      "|    n_updates          | 5352          |\n",
      "|    policyGradLoss     | -0.00666      |\n",
      "|    value_loss         | 0.000424      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 217          |\n",
      "|    total_timesteps    | 10977280     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005932545  |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.803        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0588      |\n",
      "|    mean_step_reward   | -0.007791043 |\n",
      "|    n_updates          | 5356         |\n",
      "|    policyGradLoss     | -0.00599     |\n",
      "|    value_loss         | 0.00315      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 21            |\n",
      "|    time_elapsed       | 228           |\n",
      "|    total_timesteps    | 10985472      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005509967   |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.938         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0674       |\n",
      "|    mean_step_reward   | -0.0072591063 |\n",
      "|    n_updates          | 5360          |\n",
      "|    policyGradLoss     | -0.00708      |\n",
      "|    value_loss         | 0.00198       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 240          |\n",
      "|    total_timesteps    | 10993664     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0054575335 |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.974        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0624      |\n",
      "|    mean_step_reward   | -0.006709495 |\n",
      "|    n_updates          | 5364         |\n",
      "|    policyGradLoss     | -0.00748     |\n",
      "|    value_loss         | 0.00113      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 250          |\n",
      "|    total_timesteps    | 11001856     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005294374  |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.965        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0622      |\n",
      "|    mean_step_reward   | -0.007060732 |\n",
      "|    n_updates          | 5368         |\n",
      "|    policyGradLoss     | -0.00687     |\n",
      "|    value_loss         | 0.00186      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 262          |\n",
      "|    total_timesteps    | 11010048     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0055508576 |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.981        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0656      |\n",
      "|    mean_step_reward   | -0.007883776 |\n",
      "|    n_updates          | 5372         |\n",
      "|    policyGradLoss     | -0.00771     |\n",
      "|    value_loss         | 0.000341     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 25            |\n",
      "|    time_elapsed       | 273           |\n",
      "|    total_timesteps    | 11018240      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0071299644  |\n",
      "|    entropy_loss       | -2.1          |\n",
      "|    explained_variance | 0.924         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0643       |\n",
      "|    mean_step_reward   | -0.0070114834 |\n",
      "|    n_updates          | 5376          |\n",
      "|    policyGradLoss     | -0.00783      |\n",
      "|    value_loss         | 0.00264       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 26            |\n",
      "|    time_elapsed       | 283           |\n",
      "|    total_timesteps    | 11026432      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0052947965  |\n",
      "|    entropy_loss       | -2.1          |\n",
      "|    explained_variance | 0.986         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0616       |\n",
      "|    mean_step_reward   | -0.0077169184 |\n",
      "|    n_updates          | 5380          |\n",
      "|    policyGradLoss     | -0.00868      |\n",
      "|    value_loss         | 0.000178      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 295          |\n",
      "|    total_timesteps    | 11034624     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0056615244 |\n",
      "|    entropy_loss       | -2.09        |\n",
      "|    explained_variance | 0.983        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.061       |\n",
      "|    mean_step_reward   | -0.007215767 |\n",
      "|    n_updates          | 5384         |\n",
      "|    policyGradLoss     | -0.00779     |\n",
      "|    value_loss         | 0.00101      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 28            |\n",
      "|    time_elapsed       | 306           |\n",
      "|    total_timesteps    | 11042816      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0050358027  |\n",
      "|    entropy_loss       | -2.08         |\n",
      "|    explained_variance | 0.991         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0579       |\n",
      "|    mean_step_reward   | -0.0070922426 |\n",
      "|    n_updates          | 5388          |\n",
      "|    policyGradLoss     | -0.00595      |\n",
      "|    value_loss         | 0.000437      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 29            |\n",
      "|    time_elapsed       | 317           |\n",
      "|    total_timesteps    | 11051008      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0071661808  |\n",
      "|    entropy_loss       | -2.07         |\n",
      "|    explained_variance | 0.873         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0649       |\n",
      "|    mean_step_reward   | -0.0071324566 |\n",
      "|    n_updates          | 5392          |\n",
      "|    policyGradLoss     | -0.00747      |\n",
      "|    value_loss         | 0.00439       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 746           |\n",
      "|    iterations         | 30            |\n",
      "|    time_elapsed       | 329           |\n",
      "|    total_timesteps    | 11059200      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.007525418   |\n",
      "|    entropy_loss       | -2.09         |\n",
      "|    explained_variance | 0.908         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0626       |\n",
      "|    mean_step_reward   | -0.0070376988 |\n",
      "|    n_updates          | 5396          |\n",
      "|    policyGradLoss     | 0.00362       |\n",
      "|    value_loss         | 0.00297       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 31            |\n",
      "|    time_elapsed       | 338           |\n",
      "|    total_timesteps    | 11067392      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0072977683  |\n",
      "|    entropy_loss       | -2.1          |\n",
      "|    explained_variance | 0.871         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0674       |\n",
      "|    mean_step_reward   | -0.0071154833 |\n",
      "|    n_updates          | 5400          |\n",
      "|    policyGradLoss     | -0.00645      |\n",
      "|    value_loss         | 0.00514       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 350          |\n",
      "|    total_timesteps    | 11075584     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0055410974 |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.936        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.052       |\n",
      "|    mean_step_reward   | -0.00770779  |\n",
      "|    n_updates          | 5404         |\n",
      "|    policyGradLoss     | -0.00552     |\n",
      "|    value_loss         | 0.000979     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 747           |\n",
      "|    iterations         | 33            |\n",
      "|    time_elapsed       | 361           |\n",
      "|    total_timesteps    | 11083776      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0058436505  |\n",
      "|    entropy_loss       | -2.1          |\n",
      "|    explained_variance | 0.826         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0632       |\n",
      "|    mean_step_reward   | -0.0076523162 |\n",
      "|    n_updates          | 5408          |\n",
      "|    policyGradLoss     | -0.00619      |\n",
      "|    value_loss         | 0.00578       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 34            |\n",
      "|    time_elapsed       | 372           |\n",
      "|    total_timesteps    | 11091968      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0052692117  |\n",
      "|    entropy_loss       | -2.11         |\n",
      "|    explained_variance | 0.886         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0616       |\n",
      "|    mean_step_reward   | -0.0066214935 |\n",
      "|    n_updates          | 5412          |\n",
      "|    policyGradLoss     | -0.00614      |\n",
      "|    value_loss         | 0.00676       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 747           |\n",
      "|    iterations         | 35            |\n",
      "|    time_elapsed       | 383           |\n",
      "|    total_timesteps    | 11100160      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004157706   |\n",
      "|    entropy_loss       | -2.12         |\n",
      "|    explained_variance | 0.872         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0633       |\n",
      "|    mean_step_reward   | -0.0069568325 |\n",
      "|    n_updates          | 5416          |\n",
      "|    policyGradLoss     | -0.00652      |\n",
      "|    value_loss         | 0.00365       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 393          |\n",
      "|    total_timesteps    | 11108352     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.006894596  |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.926        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.06        |\n",
      "|    mean_step_reward   | -0.007106944 |\n",
      "|    n_updates          | 5420         |\n",
      "|    policyGradLoss     | -0.00568     |\n",
      "|    value_loss         | 0.0033       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 747           |\n",
      "|    iterations         | 37            |\n",
      "|    time_elapsed       | 405           |\n",
      "|    total_timesteps    | 11116544      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003815141   |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.928         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0661       |\n",
      "|    mean_step_reward   | -0.0071312897 |\n",
      "|    n_updates          | 5424          |\n",
      "|    policyGradLoss     | -0.00641      |\n",
      "|    value_loss         | 0.00248       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 746           |\n",
      "|    iterations         | 38            |\n",
      "|    time_elapsed       | 416           |\n",
      "|    total_timesteps    | 11124736      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0051579047  |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.972         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0637       |\n",
      "|    mean_step_reward   | -0.0077614896 |\n",
      "|    n_updates          | 5428          |\n",
      "|    policyGradLoss     | -0.00719      |\n",
      "|    value_loss         | 0.000356      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 427          |\n",
      "|    total_timesteps    | 11132928     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00447099   |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.974        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.069       |\n",
      "|    mean_step_reward   | -0.007480864 |\n",
      "|    n_updates          | 5432         |\n",
      "|    policyGradLoss     | -0.0071      |\n",
      "|    value_loss         | 0.000744     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 438          |\n",
      "|    total_timesteps    | 11141120     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0049466603 |\n",
      "|    entropy_loss       | -2.09        |\n",
      "|    explained_variance | 0.983        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0631      |\n",
      "|    mean_step_reward   | -0.006763336 |\n",
      "|    n_updates          | 5436         |\n",
      "|    policyGradLoss     | -0.00664     |\n",
      "|    value_loss         | 0.000863     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_33.zip\n",
      "[EVAL] Mean Return: -121.446, Best Return: -119.926\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_33_-121.45.mp4\n",
      "\n",
      "=== Round 35 | Learn 327680 steps (Total trained: 11141120) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1281     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 11149312 |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 912          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 11157504     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00747968   |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.928        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0632      |\n",
      "|    mean_step_reward   | -0.006698687 |\n",
      "|    n_updates          | 5444         |\n",
      "|    policyGradLoss     | -0.00791     |\n",
      "|    value_loss         | 0.00379      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 849          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 11165696     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0056041093 |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.834        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0644      |\n",
      "|    mean_step_reward   | -0.007466894 |\n",
      "|    n_updates          | 5448         |\n",
      "|    policyGradLoss     | -0.00555     |\n",
      "|    value_loss         | 0.00529      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 821          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 39           |\n",
      "|    total_timesteps    | 11173888     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004376853  |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.946        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0663      |\n",
      "|    mean_step_reward   | -0.007698795 |\n",
      "|    n_updates          | 5452         |\n",
      "|    policyGradLoss     | -0.00575     |\n",
      "|    value_loss         | 0.000784     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 795          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 51           |\n",
      "|    total_timesteps    | 11182080     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0072309957 |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.787        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0607      |\n",
      "|    mean_step_reward   | -0.007424812 |\n",
      "|    n_updates          | 5456         |\n",
      "|    policyGradLoss     | -0.00804     |\n",
      "|    value_loss         | 0.0067       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 800          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 61           |\n",
      "|    total_timesteps    | 11190272     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0061027696 |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.908        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0627      |\n",
      "|    mean_step_reward   | -0.00651709  |\n",
      "|    n_updates          | 5460         |\n",
      "|    policyGradLoss     | -0.00615     |\n",
      "|    value_loss         | 0.00339      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 782           |\n",
      "|    iterations         | 7             |\n",
      "|    time_elapsed       | 73            |\n",
      "|    total_timesteps    | 11198464      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004790125   |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.917         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0699       |\n",
      "|    mean_step_reward   | -0.0076238485 |\n",
      "|    n_updates          | 5464          |\n",
      "|    policyGradLoss     | -0.00803      |\n",
      "|    value_loss         | 0.0025        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 773          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 84           |\n",
      "|    total_timesteps    | 11206656     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0053190757 |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.931        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0626      |\n",
      "|    mean_step_reward   | -0.006826953 |\n",
      "|    n_updates          | 5468         |\n",
      "|    policyGradLoss     | -0.00675     |\n",
      "|    value_loss         | 0.00436      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 779          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 94           |\n",
      "|    total_timesteps    | 11214848     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0056910645 |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.905        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0602      |\n",
      "|    mean_step_reward   | -0.007011215 |\n",
      "|    n_updates          | 5472         |\n",
      "|    policyGradLoss     | -0.00748     |\n",
      "|    value_loss         | 0.0049       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 773           |\n",
      "|    iterations         | 10            |\n",
      "|    time_elapsed       | 105           |\n",
      "|    total_timesteps    | 11223040      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0053969827  |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.86          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0676       |\n",
      "|    mean_step_reward   | -0.0077445144 |\n",
      "|    n_updates          | 5476          |\n",
      "|    policyGradLoss     | -0.0087       |\n",
      "|    value_loss         | 0.00175       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 771           |\n",
      "|    iterations         | 11            |\n",
      "|    time_elapsed       | 116           |\n",
      "|    total_timesteps    | 11231232      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0036242462  |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.934         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0604       |\n",
      "|    mean_step_reward   | -0.0070743933 |\n",
      "|    n_updates          | 5480          |\n",
      "|    policyGradLoss     | -0.00481      |\n",
      "|    value_loss         | 0.0012        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 770           |\n",
      "|    iterations         | 12            |\n",
      "|    time_elapsed       | 127           |\n",
      "|    total_timesteps    | 11239424      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.006156995   |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.836         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0699       |\n",
      "|    mean_step_reward   | -0.0071811234 |\n",
      "|    n_updates          | 5484          |\n",
      "|    policyGradLoss     | -0.00726      |\n",
      "|    value_loss         | 0.00668       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 765           |\n",
      "|    iterations         | 13            |\n",
      "|    time_elapsed       | 139           |\n",
      "|    total_timesteps    | 11247616      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0039342726  |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.896         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0657       |\n",
      "|    mean_step_reward   | -0.0074478993 |\n",
      "|    n_updates          | 5488          |\n",
      "|    policyGradLoss     | -0.00541      |\n",
      "|    value_loss         | 0.00135       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 760          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 150          |\n",
      "|    total_timesteps    | 11255808     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005609597  |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.896        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0626      |\n",
      "|    mean_step_reward   | -0.007097026 |\n",
      "|    n_updates          | 5492         |\n",
      "|    policyGradLoss     | -0.0077      |\n",
      "|    value_loss         | 0.00579      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 764          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 160          |\n",
      "|    total_timesteps    | 11264000     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0055876365 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.846        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.066       |\n",
      "|    mean_step_reward   | -0.007468171 |\n",
      "|    n_updates          | 5496         |\n",
      "|    policyGradLoss     | -0.00651     |\n",
      "|    value_loss         | 0.00493      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 172         |\n",
      "|    total_timesteps    | 11272192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006268731 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.874       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.072      |\n",
      "|    mean_step_reward   | -0.00751441 |\n",
      "|    n_updates          | 5500        |\n",
      "|    policyGradLoss     | -0.00782    |\n",
      "|    value_loss         | 0.00258     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 760          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 183          |\n",
      "|    total_timesteps    | 11280384     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004016324  |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.849        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.066       |\n",
      "|    mean_step_reward   | -0.007724341 |\n",
      "|    n_updates          | 5504         |\n",
      "|    policyGradLoss     | -0.00729     |\n",
      "|    value_loss         | 0.0048       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 760          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 193          |\n",
      "|    total_timesteps    | 11288576     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003604427  |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.925        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0545      |\n",
      "|    mean_step_reward   | -0.007114987 |\n",
      "|    n_updates          | 5508         |\n",
      "|    policyGradLoss     | -0.00475     |\n",
      "|    value_loss         | 0.00135      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 757          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 205          |\n",
      "|    total_timesteps    | 11296768     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0043811835 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.914        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0626      |\n",
      "|    mean_step_reward   | -0.007151889 |\n",
      "|    n_updates          | 5512         |\n",
      "|    policyGradLoss     | -0.00728     |\n",
      "|    value_loss         | 0.0031       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 759          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 215          |\n",
      "|    total_timesteps    | 11304960     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0037358738 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.947        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0686      |\n",
      "|    mean_step_reward   | -0.007310579 |\n",
      "|    n_updates          | 5516         |\n",
      "|    policyGradLoss     | -0.00759     |\n",
      "|    value_loss         | 0.00251      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 227         |\n",
      "|    total_timesteps    | 11313152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004337323 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0628     |\n",
      "|    mean_step_reward   | -0.00708237 |\n",
      "|    n_updates          | 5520        |\n",
      "|    policyGradLoss     | -0.00587    |\n",
      "|    value_loss         | 0.00107     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 238          |\n",
      "|    total_timesteps    | 11321344     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0059130914 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.946        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0699      |\n",
      "|    mean_step_reward   | -0.007367479 |\n",
      "|    n_updates          | 5524         |\n",
      "|    policyGradLoss     | -0.00895     |\n",
      "|    value_loss         | 0.00154      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 758          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 248          |\n",
      "|    total_timesteps    | 11329536     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004726356  |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.968        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0663      |\n",
      "|    mean_step_reward   | -0.007409024 |\n",
      "|    n_updates          | 5528         |\n",
      "|    policyGradLoss     | -0.00805     |\n",
      "|    value_loss         | 0.00101      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 755           |\n",
      "|    iterations         | 24            |\n",
      "|    time_elapsed       | 260           |\n",
      "|    total_timesteps    | 11337728      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0049520875  |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.973         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0644       |\n",
      "|    mean_step_reward   | -0.0072280457 |\n",
      "|    n_updates          | 5532          |\n",
      "|    policyGradLoss     | -0.00602      |\n",
      "|    value_loss         | 0.000915      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 271          |\n",
      "|    total_timesteps    | 11345920     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0062794723 |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.78         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0624      |\n",
      "|    mean_step_reward   | -0.007360517 |\n",
      "|    n_updates          | 5536         |\n",
      "|    policyGradLoss     | -0.00885     |\n",
      "|    value_loss         | 0.0052       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 282          |\n",
      "|    total_timesteps    | 11354112     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0048901634 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.936        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0659      |\n",
      "|    mean_step_reward   | -0.006867919 |\n",
      "|    n_updates          | 5540         |\n",
      "|    policyGradLoss     | -0.0076      |\n",
      "|    value_loss         | 0.00361      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 27            |\n",
      "|    time_elapsed       | 293           |\n",
      "|    total_timesteps    | 11362304      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.007108789   |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.868         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0602       |\n",
      "|    mean_step_reward   | -0.0070659225 |\n",
      "|    n_updates          | 5544          |\n",
      "|    policyGradLoss     | -0.00722      |\n",
      "|    value_loss         | 0.00534       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 755           |\n",
      "|    iterations         | 28            |\n",
      "|    time_elapsed       | 303           |\n",
      "|    total_timesteps    | 11370496      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0060270038  |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.864         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0656       |\n",
      "|    mean_step_reward   | -0.0073714117 |\n",
      "|    n_updates          | 5548          |\n",
      "|    policyGradLoss     | -0.00589      |\n",
      "|    value_loss         | 0.00267       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 315          |\n",
      "|    total_timesteps    | 11378688     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0042302725 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.921        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0677      |\n",
      "|    mean_step_reward   | -0.007488944 |\n",
      "|    n_updates          | 5552         |\n",
      "|    policyGradLoss     | -0.00647     |\n",
      "|    value_loss         | 0.00163      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 30            |\n",
      "|    time_elapsed       | 326           |\n",
      "|    total_timesteps    | 11386880      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0056193685  |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.833         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0666       |\n",
      "|    mean_step_reward   | -0.0076783122 |\n",
      "|    n_updates          | 5556          |\n",
      "|    policyGradLoss     | -0.0062       |\n",
      "|    value_loss         | 0.00419       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 31            |\n",
      "|    time_elapsed       | 336           |\n",
      "|    total_timesteps    | 11395072      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.007450208   |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.932         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0639       |\n",
      "|    mean_step_reward   | -0.0067925816 |\n",
      "|    n_updates          | 5560          |\n",
      "|    policyGradLoss     | -0.00805      |\n",
      "|    value_loss         | 0.00293       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 32            |\n",
      "|    time_elapsed       | 348           |\n",
      "|    total_timesteps    | 11403264      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004169973   |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.857         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0658       |\n",
      "|    mean_step_reward   | -0.0071610566 |\n",
      "|    n_updates          | 5564          |\n",
      "|    policyGradLoss     | -0.00685      |\n",
      "|    value_loss         | 0.00576       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 359          |\n",
      "|    total_timesteps    | 11411456     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004703186  |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.98         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0655      |\n",
      "|    mean_step_reward   | -0.007165132 |\n",
      "|    n_updates          | 5568         |\n",
      "|    policyGradLoss     | -0.00676     |\n",
      "|    value_loss         | 0.000573     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 34            |\n",
      "|    time_elapsed       | 370           |\n",
      "|    total_timesteps    | 11419648      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.003897677   |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.955         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0612       |\n",
      "|    mean_step_reward   | -0.0075589353 |\n",
      "|    n_updates          | 5572          |\n",
      "|    policyGradLoss     | -0.00298      |\n",
      "|    value_loss         | 0.00157       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 381         |\n",
      "|    total_timesteps    | 11427840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005925143 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.855       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0636     |\n",
      "|    mean_step_reward   | -0.00780248 |\n",
      "|    n_updates          | 5576        |\n",
      "|    policyGradLoss     | -0.0067     |\n",
      "|    value_loss         | 0.00329     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 36            |\n",
      "|    time_elapsed       | 391           |\n",
      "|    total_timesteps    | 11436032      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004421193   |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.972         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.065        |\n",
      "|    mean_step_reward   | -0.0067754574 |\n",
      "|    n_updates          | 5580          |\n",
      "|    policyGradLoss     | -0.00744      |\n",
      "|    value_loss         | 0.00111       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 403          |\n",
      "|    total_timesteps    | 11444224     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00483994   |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.972        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0641      |\n",
      "|    mean_step_reward   | -0.007117568 |\n",
      "|    n_updates          | 5584         |\n",
      "|    policyGradLoss     | -0.00763     |\n",
      "|    value_loss         | 0.00129      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 38            |\n",
      "|    time_elapsed       | 414           |\n",
      "|    total_timesteps    | 11452416      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0063076615  |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.923         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0656       |\n",
      "|    mean_step_reward   | -0.0071158586 |\n",
      "|    n_updates          | 5588          |\n",
      "|    policyGradLoss     | -0.00691      |\n",
      "|    value_loss         | 0.00362       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 424          |\n",
      "|    total_timesteps    | 11460608     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0055391407 |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.974        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0594      |\n",
      "|    mean_step_reward   | -0.007502769 |\n",
      "|    n_updates          | 5592         |\n",
      "|    policyGradLoss     | -0.00576     |\n",
      "|    value_loss         | 0.00077      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 436          |\n",
      "|    total_timesteps    | 11468800     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.007439414  |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.916        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0606      |\n",
      "|    mean_step_reward   | -0.007051395 |\n",
      "|    n_updates          | 5596         |\n",
      "|    policyGradLoss     | -0.00478     |\n",
      "|    value_loss         | 0.00346      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_34.zip\n",
      "[EVAL] Mean Return: -19.928, Best Return: -16.411\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_34_-19.93.mp4\n",
      "\n",
      "=== Round 36 | Learn 327680 steps (Total trained: 11468800) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 971      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 11476992 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 884           |\n",
      "|    iterations         | 2             |\n",
      "|    time_elapsed       | 18            |\n",
      "|    total_timesteps    | 11485184      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.006480677   |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.917         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0599       |\n",
      "|    mean_step_reward   | -0.0070999702 |\n",
      "|    n_updates          | 5604          |\n",
      "|    policyGradLoss     | -0.00674      |\n",
      "|    value_loss         | 0.00402       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 814           |\n",
      "|    iterations         | 3             |\n",
      "|    time_elapsed       | 30            |\n",
      "|    total_timesteps    | 11493376      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0055411416  |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.907         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0655       |\n",
      "|    mean_step_reward   | -0.0068201814 |\n",
      "|    n_updates          | 5608          |\n",
      "|    policyGradLoss     | -0.0066       |\n",
      "|    value_loss         | 0.00572       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 800           |\n",
      "|    iterations         | 4             |\n",
      "|    time_elapsed       | 40            |\n",
      "|    total_timesteps    | 11501568      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004668954   |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.933         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0622       |\n",
      "|    mean_step_reward   | -0.0068954597 |\n",
      "|    n_updates          | 5612          |\n",
      "|    policyGradLoss     | -0.00536      |\n",
      "|    value_loss         | 0.0027        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 787           |\n",
      "|    iterations         | 5             |\n",
      "|    time_elapsed       | 52            |\n",
      "|    total_timesteps    | 11509760      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004538606   |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.96          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0653       |\n",
      "|    mean_step_reward   | -0.0071403217 |\n",
      "|    n_updates          | 5616          |\n",
      "|    policyGradLoss     | -0.00619      |\n",
      "|    value_loss         | 0.00202       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 772          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 63           |\n",
      "|    total_timesteps    | 11517952     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004119832  |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.986        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.065       |\n",
      "|    mean_step_reward   | -0.007144319 |\n",
      "|    n_updates          | 5620         |\n",
      "|    policyGradLoss     | -0.00605     |\n",
      "|    value_loss         | 0.00046      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 781           |\n",
      "|    iterations         | 7             |\n",
      "|    time_elapsed       | 73            |\n",
      "|    total_timesteps    | 11526144      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0051862975  |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.99          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0748       |\n",
      "|    mean_step_reward   | -0.0077368836 |\n",
      "|    n_updates          | 5624          |\n",
      "|    policyGradLoss     | -0.00752      |\n",
      "|    value_loss         | 0.000167      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 770           |\n",
      "|    iterations         | 8             |\n",
      "|    time_elapsed       | 85            |\n",
      "|    total_timesteps    | 11534336      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0057529123  |\n",
      "|    entropy_loss       | -2.12         |\n",
      "|    explained_variance | 0.991         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0649       |\n",
      "|    mean_step_reward   | -0.0070973514 |\n",
      "|    n_updates          | 5628          |\n",
      "|    policyGradLoss     | -0.00607      |\n",
      "|    value_loss         | 0.000529      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 763           |\n",
      "|    iterations         | 9             |\n",
      "|    time_elapsed       | 96            |\n",
      "|    total_timesteps    | 11542528      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.006734824   |\n",
      "|    entropy_loss       | -2.12         |\n",
      "|    explained_variance | 0.956         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0698       |\n",
      "|    mean_step_reward   | -0.0070922803 |\n",
      "|    n_updates          | 5632          |\n",
      "|    policyGradLoss     | -0.00674      |\n",
      "|    value_loss         | 0.00204       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 769           |\n",
      "|    iterations         | 10            |\n",
      "|    time_elapsed       | 106           |\n",
      "|    total_timesteps    | 11550720      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0050549726  |\n",
      "|    entropy_loss       | -2.11         |\n",
      "|    explained_variance | 0.981         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0638       |\n",
      "|    mean_step_reward   | -0.0072185313 |\n",
      "|    n_updates          | 5636          |\n",
      "|    policyGradLoss     | -0.00546      |\n",
      "|    value_loss         | 0.00081       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 763          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 118          |\n",
      "|    total_timesteps    | 11558912     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0058437325 |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.901        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0577      |\n",
      "|    mean_step_reward   | -0.006612383 |\n",
      "|    n_updates          | 5640         |\n",
      "|    policyGradLoss     | -0.00418     |\n",
      "|    value_loss         | 0.00615      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 763          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 128          |\n",
      "|    total_timesteps    | 11567104     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0053069205 |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.956        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0682      |\n",
      "|    mean_step_reward   | -0.007182081 |\n",
      "|    n_updates          | 5644         |\n",
      "|    policyGradLoss     | -0.00633     |\n",
      "|    value_loss         | 0.00242      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 759           |\n",
      "|    iterations         | 13            |\n",
      "|    time_elapsed       | 140           |\n",
      "|    total_timesteps    | 11575296      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.00415182    |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.935         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0461       |\n",
      "|    mean_step_reward   | -0.0074056056 |\n",
      "|    n_updates          | 5648          |\n",
      "|    policyGradLoss     | -0.00408      |\n",
      "|    value_loss         | 0.00141       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 151          |\n",
      "|    total_timesteps    | 11583488     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0061313733 |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.89         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.053       |\n",
      "|    mean_step_reward   | -0.00730879  |\n",
      "|    n_updates          | 5652         |\n",
      "|    policyGradLoss     | -0.0061      |\n",
      "|    value_loss         | 0.00483      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 760          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 161          |\n",
      "|    total_timesteps    | 11591680     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00469147   |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.934        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0598      |\n",
      "|    mean_step_reward   | -0.006732799 |\n",
      "|    n_updates          | 5656         |\n",
      "|    policyGradLoss     | -0.00592     |\n",
      "|    value_loss         | 0.0026       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 756           |\n",
      "|    iterations         | 16            |\n",
      "|    time_elapsed       | 173           |\n",
      "|    total_timesteps    | 11599872      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005647529   |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.921         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0657       |\n",
      "|    mean_step_reward   | -0.0071394527 |\n",
      "|    n_updates          | 5660          |\n",
      "|    policyGradLoss     | -0.00725      |\n",
      "|    value_loss         | 0.00316       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 184          |\n",
      "|    total_timesteps    | 11608064     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0049324557 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.93         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0696      |\n",
      "|    mean_step_reward   | -0.007123124 |\n",
      "|    n_updates          | 5664         |\n",
      "|    policyGradLoss     | -0.00679     |\n",
      "|    value_loss         | 0.00371      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 195          |\n",
      "|    total_timesteps    | 11616256     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0036456266 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.929        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0622      |\n",
      "|    mean_step_reward   | -0.008000526 |\n",
      "|    n_updates          | 5668         |\n",
      "|    policyGradLoss     | -0.00427     |\n",
      "|    value_loss         | 0.00145      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 19            |\n",
      "|    time_elapsed       | 207           |\n",
      "|    total_timesteps    | 11624448      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0076576807  |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.978         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0641       |\n",
      "|    mean_step_reward   | -0.0073691867 |\n",
      "|    n_updates          | 5672          |\n",
      "|    policyGradLoss     | -0.00643      |\n",
      "|    value_loss         | 0.000526      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 217          |\n",
      "|    total_timesteps    | 11632640     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00523463   |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.958        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.056       |\n",
      "|    mean_step_reward   | -0.006732591 |\n",
      "|    n_updates          | 5676         |\n",
      "|    policyGradLoss     | -0.00426     |\n",
      "|    value_loss         | 0.00226      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 21            |\n",
      "|    time_elapsed       | 228           |\n",
      "|    total_timesteps    | 11640832      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0058934423  |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.928         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0659       |\n",
      "|    mean_step_reward   | -0.0074835746 |\n",
      "|    n_updates          | 5680          |\n",
      "|    policyGradLoss     | -0.00734      |\n",
      "|    value_loss         | 0.0024        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 239          |\n",
      "|    total_timesteps    | 11649024     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0056585576 |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.887        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0648      |\n",
      "|    mean_step_reward   | -0.006715106 |\n",
      "|    n_updates          | 5684         |\n",
      "|    policyGradLoss     | -0.00626     |\n",
      "|    value_loss         | 0.00691      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 249          |\n",
      "|    total_timesteps    | 11657216     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004669541  |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.966        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0575      |\n",
      "|    mean_step_reward   | -0.007086535 |\n",
      "|    n_updates          | 5688         |\n",
      "|    policyGradLoss     | -0.00542     |\n",
      "|    value_loss         | 0.00089      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 261          |\n",
      "|    total_timesteps    | 11665408     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0054582166 |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.899        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0645      |\n",
      "|    mean_step_reward   | -0.007882999 |\n",
      "|    n_updates          | 5692         |\n",
      "|    policyGradLoss     | -0.0082      |\n",
      "|    value_loss         | 0.00157      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 25            |\n",
      "|    time_elapsed       | 272           |\n",
      "|    total_timesteps    | 11673600      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005583154   |\n",
      "|    entropy_loss       | -2.12         |\n",
      "|    explained_variance | 0.924         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.068        |\n",
      "|    mean_step_reward   | -0.0071665114 |\n",
      "|    n_updates          | 5696          |\n",
      "|    policyGradLoss     | -0.0072       |\n",
      "|    value_loss         | 0.00353       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 26            |\n",
      "|    time_elapsed       | 283           |\n",
      "|    total_timesteps    | 11681792      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004568062   |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.938         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0631       |\n",
      "|    mean_step_reward   | -0.0070770625 |\n",
      "|    n_updates          | 5700          |\n",
      "|    policyGradLoss     | -0.00526      |\n",
      "|    value_loss         | 0.00122       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 27            |\n",
      "|    time_elapsed       | 295           |\n",
      "|    total_timesteps    | 11689984      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.006243975   |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.98          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0611       |\n",
      "|    mean_step_reward   | -0.0071064336 |\n",
      "|    n_updates          | 5704          |\n",
      "|    policyGradLoss     | -0.00723      |\n",
      "|    value_loss         | 0.000652      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 305          |\n",
      "|    total_timesteps    | 11698176     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005545453  |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.642        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0638      |\n",
      "|    mean_step_reward   | -0.007866236 |\n",
      "|    n_updates          | 5708         |\n",
      "|    policyGradLoss     | -0.00596     |\n",
      "|    value_loss         | 0.00574      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 29            |\n",
      "|    time_elapsed       | 315           |\n",
      "|    total_timesteps    | 11706368      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0055652615  |\n",
      "|    entropy_loss       | -2.12         |\n",
      "|    explained_variance | 0.868         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0647       |\n",
      "|    mean_step_reward   | -0.0063505946 |\n",
      "|    n_updates          | 5712          |\n",
      "|    policyGradLoss     | -0.00531      |\n",
      "|    value_loss         | 0.00916       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 30            |\n",
      "|    time_elapsed       | 327           |\n",
      "|    total_timesteps    | 11714560      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0037273401  |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.841         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0684       |\n",
      "|    mean_step_reward   | -0.0073856562 |\n",
      "|    n_updates          | 5716          |\n",
      "|    policyGradLoss     | -0.00484      |\n",
      "|    value_loss         | 0.00447       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 31            |\n",
      "|    time_elapsed       | 338           |\n",
      "|    total_timesteps    | 11722752      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004111777   |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.882         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.066        |\n",
      "|    mean_step_reward   | -0.0074530067 |\n",
      "|    n_updates          | 5720          |\n",
      "|    policyGradLoss     | -0.00603      |\n",
      "|    value_loss         | 0.0034        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 349          |\n",
      "|    total_timesteps    | 11730944     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0046312828 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.816        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0688      |\n",
      "|    mean_step_reward   | -0.008085446 |\n",
      "|    n_updates          | 5724         |\n",
      "|    policyGradLoss     | -0.00958     |\n",
      "|    value_loss         | 0.00322      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 360          |\n",
      "|    total_timesteps    | 11739136     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0046948576 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.882        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0599      |\n",
      "|    mean_step_reward   | -0.006435653 |\n",
      "|    n_updates          | 5728         |\n",
      "|    policyGradLoss     | -0.00749     |\n",
      "|    value_loss         | 0.00463      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 34            |\n",
      "|    time_elapsed       | 371           |\n",
      "|    total_timesteps    | 11747328      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004911192   |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.936         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.068        |\n",
      "|    mean_step_reward   | -0.0063595627 |\n",
      "|    n_updates          | 5732          |\n",
      "|    policyGradLoss     | -0.00731      |\n",
      "|    value_loss         | 0.00441       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 35            |\n",
      "|    time_elapsed       | 382           |\n",
      "|    total_timesteps    | 11755520      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004948725   |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.975         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0695       |\n",
      "|    mean_step_reward   | -0.0067961663 |\n",
      "|    n_updates          | 5736          |\n",
      "|    policyGradLoss     | -0.00899      |\n",
      "|    value_loss         | 0.00135       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 747           |\n",
      "|    iterations         | 36            |\n",
      "|    time_elapsed       | 394           |\n",
      "|    total_timesteps    | 11763712      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004963087   |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.945         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0623       |\n",
      "|    mean_step_reward   | -0.0077231177 |\n",
      "|    n_updates          | 5740          |\n",
      "|    policyGradLoss     | -0.00738      |\n",
      "|    value_loss         | 0.000748      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 37            |\n",
      "|    time_elapsed       | 404           |\n",
      "|    total_timesteps    | 11771904      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0053212     |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.965         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0648       |\n",
      "|    mean_step_reward   | -0.0074427323 |\n",
      "|    n_updates          | 5744          |\n",
      "|    policyGradLoss     | -0.00727      |\n",
      "|    value_loss         | 0.00116       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 416          |\n",
      "|    total_timesteps    | 11780096     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0041316855 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.945        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0692      |\n",
      "|    mean_step_reward   | -0.008209771 |\n",
      "|    n_updates          | 5748         |\n",
      "|    policyGradLoss     | -0.00881     |\n",
      "|    value_loss         | 0.000146     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 426          |\n",
      "|    total_timesteps    | 11788288     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0062927706 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.964        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0631      |\n",
      "|    mean_step_reward   | -0.007139683 |\n",
      "|    n_updates          | 5752         |\n",
      "|    policyGradLoss     | -0.00621     |\n",
      "|    value_loss         | 0.00177      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 40            |\n",
      "|    time_elapsed       | 437           |\n",
      "|    total_timesteps    | 11796480      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0060743005  |\n",
      "|    entropy_loss       | -2.11         |\n",
      "|    explained_variance | 0.908         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0599       |\n",
      "|    mean_step_reward   | -0.0063163536 |\n",
      "|    n_updates          | 5756          |\n",
      "|    policyGradLoss     | -0.00798      |\n",
      "|    value_loss         | 0.00719       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_35.zip\n",
      "[EVAL] Mean Return: -20.983, Best Return: -17.520\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_35_-20.98.mp4\n",
      "\n",
      "=== Round 37 | Learn 327680 steps (Total trained: 11796480) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 976      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 11804672 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 908           |\n",
      "|    iterations         | 2             |\n",
      "|    time_elapsed       | 18            |\n",
      "|    total_timesteps    | 11812864      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0056221383  |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.91          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0538       |\n",
      "|    mean_step_reward   | -0.0070308503 |\n",
      "|    n_updates          | 5764          |\n",
      "|    policyGradLoss     | -0.00417      |\n",
      "|    value_loss         | 0.00404       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 821           |\n",
      "|    iterations         | 3             |\n",
      "|    time_elapsed       | 29            |\n",
      "|    total_timesteps    | 11821056      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0050822385  |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.97          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0661       |\n",
      "|    mean_step_reward   | -0.0074572014 |\n",
      "|    n_updates          | 5768          |\n",
      "|    policyGradLoss     | -0.00679      |\n",
      "|    value_loss         | 0.000675      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 796          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 41           |\n",
      "|    total_timesteps    | 11829248     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0046250727 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.521        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0784      |\n",
      "|    mean_step_reward   | -0.007980181 |\n",
      "|    n_updates          | 5772         |\n",
      "|    policyGradLoss     | -0.00961     |\n",
      "|    value_loss         | 0.000191     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 793          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 51           |\n",
      "|    total_timesteps    | 11837440     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.006160946  |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.977        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0675      |\n",
      "|    mean_step_reward   | -0.007401687 |\n",
      "|    n_updates          | 5776         |\n",
      "|    policyGradLoss     | -0.00834     |\n",
      "|    value_loss         | 0.000721     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 779          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 63           |\n",
      "|    total_timesteps    | 11845632     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0054084114 |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.983        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0687      |\n",
      "|    mean_step_reward   | -0.006157376 |\n",
      "|    n_updates          | 5780         |\n",
      "|    policyGradLoss     | -0.0086      |\n",
      "|    value_loss         | 0.00114      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 786           |\n",
      "|    iterations         | 7             |\n",
      "|    time_elapsed       | 72            |\n",
      "|    total_timesteps    | 11853824      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005483662   |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.912         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0623       |\n",
      "|    mean_step_reward   | -0.0072076055 |\n",
      "|    n_updates          | 5784          |\n",
      "|    policyGradLoss     | -0.00687      |\n",
      "|    value_loss         | 0.00378       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 775           |\n",
      "|    iterations         | 8             |\n",
      "|    time_elapsed       | 84            |\n",
      "|    total_timesteps    | 11862016      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0064207288  |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.901         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0691       |\n",
      "|    mean_step_reward   | -0.0068021268 |\n",
      "|    n_updates          | 5788          |\n",
      "|    policyGradLoss     | -0.0108       |\n",
      "|    value_loss         | 0.00524       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 769          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 95           |\n",
      "|    total_timesteps    | 11870208     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0055846977 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.844        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0624      |\n",
      "|    mean_step_reward   | -0.007074366 |\n",
      "|    n_updates          | 5792         |\n",
      "|    policyGradLoss     | -0.00769     |\n",
      "|    value_loss         | 0.00685      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 772          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 105          |\n",
      "|    total_timesteps    | 11878400     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0043440494 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.925        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0684      |\n",
      "|    mean_step_reward   | -0.007746935 |\n",
      "|    n_updates          | 5796         |\n",
      "|    policyGradLoss     | -0.00433     |\n",
      "|    value_loss         | 0.000807     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 765          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 117          |\n",
      "|    total_timesteps    | 11886592     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003808945  |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.966        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0614      |\n",
      "|    mean_step_reward   | -0.007427886 |\n",
      "|    n_updates          | 5800         |\n",
      "|    policyGradLoss     | -0.00686     |\n",
      "|    value_loss         | 0.000692     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 765          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 128          |\n",
      "|    total_timesteps    | 11894784     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0063501215 |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.859        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.066       |\n",
      "|    mean_step_reward   | -0.006483338 |\n",
      "|    n_updates          | 5804         |\n",
      "|    policyGradLoss     | -0.00845     |\n",
      "|    value_loss         | 0.0121       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 763          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 139          |\n",
      "|    total_timesteps    | 11902976     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0050068726 |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.886        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0689      |\n",
      "|    mean_step_reward   | -0.005838015 |\n",
      "|    n_updates          | 5808         |\n",
      "|    policyGradLoss     | -0.00726     |\n",
      "|    value_loss         | 0.00726      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 758           |\n",
      "|    iterations         | 14            |\n",
      "|    time_elapsed       | 151           |\n",
      "|    total_timesteps    | 11911168      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004802096   |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.892         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0684       |\n",
      "|    mean_step_reward   | -0.0072064507 |\n",
      "|    n_updates          | 5812          |\n",
      "|    policyGradLoss     | -0.0077       |\n",
      "|    value_loss         | 0.00559       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 763          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 160          |\n",
      "|    total_timesteps    | 11919360     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0047698887 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.745        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0632      |\n",
      "|    mean_step_reward   | -0.007360896 |\n",
      "|    n_updates          | 5816         |\n",
      "|    policyGradLoss     | -0.00842     |\n",
      "|    value_loss         | 0.0085       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 758          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 172          |\n",
      "|    total_timesteps    | 11927552     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0043199244 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.755        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0713      |\n",
      "|    mean_step_reward   | -0.007858945 |\n",
      "|    n_updates          | 5820         |\n",
      "|    policyGradLoss     | -0.0083      |\n",
      "|    value_loss         | 0.00399      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 184          |\n",
      "|    total_timesteps    | 11935744     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0047049965 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.829        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0692      |\n",
      "|    mean_step_reward   | -0.007000799 |\n",
      "|    n_updates          | 5824         |\n",
      "|    policyGradLoss     | -0.00863     |\n",
      "|    value_loss         | 0.00522      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 757          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 194          |\n",
      "|    total_timesteps    | 11943936     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005385825  |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.856        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0649      |\n",
      "|    mean_step_reward   | -0.006884627 |\n",
      "|    n_updates          | 5828         |\n",
      "|    policyGradLoss     | -0.00824     |\n",
      "|    value_loss         | 0.00393      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 206          |\n",
      "|    total_timesteps    | 11952128     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0053670662 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.919        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0612      |\n",
      "|    mean_step_reward   | -0.006640304 |\n",
      "|    n_updates          | 5832         |\n",
      "|    policyGradLoss     | -0.00698     |\n",
      "|    value_loss         | 0.00515      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 216          |\n",
      "|    total_timesteps    | 11960320     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0050843917 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.943        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0702      |\n",
      "|    mean_step_reward   | -0.006766648 |\n",
      "|    n_updates          | 5836         |\n",
      "|    policyGradLoss     | -0.00878     |\n",
      "|    value_loss         | 0.00283      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 228          |\n",
      "|    total_timesteps    | 11968512     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0041599595 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.961        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0634      |\n",
      "|    mean_step_reward   | -0.007251371 |\n",
      "|    n_updates          | 5840         |\n",
      "|    policyGradLoss     | -0.00567     |\n",
      "|    value_loss         | 0.00145      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 239          |\n",
      "|    total_timesteps    | 11976704     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0047271093 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.983        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0692      |\n",
      "|    mean_step_reward   | -0.007869361 |\n",
      "|    n_updates          | 5844         |\n",
      "|    policyGradLoss     | -0.00972     |\n",
      "|    value_loss         | 0.000258     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 23            |\n",
      "|    time_elapsed       | 250           |\n",
      "|    total_timesteps    | 11984896      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0050946525  |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.957         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.066        |\n",
      "|    mean_step_reward   | -0.0074286014 |\n",
      "|    n_updates          | 5848          |\n",
      "|    policyGradLoss     | -0.00678      |\n",
      "|    value_loss         | 0.00154       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 24            |\n",
      "|    time_elapsed       | 261           |\n",
      "|    total_timesteps    | 11993088      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005115686   |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.866         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0621       |\n",
      "|    mean_step_reward   | -0.0078096925 |\n",
      "|    n_updates          | 5852          |\n",
      "|    policyGradLoss     | -0.00656      |\n",
      "|    value_loss         | 0.00227       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 25            |\n",
      "|    time_elapsed       | 272           |\n",
      "|    total_timesteps    | 12001280      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005018578   |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.895         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0684       |\n",
      "|    mean_step_reward   | -0.0068720095 |\n",
      "|    n_updates          | 5856          |\n",
      "|    policyGradLoss     | -0.00688      |\n",
      "|    value_loss         | 0.00574       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 26            |\n",
      "|    time_elapsed       | 283           |\n",
      "|    total_timesteps    | 12009472      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005017167   |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.904         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0694       |\n",
      "|    mean_step_reward   | -0.0063542183 |\n",
      "|    n_updates          | 5860          |\n",
      "|    policyGradLoss     | -0.00817      |\n",
      "|    value_loss         | 0.00652       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 27            |\n",
      "|    time_elapsed       | 295           |\n",
      "|    total_timesteps    | 12017664      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.007124814   |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.907         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0679       |\n",
      "|    mean_step_reward   | -0.0065481015 |\n",
      "|    n_updates          | 5864          |\n",
      "|    policyGradLoss     | -0.00951      |\n",
      "|    value_loss         | 0.00695       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 751         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 12025856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005038675 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0695     |\n",
      "|    mean_step_reward   | -0.00813289 |\n",
      "|    n_updates          | 5868        |\n",
      "|    policyGradLoss     | -0.012      |\n",
      "|    value_loss         | 9.68e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 316          |\n",
      "|    total_timesteps    | 12034048     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005323762  |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.879        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0628      |\n",
      "|    mean_step_reward   | -0.007067359 |\n",
      "|    n_updates          | 5872         |\n",
      "|    policyGradLoss     | -0.00719     |\n",
      "|    value_loss         | 0.00543      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 327          |\n",
      "|    total_timesteps    | 12042240     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0039766515 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.798        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0657      |\n",
      "|    mean_step_reward   | -0.008010855 |\n",
      "|    n_updates          | 5876         |\n",
      "|    policyGradLoss     | -0.0064      |\n",
      "|    value_loss         | 0.0027       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 31            |\n",
      "|    time_elapsed       | 338           |\n",
      "|    total_timesteps    | 12050432      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005349788   |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.912         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0688       |\n",
      "|    mean_step_reward   | -0.0066854027 |\n",
      "|    n_updates          | 5880          |\n",
      "|    policyGradLoss     | -0.00644      |\n",
      "|    value_loss         | 0.00425       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 32            |\n",
      "|    time_elapsed       | 350           |\n",
      "|    total_timesteps    | 12058624      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0042841025  |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.957         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0675       |\n",
      "|    mean_step_reward   | -0.0074696317 |\n",
      "|    n_updates          | 5884          |\n",
      "|    policyGradLoss     | -0.00677      |\n",
      "|    value_loss         | 0.00126       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 33            |\n",
      "|    time_elapsed       | 360           |\n",
      "|    total_timesteps    | 12066816      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005009856   |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.979         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0653       |\n",
      "|    mean_step_reward   | -0.0070092743 |\n",
      "|    n_updates          | 5888          |\n",
      "|    policyGradLoss     | -0.00752      |\n",
      "|    value_loss         | 0.00146       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 748           |\n",
      "|    iterations         | 34            |\n",
      "|    time_elapsed       | 372           |\n",
      "|    total_timesteps    | 12075008      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0045105917  |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.91          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0612       |\n",
      "|    mean_step_reward   | -0.0075098583 |\n",
      "|    n_updates          | 5892          |\n",
      "|    policyGradLoss     | -0.00579      |\n",
      "|    value_loss         | 0.00157       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 383          |\n",
      "|    total_timesteps    | 12083200     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0048164623 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.959        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0634      |\n",
      "|    mean_step_reward   | -0.006972227 |\n",
      "|    n_updates          | 5896         |\n",
      "|    policyGradLoss     | -0.0056      |\n",
      "|    value_loss         | 0.0019       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 394          |\n",
      "|    total_timesteps    | 12091392     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004569536  |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.893        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0616      |\n",
      "|    mean_step_reward   | -0.008151993 |\n",
      "|    n_updates          | 5900         |\n",
      "|    policyGradLoss     | -0.00725     |\n",
      "|    value_loss         | 0.00131      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 405          |\n",
      "|    total_timesteps    | 12099584     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.008921969  |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.912        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0633      |\n",
      "|    mean_step_reward   | -0.006436782 |\n",
      "|    n_updates          | 5904         |\n",
      "|    policyGradLoss     | -0.00759     |\n",
      "|    value_loss         | 0.00647      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 747           |\n",
      "|    iterations         | 38            |\n",
      "|    time_elapsed       | 416           |\n",
      "|    total_timesteps    | 12107776      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.006253756   |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.954         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.066        |\n",
      "|    mean_step_reward   | -0.0070482157 |\n",
      "|    n_updates          | 5908          |\n",
      "|    policyGradLoss     | -0.00627      |\n",
      "|    value_loss         | 0.00182       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 747           |\n",
      "|    iterations         | 39            |\n",
      "|    time_elapsed       | 427           |\n",
      "|    total_timesteps    | 12115968      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0058674356  |\n",
      "|    entropy_loss       | -2.12         |\n",
      "|    explained_variance | 0.98          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0691       |\n",
      "|    mean_step_reward   | -0.0071999147 |\n",
      "|    n_updates          | 5912          |\n",
      "|    policyGradLoss     | -0.00803      |\n",
      "|    value_loss         | 0.000805      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 745           |\n",
      "|    iterations         | 40            |\n",
      "|    time_elapsed       | 439           |\n",
      "|    total_timesteps    | 12124160      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0058380263  |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.828         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0666       |\n",
      "|    mean_step_reward   | -0.0074104127 |\n",
      "|    n_updates          | 5916          |\n",
      "|    policyGradLoss     | -0.00615      |\n",
      "|    value_loss         | 0.0043        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_36.zip\n",
      "[EVAL] Mean Return: -19.612, Best Return: -16.055\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_36_-19.61.mp4\n",
      "\n",
      "=== Round 38 | Learn 327680 steps (Total trained: 12124160) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1053     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 12132352 |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 844          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 12140544     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004830826  |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.735        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.066       |\n",
      "|    mean_step_reward   | -0.008120023 |\n",
      "|    n_updates          | 5924         |\n",
      "|    policyGradLoss     | -0.00713     |\n",
      "|    value_loss         | 0.000762     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 793          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 30           |\n",
      "|    total_timesteps    | 12148736     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0061291363 |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.861        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0664      |\n",
      "|    mean_step_reward   | -0.007011095 |\n",
      "|    n_updates          | 5928         |\n",
      "|    policyGradLoss     | -0.00778     |\n",
      "|    value_loss         | 0.00704      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 792           |\n",
      "|    iterations         | 4             |\n",
      "|    time_elapsed       | 41            |\n",
      "|    total_timesteps    | 12156928      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0074630133  |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.899         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0672       |\n",
      "|    mean_step_reward   | -0.0068551153 |\n",
      "|    n_updates          | 5932          |\n",
      "|    policyGradLoss     | -0.00856      |\n",
      "|    value_loss         | 0.00416       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 773          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 52           |\n",
      "|    total_timesteps    | 12165120     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004950883  |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.939        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0698      |\n",
      "|    mean_step_reward   | -0.006813349 |\n",
      "|    n_updates          | 5936         |\n",
      "|    policyGradLoss     | -0.00823     |\n",
      "|    value_loss         | 0.00312      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 774           |\n",
      "|    iterations         | 6             |\n",
      "|    time_elapsed       | 63            |\n",
      "|    total_timesteps    | 12173312      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004976239   |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.885         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0648       |\n",
      "|    mean_step_reward   | -0.0074512437 |\n",
      "|    n_updates          | 5940          |\n",
      "|    policyGradLoss     | -0.00538      |\n",
      "|    value_loss         | 0.00341       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 75          |\n",
      "|    total_timesteps    | 12181504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004380799 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.898       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0653     |\n",
      "|    mean_step_reward   | -0.00714122 |\n",
      "|    n_updates          | 5944        |\n",
      "|    policyGradLoss     | -0.00547    |\n",
      "|    value_loss         | 0.00474     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 755           |\n",
      "|    iterations         | 8             |\n",
      "|    time_elapsed       | 86            |\n",
      "|    total_timesteps    | 12189696      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005355879   |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.959         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0649       |\n",
      "|    mean_step_reward   | -0.0074463254 |\n",
      "|    n_updates          | 5948          |\n",
      "|    policyGradLoss     | -0.00641      |\n",
      "|    value_loss         | 0.00105       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 763           |\n",
      "|    iterations         | 9             |\n",
      "|    time_elapsed       | 96            |\n",
      "|    total_timesteps    | 12197888      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0041904137  |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.894         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0614       |\n",
      "|    mean_step_reward   | -0.0071977535 |\n",
      "|    n_updates          | 5952          |\n",
      "|    policyGradLoss     | -0.00579      |\n",
      "|    value_loss         | 0.00485       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 757          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 108          |\n",
      "|    total_timesteps    | 12206080     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004106949  |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.922        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0618      |\n",
      "|    mean_step_reward   | -0.007447836 |\n",
      "|    n_updates          | 5956         |\n",
      "|    policyGradLoss     | -0.00721     |\n",
      "|    value_loss         | 0.00185      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 119          |\n",
      "|    total_timesteps    | 12214272     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0058749495 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.931        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0623      |\n",
      "|    mean_step_reward   | -0.006955009 |\n",
      "|    n_updates          | 5960         |\n",
      "|    policyGradLoss     | -0.00697     |\n",
      "|    value_loss         | 0.00463      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 130         |\n",
      "|    total_timesteps    | 12222464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004371646 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0619     |\n",
      "|    mean_step_reward   | -0.00709813 |\n",
      "|    n_updates          | 5964        |\n",
      "|    policyGradLoss     | -0.00745    |\n",
      "|    value_loss         | 0.00217     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 141          |\n",
      "|    total_timesteps    | 12230656     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005230818  |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.939        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.066       |\n",
      "|    mean_step_reward   | -0.007912502 |\n",
      "|    n_updates          | 5968         |\n",
      "|    policyGradLoss     | -0.00796     |\n",
      "|    value_loss         | 0.00121      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 152          |\n",
      "|    total_timesteps    | 12238848     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.003940649  |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.764        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0618      |\n",
      "|    mean_step_reward   | -0.007436947 |\n",
      "|    n_updates          | 5972         |\n",
      "|    policyGradLoss     | -0.00906     |\n",
      "|    value_loss         | 0.00671      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 15            |\n",
      "|    time_elapsed       | 163           |\n",
      "|    total_timesteps    | 12247040      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0043019615  |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.927         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0685       |\n",
      "|    mean_step_reward   | -0.0072194925 |\n",
      "|    n_updates          | 5976          |\n",
      "|    policyGradLoss     | -0.00786      |\n",
      "|    value_loss         | 0.00161       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 175          |\n",
      "|    total_timesteps    | 12255232     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0055424087 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.907        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0646      |\n",
      "|    mean_step_reward   | -0.00697631  |\n",
      "|    n_updates          | 5980         |\n",
      "|    policyGradLoss     | -0.0066      |\n",
      "|    value_loss         | 0.00343      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 17            |\n",
      "|    time_elapsed       | 185           |\n",
      "|    total_timesteps    | 12263424      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.006436762   |\n",
      "|    entropy_loss       | -2.14         |\n",
      "|    explained_variance | 0.865         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0713       |\n",
      "|    mean_step_reward   | -0.0077282065 |\n",
      "|    n_updates          | 5984          |\n",
      "|    policyGradLoss     | -0.0071       |\n",
      "|    value_loss         | 0.00482       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 196          |\n",
      "|    total_timesteps    | 12271616     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0058199978 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.909        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0625      |\n",
      "|    mean_step_reward   | -0.006654925 |\n",
      "|    n_updates          | 5988         |\n",
      "|    policyGradLoss     | -0.00655     |\n",
      "|    value_loss         | 0.00538      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 207          |\n",
      "|    total_timesteps    | 12279808     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004193067  |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.948        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0667      |\n",
      "|    mean_step_reward   | -0.007142375 |\n",
      "|    n_updates          | 5992         |\n",
      "|    policyGradLoss     | -0.00761     |\n",
      "|    value_loss         | 0.00147      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 748          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 218          |\n",
      "|    total_timesteps    | 12288000     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033635695 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.939        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0645      |\n",
      "|    mean_step_reward   | -0.007619499 |\n",
      "|    n_updates          | 5996         |\n",
      "|    policyGradLoss     | -0.00667     |\n",
      "|    value_loss         | 0.0016       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 746           |\n",
      "|    iterations         | 21            |\n",
      "|    time_elapsed       | 230           |\n",
      "|    total_timesteps    | 12296192      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005595386   |\n",
      "|    entropy_loss       | -2.16         |\n",
      "|    explained_variance | 0.9           |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0635       |\n",
      "|    mean_step_reward   | -0.0076154736 |\n",
      "|    n_updates          | 6000          |\n",
      "|    policyGradLoss     | -0.00622      |\n",
      "|    value_loss         | 0.00385       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 22            |\n",
      "|    time_elapsed       | 240           |\n",
      "|    total_timesteps    | 12304384      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005101758   |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.892         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0695       |\n",
      "|    mean_step_reward   | -0.0071154702 |\n",
      "|    n_updates          | 6004          |\n",
      "|    policyGradLoss     | -0.0077       |\n",
      "|    value_loss         | 0.00369       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 252          |\n",
      "|    total_timesteps    | 12312576     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0053334394 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.944        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0607      |\n",
      "|    mean_step_reward   | -0.007272056 |\n",
      "|    n_updates          | 6008         |\n",
      "|    policyGradLoss     | -0.00667     |\n",
      "|    value_loss         | 0.00189      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 745           |\n",
      "|    iterations         | 24            |\n",
      "|    time_elapsed       | 263           |\n",
      "|    total_timesteps    | 12320768      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005572915   |\n",
      "|    entropy_loss       | -2.12         |\n",
      "|    explained_variance | 0.959         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0604       |\n",
      "|    mean_step_reward   | -0.0055136383 |\n",
      "|    n_updates          | 6012          |\n",
      "|    policyGradLoss     | -0.00702      |\n",
      "|    value_loss         | 0.0042        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 274          |\n",
      "|    total_timesteps    | 12328960     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0047102985 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.965        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0654      |\n",
      "|    mean_step_reward   | -0.008157132 |\n",
      "|    n_updates          | 6016         |\n",
      "|    policyGradLoss     | -0.0106      |\n",
      "|    value_loss         | 0.000232     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 745          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 285          |\n",
      "|    total_timesteps    | 12337152     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0068796463 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.899        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0639      |\n",
      "|    mean_step_reward   | -0.007049587 |\n",
      "|    n_updates          | 6020         |\n",
      "|    policyGradLoss     | -0.00628     |\n",
      "|    value_loss         | 0.00436      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 746          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 296          |\n",
      "|    total_timesteps    | 12345344     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005034636  |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.982        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0577      |\n",
      "|    mean_step_reward   | -0.007863043 |\n",
      "|    n_updates          | 6024         |\n",
      "|    policyGradLoss     | -0.00743     |\n",
      "|    value_loss         | 0.000418     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 746           |\n",
      "|    iterations         | 28            |\n",
      "|    time_elapsed       | 307           |\n",
      "|    total_timesteps    | 12353536      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0046776244  |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.953         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0585       |\n",
      "|    mean_step_reward   | -0.0070670443 |\n",
      "|    n_updates          | 6028          |\n",
      "|    policyGradLoss     | -0.0074       |\n",
      "|    value_loss         | 0.00165       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 744          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 318          |\n",
      "|    total_timesteps    | 12361728     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0041395794 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.984        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0652      |\n",
      "|    mean_step_reward   | -0.007414739 |\n",
      "|    n_updates          | 6032         |\n",
      "|    policyGradLoss     | -0.00582     |\n",
      "|    value_loss         | 0.000377     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 747          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 328          |\n",
      "|    total_timesteps    | 12369920     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0063590426 |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.968        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0637      |\n",
      "|    mean_step_reward   | -0.006313493 |\n",
      "|    n_updates          | 6036         |\n",
      "|    policyGradLoss     | -0.00663     |\n",
      "|    value_loss         | 0.00343      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 745          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 340          |\n",
      "|    total_timesteps    | 12378112     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0048239473 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.939        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0688      |\n",
      "|    mean_step_reward   | -0.007352708 |\n",
      "|    n_updates          | 6040         |\n",
      "|    policyGradLoss     | -0.00492     |\n",
      "|    value_loss         | 0.00183      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 744          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 352          |\n",
      "|    total_timesteps    | 12386304     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0061749467 |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.895        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0683      |\n",
      "|    mean_step_reward   | -0.007257037 |\n",
      "|    n_updates          | 6044         |\n",
      "|    policyGradLoss     | -0.00635     |\n",
      "|    value_loss         | 0.00384      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 362         |\n",
      "|    total_timesteps    | 12394496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004607141 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0688     |\n",
      "|    mean_step_reward   | -0.00771554 |\n",
      "|    n_updates          | 6048        |\n",
      "|    policyGradLoss     | -0.00676    |\n",
      "|    value_loss         | 0.000274    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 744          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 374          |\n",
      "|    total_timesteps    | 12402688     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0042691403 |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.941        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.065       |\n",
      "|    mean_step_reward   | -0.007076879 |\n",
      "|    n_updates          | 6052         |\n",
      "|    policyGradLoss     | -0.00672     |\n",
      "|    value_loss         | 0.00117      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 745          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 384          |\n",
      "|    total_timesteps    | 12410880     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0046746423 |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.99         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0679      |\n",
      "|    mean_step_reward   | -0.007382361 |\n",
      "|    n_updates          | 6056         |\n",
      "|    policyGradLoss     | -0.00794     |\n",
      "|    value_loss         | 0.000307     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 744          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 396          |\n",
      "|    total_timesteps    | 12419072     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0051452024 |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.963        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0635      |\n",
      "|    mean_step_reward   | -0.006524236 |\n",
      "|    n_updates          | 6060         |\n",
      "|    policyGradLoss     | -0.00672     |\n",
      "|    value_loss         | 0.003        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 743          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 407          |\n",
      "|    total_timesteps    | 12427264     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0068158777 |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.911        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0653      |\n",
      "|    mean_step_reward   | -0.007301748 |\n",
      "|    n_updates          | 6064         |\n",
      "|    policyGradLoss     | -0.00621     |\n",
      "|    value_loss         | 0.0029       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 746          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 417          |\n",
      "|    total_timesteps    | 12435456     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00459543   |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.934        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0679      |\n",
      "|    mean_step_reward   | -0.007845502 |\n",
      "|    n_updates          | 6068         |\n",
      "|    policyGradLoss     | -0.00649     |\n",
      "|    value_loss         | 0.00123      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 745           |\n",
      "|    iterations         | 39            |\n",
      "|    time_elapsed       | 428           |\n",
      "|    total_timesteps    | 12443648      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004365071   |\n",
      "|    entropy_loss       | -2.12         |\n",
      "|    explained_variance | 0.985         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0674       |\n",
      "|    mean_step_reward   | -0.0069413288 |\n",
      "|    n_updates          | 6072          |\n",
      "|    policyGradLoss     | -0.00649      |\n",
      "|    value_loss         | 0.000339      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 745          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 439          |\n",
      "|    total_timesteps    | 12451840     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.006177377  |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.984        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0704      |\n",
      "|    mean_step_reward   | -0.006779894 |\n",
      "|    n_updates          | 6076         |\n",
      "|    policyGradLoss     | -0.00693     |\n",
      "|    value_loss         | 0.000885     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_37.zip\n",
      "[EVAL] Mean Return: -19.606, Best Return: -16.009\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_37_-19.61.mp4\n",
      "\n",
      "=== Round 39 | Learn 327680 steps (Total trained: 12451840) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 977      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 12460032 |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 911          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 12468224     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.006671565  |\n",
      "|    entropy_loss       | -2.07        |\n",
      "|    explained_variance | 0.861        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0618      |\n",
      "|    mean_step_reward   | -0.006782349 |\n",
      "|    n_updates          | 6084         |\n",
      "|    policyGradLoss     | -0.00746     |\n",
      "|    value_loss         | 0.00847      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 825          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 29           |\n",
      "|    total_timesteps    | 12476416     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0058557647 |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.97         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0632      |\n",
      "|    mean_step_reward   | -0.00729673  |\n",
      "|    n_updates          | 6088         |\n",
      "|    policyGradLoss     | -0.00748     |\n",
      "|    value_loss         | 0.000616     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 806          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 40           |\n",
      "|    total_timesteps    | 12484608     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0046505276 |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.974        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0637      |\n",
      "|    mean_step_reward   | -0.007854925 |\n",
      "|    n_updates          | 6092         |\n",
      "|    policyGradLoss     | -0.00655     |\n",
      "|    value_loss         | 0.000464     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 794           |\n",
      "|    iterations         | 5             |\n",
      "|    time_elapsed       | 51            |\n",
      "|    total_timesteps    | 12492800      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004384656   |\n",
      "|    entropy_loss       | -2.09         |\n",
      "|    explained_variance | 0.983         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.059        |\n",
      "|    mean_step_reward   | -0.0070387204 |\n",
      "|    n_updates          | 6096          |\n",
      "|    policyGradLoss     | -0.00668      |\n",
      "|    value_loss         | 0.000697      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 780           |\n",
      "|    iterations         | 6             |\n",
      "|    time_elapsed       | 62            |\n",
      "|    total_timesteps    | 12500992      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0064348904  |\n",
      "|    entropy_loss       | -2.08         |\n",
      "|    explained_variance | 0.981         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0689       |\n",
      "|    mean_step_reward   | -0.0070128716 |\n",
      "|    n_updates          | 6100          |\n",
      "|    policyGradLoss     | -0.00685      |\n",
      "|    value_loss         | 0.000903      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 786          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 72           |\n",
      "|    total_timesteps    | 12509184     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0052145054 |\n",
      "|    entropy_loss       | -2.08        |\n",
      "|    explained_variance | 0.984        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0618      |\n",
      "|    mean_step_reward   | -0.007325462 |\n",
      "|    n_updates          | 6104         |\n",
      "|    policyGradLoss     | -0.00638     |\n",
      "|    value_loss         | 0.00036      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 773           |\n",
      "|    iterations         | 8             |\n",
      "|    time_elapsed       | 84            |\n",
      "|    total_timesteps    | 12517376      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.006861991   |\n",
      "|    entropy_loss       | -2.05         |\n",
      "|    explained_variance | 0.952         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0641       |\n",
      "|    mean_step_reward   | -0.0064973347 |\n",
      "|    n_updates          | 6108          |\n",
      "|    policyGradLoss     | -0.00529      |\n",
      "|    value_loss         | 0.00439       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 765          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 96           |\n",
      "|    total_timesteps    | 12525568     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005327086  |\n",
      "|    entropy_loss       | -2.07        |\n",
      "|    explained_variance | 0.867        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0627      |\n",
      "|    mean_step_reward   | -0.006989442 |\n",
      "|    n_updates          | 6112         |\n",
      "|    policyGradLoss     | -0.00816     |\n",
      "|    value_loss         | 0.00584      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 768           |\n",
      "|    iterations         | 10            |\n",
      "|    time_elapsed       | 106           |\n",
      "|    total_timesteps    | 12533760      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0048402837  |\n",
      "|    entropy_loss       | -2.1          |\n",
      "|    explained_variance | 0.975         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.069        |\n",
      "|    mean_step_reward   | -0.0073654735 |\n",
      "|    n_updates          | 6116          |\n",
      "|    policyGradLoss     | -0.00734      |\n",
      "|    value_loss         | 0.000546      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 762           |\n",
      "|    iterations         | 11            |\n",
      "|    time_elapsed       | 118           |\n",
      "|    total_timesteps    | 12541952      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004315721   |\n",
      "|    entropy_loss       | -2.09         |\n",
      "|    explained_variance | 0.987         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0718       |\n",
      "|    mean_step_reward   | -0.0067286994 |\n",
      "|    n_updates          | 6120          |\n",
      "|    policyGradLoss     | -0.00748      |\n",
      "|    value_loss         | 0.000719      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 764          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 128          |\n",
      "|    total_timesteps    | 12550144     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.007039597  |\n",
      "|    entropy_loss       | -2.09        |\n",
      "|    explained_variance | 0.917        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0632      |\n",
      "|    mean_step_reward   | -0.007482125 |\n",
      "|    n_updates          | 6124         |\n",
      "|    policyGradLoss     | -0.00721     |\n",
      "|    value_loss         | 0.00223      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 760          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 140          |\n",
      "|    total_timesteps    | 12558336     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0058375895 |\n",
      "|    entropy_loss       | -2.09        |\n",
      "|    explained_variance | 0.974        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0563      |\n",
      "|    mean_step_reward   | -0.007827688 |\n",
      "|    n_updates          | 6128         |\n",
      "|    policyGradLoss     | -0.00824     |\n",
      "|    value_loss         | 0.000567     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 756           |\n",
      "|    iterations         | 14            |\n",
      "|    time_elapsed       | 151           |\n",
      "|    total_timesteps    | 12566528      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.006687041   |\n",
      "|    entropy_loss       | -2.09         |\n",
      "|    explained_variance | 0.702         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0659       |\n",
      "|    mean_step_reward   | -0.0077086845 |\n",
      "|    n_updates          | 6132          |\n",
      "|    policyGradLoss     | -0.00936      |\n",
      "|    value_loss         | 0.00566       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 762          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 161          |\n",
      "|    total_timesteps    | 12574720     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.008801543  |\n",
      "|    entropy_loss       | -2.07        |\n",
      "|    explained_variance | 0.795        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0582      |\n",
      "|    mean_step_reward   | -0.006034662 |\n",
      "|    n_updates          | 6136         |\n",
      "|    policyGradLoss     | -0.00847     |\n",
      "|    value_loss         | 0.0165       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 757           |\n",
      "|    iterations         | 16            |\n",
      "|    time_elapsed       | 172           |\n",
      "|    total_timesteps    | 12582912      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004375116   |\n",
      "|    entropy_loss       | -2.12         |\n",
      "|    explained_variance | 0.945         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0605       |\n",
      "|    mean_step_reward   | -0.0077349646 |\n",
      "|    n_updates          | 6140          |\n",
      "|    policyGradLoss     | -0.00654      |\n",
      "|    value_loss         | 0.000535      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 184          |\n",
      "|    total_timesteps    | 12591104     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0058103073 |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.972        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0684      |\n",
      "|    mean_step_reward   | -0.006860898 |\n",
      "|    n_updates          | 6144         |\n",
      "|    policyGradLoss     | -0.00784     |\n",
      "|    value_loss         | 0.00136      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 758          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 194          |\n",
      "|    total_timesteps    | 12599296     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034933342 |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.977        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0689      |\n",
      "|    mean_step_reward   | -0.007450642 |\n",
      "|    n_updates          | 6148         |\n",
      "|    policyGradLoss     | -0.00771     |\n",
      "|    value_loss         | 0.000578     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 205         |\n",
      "|    total_timesteps    | 12607488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004574271 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.067      |\n",
      "|    mean_step_reward   | -0.00772455 |\n",
      "|    n_updates          | 6152        |\n",
      "|    policyGradLoss     | -0.0081     |\n",
      "|    value_loss         | 0.000257    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 216         |\n",
      "|    total_timesteps    | 12615680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007294629 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0663     |\n",
      "|    mean_step_reward   | -0.00728618 |\n",
      "|    n_updates          | 6156        |\n",
      "|    policyGradLoss     | -0.00785    |\n",
      "|    value_loss         | 0.000316    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 758           |\n",
      "|    iterations         | 21            |\n",
      "|    time_elapsed       | 226           |\n",
      "|    total_timesteps    | 12623872      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.007706637   |\n",
      "|    entropy_loss       | -2.05         |\n",
      "|    explained_variance | 0.878         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.065        |\n",
      "|    mean_step_reward   | -0.0064861253 |\n",
      "|    n_updates          | 6160          |\n",
      "|    policyGradLoss     | -0.00691      |\n",
      "|    value_loss         | 0.00896       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 757           |\n",
      "|    iterations         | 22            |\n",
      "|    time_elapsed       | 237           |\n",
      "|    total_timesteps    | 12632064      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0056946203  |\n",
      "|    entropy_loss       | -2.08         |\n",
      "|    explained_variance | 0.969         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0614       |\n",
      "|    mean_step_reward   | -0.0072827213 |\n",
      "|    n_updates          | 6164          |\n",
      "|    policyGradLoss     | -0.00689      |\n",
      "|    value_loss         | 0.000364      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 754           |\n",
      "|    iterations         | 23            |\n",
      "|    time_elapsed       | 249           |\n",
      "|    total_timesteps    | 12640256      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0060832324  |\n",
      "|    entropy_loss       | -2.06         |\n",
      "|    explained_variance | 0.977         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0643       |\n",
      "|    mean_step_reward   | -0.0067485846 |\n",
      "|    n_updates          | 6168          |\n",
      "|    policyGradLoss     | -0.00572      |\n",
      "|    value_loss         | 0.00153       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 260          |\n",
      "|    total_timesteps    | 12648448     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.006153227  |\n",
      "|    entropy_loss       | -2.07        |\n",
      "|    explained_variance | 0.989        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0672      |\n",
      "|    mean_step_reward   | -0.007690245 |\n",
      "|    n_updates          | 6172         |\n",
      "|    policyGradLoss     | -0.00857     |\n",
      "|    value_loss         | 0.000268     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 754           |\n",
      "|    iterations         | 25            |\n",
      "|    time_elapsed       | 271           |\n",
      "|    total_timesteps    | 12656640      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0054096426  |\n",
      "|    entropy_loss       | -2.05         |\n",
      "|    explained_variance | 0.99          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0669       |\n",
      "|    mean_step_reward   | -0.0072572697 |\n",
      "|    n_updates          | 6176          |\n",
      "|    policyGradLoss     | -0.0071       |\n",
      "|    value_loss         | 0.000272      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 26            |\n",
      "|    time_elapsed       | 282           |\n",
      "|    total_timesteps    | 12664832      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.006128542   |\n",
      "|    entropy_loss       | -2.06         |\n",
      "|    explained_variance | 0.893         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0581       |\n",
      "|    mean_step_reward   | -0.0072825314 |\n",
      "|    n_updates          | 6180          |\n",
      "|    policyGradLoss     | -0.00636      |\n",
      "|    value_loss         | 0.00305       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 754           |\n",
      "|    iterations         | 27            |\n",
      "|    time_elapsed       | 293           |\n",
      "|    total_timesteps    | 12673024      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0082375975  |\n",
      "|    entropy_loss       | -2.04         |\n",
      "|    explained_variance | 0.948         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0648       |\n",
      "|    mean_step_reward   | -0.0064588673 |\n",
      "|    n_updates          | 6184          |\n",
      "|    policyGradLoss     | -0.00753      |\n",
      "|    value_loss         | 0.00366       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 28            |\n",
      "|    time_elapsed       | 304           |\n",
      "|    total_timesteps    | 12681216      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0045590415  |\n",
      "|    entropy_loss       | -2.08         |\n",
      "|    explained_variance | 0.867         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0602       |\n",
      "|    mean_step_reward   | -0.0075457925 |\n",
      "|    n_updates          | 6188          |\n",
      "|    policyGradLoss     | -0.00243      |\n",
      "|    value_loss         | 0.00164       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 29            |\n",
      "|    time_elapsed       | 316           |\n",
      "|    total_timesteps    | 12689408      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005021099   |\n",
      "|    entropy_loss       | -2.08         |\n",
      "|    explained_variance | 0.968         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0608       |\n",
      "|    mean_step_reward   | -0.0068047326 |\n",
      "|    n_updates          | 6192          |\n",
      "|    policyGradLoss     | -0.00588      |\n",
      "|    value_loss         | 0.00118       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 326          |\n",
      "|    total_timesteps    | 12697600     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0047749393 |\n",
      "|    entropy_loss       | -2.09        |\n",
      "|    explained_variance | 0.984        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0619      |\n",
      "|    mean_step_reward   | -0.007651448 |\n",
      "|    n_updates          | 6196         |\n",
      "|    policyGradLoss     | -0.0076      |\n",
      "|    value_loss         | 0.000227     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 337          |\n",
      "|    total_timesteps    | 12705792     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005834353  |\n",
      "|    entropy_loss       | -2.07        |\n",
      "|    explained_variance | 0.99         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0687      |\n",
      "|    mean_step_reward   | -0.007335538 |\n",
      "|    n_updates          | 6200         |\n",
      "|    policyGradLoss     | -0.00686     |\n",
      "|    value_loss         | 0.000347     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 348          |\n",
      "|    total_timesteps    | 12713984     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.008094508  |\n",
      "|    entropy_loss       | -2.07        |\n",
      "|    explained_variance | 0.725        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0646      |\n",
      "|    mean_step_reward   | -0.007330492 |\n",
      "|    n_updates          | 6204         |\n",
      "|    policyGradLoss     | -0.00942     |\n",
      "|    value_loss         | 0.0055       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 33            |\n",
      "|    time_elapsed       | 359           |\n",
      "|    total_timesteps    | 12722176      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.006510166   |\n",
      "|    entropy_loss       | -2.06         |\n",
      "|    explained_variance | 0.973         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0623       |\n",
      "|    mean_step_reward   | -0.0065509463 |\n",
      "|    n_updates          | 6208          |\n",
      "|    policyGradLoss     | -0.00757      |\n",
      "|    value_loss         | 0.00104       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 34            |\n",
      "|    time_elapsed       | 371           |\n",
      "|    total_timesteps    | 12730368      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0062764687  |\n",
      "|    entropy_loss       | -2.08         |\n",
      "|    explained_variance | 0.907         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0622       |\n",
      "|    mean_step_reward   | -0.0073006153 |\n",
      "|    n_updates          | 6212          |\n",
      "|    policyGradLoss     | -0.00673      |\n",
      "|    value_loss         | 0.00303       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 381          |\n",
      "|    total_timesteps    | 12738560     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.007217382  |\n",
      "|    entropy_loss       | -2.07        |\n",
      "|    explained_variance | 0.956        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0674      |\n",
      "|    mean_step_reward   | -0.006425146 |\n",
      "|    n_updates          | 6216         |\n",
      "|    policyGradLoss     | -0.00753     |\n",
      "|    value_loss         | 0.00311      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 392          |\n",
      "|    total_timesteps    | 12746752     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00582037   |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.581        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0657      |\n",
      "|    mean_step_reward   | -0.008025419 |\n",
      "|    n_updates          | 6220         |\n",
      "|    policyGradLoss     | -0.00737     |\n",
      "|    value_loss         | 0.00079      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 37            |\n",
      "|    time_elapsed       | 404           |\n",
      "|    total_timesteps    | 12754944      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005506851   |\n",
      "|    entropy_loss       | -2.09         |\n",
      "|    explained_variance | 0.94          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0637       |\n",
      "|    mean_step_reward   | -0.0070414227 |\n",
      "|    n_updates          | 6224          |\n",
      "|    policyGradLoss     | -0.00782      |\n",
      "|    value_loss         | 0.00202       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 414          |\n",
      "|    total_timesteps    | 12763136     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0056898557 |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.978        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0599      |\n",
      "|    mean_step_reward   | -0.007043193 |\n",
      "|    n_updates          | 6228         |\n",
      "|    policyGradLoss     | -0.00679     |\n",
      "|    value_loss         | 0.000585     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 749          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 426          |\n",
      "|    total_timesteps    | 12771328     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0070388988 |\n",
      "|    entropy_loss       | -2.08        |\n",
      "|    explained_variance | 0.923        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0601      |\n",
      "|    mean_step_reward   | -0.006904002 |\n",
      "|    n_updates          | 6232         |\n",
      "|    policyGradLoss     | -0.00695     |\n",
      "|    value_loss         | 0.00495      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 749           |\n",
      "|    iterations         | 40            |\n",
      "|    time_elapsed       | 436           |\n",
      "|    total_timesteps    | 12779520      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005200739   |\n",
      "|    entropy_loss       | -2.11         |\n",
      "|    explained_variance | 0.975         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0617       |\n",
      "|    mean_step_reward   | -0.0071538687 |\n",
      "|    n_updates          | 6236          |\n",
      "|    policyGradLoss     | -0.00573      |\n",
      "|    value_loss         | 0.00117       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_38.zip\n",
      "[EVAL] Mean Return: -19.542, Best Return: -16.078\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_38_-19.54.mp4\n",
      "\n",
      "=== Round 40 | Learn 327680 steps (Total trained: 12779520) ===\n",
      "Logging to ./runs_smw/tb/NoRun_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1216     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 12787712 |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 884          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 12795904     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.006091073  |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.972        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0847      |\n",
      "|    mean_step_reward   | -0.007621851 |\n",
      "|    n_updates          | 6244         |\n",
      "|    policyGradLoss     | -0.0173      |\n",
      "|    value_loss         | 3.64e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 857           |\n",
      "|    iterations         | 3             |\n",
      "|    time_elapsed       | 28            |\n",
      "|    total_timesteps    | 12804096      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.008561799   |\n",
      "|    entropy_loss       | -2.1          |\n",
      "|    explained_variance | 0.87          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0685       |\n",
      "|    mean_step_reward   | -0.0073586036 |\n",
      "|    n_updates          | 6248          |\n",
      "|    policyGradLoss     | -0.00314      |\n",
      "|    value_loss         | 0.00347       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 817          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 40           |\n",
      "|    total_timesteps    | 12812288     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.006294893  |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.895        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0614      |\n",
      "|    mean_step_reward   | -0.007092135 |\n",
      "|    n_updates          | 6252         |\n",
      "|    policyGradLoss     | -0.0062      |\n",
      "|    value_loss         | 0.00404      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 791          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 51           |\n",
      "|    total_timesteps    | 12820480     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0049802247 |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.953        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0651      |\n",
      "|    mean_step_reward   | -0.006759652 |\n",
      "|    n_updates          | 6256         |\n",
      "|    policyGradLoss     | -0.00575     |\n",
      "|    value_loss         | 0.00126      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 797           |\n",
      "|    iterations         | 6             |\n",
      "|    time_elapsed       | 61            |\n",
      "|    total_timesteps    | 12828672      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.005171207   |\n",
      "|    entropy_loss       | -2.11         |\n",
      "|    explained_variance | 0.992         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0673       |\n",
      "|    mean_step_reward   | -0.0073632803 |\n",
      "|    n_updates          | 6260          |\n",
      "|    policyGradLoss     | -0.00845      |\n",
      "|    value_loss         | 0.000201      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 782           |\n",
      "|    iterations         | 7             |\n",
      "|    time_elapsed       | 73            |\n",
      "|    total_timesteps    | 12836864      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.007335675   |\n",
      "|    entropy_loss       | -2.09         |\n",
      "|    explained_variance | 0.924         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0665       |\n",
      "|    mean_step_reward   | -0.0068982025 |\n",
      "|    n_updates          | 6264          |\n",
      "|    policyGradLoss     | -0.00633      |\n",
      "|    value_loss         | 0.00459       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 84          |\n",
      "|    total_timesteps    | 12845056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.00529061  |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0636     |\n",
      "|    mean_step_reward   | -0.00753102 |\n",
      "|    n_updates          | 6268        |\n",
      "|    policyGradLoss     | -0.00813    |\n",
      "|    value_loss         | 0.000122    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 774          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 95           |\n",
      "|    total_timesteps    | 12853248     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0062935483 |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.807        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0644      |\n",
      "|    mean_step_reward   | -0.007395374 |\n",
      "|    n_updates          | 6272         |\n",
      "|    policyGradLoss     | -0.00686     |\n",
      "|    value_loss         | 0.0048       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 768           |\n",
      "|    iterations         | 10            |\n",
      "|    time_elapsed       | 106           |\n",
      "|    total_timesteps    | 12861440      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0059151836  |\n",
      "|    entropy_loss       | -2.11         |\n",
      "|    explained_variance | 0.961         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0632       |\n",
      "|    mean_step_reward   | -0.0070593045 |\n",
      "|    n_updates          | 6276          |\n",
      "|    policyGradLoss     | -0.00492      |\n",
      "|    value_loss         | 0.00123       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 773           |\n",
      "|    iterations         | 11            |\n",
      "|    time_elapsed       | 116           |\n",
      "|    total_timesteps    | 12869632      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0043041734  |\n",
      "|    entropy_loss       | -2.1          |\n",
      "|    explained_variance | 0.989         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0634       |\n",
      "|    mean_step_reward   | -0.0067430297 |\n",
      "|    n_updates          | 6280          |\n",
      "|    policyGradLoss     | -0.00722      |\n",
      "|    value_loss         | 0.000544      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 766          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 128          |\n",
      "|    total_timesteps    | 12877824     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038254613 |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.934        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0583      |\n",
      "|    mean_step_reward   | -0.007905701 |\n",
      "|    n_updates          | 6284         |\n",
      "|    policyGradLoss     | -0.00345     |\n",
      "|    value_loss         | 0.000931     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 762          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 139          |\n",
      "|    total_timesteps    | 12886016     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005191631  |\n",
      "|    entropy_loss       | -2.08        |\n",
      "|    explained_variance | 0.993        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0571      |\n",
      "|    mean_step_reward   | -0.006429029 |\n",
      "|    n_updates          | 6288         |\n",
      "|    policyGradLoss     | -0.00771     |\n",
      "|    value_loss         | 0.00053      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 766          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 149          |\n",
      "|    total_timesteps    | 12894208     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.005735685  |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.915        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0667      |\n",
      "|    mean_step_reward   | -0.007463855 |\n",
      "|    n_updates          | 6292         |\n",
      "|    policyGradLoss     | -0.00727     |\n",
      "|    value_loss         | 0.00205      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 762           |\n",
      "|    iterations         | 15            |\n",
      "|    time_elapsed       | 161           |\n",
      "|    total_timesteps    | 12902400      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.006145444   |\n",
      "|    entropy_loss       | -2.1          |\n",
      "|    explained_variance | 0.923         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0677       |\n",
      "|    mean_step_reward   | -0.0072744363 |\n",
      "|    n_updates          | 6296          |\n",
      "|    policyGradLoss     | -0.00752      |\n",
      "|    value_loss         | 0.00286       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 762           |\n",
      "|    iterations         | 16            |\n",
      "|    time_elapsed       | 171           |\n",
      "|    total_timesteps    | 12910592      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0069247917  |\n",
      "|    entropy_loss       | -2.1          |\n",
      "|    explained_variance | 0.978         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0673       |\n",
      "|    mean_step_reward   | -0.0068318974 |\n",
      "|    n_updates          | 6300          |\n",
      "|    policyGradLoss     | -0.00844      |\n",
      "|    value_loss         | 0.00101       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 760           |\n",
      "|    iterations         | 17            |\n",
      "|    time_elapsed       | 183           |\n",
      "|    total_timesteps    | 12918784      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.008139046   |\n",
      "|    entropy_loss       | -2.09         |\n",
      "|    explained_variance | 0.748         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0587       |\n",
      "|    mean_step_reward   | -0.0072914953 |\n",
      "|    n_updates          | 6304          |\n",
      "|    policyGradLoss     | -0.00508      |\n",
      "|    value_loss         | 0.00861       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 194          |\n",
      "|    total_timesteps    | 12926976     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0067361747 |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.778        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0659      |\n",
      "|    mean_step_reward   | -0.006706847 |\n",
      "|    n_updates          | 6308         |\n",
      "|    policyGradLoss     | -0.00694     |\n",
      "|    value_loss         | 0.0105       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 761           |\n",
      "|    iterations         | 19            |\n",
      "|    time_elapsed       | 204           |\n",
      "|    total_timesteps    | 12935168      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.006609865   |\n",
      "|    entropy_loss       | -2.11         |\n",
      "|    explained_variance | 0.841         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0611       |\n",
      "|    mean_step_reward   | -0.0074080583 |\n",
      "|    n_updates          | 6312          |\n",
      "|    policyGradLoss     | -0.00826      |\n",
      "|    value_loss         | 0.00778       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 758           |\n",
      "|    iterations         | 20            |\n",
      "|    time_elapsed       | 216           |\n",
      "|    total_timesteps    | 12943360      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.004794916   |\n",
      "|    entropy_loss       | -2.15         |\n",
      "|    explained_variance | 0.93          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.062        |\n",
      "|    mean_step_reward   | -0.0070049553 |\n",
      "|    n_updates          | 6316          |\n",
      "|    policyGradLoss     | -0.00572      |\n",
      "|    value_loss         | 0.00141       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 756          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 227          |\n",
      "|    total_timesteps    | 12951552     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0064247465 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | -0.0926      |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.081       |\n",
      "|    mean_step_reward   | -0.008025117 |\n",
      "|    n_updates          | 6320         |\n",
      "|    policyGradLoss     | -0.0153      |\n",
      "|    value_loss         | 3.17e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 757           |\n",
      "|    iterations         | 22            |\n",
      "|    time_elapsed       | 237           |\n",
      "|    total_timesteps    | 12959744      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0068682265  |\n",
      "|    entropy_loss       | -2.09         |\n",
      "|    explained_variance | 0.904         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0648       |\n",
      "|    mean_step_reward   | -0.0069506466 |\n",
      "|    n_updates          | 6324          |\n",
      "|    policyGradLoss     | -0.00795      |\n",
      "|    value_loss         | 0.00592       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 755          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 249          |\n",
      "|    total_timesteps    | 12967936     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.006106452  |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.877        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0641      |\n",
      "|    mean_step_reward   | -0.007029012 |\n",
      "|    n_updates          | 6328         |\n",
      "|    policyGradLoss     | -0.00598     |\n",
      "|    value_loss         | 0.00571      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 757          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 259          |\n",
      "|    total_timesteps    | 12976128     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.00672899   |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.738        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0681      |\n",
      "|    mean_step_reward   | -0.007408373 |\n",
      "|    n_updates          | 6332         |\n",
      "|    policyGradLoss     | -0.0105      |\n",
      "|    value_loss         | 0.00533      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 754           |\n",
      "|    iterations         | 25            |\n",
      "|    time_elapsed       | 271           |\n",
      "|    total_timesteps    | 12984320      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0057308953  |\n",
      "|    entropy_loss       | -2.1          |\n",
      "|    explained_variance | 0.905         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0685       |\n",
      "|    mean_step_reward   | -0.0069585936 |\n",
      "|    n_updates          | 6336          |\n",
      "|    policyGradLoss     | -0.00977      |\n",
      "|    value_loss         | 0.00453       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 282          |\n",
      "|    total_timesteps    | 12992512     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0048372857 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.966        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0613      |\n",
      "|    mean_step_reward   | -0.007001673 |\n",
      "|    n_updates          | 6340         |\n",
      "|    policyGradLoss     | -0.00606     |\n",
      "|    value_loss         | 0.000755     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 754          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 293          |\n",
      "|    total_timesteps    | 13000704     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0051283715 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.994        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0774      |\n",
      "|    mean_step_reward   | -0.007644796 |\n",
      "|    n_updates          | 6344         |\n",
      "|    policyGradLoss     | -0.0136      |\n",
      "|    value_loss         | 5.78e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 28            |\n",
      "|    time_elapsed       | 304           |\n",
      "|    total_timesteps    | 13008896      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.006718252   |\n",
      "|    entropy_loss       | -2.11         |\n",
      "|    explained_variance | 0.94          |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0582       |\n",
      "|    mean_step_reward   | -0.0071728835 |\n",
      "|    n_updates          | 6348          |\n",
      "|    policyGradLoss     | -0.00693      |\n",
      "|    value_loss         | 0.00324       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 752          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 315          |\n",
      "|    total_timesteps    | 13017088     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0053382087 |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.94         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0641      |\n",
      "|    mean_step_reward   | -0.006424869 |\n",
      "|    n_updates          | 6352         |\n",
      "|    policyGradLoss     | -0.00622     |\n",
      "|    value_loss         | 0.00322      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 752           |\n",
      "|    iterations         | 30            |\n",
      "|    time_elapsed       | 326           |\n",
      "|    total_timesteps    | 13025280      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0047594067  |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.985         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0629       |\n",
      "|    mean_step_reward   | -0.0074079833 |\n",
      "|    n_updates          | 6356          |\n",
      "|    policyGradLoss     | -0.00727      |\n",
      "|    value_loss         | 0.000416      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 338          |\n",
      "|    total_timesteps    | 13033472     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0059838546 |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.984        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0627      |\n",
      "|    mean_step_reward   | -0.007386785 |\n",
      "|    n_updates          | 6360         |\n",
      "|    policyGradLoss     | -0.00661     |\n",
      "|    value_loss         | 0.000546     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 753           |\n",
      "|    iterations         | 32            |\n",
      "|    time_elapsed       | 348           |\n",
      "|    total_timesteps    | 13041664      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.006266905   |\n",
      "|    entropy_loss       | -2.12         |\n",
      "|    explained_variance | 0.816         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0609       |\n",
      "|    mean_step_reward   | -0.0072152885 |\n",
      "|    n_updates          | 6364          |\n",
      "|    policyGradLoss     | -0.00797      |\n",
      "|    value_loss         | 0.00654       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 33            |\n",
      "|    time_elapsed       | 359           |\n",
      "|    total_timesteps    | 13049856      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0047562094  |\n",
      "|    entropy_loss       | -2.12         |\n",
      "|    explained_variance | 0.771         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.064        |\n",
      "|    mean_step_reward   | -0.0076957373 |\n",
      "|    n_updates          | 6368          |\n",
      "|    policyGradLoss     | -0.0077       |\n",
      "|    value_loss         | 0.00357       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 750          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 371          |\n",
      "|    total_timesteps    | 13058048     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004398928  |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.906        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0606      |\n",
      "|    mean_step_reward   | -0.006895815 |\n",
      "|    n_updates          | 6372         |\n",
      "|    policyGradLoss     | -0.00629     |\n",
      "|    value_loss         | 0.00625      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 35            |\n",
      "|    time_elapsed       | 381           |\n",
      "|    total_timesteps    | 13066240      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0052123824  |\n",
      "|    entropy_loss       | -2.13         |\n",
      "|    explained_variance | 0.955         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0638       |\n",
      "|    mean_step_reward   | -0.0069240085 |\n",
      "|    n_updates          | 6376          |\n",
      "|    policyGradLoss     | -0.00704      |\n",
      "|    value_loss         | 0.00148       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 36            |\n",
      "|    time_elapsed       | 393           |\n",
      "|    total_timesteps    | 13074432      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0053398437  |\n",
      "|    entropy_loss       | -2.12         |\n",
      "|    explained_variance | 0.909         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0705       |\n",
      "|    mean_step_reward   | -0.0072856215 |\n",
      "|    n_updates          | 6380          |\n",
      "|    policyGradLoss     | -0.00817      |\n",
      "|    value_loss         | 0.00404       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 403          |\n",
      "|    total_timesteps    | 13082624     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.004986916  |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.984        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0635      |\n",
      "|    mean_step_reward   | -0.007790182 |\n",
      "|    n_updates          | 6384         |\n",
      "|    policyGradLoss     | -0.00777     |\n",
      "|    value_loss         | 0.000379     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 751           |\n",
      "|    iterations         | 38            |\n",
      "|    time_elapsed       | 414           |\n",
      "|    total_timesteps    | 13090816      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0055129523  |\n",
      "|    entropy_loss       | -2.11         |\n",
      "|    explained_variance | 0.907         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0576       |\n",
      "|    mean_step_reward   | -0.0068448167 |\n",
      "|    n_updates          | 6388          |\n",
      "|    policyGradLoss     | -0.00699      |\n",
      "|    value_loss         | 0.00557       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 751          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 425          |\n",
      "|    total_timesteps    | 13099008     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.006273741  |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.126        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0883      |\n",
      "|    mean_step_reward   | -0.008008104 |\n",
      "|    n_updates          | 6392         |\n",
      "|    policyGradLoss     | -0.0188      |\n",
      "|    value_loss         | 3.16e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 750           |\n",
      "|    iterations         | 40            |\n",
      "|    time_elapsed       | 436           |\n",
      "|    total_timesteps    | 13107200      |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.0044790762  |\n",
      "|    entropy_loss       | -2.11         |\n",
      "|    explained_variance | 0.957         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | -0.0618       |\n",
      "|    mean_step_reward   | -0.0067691808 |\n",
      "|    n_updates          | 6396          |\n",
      "|    policyGradLoss     | -0.0054       |\n",
      "|    value_loss         | 0.00168       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/NoRun_39.zip\n",
      "[EVAL] Mean Return: -19.669, Best Return: -16.179\n",
      "Saved video to ./runs_smw/videos/NoRun/NoRun_39_-19.67.mp4\n",
      "Training finished. Environment closed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntensorboard --logdir=./runs_smw/tb\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    while trained < TOTAL_STEPS:\n",
    "        round_idx += 1\n",
    "        chunk = min(TRAIN_CHUNK, TOTAL_STEPS - trained)\n",
    "        # chunk = 2000\n",
    "        label = \"NoRun\"\n",
    "        tagged_label = f\"{label}_{int(trained/TRAIN_CHUNK)}\"\n",
    "\n",
    "        print(f\"\\n=== Round {round_idx} | Learn {chunk} steps (Total trained: {trained}) ===\")\n",
    "        \n",
    "        # --- Train ---\n",
    "        model.learn(total_timesteps=chunk, reset_num_timesteps=False, tb_log_name=label)\n",
    "        trained += chunk\n",
    "\n",
    "        # --- Save Checkpoint ---\n",
    "        ckpt_path = os.path.join(CKPT_DIR, f\"{tagged_label}.zip\")\n",
    "        model.save(ckpt_path)\n",
    "        print(f\"Saved checkpoint: {ckpt_path}\")\n",
    "\n",
    "        # --- Evaluate ---\n",
    "        mean_ret, best_ret = evaluate_policy(\n",
    "            model,\n",
    "            GAME,\n",
    "            STATE,\n",
    "            n_episodes=EVAL_EPISODES,\n",
    "            max_steps=EVAL_MAX_STEPS,\n",
    "        )\n",
    "        print(f\"[EVAL] Mean Return: {mean_ret:.3f}, Best Return: {best_ret:.3f}\")\n",
    "\n",
    "        # --- Save Best Model ---\n",
    "        # if mean_ret > best_mean:\n",
    "        #     best_mean = mean_ret\n",
    "        #     best_path = os.path.join(LOG_DIR, \"best_model.zip\")\n",
    "        #     model.save(best_path)\n",
    "        #     print(f\"New best record. Saved to {best_path}\")\n",
    "\n",
    "        # --- Record Video ---\n",
    "        out_path = os.path.join(VIDEO_DIR, label)\n",
    "        os.makedirs(out_path,  exist_ok=True)\n",
    "        record_video(\n",
    "            model,\n",
    "            GAME,\n",
    "            STATE,\n",
    "            VIDEO_DIR,\n",
    "            video_len=RECORD_STEPS,\n",
    "            prefix=f\"{label}/{tagged_label}_{mean_ret:.2f}\",\n",
    "        )\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nTraining interrupted manually.\")\n",
    "\n",
    "finally:\n",
    "    train_env.close()\n",
    "    print(\"Training finished. Environment closed.\")\n",
    "    \n",
    "\"\"\"\n",
    "tensorboard --logdir=./runs_smw/tb\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f088b0b3-2418-4866-b332-0312c9f6467f",
   "metadata": {},
   "source": [
    "## Display Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73191bb-e875-4939-b04c-a4670abd9612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "import glob\n",
    "\n",
    "list_of_files = glob.glob(os.path.join(VIDEO_DIR, '*.mp4')) \n",
    "if list_of_files:\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    print(f\"Playing: {latest_file}\")\n",
    "    display(Video(latest_file, embed=True, width=600))\n",
    "else:\n",
    "    print(\"No videos found yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942adf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(\"runs_smw/videos/test_16.mp4\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    cv2.imshow(\"Frame-by-Frame\", frame)\n",
    "\n",
    "    # 關鍵：這裡等待按鍵。按 'n' 鍵跳到下一幀，按 'q' 離開\n",
    "    key = cv2.waitKey(0) \n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('n'):\n",
    "        continue\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lab8 (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
