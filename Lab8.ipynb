{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dceedafe-2782-41a1-8119-50ee3d6c21fd",
   "metadata": {},
   "source": [
    "# 2025 DL Lab8: RL Assignment_Super Mario World"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fa555a-e61c-4fb3-b5d0-289b66570139",
   "metadata": {},
   "source": [
    "**Your Answer:**    \n",
    "Hi I'm XXX, XXXXXXXXXX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5b0974-9605-488a-9fd5-00816e7832cc",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This project implements a **Deep Reinforcement Learning** pipeline to train an autonomous agent for Super Mario World. Leveraging the **Proximal Policy Optimization (PPO)** algorithm, the system interacts with the **stable-retro** environment to master the YoshiIsland1 level. Key components include a custom Vision Backbone for extracting features from raw pixel data and a suite of Environment Wrappers that handle frame preprocessing, action discretization, and reward shaping to facilitate efficient learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02696447",
   "metadata": {},
   "source": [
    "Reward function implement  \n",
    "should do something in the beginning (monster attack)  \n",
    "Custom PPO implement  \n",
    "pre train weight 差不多，主要是 reward function  \n",
    "model weight capacity 1GB  \n",
    "class name 不要動 (可以新增，但是原本有的不要動)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8a0ab9-f86d-4038-833d-761ec81fc4f2",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00b10def-362c-4910-9ed0-f3d0904343ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import retro\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "\n",
    "from eval import evaluate_policy, record_video\n",
    "from custom_policy import VisionBackbonePolicy, CustomPPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10361fd-f291-4d93-b50d-cc749a3af588",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b4f6a25-738c-49dd-8e66-ae164b74a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game Settings\n",
    "GAME = \"SuperMarioWorld-Snes\"\n",
    "STATE = \"YoshiIsland1\"\n",
    "\n",
    "# Training Settings\n",
    "TOTAL_STEPS = 6_553_600\n",
    "TRAIN_CHUNK =   327_680\n",
    "N_ENVS = 16\n",
    "LEARNING_RATE = 2e-4\n",
    "\n",
    "# Evaluation & Recording Settings\n",
    "EVAL_EPISODES = 3\n",
    "EVAL_MAX_STEPS = 18000\n",
    "RECORD_STEPS = 1800\n",
    "\n",
    "# Directories\n",
    "LOG_DIR = \"./runs_smw\"\n",
    "VIDEO_DIR       = os.path.join(LOG_DIR, \"videos\")\n",
    "CKPT_DIR        = os.path.join(LOG_DIR, \"checkpoints\")\n",
    "TENSORBOARD_LOG = os.path.join(LOG_DIR, \"tb\")\n",
    "\n",
    "os.makedirs(LOG_DIR,   exist_ok=True)\n",
    "os.makedirs(CKPT_DIR,  exist_ok=True)\n",
    "os.makedirs(VIDEO_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a34b783-0273-4835-ad2e-f9186064f76f",
   "metadata": {},
   "source": [
    "## Environment Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c34213d-2c7c-42b8-922d-bafa285d1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrappers import make_base_env\n",
    "def _make_env_thunk(game: str, state: str):\n",
    "    \"\"\"Return a function that creates an environment (for multiprocessing).\"\"\"\n",
    "    def _thunk():\n",
    "        return make_base_env(game, state)\n",
    "    return _thunk\n",
    "\n",
    "def make_vec_env(game: str, state: str, n_envs: int, use_subproc: bool = True):\n",
    "    \"\"\"Create a vectorized environment (multiple envs running in parallel).\"\"\"\n",
    "    env_fns = [_make_env_thunk(game, state) for _ in range(n_envs)]\n",
    "    \n",
    "    if use_subproc and n_envs > 1:\n",
    "        vec_env = SubprocVecEnv(env_fns)\n",
    "    else:\n",
    "        vec_env = DummyVecEnv(env_fns)\n",
    "\n",
    "    return vec_env\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dff476-ea2e-4262-8780-afb32ef1b233",
   "metadata": {},
   "source": [
    "## Initialize Env & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c7c5fe-6421-4dbc-9bd8-822d61769c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment created: SuperMarioWorld-Snes - YoshiIsland1 with 16 parallel envs.\n",
      "Loading model from runs_smw/checkpoints/SF84G_10.zip...\n"
     ]
    }
   ],
   "source": [
    "# 1. Create Training Environment\n",
    "train_env = make_vec_env(GAME, STATE, n_envs=N_ENVS)\n",
    "# train_env = VecNormalize(train_env, norm_obs=True, norm_reward=True, clip_obs=10., clip_reward=10.)\n",
    "print(f\"Environment created: {GAME} - {STATE} with {N_ENVS} parallel envs.\")\n",
    "\n",
    "checkpoint_path = \"None\"\n",
    "# checkpoint_path = \"runs_smw/checkpoints/SF84_step_1600000.zip\"\n",
    "# checkpoint_path = \"runs_smw/checkpoints/SF84G_6553600.zip\"\n",
    "checkpoint_path = \"runs_smw/checkpoints/SF84G_10.zip\"\n",
    "\n",
    "# 2. Initialize Model\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\"Loading model from {checkpoint_path}...\")\n",
    "    # 讀取現有模型\n",
    "    model = CustomPPO.load(\n",
    "        checkpoint_path, \n",
    "        env=train_env,\n",
    "        device=\"cuda:0\" # 確保使用 GPU\n",
    "    )\n",
    "else:\n",
    "    print(f\"Fail to load {checkpoint_path}...\")\n",
    "    model = CustomPPO(\n",
    "        VisionBackbonePolicy,\n",
    "        train_env,\n",
    "        policy_kwargs   = dict(normalize_images=False),\n",
    "        n_epochs        = 4,\n",
    "        n_steps         = 512,\n",
    "        batch_size      = 512,\n",
    "        learning_rate   = LEARNING_RATE,\n",
    "        verbose         = 1,\n",
    "        gamma           = 0.99,\n",
    "        kl_coef         = 1,\n",
    "        clip_range      = 0.125,\n",
    "        tensorboard_log = TENSORBOARD_LOG,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f594e443-843f-42c1-9fc6-3fbc82962021",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3af4932-c531-4113-a33a-defc6fb5858e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Round 1 | Learn 327680 steps (Total trained: 3276800) ===\n",
      "Logging to ./runs_smw/tb/SF84G_1220_1_0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 731     |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 11      |\n",
      "|    total_timesteps | 3284992 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 622         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 26          |\n",
      "|    total_timesteps    | 3293184     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014622673 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.87        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.104       |\n",
      "|    mean_step_reward   | 0.09469484  |\n",
      "|    n_updates          | 1604        |\n",
      "|    policyGradLoss     | -0.00501    |\n",
      "|    value_loss         | 0.577       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 598         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 3301376     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013938529 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0583      |\n",
      "|    mean_step_reward   | 0.08296143  |\n",
      "|    n_updates          | 1608        |\n",
      "|    policyGradLoss     | -0.0108     |\n",
      "|    value_loss         | 0.366       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 585        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 55         |\n",
      "|    total_timesteps    | 3309568    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01277257 |\n",
      "|    entropy_loss       | -2.01      |\n",
      "|    explained_variance | 0.907      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0335     |\n",
      "|    mean_step_reward   | 0.08381959 |\n",
      "|    n_updates          | 1612       |\n",
      "|    policyGradLoss     | -0.0112    |\n",
      "|    value_loss         | 0.431      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 578         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 3317760     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008118318 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.839       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0169      |\n",
      "|    mean_step_reward   | 0.079316415 |\n",
      "|    n_updates          | 1616        |\n",
      "|    policyGradLoss     | -0.000314   |\n",
      "|    value_loss         | 4.74        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 574         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 3325952     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008862335 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.86        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 3.99        |\n",
      "|    mean_step_reward   | 0.07823731  |\n",
      "|    n_updates          | 1620        |\n",
      "|    policyGradLoss     | -0.00244    |\n",
      "|    value_loss         | 5.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 572         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 100         |\n",
      "|    total_timesteps    | 3334144     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012403797 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.149       |\n",
      "|    mean_step_reward   | 0.08090699  |\n",
      "|    n_updates          | 1624        |\n",
      "|    policyGradLoss     | -0.0113     |\n",
      "|    value_loss         | 0.485       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 569         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 3342336     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013019402 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.087       |\n",
      "|    mean_step_reward   | 0.07559083  |\n",
      "|    n_updates          | 1628        |\n",
      "|    policyGradLoss     | -0.0105     |\n",
      "|    value_loss         | 0.482       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 567         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 130         |\n",
      "|    total_timesteps    | 3350528     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009910957 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0275      |\n",
      "|    mean_step_reward   | 0.08704102  |\n",
      "|    n_updates          | 1632        |\n",
      "|    policyGradLoss     | -0.011      |\n",
      "|    value_loss         | 0.457       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 563          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 145          |\n",
      "|    total_timesteps    | 3358720      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0112838065 |\n",
      "|    entropy_loss       | -1.99        |\n",
      "|    explained_variance | 0.91         |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.123        |\n",
      "|    mean_step_reward   | 0.08656495   |\n",
      "|    n_updates          | 1636         |\n",
      "|    policyGradLoss     | -0.00948     |\n",
      "|    value_loss         | 0.527        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 3366912     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010316145 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.881       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0418      |\n",
      "|    mean_step_reward   | 0.09091187  |\n",
      "|    n_updates          | 1640        |\n",
      "|    policyGradLoss     | -0.00886    |\n",
      "|    value_loss         | 0.682       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 569         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 172         |\n",
      "|    total_timesteps    | 3375104     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009155527 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.871       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 1.91        |\n",
      "|    mean_step_reward   | 0.07236573  |\n",
      "|    n_updates          | 1644        |\n",
      "|    policyGradLoss     | -0.00338    |\n",
      "|    value_loss         | 4.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 572         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 186         |\n",
      "|    total_timesteps    | 3383296     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008312117 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.874       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 3.89        |\n",
      "|    mean_step_reward   | 0.06900879  |\n",
      "|    n_updates          | 1648        |\n",
      "|    policyGradLoss     | -0.00342    |\n",
      "|    value_loss         | 4.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 574         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 3391488     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009538944 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.903       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.177       |\n",
      "|    mean_step_reward   | 0.07213624  |\n",
      "|    n_updates          | 1652        |\n",
      "|    policyGradLoss     | -0.00499    |\n",
      "|    value_loss         | 0.679       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 575         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 213         |\n",
      "|    total_timesteps    | 3399680     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015880534 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0515      |\n",
      "|    mean_step_reward   | 0.08338013  |\n",
      "|    n_updates          | 1656        |\n",
      "|    policyGradLoss     | -0.00821    |\n",
      "|    value_loss         | 0.346       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 571         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 3407872     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008905575 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.867       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 4.49        |\n",
      "|    mean_step_reward   | 0.0775525   |\n",
      "|    n_updates          | 1660        |\n",
      "|    policyGradLoss     | -0.00407    |\n",
      "|    value_loss         | 4.24        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 569          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 244          |\n",
      "|    total_timesteps    | 3416064      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0146297105 |\n",
      "|    entropy_loss       | -2           |\n",
      "|    explained_variance | 0.902        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.0928       |\n",
      "|    mean_step_reward   | 0.07894288   |\n",
      "|    n_updates          | 1664         |\n",
      "|    policyGradLoss     | -0.00677     |\n",
      "|    value_loss         | 0.783        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 569         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 259         |\n",
      "|    total_timesteps    | 3424256     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015167041 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0494      |\n",
      "|    mean_step_reward   | 0.0855774   |\n",
      "|    n_updates          | 1668        |\n",
      "|    policyGradLoss     | -0.00915    |\n",
      "|    value_loss         | 0.318       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 568          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 273          |\n",
      "|    total_timesteps    | 3432448      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0137658715 |\n",
      "|    entropy_loss       | -2.03        |\n",
      "|    explained_variance | 0.939        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.0185       |\n",
      "|    mean_step_reward   | 0.08266847   |\n",
      "|    n_updates          | 1672         |\n",
      "|    policyGradLoss     | -0.00746     |\n",
      "|    value_loss         | 0.47         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 567          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 288          |\n",
      "|    total_timesteps    | 3440640      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0070198597 |\n",
      "|    entropy_loss       | -2.06        |\n",
      "|    explained_variance | 0.878        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 1.48         |\n",
      "|    mean_step_reward   | 0.06030518   |\n",
      "|    n_updates          | 1676         |\n",
      "|    policyGradLoss     | -0.00178     |\n",
      "|    value_loss         | 7.83         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 303         |\n",
      "|    total_timesteps    | 3448832     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008131845 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.912       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 4.86        |\n",
      "|    mean_step_reward   | 0.06905274  |\n",
      "|    n_updates          | 1680        |\n",
      "|    policyGradLoss     | -0.00325    |\n",
      "|    value_loss         | 4.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 3457024     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009072825 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.876       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 4.09        |\n",
      "|    mean_step_reward   | 0.04639771  |\n",
      "|    n_updates          | 1684        |\n",
      "|    policyGradLoss     | -0.00489    |\n",
      "|    value_loss         | 6.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 3465216     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010523851 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.346       |\n",
      "|    mean_step_reward   | 0.05962891  |\n",
      "|    n_updates          | 1688        |\n",
      "|    policyGradLoss     | -0.00206    |\n",
      "|    value_loss         | 0.641       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 348         |\n",
      "|    total_timesteps    | 3473408     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012140631 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00893     |\n",
      "|    mean_step_reward   | 0.066823736 |\n",
      "|    n_updates          | 1692        |\n",
      "|    policyGradLoss     | -0.0116     |\n",
      "|    value_loss         | 0.304       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 363         |\n",
      "|    total_timesteps    | 3481600     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012326569 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0873      |\n",
      "|    mean_step_reward   | 0.06906983  |\n",
      "|    n_updates          | 1696        |\n",
      "|    policyGradLoss     | -0.00645    |\n",
      "|    value_loss         | 0.558       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 378         |\n",
      "|    total_timesteps    | 3489792     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012901158 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0745      |\n",
      "|    mean_step_reward   | 0.07398683  |\n",
      "|    n_updates          | 1700        |\n",
      "|    policyGradLoss     | -0.00844    |\n",
      "|    value_loss         | 0.507       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 393         |\n",
      "|    total_timesteps    | 3497984     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012443188 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.883       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0222      |\n",
      "|    mean_step_reward   | 0.08904908  |\n",
      "|    n_updates          | 1704        |\n",
      "|    policyGradLoss     | -0.00684    |\n",
      "|    value_loss         | 0.561       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 408         |\n",
      "|    total_timesteps    | 3506176     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011957521 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.778       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.129       |\n",
      "|    mean_step_reward   | 0.08823487  |\n",
      "|    n_updates          | 1708        |\n",
      "|    policyGradLoss     | -0.00574    |\n",
      "|    value_loss         | 1.07        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 423         |\n",
      "|    total_timesteps    | 3514368     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009485729 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.853       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 8.74        |\n",
      "|    mean_step_reward   | 0.055478517 |\n",
      "|    n_updates          | 1712        |\n",
      "|    policyGradLoss     | -0.000931   |\n",
      "|    value_loss         | 7.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 438         |\n",
      "|    total_timesteps    | 3522560     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008156281 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.903       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 1.98        |\n",
      "|    mean_step_reward   | 0.059635013 |\n",
      "|    n_updates          | 1716        |\n",
      "|    policyGradLoss     | -0.00384    |\n",
      "|    value_loss         | 3.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 453         |\n",
      "|    total_timesteps    | 3530752     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010289482 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.107       |\n",
      "|    mean_step_reward   | 0.07197022  |\n",
      "|    n_updates          | 1720        |\n",
      "|    policyGradLoss     | -0.00864    |\n",
      "|    value_loss         | 0.52        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 467         |\n",
      "|    total_timesteps    | 3538944     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009539275 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.907       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.126       |\n",
      "|    mean_step_reward   | 0.06252076  |\n",
      "|    n_updates          | 1724        |\n",
      "|    policyGradLoss     | -0.00419    |\n",
      "|    value_loss         | 3.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 482         |\n",
      "|    total_timesteps    | 3547136     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013194976 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0617      |\n",
      "|    mean_step_reward   | 0.07326539  |\n",
      "|    n_updates          | 1728        |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.669       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 497         |\n",
      "|    total_timesteps    | 3555328     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009952248 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.896       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 1.75        |\n",
      "|    mean_step_reward   | 0.061419684 |\n",
      "|    n_updates          | 1732        |\n",
      "|    policyGradLoss     | -0.00482    |\n",
      "|    value_loss         | 3.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 512         |\n",
      "|    total_timesteps    | 3563520     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009906804 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0457      |\n",
      "|    mean_step_reward   | 0.061590586 |\n",
      "|    n_updates          | 1736        |\n",
      "|    policyGradLoss     | -0.00526    |\n",
      "|    value_loss         | 3.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 527         |\n",
      "|    total_timesteps    | 3571712     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014655792 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0474      |\n",
      "|    mean_step_reward   | 0.073491216 |\n",
      "|    n_updates          | 1740        |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.382       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 542         |\n",
      "|    total_timesteps    | 3579904     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013176885 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00774     |\n",
      "|    mean_step_reward   | 0.07843751  |\n",
      "|    n_updates          | 1744        |\n",
      "|    policyGradLoss     | -0.0119     |\n",
      "|    value_loss         | 0.345       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 557         |\n",
      "|    total_timesteps    | 3588096     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015067399 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.859       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0332      |\n",
      "|    mean_step_reward   | 0.07974976  |\n",
      "|    n_updates          | 1748        |\n",
      "|    policyGradLoss     | -0.00478    |\n",
      "|    value_loss         | 0.52        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 572         |\n",
      "|    total_timesteps    | 3596288     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017094575 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.904       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0204     |\n",
      "|    mean_step_reward   | 0.087001964 |\n",
      "|    n_updates          | 1752        |\n",
      "|    policyGradLoss     | -0.0133     |\n",
      "|    value_loss         | 0.318       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 586         |\n",
      "|    total_timesteps    | 3604480     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013401402 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.894       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.895       |\n",
      "|    mean_step_reward   | 0.075903326 |\n",
      "|    n_updates          | 1756        |\n",
      "|    policyGradLoss     | -0.00365    |\n",
      "|    value_loss         | 3.24        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/SF84G_11.zip\n",
      "[EVAL] Mean Return: 20.100, Best Return: 20.100\n",
      "New best record. Saved to ./runs_smw/best_model.zip\n",
      "Saved video to ./runs_smw/videos/step_3604480_mean_20.10.mp4\n",
      "\n",
      "=== Round 2 | Learn 327680 steps (Total trained: 3604480) ===\n",
      "Logging to ./runs_smw/tb/SF84G_1220_1_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 731     |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 11      |\n",
      "|    total_timesteps | 3612672 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 631         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 3620864     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010742353 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.891       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 7.72        |\n",
      "|    mean_step_reward   | 0.07172364  |\n",
      "|    n_updates          | 1764        |\n",
      "|    policyGradLoss     | -0.00451    |\n",
      "|    value_loss         | 3.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 600         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 3629056     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010112369 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 1           |\n",
      "|    mean_step_reward   | 0.077884525 |\n",
      "|    n_updates          | 1768        |\n",
      "|    policyGradLoss     | -0.00476    |\n",
      "|    value_loss         | 3.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 587         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 55          |\n",
      "|    total_timesteps    | 3637248     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013699713 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.108       |\n",
      "|    mean_step_reward   | 0.0847815   |\n",
      "|    n_updates          | 1772        |\n",
      "|    policyGradLoss     | -0.00922    |\n",
      "|    value_loss         | 0.265       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 576         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 3645440     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008592769 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 1.6         |\n",
      "|    mean_step_reward   | 0.059465338 |\n",
      "|    n_updates          | 1776        |\n",
      "|    policyGradLoss     | -0.00553    |\n",
      "|    value_loss         | 3.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 573         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 3653632     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009177373 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.472       |\n",
      "|    mean_step_reward   | 0.063006595 |\n",
      "|    n_updates          | 1780        |\n",
      "|    policyGradLoss     | -0.00621    |\n",
      "|    value_loss         | 2.99        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 568         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 100         |\n",
      "|    total_timesteps    | 3661824     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012970399 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0333     |\n",
      "|    mean_step_reward   | 0.075090334 |\n",
      "|    n_updates          | 1784        |\n",
      "|    policyGradLoss     | -0.0106     |\n",
      "|    value_loss         | 0.192       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 3670016     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011076361 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0303     |\n",
      "|    mean_step_reward   | 0.07552491  |\n",
      "|    n_updates          | 1788        |\n",
      "|    policyGradLoss     | -0.0115     |\n",
      "|    value_loss         | 0.244       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 130         |\n",
      "|    total_timesteps    | 3678208     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014420012 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00875     |\n",
      "|    mean_step_reward   | 0.07648194  |\n",
      "|    n_updates          | 1792        |\n",
      "|    policyGradLoss     | -0.00977    |\n",
      "|    value_loss         | 0.367       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 3686400     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010317039 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.869       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0459      |\n",
      "|    mean_step_reward   | 0.07346314  |\n",
      "|    n_updates          | 1796        |\n",
      "|    policyGradLoss     | -0.00727    |\n",
      "|    value_loss         | 0.649       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 3694592     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008659495 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.909       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.244       |\n",
      "|    mean_step_reward   | 0.06354248  |\n",
      "|    n_updates          | 1800        |\n",
      "|    policyGradLoss     | -0.00381    |\n",
      "|    value_loss         | 5.72        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 175         |\n",
      "|    total_timesteps    | 3702784     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014097092 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.029       |\n",
      "|    mean_step_reward   | 0.07786866  |\n",
      "|    n_updates          | 1804        |\n",
      "|    policyGradLoss     | -0.00894    |\n",
      "|    value_loss         | 0.524       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 3710976     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010781396 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0801      |\n",
      "|    mean_step_reward   | 0.07777588  |\n",
      "|    n_updates          | 1808        |\n",
      "|    policyGradLoss     | -0.0133     |\n",
      "|    value_loss         | 0.492       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 558          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 205          |\n",
      "|    total_timesteps    | 3719168      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0075950394 |\n",
      "|    entropy_loss       | -2.06        |\n",
      "|    explained_variance | 0.915        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.171        |\n",
      "|    mean_step_reward   | 0.059991464  |\n",
      "|    n_updates          | 1812         |\n",
      "|    policyGradLoss     | -0.00508     |\n",
      "|    value_loss         | 3.33         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 3727360     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014246358 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0041      |\n",
      "|    mean_step_reward   | 0.07317139  |\n",
      "|    n_updates          | 1816        |\n",
      "|    policyGradLoss     | -0.0123     |\n",
      "|    value_loss         | 0.383       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 557        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 235        |\n",
      "|    total_timesteps    | 3735552    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01259407 |\n",
      "|    entropy_loss       | -2.01      |\n",
      "|    explained_variance | 0.938      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.156      |\n",
      "|    mean_step_reward   | 0.08056886 |\n",
      "|    n_updates          | 1820       |\n",
      "|    policyGradLoss     | -0.00897   |\n",
      "|    value_loss         | 0.57       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 556         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 250         |\n",
      "|    total_timesteps    | 3743744     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011446129 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 3.02        |\n",
      "|    mean_step_reward   | 0.07490723  |\n",
      "|    n_updates          | 1824        |\n",
      "|    policyGradLoss     | -0.00497    |\n",
      "|    value_loss         | 3.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 556         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 265         |\n",
      "|    total_timesteps    | 3751936     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012178462 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0163     |\n",
      "|    mean_step_reward   | 0.07924561  |\n",
      "|    n_updates          | 1828        |\n",
      "|    policyGradLoss     | -0.0139     |\n",
      "|    value_loss         | 0.377       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 557         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 279         |\n",
      "|    total_timesteps    | 3760128     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009232506 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.225       |\n",
      "|    mean_step_reward   | 0.07116212  |\n",
      "|    n_updates          | 1832        |\n",
      "|    policyGradLoss     | -0.00147    |\n",
      "|    value_loss         | 5.08        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 556          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 294          |\n",
      "|    total_timesteps    | 3768320      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0105901025 |\n",
      "|    entropy_loss       | -2.09        |\n",
      "|    explained_variance | 0.91         |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 5.57         |\n",
      "|    mean_step_reward   | 0.054521486  |\n",
      "|    n_updates          | 1836         |\n",
      "|    policyGradLoss     | -0.00165     |\n",
      "|    value_loss         | 2.98         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 556         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 309         |\n",
      "|    total_timesteps    | 3776512     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007709474 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 1.68        |\n",
      "|    mean_step_reward   | 0.046513677 |\n",
      "|    n_updates          | 1840        |\n",
      "|    policyGradLoss     | -0.0051     |\n",
      "|    value_loss         | 2.77        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 555        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 324        |\n",
      "|    total_timesteps    | 3784704    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01304623 |\n",
      "|    entropy_loss       | -2.08      |\n",
      "|    explained_variance | 0.933      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0327     |\n",
      "|    mean_step_reward   | 0.07654542 |\n",
      "|    n_updates          | 1844       |\n",
      "|    policyGradLoss     | -0.00713   |\n",
      "|    value_loss         | 0.439      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 556         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 3792896     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011244821 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.894       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00546     |\n",
      "|    mean_step_reward   | 0.08393922  |\n",
      "|    n_updates          | 1848        |\n",
      "|    policyGradLoss     | -0.00859    |\n",
      "|    value_loss         | 0.447       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 556         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 353         |\n",
      "|    total_timesteps    | 3801088     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009565043 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 4.35        |\n",
      "|    mean_step_reward   | 0.06282838  |\n",
      "|    n_updates          | 1852        |\n",
      "|    policyGradLoss     | -0.00251    |\n",
      "|    value_loss         | 4.93        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 365         |\n",
      "|    total_timesteps    | 3809280     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008119199 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.144       |\n",
      "|    mean_step_reward   | 0.061594244 |\n",
      "|    n_updates          | 1856        |\n",
      "|    policyGradLoss     | -0.00385    |\n",
      "|    value_loss         | 2.66        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 378         |\n",
      "|    total_timesteps    | 3817472     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007433677 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.298       |\n",
      "|    mean_step_reward   | 0.07591187  |\n",
      "|    n_updates          | 1860        |\n",
      "|    policyGradLoss     | -0.00345    |\n",
      "|    value_loss         | 2.71        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 563          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 392          |\n",
      "|    total_timesteps    | 3825664      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0075340844 |\n",
      "|    entropy_loss       | -2.08        |\n",
      "|    explained_variance | 0.937        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 3.04         |\n",
      "|    mean_step_reward   | 0.05459717   |\n",
      "|    n_updates          | 1864         |\n",
      "|    policyGradLoss     | -0.00201     |\n",
      "|    value_loss         | 4.09         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 405         |\n",
      "|    total_timesteps    | 3833856     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012961705 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0197     |\n",
      "|    mean_step_reward   | 0.07278809  |\n",
      "|    n_updates          | 1868        |\n",
      "|    policyGradLoss     | -0.0119     |\n",
      "|    value_loss         | 0.297       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 421         |\n",
      "|    total_timesteps    | 3842048     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008662859 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0726      |\n",
      "|    mean_step_reward   | 0.07431641  |\n",
      "|    n_updates          | 1872        |\n",
      "|    policyGradLoss     | -0.00708    |\n",
      "|    value_loss         | 0.827       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 436         |\n",
      "|    total_timesteps    | 3850240     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006014375 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 1.86        |\n",
      "|    mean_step_reward   | 0.042917483 |\n",
      "|    n_updates          | 1876        |\n",
      "|    policyGradLoss     | -0.00403    |\n",
      "|    value_loss         | 3.95        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 451         |\n",
      "|    total_timesteps    | 3858432     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012964988 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0629      |\n",
      "|    mean_step_reward   | 0.060394295 |\n",
      "|    n_updates          | 1880        |\n",
      "|    policyGradLoss     | -0.00877    |\n",
      "|    value_loss         | 0.55        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 466         |\n",
      "|    total_timesteps    | 3866624     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010029513 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 2.38        |\n",
      "|    mean_step_reward   | 0.067288816 |\n",
      "|    n_updates          | 1884        |\n",
      "|    policyGradLoss     | -0.00185    |\n",
      "|    value_loss         | 2.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 480         |\n",
      "|    total_timesteps    | 3874816     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012717064 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00676    |\n",
      "|    mean_step_reward   | 0.07928711  |\n",
      "|    n_updates          | 1888        |\n",
      "|    policyGradLoss     | -0.0101     |\n",
      "|    value_loss         | 0.296       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 496         |\n",
      "|    total_timesteps    | 3883008     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007939933 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 2           |\n",
      "|    mean_step_reward   | 0.060737304 |\n",
      "|    n_updates          | 1892        |\n",
      "|    policyGradLoss     | -0.0036     |\n",
      "|    value_loss         | 3.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 511         |\n",
      "|    total_timesteps    | 3891200     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010764254 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0449      |\n",
      "|    mean_step_reward   | 0.07476564  |\n",
      "|    n_updates          | 1896        |\n",
      "|    policyGradLoss     | -0.0122     |\n",
      "|    value_loss         | 0.318       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 526         |\n",
      "|    total_timesteps    | 3899392     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013043019 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0262     |\n",
      "|    mean_step_reward   | 0.0729419   |\n",
      "|    n_updates          | 1900        |\n",
      "|    policyGradLoss     | -0.0129     |\n",
      "|    value_loss         | 0.358       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 541         |\n",
      "|    total_timesteps    | 3907584     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009636252 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 2.01        |\n",
      "|    mean_step_reward   | 0.059738778 |\n",
      "|    n_updates          | 1904        |\n",
      "|    policyGradLoss     | -0.00548    |\n",
      "|    value_loss         | 2.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 555         |\n",
      "|    total_timesteps    | 3915776     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.00884385  |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0319      |\n",
      "|    mean_step_reward   | 0.068964854 |\n",
      "|    n_updates          | 1908        |\n",
      "|    policyGradLoss     | -0.00297    |\n",
      "|    value_loss         | 2.07        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 570         |\n",
      "|    total_timesteps    | 3923968     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011084903 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00655    |\n",
      "|    mean_step_reward   | 0.0790503   |\n",
      "|    n_updates          | 1912        |\n",
      "|    policyGradLoss     | -0.00948    |\n",
      "|    value_loss         | 0.431       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 585         |\n",
      "|    total_timesteps    | 3932160     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012988313 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00662    |\n",
      "|    mean_step_reward   | 0.085996106 |\n",
      "|    n_updates          | 1916        |\n",
      "|    policyGradLoss     | -0.00849    |\n",
      "|    value_loss         | 0.328       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/SF84G_12.zip\n",
      "[EVAL] Mean Return: 18.300, Best Return: 18.300\n",
      "Saved video to ./runs_smw/videos/step_3932160_mean_18.30.mp4\n",
      "\n",
      "=== Round 3 | Learn 327680 steps (Total trained: 3932160) ===\n",
      "Logging to ./runs_smw/tb/SF84G_1220_1_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 749     |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 10      |\n",
      "|    total_timesteps | 3940352 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 630         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 3948544     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011818454 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0384      |\n",
      "|    mean_step_reward   | 0.07827149  |\n",
      "|    n_updates          | 1924        |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.427       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 605         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 3956736     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011871622 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.87        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.275       |\n",
      "|    mean_step_reward   | 0.07003419  |\n",
      "|    n_updates          | 1928        |\n",
      "|    policyGradLoss     | -0.00438    |\n",
      "|    value_loss         | 0.932       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 589         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 55          |\n",
      "|    total_timesteps    | 3964928     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012849397 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.906       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0882      |\n",
      "|    mean_step_reward   | 0.07730103  |\n",
      "|    n_updates          | 1932        |\n",
      "|    policyGradLoss     | -0.0114     |\n",
      "|    value_loss         | 0.478       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 581         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 3973120     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.00919497  |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.216       |\n",
      "|    mean_step_reward   | 0.069022216 |\n",
      "|    n_updates          | 1936        |\n",
      "|    policyGradLoss     | -0.00381    |\n",
      "|    value_loss         | 2.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 576         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 3981312     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008707404 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.956       |\n",
      "|    mean_step_reward   | 0.07141358  |\n",
      "|    n_updates          | 1940        |\n",
      "|    policyGradLoss     | -0.00713    |\n",
      "|    value_loss         | 1.97        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 571         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 100         |\n",
      "|    total_timesteps    | 3989504     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013646992 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.316       |\n",
      "|    mean_step_reward   | 0.069198005 |\n",
      "|    n_updates          | 1944        |\n",
      "|    policyGradLoss     | -0.00286    |\n",
      "|    value_loss         | 2.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 568         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 3997696     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009496151 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 4.1         |\n",
      "|    mean_step_reward   | 0.058551025 |\n",
      "|    n_updates          | 1948        |\n",
      "|    policyGradLoss     | -0.00316    |\n",
      "|    value_loss         | 2.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 575         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 128         |\n",
      "|    total_timesteps    | 4005888     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007059142 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 1.47        |\n",
      "|    mean_step_reward   | 0.04241455  |\n",
      "|    n_updates          | 1952        |\n",
      "|    policyGradLoss     | -0.00396    |\n",
      "|    value_loss         | 3.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 578         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 141         |\n",
      "|    total_timesteps    | 4014080     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013004353 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.071       |\n",
      "|    mean_step_reward   | 0.057158206 |\n",
      "|    n_updates          | 1956        |\n",
      "|    policyGradLoss     | -0.00663    |\n",
      "|    value_loss         | 0.833       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 580        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 155        |\n",
      "|    total_timesteps    | 4022272    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01209539 |\n",
      "|    entropy_loss       | -2.08      |\n",
      "|    explained_variance | 0.942      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0149    |\n",
      "|    mean_step_reward   | 0.07585084 |\n",
      "|    n_updates          | 1960       |\n",
      "|    policyGradLoss     | -0.00962   |\n",
      "|    value_loss         | 0.347      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 581         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 4030464     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0104744   |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.229       |\n",
      "|    mean_step_reward   | 0.067236334 |\n",
      "|    n_updates          | 1964        |\n",
      "|    policyGradLoss     | -0.00596    |\n",
      "|    value_loss         | 1.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 584         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 182         |\n",
      "|    total_timesteps    | 4038656     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010492023 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00991     |\n",
      "|    mean_step_reward   | 0.084653325 |\n",
      "|    n_updates          | 1968        |\n",
      "|    policyGradLoss     | -0.00843    |\n",
      "|    value_loss         | 0.451       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 591         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 193         |\n",
      "|    total_timesteps    | 4046848     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010816406 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0216      |\n",
      "|    mean_step_reward   | 0.076341555 |\n",
      "|    n_updates          | 1972        |\n",
      "|    policyGradLoss     | -0.00864    |\n",
      "|    value_loss         | 0.475       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 598         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 205         |\n",
      "|    total_timesteps    | 4055040     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008422973 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 3.26        |\n",
      "|    mean_step_reward   | 0.049747318 |\n",
      "|    n_updates          | 1976        |\n",
      "|    policyGradLoss     | -0.00261    |\n",
      "|    value_loss         | 3.75        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 600         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 218         |\n",
      "|    total_timesteps    | 4063232     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009990018 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.197       |\n",
      "|    mean_step_reward   | 0.061229255 |\n",
      "|    n_updates          | 1980        |\n",
      "|    policyGradLoss     | -0.00439    |\n",
      "|    value_loss         | 1.93        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 597         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 4071424     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009891989 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0127     |\n",
      "|    mean_step_reward   | 0.06467774  |\n",
      "|    n_updates          | 1984        |\n",
      "|    policyGradLoss     | -0.00486    |\n",
      "|    value_loss         | 1.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 594         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 247         |\n",
      "|    total_timesteps    | 4079616     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009596347 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0295      |\n",
      "|    mean_step_reward   | 0.061024174 |\n",
      "|    n_updates          | 1988        |\n",
      "|    policyGradLoss     | -0.00807    |\n",
      "|    value_loss         | 0.567       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 592         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 4087808     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008869959 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 1.15        |\n",
      "|    mean_step_reward   | 0.057281498 |\n",
      "|    n_updates          | 1992        |\n",
      "|    policyGradLoss     | -0.00585    |\n",
      "|    value_loss         | 1.55        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 590         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 277         |\n",
      "|    total_timesteps    | 4096000     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012772017 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0636      |\n",
      "|    mean_step_reward   | 0.07575318  |\n",
      "|    n_updates          | 1996        |\n",
      "|    policyGradLoss     | -0.00899    |\n",
      "|    value_loss         | 0.431       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 589         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 291         |\n",
      "|    total_timesteps    | 4104192     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011217643 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00673     |\n",
      "|    mean_step_reward   | 0.07491334  |\n",
      "|    n_updates          | 2000        |\n",
      "|    policyGradLoss     | -0.0137     |\n",
      "|    value_loss         | 0.376       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 587         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 4112384     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010633595 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0633      |\n",
      "|    mean_step_reward   | 0.05922974  |\n",
      "|    n_updates          | 2004        |\n",
      "|    policyGradLoss     | -0.00923    |\n",
      "|    value_loss         | 1.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 586         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 321         |\n",
      "|    total_timesteps    | 4120576     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013064593 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.143       |\n",
      "|    mean_step_reward   | 0.057362065 |\n",
      "|    n_updates          | 2008        |\n",
      "|    policyGradLoss     | -0.00674    |\n",
      "|    value_loss         | 1.53        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 584         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 4128768     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011886537 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0759      |\n",
      "|    mean_step_reward   | 0.07889649  |\n",
      "|    n_updates          | 2012        |\n",
      "|    policyGradLoss     | -0.00681    |\n",
      "|    value_loss         | 0.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 583         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 351         |\n",
      "|    total_timesteps    | 4136960     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011982551 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.168       |\n",
      "|    mean_step_reward   | 0.07392823  |\n",
      "|    n_updates          | 2016        |\n",
      "|    policyGradLoss     | -0.00714    |\n",
      "|    value_loss         | 0.521       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 581         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 366         |\n",
      "|    total_timesteps    | 4145152     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011082076 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.866       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.176       |\n",
      "|    mean_step_reward   | 0.06880127  |\n",
      "|    n_updates          | 2020        |\n",
      "|    policyGradLoss     | -0.00447    |\n",
      "|    value_loss         | 0.867       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 579         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 381         |\n",
      "|    total_timesteps    | 4153344     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011703829 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.282       |\n",
      "|    mean_step_reward   | 0.06565552  |\n",
      "|    n_updates          | 2024        |\n",
      "|    policyGradLoss     | -0.00547    |\n",
      "|    value_loss         | 1.43        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 578         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 396         |\n",
      "|    total_timesteps    | 4161536     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012671849 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.000635    |\n",
      "|    mean_step_reward   | 0.08152832  |\n",
      "|    n_updates          | 2028        |\n",
      "|    policyGradLoss     | -0.00736    |\n",
      "|    value_loss         | 0.441       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 577         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 411         |\n",
      "|    total_timesteps    | 4169728     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011624411 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0841      |\n",
      "|    mean_step_reward   | 0.076607674 |\n",
      "|    n_updates          | 2032        |\n",
      "|    policyGradLoss     | -0.0113     |\n",
      "|    value_loss         | 0.466       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 577         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 425         |\n",
      "|    total_timesteps    | 4177920     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012108555 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0758      |\n",
      "|    mean_step_reward   | 0.07625978  |\n",
      "|    n_updates          | 2036        |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.635       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 575         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 440         |\n",
      "|    total_timesteps    | 4186112     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012087693 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 1.31        |\n",
      "|    mean_step_reward   | 0.06291748  |\n",
      "|    n_updates          | 2040        |\n",
      "|    policyGradLoss     | -0.00773    |\n",
      "|    value_loss         | 1.61        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 575         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 455         |\n",
      "|    total_timesteps    | 4194304     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010149976 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.554       |\n",
      "|    mean_step_reward   | 0.06625366  |\n",
      "|    n_updates          | 2044        |\n",
      "|    policyGradLoss     | -0.00793    |\n",
      "|    value_loss         | 1.43        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 574         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 470         |\n",
      "|    total_timesteps    | 4202496     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0114284   |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0125      |\n",
      "|    mean_step_reward   | 0.061098635 |\n",
      "|    n_updates          | 2048        |\n",
      "|    policyGradLoss     | -0.00632    |\n",
      "|    value_loss         | 0.56        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 573          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 485          |\n",
      "|    total_timesteps    | 4210688      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0070746336 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.975        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.101        |\n",
      "|    mean_step_reward   | 0.040089116  |\n",
      "|    n_updates          | 2052         |\n",
      "|    policyGradLoss     | -0.00565     |\n",
      "|    value_loss         | 1.28         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 573         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 500         |\n",
      "|    total_timesteps    | 4218880     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009083508 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.281       |\n",
      "|    mean_step_reward   | 0.03970215  |\n",
      "|    n_updates          | 2056        |\n",
      "|    policyGradLoss     | -0.00315    |\n",
      "|    value_loss         | 1.31        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 572          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 515          |\n",
      "|    total_timesteps    | 4227072      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0143263275 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.973        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.0168       |\n",
      "|    mean_step_reward   | 0.06507447   |\n",
      "|    n_updates          | 2060         |\n",
      "|    policyGradLoss     | -0.0101      |\n",
      "|    value_loss         | 0.303        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 571         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 530         |\n",
      "|    total_timesteps    | 4235264     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008885089 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.76        |\n",
      "|    mean_step_reward   | 0.047142334 |\n",
      "|    n_updates          | 2064        |\n",
      "|    policyGradLoss     | -0.00291    |\n",
      "|    value_loss         | 2.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 570         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 545         |\n",
      "|    total_timesteps    | 4243456     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011734675 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0659      |\n",
      "|    mean_step_reward   | 0.071597904 |\n",
      "|    n_updates          | 2068        |\n",
      "|    policyGradLoss     | -0.00951    |\n",
      "|    value_loss         | 0.517       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 569         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 560         |\n",
      "|    total_timesteps    | 4251648     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009812128 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0131     |\n",
      "|    mean_step_reward   | 0.05761475  |\n",
      "|    n_updates          | 2072        |\n",
      "|    policyGradLoss     | -0.00725    |\n",
      "|    value_loss         | 1.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 569         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 575         |\n",
      "|    total_timesteps    | 4259840     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010852832 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0158      |\n",
      "|    mean_step_reward   | 0.07249634  |\n",
      "|    n_updates          | 2076        |\n",
      "|    policyGradLoss     | -0.00778    |\n",
      "|    value_loss         | 0.374       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/SF84G_13.zip\n",
      "[EVAL] Mean Return: 18.900, Best Return: 18.900\n",
      "Saved video to ./runs_smw/videos/step_4259840_mean_18.90.mp4\n",
      "\n",
      "=== Round 4 | Learn 327680 steps (Total trained: 4259840) ===\n",
      "Logging to ./runs_smw/tb/SF84G_1220_1_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 765     |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 10      |\n",
      "|    total_timesteps | 4268032 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 643         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 4276224     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011647609 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0359      |\n",
      "|    mean_step_reward   | 0.079268806 |\n",
      "|    n_updates          | 2084        |\n",
      "|    policyGradLoss     | -0.0079     |\n",
      "|    value_loss         | 0.617       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 604         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 4284416     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010267872 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0752      |\n",
      "|    mean_step_reward   | 0.06714478  |\n",
      "|    n_updates          | 2088        |\n",
      "|    policyGradLoss     | -0.00634    |\n",
      "|    value_loss         | 1.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 591         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 55          |\n",
      "|    total_timesteps    | 4292608     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018053295 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.0667      |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 30          |\n",
      "|    mean_step_reward   | 0.050903283 |\n",
      "|    n_updates          | 2092        |\n",
      "|    policyGradLoss     | 0.0126      |\n",
      "|    value_loss         | 1.36e+03    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 584         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 4300800     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012374009 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.879       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.136       |\n",
      "|    mean_step_reward   | 0.064390875 |\n",
      "|    n_updates          | 2096        |\n",
      "|    policyGradLoss     | -0.00139    |\n",
      "|    value_loss         | 0.736       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 579         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 84          |\n",
      "|    total_timesteps    | 4308992     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010820676 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00474     |\n",
      "|    mean_step_reward   | 0.05640991  |\n",
      "|    n_updates          | 2100        |\n",
      "|    policyGradLoss     | -0.00892    |\n",
      "|    value_loss         | 1.04        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 573         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 99          |\n",
      "|    total_timesteps    | 4317184     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011028229 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00065    |\n",
      "|    mean_step_reward   | 0.055699468 |\n",
      "|    n_updates          | 2104        |\n",
      "|    policyGradLoss     | -0.0079     |\n",
      "|    value_loss         | 0.476       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 571         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 4325376     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012545226 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00738     |\n",
      "|    mean_step_reward   | 0.06321655  |\n",
      "|    n_updates          | 2108        |\n",
      "|    policyGradLoss     | -0.0118     |\n",
      "|    value_loss         | 0.418       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 569         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 129         |\n",
      "|    total_timesteps    | 4333568     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011830902 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 1.72        |\n",
      "|    mean_step_reward   | 0.057141118 |\n",
      "|    n_updates          | 2112        |\n",
      "|    policyGradLoss     | -0.00343    |\n",
      "|    value_loss         | 1.45        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 568         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 4341760     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013967991 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0408     |\n",
      "|    mean_step_reward   | 0.06633179  |\n",
      "|    n_updates          | 2116        |\n",
      "|    policyGradLoss     | -0.00797    |\n",
      "|    value_loss         | 0.287       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 4349952     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012204904 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0369      |\n",
      "|    mean_step_reward   | 0.07153077  |\n",
      "|    n_updates          | 2120        |\n",
      "|    policyGradLoss     | -0.012      |\n",
      "|    value_loss         | 0.427       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 174         |\n",
      "|    total_timesteps    | 4358144     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010279934 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0196     |\n",
      "|    mean_step_reward   | 0.06877808  |\n",
      "|    n_updates          | 2124        |\n",
      "|    policyGradLoss     | -0.0115     |\n",
      "|    value_loss         | 0.274       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 4366336     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011907515 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0496      |\n",
      "|    mean_step_reward   | 0.07283082  |\n",
      "|    n_updates          | 2128        |\n",
      "|    policyGradLoss     | -0.0135     |\n",
      "|    value_loss         | 0.363       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 203         |\n",
      "|    total_timesteps    | 4374528     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013723517 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.02        |\n",
      "|    mean_step_reward   | 0.073835455 |\n",
      "|    n_updates          | 2132        |\n",
      "|    policyGradLoss     | -0.00975    |\n",
      "|    value_loss         | 0.34        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 218         |\n",
      "|    total_timesteps    | 4382720     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014432805 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00154    |\n",
      "|    mean_step_reward   | 0.07143311  |\n",
      "|    n_updates          | 2136        |\n",
      "|    policyGradLoss     | -0.00742    |\n",
      "|    value_loss         | 0.364       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 560          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 233          |\n",
      "|    total_timesteps    | 4390912      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0140760625 |\n",
      "|    entropy_loss       | -2.04        |\n",
      "|    explained_variance | 0.939        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.0147       |\n",
      "|    mean_step_reward   | 0.087478034  |\n",
      "|    n_updates          | 2140         |\n",
      "|    policyGradLoss     | -0.0106      |\n",
      "|    value_loss         | 0.407        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 248         |\n",
      "|    total_timesteps    | 4399104     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01652288  |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.893       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0449      |\n",
      "|    mean_step_reward   | 0.086752936 |\n",
      "|    n_updates          | 2144        |\n",
      "|    policyGradLoss     | -0.00815    |\n",
      "|    value_loss         | 0.538       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 4407296     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016891427 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.909       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0723      |\n",
      "|    mean_step_reward   | 0.079370126 |\n",
      "|    n_updates          | 2148        |\n",
      "|    policyGradLoss     | -0.0069     |\n",
      "|    value_loss         | 0.554       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 278         |\n",
      "|    total_timesteps    | 4415488     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013012923 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.91        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00122     |\n",
      "|    mean_step_reward   | 0.08544923  |\n",
      "|    n_updates          | 2152        |\n",
      "|    policyGradLoss     | -0.0106     |\n",
      "|    value_loss         | 0.337       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 4423680     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015105786 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0125     |\n",
      "|    mean_step_reward   | 0.081951916 |\n",
      "|    n_updates          | 2156        |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 557         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 308         |\n",
      "|    total_timesteps    | 4431872     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01255157  |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.904       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0714      |\n",
      "|    mean_step_reward   | 0.077587895 |\n",
      "|    n_updates          | 2160        |\n",
      "|    policyGradLoss     | -0.0108     |\n",
      "|    value_loss         | 0.592       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 557         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 323         |\n",
      "|    total_timesteps    | 4440064     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016465582 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0213     |\n",
      "|    mean_step_reward   | 0.084775396 |\n",
      "|    n_updates          | 2164        |\n",
      "|    policyGradLoss     | -0.0108     |\n",
      "|    value_loss         | 0.341       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 557         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 4448256     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010014655 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.396       |\n",
      "|    mean_step_reward   | 0.06888795  |\n",
      "|    n_updates          | 2168        |\n",
      "|    policyGradLoss     | -0.00731    |\n",
      "|    value_loss         | 1.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 556         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 353         |\n",
      "|    total_timesteps    | 4456448     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013379911 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0313      |\n",
      "|    mean_step_reward   | 0.08695802  |\n",
      "|    n_updates          | 2172        |\n",
      "|    policyGradLoss     | -0.0116     |\n",
      "|    value_loss         | 0.446       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 557         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 367         |\n",
      "|    total_timesteps    | 4464640     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011906318 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0845      |\n",
      "|    mean_step_reward   | 0.0807666   |\n",
      "|    n_updates          | 2176        |\n",
      "|    policyGradLoss     | -0.00982    |\n",
      "|    value_loss         | 0.601       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 380         |\n",
      "|    total_timesteps    | 4472832     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014105954 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00478     |\n",
      "|    mean_step_reward   | 0.08805665  |\n",
      "|    n_updates          | 2180        |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 394         |\n",
      "|    total_timesteps    | 4481024     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013687688 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.826       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.122       |\n",
      "|    mean_step_reward   | 0.08472657  |\n",
      "|    n_updates          | 2184        |\n",
      "|    policyGradLoss     | -0.00942    |\n",
      "|    value_loss         | 1.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 408         |\n",
      "|    total_timesteps    | 4489216     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013073818 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.208       |\n",
      "|    mean_step_reward   | 0.071329355 |\n",
      "|    n_updates          | 2188        |\n",
      "|    policyGradLoss     | -0.00501    |\n",
      "|    value_loss         | 1.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 422         |\n",
      "|    total_timesteps    | 4497408     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009361707 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 1.35        |\n",
      "|    mean_step_reward   | 0.05729737  |\n",
      "|    n_updates          | 2192        |\n",
      "|    policyGradLoss     | -0.00433    |\n",
      "|    value_loss         | 2.09        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 437         |\n",
      "|    total_timesteps    | 4505600     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010762512 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.153       |\n",
      "|    mean_step_reward   | 0.056479495 |\n",
      "|    n_updates          | 2196        |\n",
      "|    policyGradLoss     | -0.00941    |\n",
      "|    value_loss         | 1.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 452         |\n",
      "|    total_timesteps    | 4513792     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015567996 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0121     |\n",
      "|    mean_step_reward   | 0.07631104  |\n",
      "|    n_updates          | 2200        |\n",
      "|    policyGradLoss     | -0.00876    |\n",
      "|    value_loss         | 0.333       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 467         |\n",
      "|    total_timesteps    | 4521984     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017081482 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0837      |\n",
      "|    mean_step_reward   | 0.074910894 |\n",
      "|    n_updates          | 2204        |\n",
      "|    policyGradLoss     | -0.00896    |\n",
      "|    value_loss         | 0.326       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 481         |\n",
      "|    total_timesteps    | 4530176     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010137658 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0549      |\n",
      "|    mean_step_reward   | 0.071997076 |\n",
      "|    n_updates          | 2208        |\n",
      "|    policyGradLoss     | -0.0072     |\n",
      "|    value_loss         | 0.856       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 496         |\n",
      "|    total_timesteps    | 4538368     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013851413 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0505      |\n",
      "|    mean_step_reward   | 0.08030518  |\n",
      "|    n_updates          | 2212        |\n",
      "|    policyGradLoss     | -0.00808    |\n",
      "|    value_loss         | 0.577       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 511         |\n",
      "|    total_timesteps    | 4546560     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012079269 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0182      |\n",
      "|    mean_step_reward   | 0.08369264  |\n",
      "|    n_updates          | 2216        |\n",
      "|    policyGradLoss     | -0.0101     |\n",
      "|    value_loss         | 0.422       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 526         |\n",
      "|    total_timesteps    | 4554752     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011608839 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.835       |\n",
      "|    mean_step_reward   | 0.06309937  |\n",
      "|    n_updates          | 2220        |\n",
      "|    policyGradLoss     | -0.00436    |\n",
      "|    value_loss         | 1.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 541         |\n",
      "|    total_timesteps    | 4562944     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013926083 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.131       |\n",
      "|    mean_step_reward   | 0.05815186  |\n",
      "|    n_updates          | 2224        |\n",
      "|    policyGradLoss     | -0.0055     |\n",
      "|    value_loss         | 1.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 556         |\n",
      "|    total_timesteps    | 4571136     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012439333 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.022       |\n",
      "|    mean_step_reward   | 0.06954102  |\n",
      "|    n_updates          | 2228        |\n",
      "|    policyGradLoss     | -0.00806    |\n",
      "|    value_loss         | 0.464       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 571         |\n",
      "|    total_timesteps    | 4579328     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007541154 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.443       |\n",
      "|    mean_step_reward   | 0.041658945 |\n",
      "|    n_updates          | 2232        |\n",
      "|    policyGradLoss     | -0.00736    |\n",
      "|    value_loss         | 1.64        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 586         |\n",
      "|    total_timesteps    | 4587520     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012682665 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0248     |\n",
      "|    mean_step_reward   | 0.064833984 |\n",
      "|    n_updates          | 2236        |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.273       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/SF84G_14.zip\n",
      "[EVAL] Mean Return: 20.220, Best Return: 20.220\n",
      "New best record. Saved to ./runs_smw/best_model.zip\n",
      "Saved video to ./runs_smw/videos/step_4587520_mean_20.22.mp4\n",
      "\n",
      "=== Round 5 | Learn 327680 steps (Total trained: 4587520) ===\n",
      "Logging to ./runs_smw/tb/SF84G_1220_1_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 775     |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 10      |\n",
      "|    total_timesteps | 4595712 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 644         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 4603904     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010504743 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 1.05        |\n",
      "|    mean_step_reward   | 0.054827884 |\n",
      "|    n_updates          | 2244        |\n",
      "|    policyGradLoss     | -0.00701    |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 608         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 4612096     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012016727 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.112       |\n",
      "|    mean_step_reward   | 0.07029298  |\n",
      "|    n_updates          | 2248        |\n",
      "|    policyGradLoss     | -0.00615    |\n",
      "|    value_loss         | 0.586       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 591         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 55          |\n",
      "|    total_timesteps    | 4620288     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011200838 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0388      |\n",
      "|    mean_step_reward   | 0.08221314  |\n",
      "|    n_updates          | 2252        |\n",
      "|    policyGradLoss     | -0.00914    |\n",
      "|    value_loss         | 0.459       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 583         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 4628480     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008101381 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0381      |\n",
      "|    mean_step_reward   | 0.06987916  |\n",
      "|    n_updates          | 2256        |\n",
      "|    policyGradLoss     | -0.00526    |\n",
      "|    value_loss         | 1.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 578         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 4636672     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009382074 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.416       |\n",
      "|    mean_step_reward   | 0.055950932 |\n",
      "|    n_updates          | 2260        |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.925       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 571         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 100         |\n",
      "|    total_timesteps    | 4644864     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011499226 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0101      |\n",
      "|    mean_step_reward   | 0.069351815 |\n",
      "|    n_updates          | 2264        |\n",
      "|    policyGradLoss     | -0.00668    |\n",
      "|    value_loss         | 0.496       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 568        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 115        |\n",
      "|    total_timesteps    | 4653056    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01046067 |\n",
      "|    entropy_loss       | -2.08      |\n",
      "|    explained_variance | 0.977      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0704     |\n",
      "|    mean_step_reward   | 0.06431641 |\n",
      "|    n_updates          | 2268       |\n",
      "|    policyGradLoss     | -0.00893   |\n",
      "|    value_loss         | 0.984      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 130         |\n",
      "|    total_timesteps    | 4661248     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011839256 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.025       |\n",
      "|    mean_step_reward   | 0.06749268  |\n",
      "|    n_updates          | 2272        |\n",
      "|    policyGradLoss     | -0.0119     |\n",
      "|    value_loss         | 0.411       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 574         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 4669440     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013832961 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0736      |\n",
      "|    mean_step_reward   | 0.0571106   |\n",
      "|    n_updates          | 2276        |\n",
      "|    policyGradLoss     | -0.0111     |\n",
      "|    value_loss         | 0.514       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 577         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 4677632     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016388604 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0217     |\n",
      "|    mean_step_reward   | 0.05802247  |\n",
      "|    n_updates          | 2280        |\n",
      "|    policyGradLoss     | -0.00907    |\n",
      "|    value_loss         | 0.366       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 580         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 4685824     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012708193 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.023       |\n",
      "|    mean_step_reward   | 0.06987306  |\n",
      "|    n_updates          | 2284        |\n",
      "|    policyGradLoss     | -0.00928    |\n",
      "|    value_loss         | 0.501       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 580         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 183         |\n",
      "|    total_timesteps    | 4694016     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011269948 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.885       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.237       |\n",
      "|    mean_step_reward   | 0.075578615 |\n",
      "|    n_updates          | 2288        |\n",
      "|    policyGradLoss     | -0.00859    |\n",
      "|    value_loss         | 0.769       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 578         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 4702208     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014965412 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.865       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.147       |\n",
      "|    mean_step_reward   | 0.08678712  |\n",
      "|    n_updates          | 2292        |\n",
      "|    policyGradLoss     | -0.00679    |\n",
      "|    value_loss         | 0.698       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 576        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 213        |\n",
      "|    total_timesteps    | 4710400    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01624547 |\n",
      "|    entropy_loss       | -2.05      |\n",
      "|    explained_variance | 0.889      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.00479   |\n",
      "|    mean_step_reward   | 0.08494385 |\n",
      "|    n_updates          | 2296       |\n",
      "|    policyGradLoss     | -0.0107    |\n",
      "|    value_loss         | 0.332      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 573         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 228         |\n",
      "|    total_timesteps    | 4718592     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012133604 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0192      |\n",
      "|    mean_step_reward   | 0.08411378  |\n",
      "|    n_updates          | 2300        |\n",
      "|    policyGradLoss     | -0.0123     |\n",
      "|    value_loss         | 0.463       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 572         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 4726784     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017023169 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0334     |\n",
      "|    mean_step_reward   | 0.081098646 |\n",
      "|    n_updates          | 2304        |\n",
      "|    policyGradLoss     | -0.0126     |\n",
      "|    value_loss         | 0.235       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 570         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 258         |\n",
      "|    total_timesteps    | 4734976     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011025663 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0722      |\n",
      "|    mean_step_reward   | 0.07648926  |\n",
      "|    n_updates          | 2308        |\n",
      "|    policyGradLoss     | -0.00697    |\n",
      "|    value_loss         | 0.453       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 569        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 273        |\n",
      "|    total_timesteps    | 4743168    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01240855 |\n",
      "|    entropy_loss       | -2.07      |\n",
      "|    explained_variance | 0.937      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.00943   |\n",
      "|    mean_step_reward   | 0.07263672 |\n",
      "|    n_updates          | 2312       |\n",
      "|    policyGradLoss     | -0.0106    |\n",
      "|    value_loss         | 0.453      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 569         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 287         |\n",
      "|    total_timesteps    | 4751360     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010317197 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.91        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.252       |\n",
      "|    mean_step_reward   | 0.07220948  |\n",
      "|    n_updates          | 2316        |\n",
      "|    policyGradLoss     | -0.0079     |\n",
      "|    value_loss         | 0.769       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 568        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 302        |\n",
      "|    total_timesteps    | 4759552    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01527601 |\n",
      "|    entropy_loss       | -2.05      |\n",
      "|    explained_variance | 0.934      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0406     |\n",
      "|    mean_step_reward   | 0.07840089 |\n",
      "|    n_updates          | 2320       |\n",
      "|    policyGradLoss     | -0.00964   |\n",
      "|    value_loss         | 0.446      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 568         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 4767744     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011214337 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.856       |\n",
      "|    mean_step_reward   | 0.06984742  |\n",
      "|    n_updates          | 2324        |\n",
      "|    policyGradLoss     | -0.00686    |\n",
      "|    value_loss         | 1.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 567         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 332         |\n",
      "|    total_timesteps    | 4775936     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011758011 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.303       |\n",
      "|    mean_step_reward   | 0.062070318 |\n",
      "|    n_updates          | 2328        |\n",
      "|    policyGradLoss     | -0.00554    |\n",
      "|    value_loss         | 0.993       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 346         |\n",
      "|    total_timesteps    | 4784128     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011832122 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.145       |\n",
      "|    mean_step_reward   | 0.072053224 |\n",
      "|    n_updates          | 2332        |\n",
      "|    policyGradLoss     | -0.00881    |\n",
      "|    value_loss         | 0.735       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 361         |\n",
      "|    total_timesteps    | 4792320     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008222701 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.506       |\n",
      "|    mean_step_reward   | 0.080974124 |\n",
      "|    n_updates          | 2336        |\n",
      "|    policyGradLoss     | -0.00542    |\n",
      "|    value_loss         | 0.833       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 376         |\n",
      "|    total_timesteps    | 4800512     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013007026 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.91        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0962      |\n",
      "|    mean_step_reward   | 0.081425786 |\n",
      "|    n_updates          | 2340        |\n",
      "|    policyGradLoss     | -0.0059     |\n",
      "|    value_loss         | 0.677       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 391         |\n",
      "|    total_timesteps    | 4808704     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010721829 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.866       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0021      |\n",
      "|    mean_step_reward   | 0.08137818  |\n",
      "|    n_updates          | 2344        |\n",
      "|    policyGradLoss     | -0.00685    |\n",
      "|    value_loss         | 0.422       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 406         |\n",
      "|    total_timesteps    | 4816896     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016190387 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0267     |\n",
      "|    mean_step_reward   | 0.07930665  |\n",
      "|    n_updates          | 2348        |\n",
      "|    policyGradLoss     | -0.013      |\n",
      "|    value_loss         | 0.264       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 563          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 421          |\n",
      "|    total_timesteps    | 4825088      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0073871375 |\n",
      "|    entropy_loss       | -2.06        |\n",
      "|    explained_variance | 0.977        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.313        |\n",
      "|    mean_step_reward   | 0.049799804  |\n",
      "|    n_updates          | 2352         |\n",
      "|    policyGradLoss     | -0.00131     |\n",
      "|    value_loss         | 1.38         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 436         |\n",
      "|    total_timesteps    | 4833280     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007327201 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 1.24        |\n",
      "|    mean_step_reward   | 0.062589124 |\n",
      "|    n_updates          | 2356        |\n",
      "|    policyGradLoss     | -0.00819    |\n",
      "|    value_loss         | 0.953       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 451         |\n",
      "|    total_timesteps    | 4841472     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010625776 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0438      |\n",
      "|    mean_step_reward   | 0.05394776  |\n",
      "|    n_updates          | 2360        |\n",
      "|    policyGradLoss     | -0.00791    |\n",
      "|    value_loss         | 0.902       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 466         |\n",
      "|    total_timesteps    | 4849664     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007928914 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.445       |\n",
      "|    mean_step_reward   | 0.024575202 |\n",
      "|    n_updates          | 2364        |\n",
      "|    policyGradLoss     | -0.00328    |\n",
      "|    value_loss         | 1.88        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 481         |\n",
      "|    total_timesteps    | 4857856     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013663954 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00848    |\n",
      "|    mean_step_reward   | 0.05414307  |\n",
      "|    n_updates          | 2368        |\n",
      "|    policyGradLoss     | -0.00837    |\n",
      "|    value_loss         | 0.253       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 496         |\n",
      "|    total_timesteps    | 4866048     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01250935  |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00519    |\n",
      "|    mean_step_reward   | 0.050816655 |\n",
      "|    n_updates          | 2372        |\n",
      "|    policyGradLoss     | -0.00975    |\n",
      "|    value_loss         | 0.212       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 510         |\n",
      "|    total_timesteps    | 4874240     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012582261 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.019      |\n",
      "|    mean_step_reward   | 0.07108643  |\n",
      "|    n_updates          | 2376        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.304       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 525         |\n",
      "|    total_timesteps    | 4882432     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012478464 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00415    |\n",
      "|    mean_step_reward   | 0.074110106 |\n",
      "|    n_updates          | 2380        |\n",
      "|    policyGradLoss     | -0.00868    |\n",
      "|    value_loss         | 0.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 540         |\n",
      "|    total_timesteps    | 4890624     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010877255 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0179      |\n",
      "|    mean_step_reward   | 0.08135988  |\n",
      "|    n_updates          | 2384        |\n",
      "|    policyGradLoss     | -0.00634    |\n",
      "|    value_loss         | 0.448       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 554         |\n",
      "|    total_timesteps    | 4898816     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012238665 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.295       |\n",
      "|    mean_step_reward   | 0.07608765  |\n",
      "|    n_updates          | 2388        |\n",
      "|    policyGradLoss     | -0.00657    |\n",
      "|    value_loss         | 0.792       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 569         |\n",
      "|    total_timesteps    | 4907008     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010664007 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.407       |\n",
      "|    mean_step_reward   | 0.064760745 |\n",
      "|    n_updates          | 2392        |\n",
      "|    policyGradLoss     | -0.00759    |\n",
      "|    value_loss         | 0.99        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 582         |\n",
      "|    total_timesteps    | 4915200     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015729096 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.168       |\n",
      "|    mean_step_reward   | 0.06292847  |\n",
      "|    n_updates          | 2396        |\n",
      "|    policyGradLoss     | -0.00934    |\n",
      "|    value_loss         | 0.983       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/SF84G_15.zip\n",
      "[EVAL] Mean Return: 20.220, Best Return: 20.220\n",
      "Saved video to ./runs_smw/videos/step_4915200_mean_20.22.mp4\n",
      "\n",
      "=== Round 6 | Learn 327680 steps (Total trained: 4915200) ===\n",
      "Logging to ./runs_smw/tb/SF84G_1220_1_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 739     |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 11      |\n",
      "|    total_timesteps | 4923392 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 633         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 4931584     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008782316 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.192       |\n",
      "|    mean_step_reward   | 0.05036866  |\n",
      "|    n_updates          | 2404        |\n",
      "|    policyGradLoss     | -0.005      |\n",
      "|    value_loss         | 0.966       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 602         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 4939776     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011790931 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0145     |\n",
      "|    mean_step_reward   | 0.05285645  |\n",
      "|    n_updates          | 2408        |\n",
      "|    policyGradLoss     | -0.00809    |\n",
      "|    value_loss         | 0.431       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 586         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 55          |\n",
      "|    total_timesteps    | 4947968     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006959101 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.735       |\n",
      "|    mean_step_reward   | 0.03684326  |\n",
      "|    n_updates          | 2412        |\n",
      "|    policyGradLoss     | -0.00622    |\n",
      "|    value_loss         | 0.941       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 581          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 70           |\n",
      "|    total_timesteps    | 4956160      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0141929565 |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.982        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | -0.0135      |\n",
      "|    mean_step_reward   | 0.05281006   |\n",
      "|    n_updates          | 2416         |\n",
      "|    policyGradLoss     | -0.0129      |\n",
      "|    value_loss         | 0.267        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 575         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 4964352     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011848942 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0274      |\n",
      "|    mean_step_reward   | 0.057912603 |\n",
      "|    n_updates          | 2420        |\n",
      "|    policyGradLoss     | -0.011      |\n",
      "|    value_loss         | 0.255       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 571         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 100         |\n",
      "|    total_timesteps    | 4972544     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016121719 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0448     |\n",
      "|    mean_step_reward   | 0.06033692  |\n",
      "|    n_updates          | 2424        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 567         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 4980736     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011302395 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0929      |\n",
      "|    mean_step_reward   | 0.06791871  |\n",
      "|    n_updates          | 2428        |\n",
      "|    policyGradLoss     | -0.00809    |\n",
      "|    value_loss         | 0.653       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 130         |\n",
      "|    total_timesteps    | 4988928     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010257037 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.904       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0219      |\n",
      "|    mean_step_reward   | 0.07684205  |\n",
      "|    n_updates          | 2432        |\n",
      "|    policyGradLoss     | -0.00371    |\n",
      "|    value_loss         | 0.697       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 4997120     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010997666 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.912       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0123      |\n",
      "|    mean_step_reward   | 0.06272706  |\n",
      "|    n_updates          | 2436        |\n",
      "|    policyGradLoss     | -0.00386    |\n",
      "|    value_loss         | 0.64        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 5005312     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011491434 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.463       |\n",
      "|    mean_step_reward   | 0.058774423 |\n",
      "|    n_updates          | 2440        |\n",
      "|    policyGradLoss     | -0.00811    |\n",
      "|    value_loss         | 0.761       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 561        |\n",
      "|    iterations         | 12         |\n",
      "|    time_elapsed       | 175        |\n",
      "|    total_timesteps    | 5013504    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01200453 |\n",
      "|    entropy_loss       | -2.05      |\n",
      "|    explained_variance | 0.954      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.153      |\n",
      "|    mean_step_reward   | 0.07021485 |\n",
      "|    n_updates          | 2444       |\n",
      "|    policyGradLoss     | -0.0102    |\n",
      "|    value_loss         | 0.458      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 5021696     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013132997 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.014       |\n",
      "|    mean_step_reward   | 0.07434571  |\n",
      "|    n_updates          | 2448        |\n",
      "|    policyGradLoss     | -0.0063     |\n",
      "|    value_loss         | 0.464       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 205         |\n",
      "|    total_timesteps    | 5029888     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008631811 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.165       |\n",
      "|    mean_step_reward   | 0.06432862  |\n",
      "|    n_updates          | 2452        |\n",
      "|    policyGradLoss     | -0.00627    |\n",
      "|    value_loss         | 0.973       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 5038080     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007864395 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.449       |\n",
      "|    mean_step_reward   | 0.04987671  |\n",
      "|    n_updates          | 2456        |\n",
      "|    policyGradLoss     | -0.00507    |\n",
      "|    value_loss         | 1.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 234         |\n",
      "|    total_timesteps    | 5046272     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010465702 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.334       |\n",
      "|    mean_step_reward   | 0.054512944 |\n",
      "|    n_updates          | 2460        |\n",
      "|    policyGradLoss     | -0.00481    |\n",
      "|    value_loss         | 0.89        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 557         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 249         |\n",
      "|    total_timesteps    | 5054464     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010077917 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0787      |\n",
      "|    mean_step_reward   | 0.05953858  |\n",
      "|    n_updates          | 2464        |\n",
      "|    policyGradLoss     | -0.00581    |\n",
      "|    value_loss         | 0.553       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 557         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 5062656     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012389984 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0135      |\n",
      "|    mean_step_reward   | 0.0545459   |\n",
      "|    n_updates          | 2468        |\n",
      "|    policyGradLoss     | -0.00792    |\n",
      "|    value_loss         | 0.578       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 556         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 279         |\n",
      "|    total_timesteps    | 5070848     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010695441 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.183       |\n",
      "|    mean_step_reward   | 0.06667115  |\n",
      "|    n_updates          | 2472        |\n",
      "|    policyGradLoss     | -0.00711    |\n",
      "|    value_loss         | 0.875       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 556        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 294        |\n",
      "|    total_timesteps    | 5079040    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01309534 |\n",
      "|    entropy_loss       | -2.05      |\n",
      "|    explained_variance | 0.938      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0222     |\n",
      "|    mean_step_reward   | 0.06697877 |\n",
      "|    n_updates          | 2476       |\n",
      "|    policyGradLoss     | -0.0088    |\n",
      "|    value_loss         | 0.844      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 555         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 309         |\n",
      "|    total_timesteps    | 5087232     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009255602 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.765       |\n",
      "|    mean_step_reward   | 0.072452396 |\n",
      "|    n_updates          | 2480        |\n",
      "|    policyGradLoss     | -0.00815    |\n",
      "|    value_loss         | 1.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 555         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 324         |\n",
      "|    total_timesteps    | 5095424     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011600135 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.03        |\n",
      "|    mean_step_reward   | 0.0660376   |\n",
      "|    n_updates          | 2484        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.674       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 335         |\n",
      "|    total_timesteps    | 5103616     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012691464 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.103       |\n",
      "|    mean_step_reward   | 0.05537476  |\n",
      "|    n_updates          | 2488        |\n",
      "|    policyGradLoss     | -0.00928    |\n",
      "|    value_loss         | 0.778       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 349         |\n",
      "|    total_timesteps    | 5111808     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.00796035  |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.407       |\n",
      "|    mean_step_reward   | 0.028276365 |\n",
      "|    n_updates          | 2492        |\n",
      "|    policyGradLoss     | -0.00717    |\n",
      "|    value_loss         | 1.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 363         |\n",
      "|    total_timesteps    | 5120000     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012475744 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0149      |\n",
      "|    mean_step_reward   | 0.04883668  |\n",
      "|    n_updates          | 2496        |\n",
      "|    policyGradLoss     | -0.00975    |\n",
      "|    value_loss         | 0.358       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 376         |\n",
      "|    total_timesteps    | 5128192     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012620073 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.463       |\n",
      "|    mean_step_reward   | 0.040268563 |\n",
      "|    n_updates          | 2500        |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.696       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 392         |\n",
      "|    total_timesteps    | 5136384     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010338723 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.103       |\n",
      "|    mean_step_reward   | 0.04901734  |\n",
      "|    n_updates          | 2504        |\n",
      "|    policyGradLoss     | -0.00638    |\n",
      "|    value_loss         | 0.585       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 407         |\n",
      "|    total_timesteps    | 5144576     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014963245 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.111       |\n",
      "|    mean_step_reward   | 0.066499025 |\n",
      "|    n_updates          | 2508        |\n",
      "|    policyGradLoss     | -0.0104     |\n",
      "|    value_loss         | 0.69        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 563        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 421        |\n",
      "|    total_timesteps    | 5152768    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01127095 |\n",
      "|    entropy_loss       | -2.04      |\n",
      "|    explained_variance | 0.895      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0431     |\n",
      "|    mean_step_reward   | 0.07896973 |\n",
      "|    n_updates          | 2512       |\n",
      "|    policyGradLoss     | -0.0096    |\n",
      "|    value_loss         | 0.626      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 562          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 436          |\n",
      "|    total_timesteps    | 5160960      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0112178605 |\n",
      "|    entropy_loss       | -2.04        |\n",
      "|    explained_variance | 0.928        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | -0.00178     |\n",
      "|    mean_step_reward   | 0.078320324  |\n",
      "|    n_updates          | 2516         |\n",
      "|    policyGradLoss     | -0.0124      |\n",
      "|    value_loss         | 0.412        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 451         |\n",
      "|    total_timesteps    | 5169152     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009733005 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0264      |\n",
      "|    mean_step_reward   | 0.07408692  |\n",
      "|    n_updates          | 2520        |\n",
      "|    policyGradLoss     | -0.011      |\n",
      "|    value_loss         | 0.511       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 466         |\n",
      "|    total_timesteps    | 5177344     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008575147 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.199       |\n",
      "|    mean_step_reward   | 0.04791138  |\n",
      "|    n_updates          | 2524        |\n",
      "|    policyGradLoss     | -0.00648    |\n",
      "|    value_loss         | 1.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 481         |\n",
      "|    total_timesteps    | 5185536     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009632312 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0599      |\n",
      "|    mean_step_reward   | 0.055905767 |\n",
      "|    n_updates          | 2528        |\n",
      "|    policyGradLoss     | -0.00895    |\n",
      "|    value_loss         | 0.535       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 496         |\n",
      "|    total_timesteps    | 5193728     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009942802 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.204       |\n",
      "|    mean_step_reward   | 0.021760251 |\n",
      "|    n_updates          | 2532        |\n",
      "|    policyGradLoss     | -0.00806    |\n",
      "|    value_loss         | 1.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 511         |\n",
      "|    total_timesteps    | 5201920     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013049481 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0335     |\n",
      "|    mean_step_reward   | 0.053078618 |\n",
      "|    n_updates          | 2536        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.206       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 526         |\n",
      "|    total_timesteps    | 5210112     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013766726 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0192      |\n",
      "|    mean_step_reward   | 0.053247076 |\n",
      "|    n_updates          | 2540        |\n",
      "|    policyGradLoss     | -0.00813    |\n",
      "|    value_loss         | 0.448       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 541         |\n",
      "|    total_timesteps    | 5218304     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012728224 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0247      |\n",
      "|    mean_step_reward   | 0.07925416  |\n",
      "|    n_updates          | 2544        |\n",
      "|    policyGradLoss     | -0.00853    |\n",
      "|    value_loss         | 0.355       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 555         |\n",
      "|    total_timesteps    | 5226496     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011861794 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.409       |\n",
      "|    mean_step_reward   | 0.059399415 |\n",
      "|    n_updates          | 2548        |\n",
      "|    policyGradLoss     | -0.0138     |\n",
      "|    value_loss         | 0.421       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 571         |\n",
      "|    total_timesteps    | 5234688     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010775364 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.37        |\n",
      "|    mean_step_reward   | 0.065896004 |\n",
      "|    n_updates          | 2552        |\n",
      "|    policyGradLoss     | -0.000221   |\n",
      "|    value_loss         | 1.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 585         |\n",
      "|    total_timesteps    | 5242880     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01159584  |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00723     |\n",
      "|    mean_step_reward   | 0.062163092 |\n",
      "|    n_updates          | 2556        |\n",
      "|    policyGradLoss     | -0.0109     |\n",
      "|    value_loss         | 0.415       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/SF84G_16.zip\n",
      "[EVAL] Mean Return: 116.110, Best Return: 116.110\n",
      "New best record. Saved to ./runs_smw/best_model.zip\n",
      "Saved video to ./runs_smw/videos/step_5242880_mean_116.11.mp4\n",
      "\n",
      "=== Round 7 | Learn 327680 steps (Total trained: 5242880) ===\n",
      "Logging to ./runs_smw/tb/SF84G_1220_1_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 733     |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 11      |\n",
      "|    total_timesteps | 5251072 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 629         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 26          |\n",
      "|    total_timesteps    | 5259264     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013943061 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00492     |\n",
      "|    mean_step_reward   | 0.06589844  |\n",
      "|    n_updates          | 2564        |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.351       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 601         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 5267456     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009587385 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.26        |\n",
      "|    mean_step_reward   | 0.04512085  |\n",
      "|    n_updates          | 2568        |\n",
      "|    policyGradLoss     | -0.00679    |\n",
      "|    value_loss         | 1.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 589         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 55          |\n",
      "|    total_timesteps    | 5275648     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010538285 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0421      |\n",
      "|    mean_step_reward   | 0.064857185 |\n",
      "|    n_updates          | 2572        |\n",
      "|    policyGradLoss     | -0.0101     |\n",
      "|    value_loss         | 0.469       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 580         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 5283840     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010132631 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0221      |\n",
      "|    mean_step_reward   | 0.06928956  |\n",
      "|    n_updates          | 2576        |\n",
      "|    policyGradLoss     | -0.00924    |\n",
      "|    value_loss         | 0.379       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 573         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 5292032     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012858171 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0104      |\n",
      "|    mean_step_reward   | 0.07096558  |\n",
      "|    n_updates          | 2580        |\n",
      "|    policyGradLoss     | -0.0113     |\n",
      "|    value_loss         | 0.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 569         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 100         |\n",
      "|    total_timesteps    | 5300224     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011521798 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0129      |\n",
      "|    mean_step_reward   | 0.053033452 |\n",
      "|    n_updates          | 2584        |\n",
      "|    policyGradLoss     | -0.0124     |\n",
      "|    value_loss         | 0.424       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 5308416     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013528412 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0347     |\n",
      "|    mean_step_reward   | 0.06302735  |\n",
      "|    n_updates          | 2588        |\n",
      "|    policyGradLoss     | -0.00846    |\n",
      "|    value_loss         | 0.363       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 130         |\n",
      "|    total_timesteps    | 5316608     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008874558 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0557      |\n",
      "|    mean_step_reward   | 0.06410889  |\n",
      "|    n_updates          | 2592        |\n",
      "|    policyGradLoss     | -0.0117     |\n",
      "|    value_loss         | 0.611       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 573         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 5324800     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008392697 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.113       |\n",
      "|    mean_step_reward   | 0.06244996  |\n",
      "|    n_updates          | 2596        |\n",
      "|    policyGradLoss     | -0.011      |\n",
      "|    value_loss         | 0.665       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 575         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 5332992     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011222779 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.117       |\n",
      "|    mean_step_reward   | 0.075001225 |\n",
      "|    n_updates          | 2600        |\n",
      "|    policyGradLoss     | -0.00608    |\n",
      "|    value_loss         | 0.861       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 577         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 5341184     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014569915 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0903      |\n",
      "|    mean_step_reward   | 0.07567139  |\n",
      "|    n_updates          | 2604        |\n",
      "|    policyGradLoss     | -0.0101     |\n",
      "|    value_loss         | 0.376       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 576         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 184         |\n",
      "|    total_timesteps    | 5349376     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014624558 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.019       |\n",
      "|    mean_step_reward   | 0.07798707  |\n",
      "|    n_updates          | 2608        |\n",
      "|    policyGradLoss     | -0.0123     |\n",
      "|    value_loss         | 0.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 575         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 5357568     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013230833 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.908       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0563      |\n",
      "|    mean_step_reward   | 0.0649707   |\n",
      "|    n_updates          | 2612        |\n",
      "|    policyGradLoss     | -0.00609    |\n",
      "|    value_loss         | 0.536       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 573        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 214        |\n",
      "|    total_timesteps    | 5365760    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01254227 |\n",
      "|    entropy_loss       | -2.14      |\n",
      "|    explained_variance | 0.959      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0346    |\n",
      "|    mean_step_reward   | 0.05815064 |\n",
      "|    n_updates          | 2616       |\n",
      "|    policyGradLoss     | -0.0129    |\n",
      "|    value_loss         | 0.369      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 571         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 5373952     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015652211 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.185       |\n",
      "|    mean_step_reward   | 0.057977304 |\n",
      "|    n_updates          | 2620        |\n",
      "|    policyGradLoss     | -0.0106     |\n",
      "|    value_loss         | 0.488       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 569         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 5382144     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016366038 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0171     |\n",
      "|    mean_step_reward   | 0.06603272  |\n",
      "|    n_updates          | 2624        |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.264       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 567         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 259         |\n",
      "|    total_timesteps    | 5390336     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014006749 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.162       |\n",
      "|    mean_step_reward   | 0.07384767  |\n",
      "|    n_updates          | 2628        |\n",
      "|    policyGradLoss     | -0.0122     |\n",
      "|    value_loss         | 0.524       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 5398528     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015173847 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.871       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0803      |\n",
      "|    mean_step_reward   | 0.08423951  |\n",
      "|    n_updates          | 2632        |\n",
      "|    policyGradLoss     | -0.0116     |\n",
      "|    value_loss         | 0.706       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 289         |\n",
      "|    total_timesteps    | 5406720     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010020701 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.158       |\n",
      "|    mean_step_reward   | 0.07294434  |\n",
      "|    n_updates          | 2636        |\n",
      "|    policyGradLoss     | -0.0106     |\n",
      "|    value_loss         | 0.837       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 304        |\n",
      "|    total_timesteps    | 5414912    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01124728 |\n",
      "|    entropy_loss       | -2.05      |\n",
      "|    explained_variance | 0.972      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0436     |\n",
      "|    mean_step_reward   | 0.06759155 |\n",
      "|    n_updates          | 2640       |\n",
      "|    policyGradLoss     | -0.0098    |\n",
      "|    value_loss         | 0.857      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 319         |\n",
      "|    total_timesteps    | 5423104     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012528564 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.143       |\n",
      "|    mean_step_reward   | 0.06926514  |\n",
      "|    n_updates          | 2644        |\n",
      "|    policyGradLoss     | -0.0115     |\n",
      "|    value_loss         | 0.651       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 334         |\n",
      "|    total_timesteps    | 5431296     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010002933 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.168       |\n",
      "|    mean_step_reward   | 0.05766724  |\n",
      "|    n_updates          | 2648        |\n",
      "|    policyGradLoss     | -0.00871    |\n",
      "|    value_loss         | 0.703       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 349         |\n",
      "|    total_timesteps    | 5439488     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011402227 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.904       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00689     |\n",
      "|    mean_step_reward   | 0.07320679  |\n",
      "|    n_updates          | 2652        |\n",
      "|    policyGradLoss     | -0.00737    |\n",
      "|    value_loss         | 0.395       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 364         |\n",
      "|    total_timesteps    | 5447680     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012306992 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0424      |\n",
      "|    mean_step_reward   | 0.07208374  |\n",
      "|    n_updates          | 2656        |\n",
      "|    policyGradLoss     | -0.0117     |\n",
      "|    value_loss         | 0.409       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 561          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 379          |\n",
      "|    total_timesteps    | 5455872      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0105296485 |\n",
      "|    entropy_loss       | -2.04        |\n",
      "|    explained_variance | 0.91         |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.116        |\n",
      "|    mean_step_reward   | 0.07723145   |\n",
      "|    n_updates          | 2660         |\n",
      "|    policyGradLoss     | -0.0104      |\n",
      "|    value_loss         | 0.714        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 394         |\n",
      "|    total_timesteps    | 5464064     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008459753 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.507       |\n",
      "|    mean_step_reward   | 0.051490486 |\n",
      "|    n_updates          | 2664        |\n",
      "|    policyGradLoss     | -0.00721    |\n",
      "|    value_loss         | 0.707       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 560        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 409        |\n",
      "|    total_timesteps    | 5472256    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01002357 |\n",
      "|    entropy_loss       | -2.04      |\n",
      "|    explained_variance | 0.988      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | -0.0179    |\n",
      "|    mean_step_reward   | 0.06925415 |\n",
      "|    n_updates          | 2668       |\n",
      "|    policyGradLoss     | -0.01      |\n",
      "|    value_loss         | 0.416      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 423         |\n",
      "|    total_timesteps    | 5480448     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011935557 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.016       |\n",
      "|    mean_step_reward   | 0.048933104 |\n",
      "|    n_updates          | 2672        |\n",
      "|    policyGradLoss     | -0.0104     |\n",
      "|    value_loss         | 0.5         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 560          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 438          |\n",
      "|    total_timesteps    | 5488640      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0090491045 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.989        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.621        |\n",
      "|    mean_step_reward   | 0.02461914   |\n",
      "|    n_updates          | 2676         |\n",
      "|    policyGradLoss     | -0.00525     |\n",
      "|    value_loss         | 0.882        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 453         |\n",
      "|    total_timesteps    | 5496832     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010051588 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00785    |\n",
      "|    mean_step_reward   | 0.037680667 |\n",
      "|    n_updates          | 2680        |\n",
      "|    policyGradLoss     | -0.00737    |\n",
      "|    value_loss         | 0.466       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 468         |\n",
      "|    total_timesteps    | 5505024     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013082462 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0302      |\n",
      "|    mean_step_reward   | 0.0651709   |\n",
      "|    n_updates          | 2684        |\n",
      "|    policyGradLoss     | -0.0114     |\n",
      "|    value_loss         | 0.311       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 483         |\n",
      "|    total_timesteps    | 5513216     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012480557 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0333     |\n",
      "|    mean_step_reward   | 0.04546631  |\n",
      "|    n_updates          | 2688        |\n",
      "|    policyGradLoss     | -0.0124     |\n",
      "|    value_loss         | 0.245       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 559          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 498          |\n",
      "|    total_timesteps    | 5521408      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0076404335 |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.941        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.0907       |\n",
      "|    mean_step_reward   | 0.044869393  |\n",
      "|    n_updates          | 2692         |\n",
      "|    policyGradLoss     | -0.00564     |\n",
      "|    value_loss         | 0.513        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 513         |\n",
      "|    total_timesteps    | 5529600     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011505872 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0372     |\n",
      "|    mean_step_reward   | 0.06443726  |\n",
      "|    n_updates          | 2696        |\n",
      "|    policyGradLoss     | -0.0141     |\n",
      "|    value_loss         | 0.215       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 527         |\n",
      "|    total_timesteps    | 5537792     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015650325 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0208     |\n",
      "|    mean_step_reward   | 0.06509279  |\n",
      "|    n_updates          | 2700        |\n",
      "|    policyGradLoss     | -0.0124     |\n",
      "|    value_loss         | 0.298       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 542         |\n",
      "|    total_timesteps    | 5545984     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008334946 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.127       |\n",
      "|    mean_step_reward   | 0.07928833  |\n",
      "|    n_updates          | 2704        |\n",
      "|    policyGradLoss     | -0.00562    |\n",
      "|    value_loss         | 0.644       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 557         |\n",
      "|    total_timesteps    | 5554176     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012481337 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0019      |\n",
      "|    mean_step_reward   | 0.07418336  |\n",
      "|    n_updates          | 2708        |\n",
      "|    policyGradLoss     | -0.0129     |\n",
      "|    value_loss         | 0.526       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 572         |\n",
      "|    total_timesteps    | 5562368     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012678529 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0261     |\n",
      "|    mean_step_reward   | 0.07864137  |\n",
      "|    n_updates          | 2712        |\n",
      "|    policyGradLoss     | -0.0135     |\n",
      "|    value_loss         | 0.312       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 585         |\n",
      "|    total_timesteps    | 5570560     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008584681 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.184       |\n",
      "|    mean_step_reward   | 0.045559086 |\n",
      "|    n_updates          | 2716        |\n",
      "|    policyGradLoss     | -0.00973    |\n",
      "|    value_loss         | 0.587       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/SF84G_17.zip\n",
      "[EVAL] Mean Return: 10.250, Best Return: 10.250\n",
      "Saved video to ./runs_smw/videos/step_5570560_mean_10.25.mp4\n",
      "\n",
      "=== Round 8 | Learn 327680 steps (Total trained: 5570560) ===\n",
      "Logging to ./runs_smw/tb/SF84G_1220_1_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1032    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 5578752 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 831         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 19          |\n",
      "|    total_timesteps    | 5586944     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011801426 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0449     |\n",
      "|    mean_step_reward   | 0.04399048  |\n",
      "|    n_updates          | 2724        |\n",
      "|    policyGradLoss     | -0.00526    |\n",
      "|    value_loss         | 0.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 31          |\n",
      "|    total_timesteps    | 5595136     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01111798  |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0245     |\n",
      "|    mean_step_reward   | 0.049959723 |\n",
      "|    n_updates          | 2728        |\n",
      "|    policyGradLoss     | -0.00965    |\n",
      "|    value_loss         | 0.248       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 767          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 42           |\n",
      "|    total_timesteps    | 5603328      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0115208905 |\n",
      "|    entropy_loss       | -2.09        |\n",
      "|    explained_variance | 0.97         |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | -0.0293      |\n",
      "|    mean_step_reward   | 0.05582764   |\n",
      "|    n_updates          | 2732         |\n",
      "|    policyGradLoss     | -0.0113      |\n",
      "|    value_loss         | 0.186        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 707         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 57          |\n",
      "|    total_timesteps    | 5611520     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015947912 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0225     |\n",
      "|    mean_step_reward   | 0.073908694 |\n",
      "|    n_updates          | 2736        |\n",
      "|    policyGradLoss     | -0.0104     |\n",
      "|    value_loss         | 0.336       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 672         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 73          |\n",
      "|    total_timesteps    | 5619712     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016100816 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0376      |\n",
      "|    mean_step_reward   | 0.06641846  |\n",
      "|    n_updates          | 2740        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.467       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 651          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 88           |\n",
      "|    total_timesteps    | 5627904      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0124995615 |\n",
      "|    entropy_loss       | -2.04        |\n",
      "|    explained_variance | 0.964        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.0689       |\n",
      "|    mean_step_reward   | 0.064660646  |\n",
      "|    n_updates          | 2744         |\n",
      "|    policyGradLoss     | -0.0124      |\n",
      "|    value_loss         | 0.313        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 637         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 5636096     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016933668 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0348     |\n",
      "|    mean_step_reward   | 0.059547126 |\n",
      "|    n_updates          | 2748        |\n",
      "|    policyGradLoss     | -0.00875    |\n",
      "|    value_loss         | 0.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 626         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 117         |\n",
      "|    total_timesteps    | 5644288     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017439801 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0159     |\n",
      "|    mean_step_reward   | 0.07950074  |\n",
      "|    n_updates          | 2752        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.208       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 619         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 132         |\n",
      "|    total_timesteps    | 5652480     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015711509 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0417      |\n",
      "|    mean_step_reward   | 0.081960455 |\n",
      "|    n_updates          | 2756        |\n",
      "|    policyGradLoss     | -0.00725    |\n",
      "|    value_loss         | 0.498       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 612         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 5660672     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015849482 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0514     |\n",
      "|    mean_step_reward   | 0.08292359  |\n",
      "|    n_updates          | 2760        |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.237       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 606         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 162         |\n",
      "|    total_timesteps    | 5668864     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018075228 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0261      |\n",
      "|    mean_step_reward   | 0.0853235   |\n",
      "|    n_updates          | 2764        |\n",
      "|    policyGradLoss     | -0.0114     |\n",
      "|    value_loss         | 0.552       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 602         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 5677056     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013141565 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.257       |\n",
      "|    mean_step_reward   | 0.059565436 |\n",
      "|    n_updates          | 2768        |\n",
      "|    policyGradLoss     | 0.00121     |\n",
      "|    value_loss         | 1.84        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 598         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 5685248     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01504338  |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0314      |\n",
      "|    mean_step_reward   | 0.079597175 |\n",
      "|    n_updates          | 2772        |\n",
      "|    policyGradLoss     | -0.0121     |\n",
      "|    value_loss         | 0.369       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 595          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 206          |\n",
      "|    total_timesteps    | 5693440      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0133665465 |\n",
      "|    entropy_loss       | -2.01        |\n",
      "|    explained_variance | 0.948        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.0819       |\n",
      "|    mean_step_reward   | 0.083444834  |\n",
      "|    n_updates          | 2776         |\n",
      "|    policyGradLoss     | -0.00894     |\n",
      "|    value_loss         | 0.535        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 221        |\n",
      "|    total_timesteps    | 5701632    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01003781 |\n",
      "|    entropy_loss       | -2.03      |\n",
      "|    explained_variance | 0.98       |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.0415     |\n",
      "|    mean_step_reward   | 0.0696399  |\n",
      "|    n_updates          | 2780       |\n",
      "|    policyGradLoss     | -0.00873   |\n",
      "|    value_loss         | 0.553      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 589         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 236         |\n",
      "|    total_timesteps    | 5709824     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013496878 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00206    |\n",
      "|    mean_step_reward   | 0.06835694  |\n",
      "|    n_updates          | 2784        |\n",
      "|    policyGradLoss     | -0.0112     |\n",
      "|    value_loss         | 0.586       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 586         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 5718016     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012959395 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.126       |\n",
      "|    mean_step_reward   | 0.051704105 |\n",
      "|    n_updates          | 2788        |\n",
      "|    policyGradLoss     | -0.00637    |\n",
      "|    value_loss         | 0.931       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 585         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 265         |\n",
      "|    total_timesteps    | 5726208     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013316681 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0263      |\n",
      "|    mean_step_reward   | 0.060880132 |\n",
      "|    n_updates          | 2792        |\n",
      "|    policyGradLoss     | -0.00853    |\n",
      "|    value_loss         | 0.483       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 582         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 281         |\n",
      "|    total_timesteps    | 5734400     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015796162 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.095       |\n",
      "|    mean_step_reward   | 0.05643677  |\n",
      "|    n_updates          | 2796        |\n",
      "|    policyGradLoss     | -0.00982    |\n",
      "|    value_loss         | 0.468       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 581         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 5742592     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009935351 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0998      |\n",
      "|    mean_step_reward   | 0.05851075  |\n",
      "|    n_updates          | 2800        |\n",
      "|    policyGradLoss     | -0.00295    |\n",
      "|    value_loss         | 0.896       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 579        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 311        |\n",
      "|    total_timesteps    | 5750784    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01132565 |\n",
      "|    entropy_loss       | -2.04      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    loss               | 0.108      |\n",
      "|    mean_step_reward   | 0.06794435 |\n",
      "|    n_updates          | 2804       |\n",
      "|    policyGradLoss     | -0.0106    |\n",
      "|    value_loss         | 0.497      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 577         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 5758976     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011812832 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00646    |\n",
      "|    mean_step_reward   | 0.065747075 |\n",
      "|    n_updates          | 2808        |\n",
      "|    policyGradLoss     | -0.00444    |\n",
      "|    value_loss         | 0.447       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 576         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 340         |\n",
      "|    total_timesteps    | 5767168     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012233539 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00479    |\n",
      "|    mean_step_reward   | 0.043524176 |\n",
      "|    n_updates          | 2812        |\n",
      "|    policyGradLoss     | -0.0101     |\n",
      "|    value_loss         | 0.405       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 575         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 355         |\n",
      "|    total_timesteps    | 5775360     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012842136 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00926     |\n",
      "|    mean_step_reward   | 0.050806887 |\n",
      "|    n_updates          | 2816        |\n",
      "|    policyGradLoss     | -0.00853    |\n",
      "|    value_loss         | 0.326       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 574         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 370         |\n",
      "|    total_timesteps    | 5783552     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013377408 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0165     |\n",
      "|    mean_step_reward   | 0.06388062  |\n",
      "|    n_updates          | 2820        |\n",
      "|    policyGradLoss     | -0.0122     |\n",
      "|    value_loss         | 0.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 574         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 385         |\n",
      "|    total_timesteps    | 5791744     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012542927 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.144       |\n",
      "|    mean_step_reward   | 0.06302491  |\n",
      "|    n_updates          | 2824        |\n",
      "|    policyGradLoss     | -0.00797    |\n",
      "|    value_loss         | 0.262       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 573         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 399         |\n",
      "|    total_timesteps    | 5799936     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009370346 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0204     |\n",
      "|    mean_step_reward   | 0.04664795  |\n",
      "|    n_updates          | 2828        |\n",
      "|    policyGradLoss     | -0.00743    |\n",
      "|    value_loss         | 0.353       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 572           |\n",
      "|    iterations         | 29            |\n",
      "|    time_elapsed       | 414           |\n",
      "|    total_timesteps    | 5808128       |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.006520671   |\n",
      "|    entropy_loss       | -2.17         |\n",
      "|    explained_variance | 0.992         |\n",
      "|    learning_rate      | 0.0002        |\n",
      "|    loss               | 0.236         |\n",
      "|    mean_step_reward   | -0.0020190421 |\n",
      "|    n_updates          | 2832          |\n",
      "|    policyGradLoss     | -0.00275      |\n",
      "|    value_loss         | 1.06          |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 571         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 429         |\n",
      "|    total_timesteps    | 5816320     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008237632 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.148       |\n",
      "|    mean_step_reward   | 0.009638669 |\n",
      "|    n_updates          | 2836        |\n",
      "|    policyGradLoss     | -0.00583    |\n",
      "|    value_loss         | 1.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 573         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 442         |\n",
      "|    total_timesteps    | 5824512     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008844746 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0121      |\n",
      "|    mean_step_reward   | 0.022086183 |\n",
      "|    n_updates          | 2840        |\n",
      "|    policyGradLoss     | -0.00796    |\n",
      "|    value_loss         | 0.542       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 574         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 455         |\n",
      "|    total_timesteps    | 5832704     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008454526 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0471      |\n",
      "|    mean_step_reward   | 0.016949465 |\n",
      "|    n_updates          | 2844        |\n",
      "|    policyGradLoss     | -0.00276    |\n",
      "|    value_loss         | 0.533       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 575         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 469         |\n",
      "|    total_timesteps    | 5840896     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014227159 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00311     |\n",
      "|    mean_step_reward   | 0.024293214 |\n",
      "|    n_updates          | 2848        |\n",
      "|    policyGradLoss     | -0.00974    |\n",
      "|    value_loss         | 0.275       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 575         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 483         |\n",
      "|    total_timesteps    | 5849088     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014399566 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0546     |\n",
      "|    mean_step_reward   | 0.057187505 |\n",
      "|    n_updates          | 2852        |\n",
      "|    policyGradLoss     | -0.0108     |\n",
      "|    value_loss         | 0.126       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 574         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 498         |\n",
      "|    total_timesteps    | 5857280     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014603158 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0084      |\n",
      "|    mean_step_reward   | 0.066977546 |\n",
      "|    n_updates          | 2856        |\n",
      "|    policyGradLoss     | -0.00922    |\n",
      "|    value_loss         | 0.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 573         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 513         |\n",
      "|    total_timesteps    | 5865472     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008852252 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00287     |\n",
      "|    mean_step_reward   | 0.06684693  |\n",
      "|    n_updates          | 2860        |\n",
      "|    policyGradLoss     | -0.00922    |\n",
      "|    value_loss         | 0.467       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 573         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 528         |\n",
      "|    total_timesteps    | 5873664     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009116536 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0626      |\n",
      "|    mean_step_reward   | 0.036281735 |\n",
      "|    n_updates          | 2864        |\n",
      "|    policyGradLoss     | -0.00992    |\n",
      "|    value_loss         | 0.646       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 572         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 543         |\n",
      "|    total_timesteps    | 5881856     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009498884 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.176       |\n",
      "|    mean_step_reward   | 0.016751712 |\n",
      "|    n_updates          | 2868        |\n",
      "|    policyGradLoss     | -0.00318    |\n",
      "|    value_loss         | 1.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 571         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 558         |\n",
      "|    total_timesteps    | 5890048     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010369649 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.000755    |\n",
      "|    mean_step_reward   | 0.029914554 |\n",
      "|    n_updates          | 2872        |\n",
      "|    policyGradLoss     | -0.00667    |\n",
      "|    value_loss         | 0.536       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 571         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 573         |\n",
      "|    total_timesteps    | 5898240     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009733625 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0258      |\n",
      "|    mean_step_reward   | 0.020854494 |\n",
      "|    n_updates          | 2876        |\n",
      "|    policyGradLoss     | -0.00803    |\n",
      "|    value_loss         | 0.422       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/SF84G_18.zip\n",
      "[EVAL] Mean Return: 18.900, Best Return: 18.900\n",
      "Saved video to ./runs_smw/videos/step_5898240_mean_18.90.mp4\n",
      "\n",
      "=== Round 9 | Learn 327680 steps (Total trained: 5898240) ===\n",
      "Logging to ./runs_smw/tb/SF84G_1220_1_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 751     |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 10      |\n",
      "|    total_timesteps | 5906432 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 636         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 5914624     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01170413  |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.113       |\n",
      "|    mean_step_reward   | 0.034542236 |\n",
      "|    n_updates          | 2884        |\n",
      "|    policyGradLoss     | -0.00778    |\n",
      "|    value_loss         | 0.305       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 600         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 5922816     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011644488 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0352     |\n",
      "|    mean_step_reward   | 0.04826905  |\n",
      "|    n_updates          | 2888        |\n",
      "|    policyGradLoss     | -0.0116     |\n",
      "|    value_loss         | 0.264       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 589         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 55          |\n",
      "|    total_timesteps    | 5931008     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012172573 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0422     |\n",
      "|    mean_step_reward   | 0.05322022  |\n",
      "|    n_updates          | 2892        |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.208       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 581         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 5939200     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010627434 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0379      |\n",
      "|    mean_step_reward   | 0.045582276 |\n",
      "|    n_updates          | 2896        |\n",
      "|    policyGradLoss     | -0.00591    |\n",
      "|    value_loss         | 0.683       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 575         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 5947392     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008780391 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.151       |\n",
      "|    mean_step_reward   | 0.05532227  |\n",
      "|    n_updates          | 2900        |\n",
      "|    policyGradLoss     | -0.00585    |\n",
      "|    value_loss         | 0.765       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 570         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 100         |\n",
      "|    total_timesteps    | 5955584     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010526564 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.292       |\n",
      "|    mean_step_reward   | 0.02887085  |\n",
      "|    n_updates          | 2904        |\n",
      "|    policyGradLoss     | -0.00571    |\n",
      "|    value_loss         | 0.678       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 568         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 5963776     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010378992 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0135     |\n",
      "|    mean_step_reward   | 0.03839966  |\n",
      "|    n_updates          | 2908        |\n",
      "|    policyGradLoss     | -0.0109     |\n",
      "|    value_loss         | 0.424       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 566          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 130          |\n",
      "|    total_timesteps    | 5971968      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0076325396 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.99         |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.108        |\n",
      "|    mean_step_reward   | 0.020252686  |\n",
      "|    n_updates          | 2912         |\n",
      "|    policyGradLoss     | -0.00717     |\n",
      "|    value_loss         | 0.811        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 5980160     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011687578 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0102     |\n",
      "|    mean_step_reward   | 0.061263435 |\n",
      "|    n_updates          | 2916        |\n",
      "|    policyGradLoss     | -0.00578    |\n",
      "|    value_loss         | 0.465       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 159         |\n",
      "|    total_timesteps    | 5988352     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019083502 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00167     |\n",
      "|    mean_step_reward   | 0.05752686  |\n",
      "|    n_updates          | 2920        |\n",
      "|    policyGradLoss     | -0.0112     |\n",
      "|    value_loss         | 0.268       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 174         |\n",
      "|    total_timesteps    | 5996544     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013124256 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0911      |\n",
      "|    mean_step_reward   | 0.053164065 |\n",
      "|    n_updates          | 2924        |\n",
      "|    policyGradLoss     | -0.0062     |\n",
      "|    value_loss         | 0.564       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 6004736     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011018877 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0382      |\n",
      "|    mean_step_reward   | 0.04863892  |\n",
      "|    n_updates          | 2928        |\n",
      "|    policyGradLoss     | -0.00702    |\n",
      "|    value_loss         | 0.513       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 204         |\n",
      "|    total_timesteps    | 6012928     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013139594 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0367     |\n",
      "|    mean_step_reward   | 0.05777833  |\n",
      "|    n_updates          | 2932        |\n",
      "|    policyGradLoss     | -0.00843    |\n",
      "|    value_loss         | 0.242       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 217         |\n",
      "|    total_timesteps    | 6021120     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01518838  |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0374     |\n",
      "|    mean_step_reward   | 0.060273442 |\n",
      "|    n_updates          | 2936        |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.191       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 6029312     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010596077 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0408     |\n",
      "|    mean_step_reward   | 0.063298345 |\n",
      "|    n_updates          | 2940        |\n",
      "|    policyGradLoss     | -0.00788    |\n",
      "|    value_loss         | 0.241       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 568         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 245         |\n",
      "|    total_timesteps    | 6037504     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015178775 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.00717    |\n",
      "|    mean_step_reward   | 0.072679445 |\n",
      "|    n_updates          | 2944        |\n",
      "|    policyGradLoss     | -0.0074     |\n",
      "|    value_loss         | 0.436       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 570         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 258         |\n",
      "|    total_timesteps    | 6045696     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01608523  |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0288     |\n",
      "|    mean_step_reward   | 0.080805674 |\n",
      "|    n_updates          | 2948        |\n",
      "|    policyGradLoss     | -0.0114     |\n",
      "|    value_loss         | 0.322       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 568         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 6053888     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016817773 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0353      |\n",
      "|    mean_step_reward   | 0.08083497  |\n",
      "|    n_updates          | 2952        |\n",
      "|    policyGradLoss     | -0.0109     |\n",
      "|    value_loss         | 0.465       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 567         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 288         |\n",
      "|    total_timesteps    | 6062080     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012227913 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.012      |\n",
      "|    mean_step_reward   | 0.07766602  |\n",
      "|    n_updates          | 2956        |\n",
      "|    policyGradLoss     | -0.00596    |\n",
      "|    value_loss         | 0.542       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 566          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 303          |\n",
      "|    total_timesteps    | 6070272      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0112025505 |\n",
      "|    entropy_loss       | -2.05        |\n",
      "|    explained_variance | 0.986        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.13         |\n",
      "|    mean_step_reward   | 0.05164185   |\n",
      "|    n_updates          | 2960         |\n",
      "|    policyGradLoss     | -0.0116      |\n",
      "|    value_loss         | 0.588        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 6078464     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015636034 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0369      |\n",
      "|    mean_step_reward   | 0.071805425 |\n",
      "|    n_updates          | 2964        |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.342       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 332         |\n",
      "|    total_timesteps    | 6086656     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011422058 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0201     |\n",
      "|    mean_step_reward   | 0.07563966  |\n",
      "|    n_updates          | 2968        |\n",
      "|    policyGradLoss     | -0.00893    |\n",
      "|    value_loss         | 0.304       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 347         |\n",
      "|    total_timesteps    | 6094848     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013228087 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.024       |\n",
      "|    mean_step_reward   | 0.07859863  |\n",
      "|    n_updates          | 2972        |\n",
      "|    policyGradLoss     | -0.00764    |\n",
      "|    value_loss         | 0.554       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 362         |\n",
      "|    total_timesteps    | 6103040     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013200718 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0155     |\n",
      "|    mean_step_reward   | 0.052174076 |\n",
      "|    n_updates          | 2976        |\n",
      "|    policyGradLoss     | -0.00752    |\n",
      "|    value_loss         | 0.384       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 377         |\n",
      "|    total_timesteps    | 6111232     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019394789 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0325     |\n",
      "|    mean_step_reward   | 0.06102784  |\n",
      "|    n_updates          | 2980        |\n",
      "|    policyGradLoss     | -0.00883    |\n",
      "|    value_loss         | 0.332       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 392         |\n",
      "|    total_timesteps    | 6119424     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012343153 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.104       |\n",
      "|    mean_step_reward   | 0.046428226 |\n",
      "|    n_updates          | 2984        |\n",
      "|    policyGradLoss     | -0.00952    |\n",
      "|    value_loss         | 0.697       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 407         |\n",
      "|    total_timesteps    | 6127616     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015392224 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0145     |\n",
      "|    mean_step_reward   | 0.060712896 |\n",
      "|    n_updates          | 2988        |\n",
      "|    policyGradLoss     | -0.0104     |\n",
      "|    value_loss         | 0.392       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 422         |\n",
      "|    total_timesteps    | 6135808     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013460711 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.269       |\n",
      "|    mean_step_reward   | 0.056329347 |\n",
      "|    n_updates          | 2992        |\n",
      "|    policyGradLoss     | -0.00449    |\n",
      "|    value_loss         | 0.775       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 436         |\n",
      "|    total_timesteps    | 6144000     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017733796 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0232      |\n",
      "|    mean_step_reward   | 0.08934815  |\n",
      "|    n_updates          | 2996        |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.389       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 451         |\n",
      "|    total_timesteps    | 6152192     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010773443 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.195       |\n",
      "|    mean_step_reward   | 0.06875977  |\n",
      "|    n_updates          | 3000        |\n",
      "|    policyGradLoss     | -0.00159    |\n",
      "|    value_loss         | 0.562       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 466         |\n",
      "|    total_timesteps    | 6160384     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010600282 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.124       |\n",
      "|    mean_step_reward   | 0.066584475 |\n",
      "|    n_updates          | 3004        |\n",
      "|    policyGradLoss     | -0.00789    |\n",
      "|    value_loss         | 0.658       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 481         |\n",
      "|    total_timesteps    | 6168576     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012556668 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0954      |\n",
      "|    mean_step_reward   | 0.05419434  |\n",
      "|    n_updates          | 3008        |\n",
      "|    policyGradLoss     | -0.0118     |\n",
      "|    value_loss         | 0.453       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 496         |\n",
      "|    total_timesteps    | 6176768     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012350373 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.02       |\n",
      "|    mean_step_reward   | 0.042478032 |\n",
      "|    n_updates          | 3012        |\n",
      "|    policyGradLoss     | -0.0128     |\n",
      "|    value_loss         | 0.229       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 511         |\n",
      "|    total_timesteps    | 6184960     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008694703 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0189     |\n",
      "|    mean_step_reward   | 0.04040406  |\n",
      "|    n_updates          | 3016        |\n",
      "|    policyGradLoss     | -0.00551    |\n",
      "|    value_loss         | 0.435       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 526         |\n",
      "|    total_timesteps    | 6193152     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014598309 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.167       |\n",
      "|    mean_step_reward   | 0.05657471  |\n",
      "|    n_updates          | 3020        |\n",
      "|    policyGradLoss     | -0.00906    |\n",
      "|    value_loss         | 0.398       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 541         |\n",
      "|    total_timesteps    | 6201344     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015380716 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0335     |\n",
      "|    mean_step_reward   | 0.058565676 |\n",
      "|    n_updates          | 3024        |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.447       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 556         |\n",
      "|    total_timesteps    | 6209536     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010243867 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0996      |\n",
      "|    mean_step_reward   | 0.059090577 |\n",
      "|    n_updates          | 3028        |\n",
      "|    policyGradLoss     | -0.00314    |\n",
      "|    value_loss         | 0.599       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 571         |\n",
      "|    total_timesteps    | 6217728     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011836855 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.011       |\n",
      "|    mean_step_reward   | 0.043438725 |\n",
      "|    n_updates          | 3032        |\n",
      "|    policyGradLoss     | -0.00814    |\n",
      "|    value_loss         | 0.484       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 586         |\n",
      "|    total_timesteps    | 6225920     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013391933 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.345       |\n",
      "|    mean_step_reward   | 0.038162842 |\n",
      "|    n_updates          | 3036        |\n",
      "|    policyGradLoss     | -0.00511    |\n",
      "|    value_loss         | 0.831       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/SF84G_19.zip\n",
      "[EVAL] Mean Return: 83.020, Best Return: 83.020\n",
      "Saved video to ./runs_smw/videos/step_6225920_mean_83.02.mp4\n",
      "\n",
      "=== Round 10 | Learn 327680 steps (Total trained: 6225920) ===\n",
      "Logging to ./runs_smw/tb/SF84G_1220_1_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 749     |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 10      |\n",
      "|    total_timesteps | 6234112 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 626         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 26          |\n",
      "|    total_timesteps    | 6242304     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011690625 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.122       |\n",
      "|    mean_step_reward   | 0.059542242 |\n",
      "|    n_updates          | 3044        |\n",
      "|    policyGradLoss     | -0.00483    |\n",
      "|    value_loss         | 0.569       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 615         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 6250496     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015702523 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0123      |\n",
      "|    mean_step_reward   | 0.08089112  |\n",
      "|    n_updates          | 3048        |\n",
      "|    policyGradLoss     | -0.00794    |\n",
      "|    value_loss         | 0.564       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 612         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 53          |\n",
      "|    total_timesteps    | 6258688     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010923408 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.00789     |\n",
      "|    mean_step_reward   | 0.07771607  |\n",
      "|    n_updates          | 3052        |\n",
      "|    policyGradLoss     | -0.00959    |\n",
      "|    value_loss         | 0.459       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 607         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 67          |\n",
      "|    total_timesteps    | 6266880     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009953717 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0243      |\n",
      "|    mean_step_reward   | 0.057368167 |\n",
      "|    n_updates          | 3056        |\n",
      "|    policyGradLoss     | -0.00834    |\n",
      "|    value_loss         | 0.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 593         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 6275072     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01119612  |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0388      |\n",
      "|    mean_step_reward   | 0.055563968 |\n",
      "|    n_updates          | 3060        |\n",
      "|    policyGradLoss     | -0.00686    |\n",
      "|    value_loss         | 0.615       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 586         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 6283264     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014731777 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.055      |\n",
      "|    mean_step_reward   | 0.043857418 |\n",
      "|    n_updates          | 3064        |\n",
      "|    policyGradLoss     | -0.0139     |\n",
      "|    value_loss         | 0.236       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 581          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 112          |\n",
      "|    total_timesteps    | 6291456      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0121897645 |\n",
      "|    entropy_loss       | -2.06        |\n",
      "|    explained_variance | 0.986        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.0583       |\n",
      "|    mean_step_reward   | 0.05234375   |\n",
      "|    n_updates          | 3068         |\n",
      "|    policyGradLoss     | -0.00846     |\n",
      "|    value_loss         | 0.512        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 576         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 127         |\n",
      "|    total_timesteps    | 6299648     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016771134 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0211     |\n",
      "|    mean_step_reward   | 0.08175538  |\n",
      "|    n_updates          | 3072        |\n",
      "|    policyGradLoss     | -0.00956    |\n",
      "|    value_loss         | 0.285       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 573         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 6307840     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010298265 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0188      |\n",
      "|    mean_step_reward   | 0.06071656  |\n",
      "|    n_updates          | 3076        |\n",
      "|    policyGradLoss     | -0.00452    |\n",
      "|    value_loss         | 0.508       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 571         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 6316032     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010432454 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.153       |\n",
      "|    mean_step_reward   | 0.059429936 |\n",
      "|    n_updates          | 3080        |\n",
      "|    policyGradLoss     | -0.00396    |\n",
      "|    value_loss         | 0.826       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 569         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 172         |\n",
      "|    total_timesteps    | 6324224     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008301696 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.054       |\n",
      "|    mean_step_reward   | 0.049750984 |\n",
      "|    n_updates          | 3084        |\n",
      "|    policyGradLoss     | -0.0095     |\n",
      "|    value_loss         | 0.536       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 6332416     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011956309 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0672      |\n",
      "|    mean_step_reward   | 0.068740234 |\n",
      "|    n_updates          | 3088        |\n",
      "|    policyGradLoss     | -0.0108     |\n",
      "|    value_loss         | 0.341       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 202         |\n",
      "|    total_timesteps    | 6340608     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011988649 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0889      |\n",
      "|    mean_step_reward   | 0.045010988 |\n",
      "|    n_updates          | 3092        |\n",
      "|    policyGradLoss     | -0.01       |\n",
      "|    value_loss         | 0.402       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 217         |\n",
      "|    total_timesteps    | 6348800     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01179246  |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0292     |\n",
      "|    mean_step_reward   | 0.058645025 |\n",
      "|    n_updates          | 3096        |\n",
      "|    policyGradLoss     | -0.00879    |\n",
      "|    value_loss         | 0.267       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 6356992     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013974015 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0334     |\n",
      "|    mean_step_reward   | 0.066590585 |\n",
      "|    n_updates          | 3100        |\n",
      "|    policyGradLoss     | -0.0105     |\n",
      "|    value_loss         | 0.377       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 247         |\n",
      "|    total_timesteps    | 6365184     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013702778 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0622      |\n",
      "|    mean_step_reward   | 0.0734253   |\n",
      "|    n_updates          | 3104        |\n",
      "|    policyGradLoss     | -0.00883    |\n",
      "|    value_loss         | 0.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 6373376     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018074196 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0281     |\n",
      "|    mean_step_reward   | 0.08116578  |\n",
      "|    n_updates          | 3108        |\n",
      "|    policyGradLoss     | -0.01       |\n",
      "|    value_loss         | 0.379       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 277         |\n",
      "|    total_timesteps    | 6381568     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012328702 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0385     |\n",
      "|    mean_step_reward   | 0.07538575  |\n",
      "|    n_updates          | 3112        |\n",
      "|    policyGradLoss     | -0.00939    |\n",
      "|    value_loss         | 0.338       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 6389760     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011020465 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0491     |\n",
      "|    mean_step_reward   | 0.061593022 |\n",
      "|    n_updates          | 3116        |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.265       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 560         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 6397952     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0138188   |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0303      |\n",
      "|    mean_step_reward   | 0.041550294 |\n",
      "|    n_updates          | 3120        |\n",
      "|    policyGradLoss     | -0.00798    |\n",
      "|    value_loss         | 0.337       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 321         |\n",
      "|    total_timesteps    | 6406144     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010507671 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.13        |\n",
      "|    mean_step_reward   | 0.03842896  |\n",
      "|    n_updates          | 3124        |\n",
      "|    policyGradLoss     | -0.00556    |\n",
      "|    value_loss         | 0.347       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 6414336     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008565767 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.157       |\n",
      "|    mean_step_reward   | 0.015175778 |\n",
      "|    n_updates          | 3128        |\n",
      "|    policyGradLoss     | -0.00356    |\n",
      "|    value_loss         | 0.959       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 351         |\n",
      "|    total_timesteps    | 6422528     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010899942 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.327       |\n",
      "|    mean_step_reward   | 0.040739752 |\n",
      "|    n_updates          | 3132        |\n",
      "|    policyGradLoss     | -0.00397    |\n",
      "|    value_loss         | 1.17        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 559          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 366          |\n",
      "|    total_timesteps    | 6430720      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0112762535 |\n",
      "|    entropy_loss       | -2.08        |\n",
      "|    explained_variance | 0.935        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.0108       |\n",
      "|    mean_step_reward   | 0.05577271   |\n",
      "|    n_updates          | 3136         |\n",
      "|    policyGradLoss     | -0.00841     |\n",
      "|    value_loss         | 0.592        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 380         |\n",
      "|    total_timesteps    | 6438912     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012936787 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0413      |\n",
      "|    mean_step_reward   | 0.05988892  |\n",
      "|    n_updates          | 3140        |\n",
      "|    policyGradLoss     | -0.00468    |\n",
      "|    value_loss         | 0.498       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 395         |\n",
      "|    total_timesteps    | 6447104     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011857601 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0092     |\n",
      "|    mean_step_reward   | 0.048961185 |\n",
      "|    n_updates          | 3144        |\n",
      "|    policyGradLoss     | -0.00952    |\n",
      "|    value_loss         | 0.457       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 559         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 409         |\n",
      "|    total_timesteps    | 6455296     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009797527 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0419      |\n",
      "|    mean_step_reward   | 0.049735114 |\n",
      "|    n_updates          | 3148        |\n",
      "|    policyGradLoss     | -0.00873    |\n",
      "|    value_loss         | 0.612       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 559          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 424          |\n",
      "|    total_timesteps    | 6463488      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0087346975 |\n",
      "|    entropy_loss       | -2.07        |\n",
      "|    explained_variance | 0.988        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.209        |\n",
      "|    mean_step_reward   | 0.04025757   |\n",
      "|    n_updates          | 3152         |\n",
      "|    policyGradLoss     | -0.00974     |\n",
      "|    value_loss         | 0.816        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 439         |\n",
      "|    total_timesteps    | 6471680     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.00995675  |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.181       |\n",
      "|    mean_step_reward   | 0.057229005 |\n",
      "|    n_updates          | 3156        |\n",
      "|    policyGradLoss     | -0.00693    |\n",
      "|    value_loss         | 0.873       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 454         |\n",
      "|    total_timesteps    | 6479872     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009698564 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0399      |\n",
      "|    mean_step_reward   | 0.06848022  |\n",
      "|    n_updates          | 3160        |\n",
      "|    policyGradLoss     | -0.009      |\n",
      "|    value_loss         | 0.482       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 558         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 469         |\n",
      "|    total_timesteps    | 6488064     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010064242 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.147       |\n",
      "|    mean_step_reward   | 0.03784546  |\n",
      "|    n_updates          | 3164        |\n",
      "|    policyGradLoss     | -0.00942    |\n",
      "|    value_loss         | 0.614       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 560          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 482          |\n",
      "|    total_timesteps    | 6496256      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0101563465 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.948        |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.0135       |\n",
      "|    mean_step_reward   | 0.04261353   |\n",
      "|    n_updates          | 3168         |\n",
      "|    policyGradLoss     | -0.00123     |\n",
      "|    value_loss         | 0.474        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 496         |\n",
      "|    total_timesteps    | 6504448     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01084443  |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.14        |\n",
      "|    mean_step_reward   | 0.023596196 |\n",
      "|    n_updates          | 3172        |\n",
      "|    policyGradLoss     | -0.00864    |\n",
      "|    value_loss         | 0.509       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 509         |\n",
      "|    total_timesteps    | 6512640     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013965469 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0313     |\n",
      "|    mean_step_reward   | 0.04946778  |\n",
      "|    n_updates          | 3176        |\n",
      "|    policyGradLoss     | -0.00952    |\n",
      "|    value_loss         | 0.266       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 524         |\n",
      "|    total_timesteps    | 6520832     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010854231 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.585       |\n",
      "|    mean_step_reward   | 0.036480717 |\n",
      "|    n_updates          | 3180        |\n",
      "|    policyGradLoss     | -0.00621    |\n",
      "|    value_loss         | 1.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 539         |\n",
      "|    total_timesteps    | 6529024     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011614736 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0369      |\n",
      "|    mean_step_reward   | 0.062062997 |\n",
      "|    n_updates          | 3184        |\n",
      "|    policyGradLoss     | -0.0055     |\n",
      "|    value_loss         | 0.405       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 554         |\n",
      "|    total_timesteps    | 6537216     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018386217 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | -0.0114     |\n",
      "|    mean_step_reward   | 0.07719483  |\n",
      "|    n_updates          | 3188        |\n",
      "|    policyGradLoss     | -0.00842    |\n",
      "|    value_loss         | 0.335       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 561          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 569          |\n",
      "|    total_timesteps    | 6545408      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0123249255 |\n",
      "|    entropy_loss       | -2.07        |\n",
      "|    explained_variance | 0.9          |\n",
      "|    learning_rate      | 0.0002       |\n",
      "|    loss               | 0.0249       |\n",
      "|    mean_step_reward   | 0.080148935  |\n",
      "|    n_updates          | 3192         |\n",
      "|    policyGradLoss     | -0.00962     |\n",
      "|    value_loss         | 0.602        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 584         |\n",
      "|    total_timesteps    | 6553600     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012560589 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0002      |\n",
      "|    loss               | 0.0289      |\n",
      "|    mean_step_reward   | 0.07196534  |\n",
      "|    n_updates          | 3196        |\n",
      "|    policyGradLoss     | -0.01       |\n",
      "|    value_loss         | 0.539       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/SF84G_20.zip\n",
      "[EVAL] Mean Return: 92.080, Best Return: 92.080\n",
      "Saved video to ./runs_smw/videos/step_6553600_mean_92.08.mp4\n",
      "Training finished. Environment closed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntensorboard --logdir=./runs_smw/tb\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mean = -1e18\n",
    "trained = 3276800\n",
    "round_idx = 0\n",
    "\n",
    "try:\n",
    "    while trained < TOTAL_STEPS:\n",
    "        round_idx += 1\n",
    "        chunk = min(TRAIN_CHUNK, TOTAL_STEPS - trained)\n",
    "        # chunk = 2000\n",
    "\n",
    "        print(f\"\\n=== Round {round_idx} | Learn {chunk} steps (Total trained: {trained}) ===\")\n",
    "        \n",
    "        # --- Train ---\n",
    "        model.learn(total_timesteps=chunk, reset_num_timesteps=False, tb_log_name='SF84G_1220_1')\n",
    "        trained += chunk\n",
    "\n",
    "        # --- Save Checkpoint ---\n",
    "        ckpt_path = os.path.join(CKPT_DIR, f\"SF84G_{int(trained/TRAIN_CHUNK)}.zip\")\n",
    "        model.save(ckpt_path)\n",
    "        print(f\"Saved checkpoint: {ckpt_path}\")\n",
    "\n",
    "        # --- Evaluate ---\n",
    "        mean_ret, best_ret = evaluate_policy(\n",
    "            model,\n",
    "            GAME,\n",
    "            STATE,\n",
    "            n_episodes=EVAL_EPISODES,\n",
    "            max_steps=EVAL_MAX_STEPS,\n",
    "        )\n",
    "        print(f\"[EVAL] Mean Return: {mean_ret:.3f}, Best Return: {best_ret:.3f}\")\n",
    "\n",
    "        # --- Save Best Model ---\n",
    "        if mean_ret > best_mean:\n",
    "            best_mean = mean_ret\n",
    "            best_path = os.path.join(LOG_DIR, \"best_model.zip\")\n",
    "            model.save(best_path)\n",
    "            print(f\"New best record. Saved to {best_path}\")\n",
    "\n",
    "        # --- Record Video ---\n",
    "        record_video(\n",
    "            model,\n",
    "            GAME,\n",
    "            STATE,\n",
    "            VIDEO_DIR,\n",
    "            video_len=RECORD_STEPS,\n",
    "            prefix=f\"step_{trained}_mean_{mean_ret:.2f}\",\n",
    "        )\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nTraining interrupted manually.\")\n",
    "\n",
    "finally:\n",
    "    train_env.close()\n",
    "    print(\"Training finished. Environment closed.\")\n",
    "    \n",
    "\"\"\"\n",
    "tensorboard --logdir=./runs_smw/tb\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f088b0b3-2418-4866-b332-0312c9f6467f",
   "metadata": {},
   "source": [
    "## Display Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a73191bb-e875-4939-b04c-a4670abd9612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Video\n",
    "# import glob\n",
    "\n",
    "# list_of_files = glob.glob(os.path.join(VIDEO_DIR, '*.mp4')) \n",
    "# if list_of_files:\n",
    "#     latest_file = max(list_of_files, key=os.path.getctime)\n",
    "#     print(f\"Playing: {latest_file}\")\n",
    "#     display(Video(latest_file, embed=True, width=600))\n",
    "# else:\n",
    "#     print(\"No videos found yet.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lab8 (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
