{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dceedafe-2782-41a1-8119-50ee3d6c21fd",
   "metadata": {},
   "source": [
    "# 2025 DL Lab8: RL Assignment_Super Mario World"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fa555a-e61c-4fb3-b5d0-289b66570139",
   "metadata": {},
   "source": [
    "**Your Answer:**    \n",
    "Hi I'm XXX, XXXXXXXXXX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5b0974-9605-488a-9fd5-00816e7832cc",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This project implements a **Deep Reinforcement Learning** pipeline to train an autonomous agent for Super Mario World. Leveraging the **Proximal Policy Optimization (PPO)** algorithm, the system interacts with the **stable-retro** environment to master the YoshiIsland1 level. Key components include a custom Vision Backbone for extracting features from raw pixel data and a suite of Environment Wrappers that handle frame preprocessing, action discretization, and reward shaping to facilitate efficient learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02696447",
   "metadata": {},
   "source": [
    "Reward function implement  \n",
    "should do something in the beginning (monster attack)  \n",
    "Custom PPO implement  \n",
    "pre train weight Â∑Æ‰∏çÂ§öÔºå‰∏ªË¶ÅÊòØ reward function  \n",
    "model weight capacity 1GB  \n",
    "class name ‰∏çË¶ÅÂãï (ÂèØ‰ª•Êñ∞Â¢ûÔºå‰ΩÜÊòØÂéüÊú¨ÊúâÁöÑ‰∏çË¶ÅÂãï)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8a0ab9-f86d-4038-833d-761ec81fc4f2",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00b10def-362c-4910-9ed0-f3d0904343ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import retro\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "\n",
    "from eval import evaluate_policy, record_video\n",
    "from custom_policy import VisionBackbonePolicy, CustomPPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10361fd-f291-4d93-b50d-cc749a3af588",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b4f6a25-738c-49dd-8e66-ae164b74a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game Settings\n",
    "GAME = \"SuperMarioWorld-Snes\"\n",
    "STATE = \"YoshiIsland1\"\n",
    "\n",
    "# Training Settings\n",
    "# TOTAL_STEPS = 0x1400000 # 20,971,520\n",
    "TOTAL_STEPS = 0x0A00000 # 10,485,760\n",
    "# TOTAL_STEPS = 0X3200000 # 52,428,800\n",
    "TRAIN_CHUNK = 0x0040000 #    262,144\n",
    "N_ENVS = 16\n",
    "\n",
    "# Evaluation & Recording Settings\n",
    "EVAL_EPISODES = 3\n",
    "EVAL_MAX_STEPS = 18000\n",
    "RECORD_STEPS = 1200\n",
    "\n",
    "# Directories\n",
    "LOG_DIR = \"./runs_smw\"\n",
    "VIDEO_DIR       = os.path.join(LOG_DIR, \"videos\")\n",
    "CKPT_DIR        = os.path.join(LOG_DIR, \"checkpoints\")\n",
    "TENSORBOARD_LOG = os.path.join(LOG_DIR, \"tb\")\n",
    "\n",
    "os.makedirs(LOG_DIR,   exist_ok=True)\n",
    "os.makedirs(CKPT_DIR,  exist_ok=True)\n",
    "os.makedirs(VIDEO_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a34b783-0273-4835-ad2e-f9186064f76f",
   "metadata": {},
   "source": [
    "## Environment Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c34213d-2c7c-42b8-922d-bafa285d1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrappers import make_base_env\n",
    "def _make_env_thunk(game: str, state: str):\n",
    "    \"\"\"Return a function that creates an environment (for multiprocessing).\"\"\"\n",
    "    def _thunk():\n",
    "        return make_base_env(game, state)\n",
    "    return _thunk\n",
    "\n",
    "def make_vec_env(game: str, state: str, n_envs: int, use_subproc: bool = True):\n",
    "    \"\"\"Create a vectorized environment (multiple envs running in parallel).\"\"\"\n",
    "    env_fns = [_make_env_thunk(game, state) for _ in range(n_envs)]\n",
    "    \n",
    "    if use_subproc and n_envs > 1:\n",
    "        vec_env = SubprocVecEnv(env_fns)\n",
    "    else:\n",
    "        vec_env = DummyVecEnv(env_fns)\n",
    "\n",
    "    return vec_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dff476-ea2e-4262-8780-afb32ef1b233",
   "metadata": {},
   "source": [
    "## Initialize Env & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c7c5fe-6421-4dbc-9bd8-822d61769c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment created: SuperMarioWorld-Snes - YoshiIsland1 with 16 parallel envs.\n",
      "[Fail] Can't load None. Will use new model\n",
      "Using cuda:0 device\n"
     ]
    }
   ],
   "source": [
    "# 1. Create Training Environment\n",
    "train_env = make_vec_env(GAME, STATE, n_envs=N_ENVS)\n",
    "# train_env = VecNormalize(train_env, norm_obs=True, norm_reward=True, clip_obs=10., clip_reward=10.)\n",
    "print(f\"Environment created: {GAME} - {STATE} with {N_ENVS} parallel envs.\")\n",
    "\n",
    "checkpoint_path = \"None\" # 6225920 (19) ÊúâÁ†¥Â£û\n",
    "# checkpoint_path = \"runs_smw/preserved/Enc5_67.zip\"\n",
    "\n",
    "best_mean = -1e18\n",
    "trained = 0\n",
    "round_idx = 0\n",
    "\n",
    "# 2. Initialize Model\n",
    "if os.path.exists(checkpoint_path):\n",
    "    # ËÆÄÂèñÁèæÊúâÊ®°Âûã\n",
    "    model = CustomPPO.load(\n",
    "        checkpoint_path, \n",
    "        env=train_env,\n",
    "        device=\"cuda:0\" # Á¢∫‰øù‰ΩøÁî® GPU\n",
    "    )\n",
    "    trained = model.num_timesteps\n",
    "    round_idx = int(trained / TRAIN_CHUNK)\n",
    "    print(f\"[Sucess] Loaded model from {checkpoint_path}\")\n",
    "    print(f\"trained: {trained}, round_index: {round_idx}\")\n",
    "else:\n",
    "    print(f\"[Fail] Can't load {checkpoint_path}. Will use new model\")\n",
    "    model = CustomPPO(\n",
    "        VisionBackbonePolicy,\n",
    "        train_env,\n",
    "        policy_kwargs   = dict(normalize_images=False),\n",
    "        n_epochs        = 4,\n",
    "        n_steps         = 512,\n",
    "        batch_size      = 512,\n",
    "        learning_rate   = 1e-4,\n",
    "        verbose         = 1,\n",
    "        gamma           = 0.96875,\n",
    "        kl_coef         = 1,\n",
    "        clip_range      = 0.125,\n",
    "        ent_coef        = 0.0375,\n",
    "        tensorboard_log = TENSORBOARD_LOG,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cb3d0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"policy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eb7a896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from custom_policy import CustomPPO\n",
    "# from wrappers import make_base_env  # [Êñ∞Â¢û] ÂøÖÈ†àÂºïÂÖ•ÈÄôË°å‰æÜÂª∫Á´ãÁí∞Â¢É\n",
    "\n",
    "# # ================= Ë®≠ÂÆöÂçÄ =================\n",
    "# # Ë´ãÁ¢∫‰øùÈÄô‰∫õËÆäÊï∏ÊúâË¢´ÂÆöÁæ© (ÈÄôË£°Ê≤øÁî®‰Ω†ÂéüÊú¨ÁöÑËÆäÊï∏ÂêçÁ®±)\n",
    "# # GAME = \"SuperMarioWorld-Snes\"\n",
    "# # STATE = \"Level1\" \n",
    "# # CKPT_DIR = \"./\"\n",
    "# # RECORD_STEPS = 2000\n",
    "# PSVD_DIR = \"./runs_smw/preserved/\"\n",
    "\n",
    "# # target_numbers = list(range(159, 180))\n",
    "# target_numbers = [27, 28, 59, 63, 67, 124, 137, 147, 151, 179]\n",
    "\n",
    "# # ================= Âü∑Ë°åËø¥Âúà =================\n",
    "# print(f\"Ê∫ñÂÇôÊ∏¨Ë©¶‰ª•‰∏ã Checkpoints: {target_numbers}\")\n",
    "\n",
    "# for num in target_numbers:\n",
    "#     model_path = os.path.join(PSVD_DIR, f\"Enc5_{num}.zip\")\n",
    "    \n",
    "#     # Ê™¢Êü•Ê™îÊ°àÊòØÂê¶Â≠òÂú®\n",
    "#     if not os.path.exists(model_path):\n",
    "#         print(f\"‚ö†Ô∏è Êâæ‰∏çÂà∞Ê™îÊ°à: {model_path}ÔºåË∑≥ÈÅé„ÄÇ\")\n",
    "#         continue\n",
    "    \n",
    "#     print(f\"\\n[{num}] Ê≠£Âú®ËºâÂÖ•Ê®°Âûã: {model_path} ...\")\n",
    "    \n",
    "#     env = None\n",
    "#     try:\n",
    "#         # 1. ËºâÂÖ•Ê®°Âûã\n",
    "#         model = CustomPPO.load(model_path, device=\"auto\")\n",
    "        \n",
    "#         # 2. Âª∫Á´ãÁí∞Â¢É (ÈÄôÂ∞±ÊòØÂéüÊú¨ record_video Ë£°ÂÅöÁöÑ‰∫ãÔºå‰ΩÜÊàëÂÄëÁèæÂú®Ëá™Â∑±ÂÅö)\n",
    "#         env = make_base_env(game=GAME, state=STATE)\n",
    "        \n",
    "#         print(f\"[{num}] Ê≠£Âú®Âü∑Ë°åÈÅäÊà≤ (‰∏äÈôê {RECORD_STEPS} steps)...\")\n",
    "        \n",
    "#         # 3. ÈñãÂßãË©¶Ë∑ë\n",
    "#         obs, info = env.reset()\n",
    "#         final_score = 0\n",
    "        \n",
    "#         for step in range(RECORD_STEPS):\n",
    "#             # È†êÊ∏¨Âãï‰Ωú\n",
    "#             action, _ = model.predict(obs, deterministic=True)\n",
    "            \n",
    "#             # Âü∑Ë°åÂãï‰Ωú\n",
    "#             obs, reward, terminated, truncated, info = env.step(action)\n",
    "            \n",
    "#             # Êõ¥Êñ∞Áï∂ÂâçÂàÜÊï∏ (Â¶ÇÊûúÊúâ score ÁöÑË©±)\n",
    "#             if \"score\" in info:\n",
    "#                 final_score = info[\"score\"]\n",
    "            \n",
    "#             # Âà§Êñ∑ÊòØÂê¶ÁµêÊùü\n",
    "#             if terminated or truncated:\n",
    "#                 print(f\"   -> ÈÅäÊà≤Âú® step {step} ÁµêÊùü (Terminated/Truncated)\")\n",
    "#                 break\n",
    "        \n",
    "#         # 4. Âç∞Âá∫ÁµêÊûú\n",
    "#         print(f\"üèÜ Checkpoint {num} ÊúÄÁµÇÂàÜÊï∏: {final_score}\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå ÁôºÁîüÈåØË™§ (Model: {num}): {e}\")\n",
    "        \n",
    "#     finally:\n",
    "#         # Á¢∫‰øùÁí∞Â¢ÉË¢´ÈóúÈñâÔºåÈáãÊîæË≥áÊ∫ê\n",
    "#         if env is not None:\n",
    "#             env.close()\n",
    "\n",
    "# print(\"\\nÊâÄÊúâÊ∏¨Ë©¶ÁµêÊùü„ÄÇ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f594e443-843f-42c1-9fc6-3fbc82962021",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af4932-c531-4113-a33a-defc6fb5858e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Round 1 | Learn 262144 steps (Total trained: 0) ===\n",
      "Logging to ./runs_smw/tb/S2K_0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1088 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 7    |\n",
      "|    total_timesteps | 8192 |\n",
      "-----------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 923         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 16384       |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005303599 |\n",
      "|    entropy_loss       | -2.3        |\n",
      "|    explained_variance | -0.000722   |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0627     |\n",
      "|    mean_step_reward   | 0.01425518  |\n",
      "|    n_updates          | 4           |\n",
      "|    policyGradLoss     | -0.0111     |\n",
      "|    value_loss         | 0.106       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 871          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 24576        |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0049804654 |\n",
      "|    entropy_loss       | -2.29        |\n",
      "|    explained_variance | 0.274        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0427      |\n",
      "|    mean_step_reward   | 0.019652724  |\n",
      "|    n_updates          | 8            |\n",
      "|    policyGradLoss     | -0.0103      |\n",
      "|    value_loss         | 0.112        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 835          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 39           |\n",
      "|    total_timesteps    | 32768        |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0056944704 |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.47         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0325      |\n",
      "|    mean_step_reward   | 0.02135288   |\n",
      "|    n_updates          | 12           |\n",
      "|    policyGradLoss     | -0.00861     |\n",
      "|    value_loss         | 0.15         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 825          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 49           |\n",
      "|    total_timesteps    | 40960        |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0034707852 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.58         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.00123     |\n",
      "|    mean_step_reward   | 0.029790029  |\n",
      "|    n_updates          | 16           |\n",
      "|    policyGradLoss     | -0.00471     |\n",
      "|    value_loss         | 0.255        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 822          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 59           |\n",
      "|    total_timesteps    | 49152        |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0040122466 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.659        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0141      |\n",
      "|    mean_step_reward   | 0.03230532   |\n",
      "|    n_updates          | 20           |\n",
      "|    policyGradLoss     | -0.00465     |\n",
      "|    value_loss         | 0.28         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 828         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 69          |\n",
      "|    total_timesteps    | 57344       |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004859435 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.735       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0361     |\n",
      "|    mean_step_reward   | 0.035619218 |\n",
      "|    n_updates          | 24          |\n",
      "|    policyGradLoss     | -0.00521    |\n",
      "|    value_loss         | 0.259       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 835          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 78           |\n",
      "|    total_timesteps    | 65536        |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0032273876 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.641        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.198        |\n",
      "|    mean_step_reward   | 0.041347496  |\n",
      "|    n_updates          | 28           |\n",
      "|    policyGradLoss     | -0.0025      |\n",
      "|    value_loss         | 0.478        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 825          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 89           |\n",
      "|    total_timesteps    | 73728        |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027121347 |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.688        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.19         |\n",
      "|    mean_step_reward   | 0.04406523   |\n",
      "|    n_updates          | 32           |\n",
      "|    policyGradLoss     | -0.00239     |\n",
      "|    value_loss         | 0.557        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 820          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 99           |\n",
      "|    total_timesteps    | 81920        |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0012724225 |\n",
      "|    entropy_loss       | -2.09        |\n",
      "|    explained_variance | 0.772        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0883       |\n",
      "|    mean_step_reward   | 0.045610674  |\n",
      "|    n_updates          | 36           |\n",
      "|    policyGradLoss     | -0.00118     |\n",
      "|    value_loss         | 0.405        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 90112       |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.001179348 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.811       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0857      |\n",
      "|    mean_step_reward   | 0.042728636 |\n",
      "|    n_updates          | 40          |\n",
      "|    policyGradLoss     | -0.000751   |\n",
      "|    value_loss         | 0.357       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 817          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 120          |\n",
      "|    total_timesteps    | 98304        |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0014395954 |\n",
      "|    entropy_loss       | -2.07        |\n",
      "|    explained_variance | 0.781        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0244       |\n",
      "|    mean_step_reward   | 0.044788763  |\n",
      "|    n_updates          | 44           |\n",
      "|    policyGradLoss     | -0.00124     |\n",
      "|    value_loss         | 0.398        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 131         |\n",
      "|    total_timesteps    | 106496      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.001171049 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.84        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.125       |\n",
      "|    mean_step_reward   | 0.042090133 |\n",
      "|    n_updates          | 48          |\n",
      "|    policyGradLoss     | -0.00064    |\n",
      "|    value_loss         | 0.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 141         |\n",
      "|    total_timesteps    | 114688      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002477637 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.831       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.11        |\n",
      "|    mean_step_reward   | 0.04683377  |\n",
      "|    n_updates          | 52          |\n",
      "|    policyGradLoss     | -0.0012     |\n",
      "|    value_loss         | 0.347       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 812          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 151          |\n",
      "|    total_timesteps    | 122880       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0005462127 |\n",
      "|    entropy_loss       | -2.05        |\n",
      "|    explained_variance | 0.781        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.115        |\n",
      "|    mean_step_reward   | 0.04898233   |\n",
      "|    n_updates          | 56           |\n",
      "|    policyGradLoss     | -0.000291    |\n",
      "|    value_loss         | 0.478        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 814          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 160          |\n",
      "|    total_timesteps    | 131072       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0012318552 |\n",
      "|    entropy_loss       | -2.04        |\n",
      "|    explained_variance | 0.797        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0578       |\n",
      "|    mean_step_reward   | 0.04528378   |\n",
      "|    n_updates          | 60           |\n",
      "|    policyGradLoss     | -0.00129     |\n",
      "|    value_loss         | 0.334        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 819          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 170          |\n",
      "|    total_timesteps    | 139264       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027694227 |\n",
      "|    entropy_loss       | -2.03        |\n",
      "|    explained_variance | 0.79         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.104        |\n",
      "|    mean_step_reward   | 0.048874334  |\n",
      "|    n_updates          | 64           |\n",
      "|    policyGradLoss     | -0.00199     |\n",
      "|    value_loss         | 0.449        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 816           |\n",
      "|    iterations         | 18            |\n",
      "|    time_elapsed       | 180           |\n",
      "|    total_timesteps    | 147456        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.00084357016 |\n",
      "|    entropy_loss       | -2.04         |\n",
      "|    explained_variance | 0.849         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.0255        |\n",
      "|    mean_step_reward   | 0.04778215    |\n",
      "|    n_updates          | 68            |\n",
      "|    policyGradLoss     | -0.00019      |\n",
      "|    value_loss         | 0.362         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 155648      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.001214491 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.841       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0504      |\n",
      "|    mean_step_reward   | 0.046080157 |\n",
      "|    n_updates          | 72          |\n",
      "|    policyGradLoss     | -0.000616   |\n",
      "|    value_loss         | 0.33        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 812          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 201          |\n",
      "|    total_timesteps    | 163840       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0039267475 |\n",
      "|    entropy_loss       | -2.07        |\n",
      "|    explained_variance | 0.821        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.117        |\n",
      "|    mean_step_reward   | 0.048203286  |\n",
      "|    n_updates          | 76           |\n",
      "|    policyGradLoss     | -0.000536    |\n",
      "|    value_loss         | 0.344        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 812          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 211          |\n",
      "|    total_timesteps    | 172032       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0003192377 |\n",
      "|    entropy_loss       | -2.09        |\n",
      "|    explained_variance | 0.768        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.137        |\n",
      "|    mean_step_reward   | 0.056001917  |\n",
      "|    n_updates          | 80           |\n",
      "|    policyGradLoss     | -0.000188    |\n",
      "|    value_loss         | 0.604        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 811          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 222          |\n",
      "|    total_timesteps    | 180224       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0019239084 |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.826        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.000162     |\n",
      "|    mean_step_reward   | 0.046343803  |\n",
      "|    n_updates          | 84           |\n",
      "|    policyGradLoss     | -0.000945    |\n",
      "|    value_loss         | 0.319        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 188416      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.001344179 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.827       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.106       |\n",
      "|    mean_step_reward   | 0.04517141  |\n",
      "|    n_updates          | 88          |\n",
      "|    policyGradLoss     | -0.0021     |\n",
      "|    value_loss         | 0.401       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 807          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 243          |\n",
      "|    total_timesteps    | 196608       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0018102219 |\n",
      "|    entropy_loss       | -2.07        |\n",
      "|    explained_variance | 0.838        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0306       |\n",
      "|    mean_step_reward   | 0.04957165   |\n",
      "|    n_updates          | 92           |\n",
      "|    policyGradLoss     | -0.00186     |\n",
      "|    value_loss         | 0.313        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 807          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 253          |\n",
      "|    total_timesteps    | 204800       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0016412653 |\n",
      "|    entropy_loss       | -2.09        |\n",
      "|    explained_variance | 0.865        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.047        |\n",
      "|    mean_step_reward   | 0.04476665   |\n",
      "|    n_updates          | 96           |\n",
      "|    policyGradLoss     | -0.000391    |\n",
      "|    value_loss         | 0.254        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 813          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 261          |\n",
      "|    total_timesteps    | 212992       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0007877527 |\n",
      "|    entropy_loss       | -2.08        |\n",
      "|    explained_variance | 0.857        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0366       |\n",
      "|    mean_step_reward   | 0.047761843  |\n",
      "|    n_updates          | 100          |\n",
      "|    policyGradLoss     | -0.000825    |\n",
      "|    value_loss         | 0.322        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 812          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 272          |\n",
      "|    total_timesteps    | 221184       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0020788556 |\n",
      "|    entropy_loss       | -2.06        |\n",
      "|    explained_variance | 0.813        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.143        |\n",
      "|    mean_step_reward   | 0.051984258  |\n",
      "|    n_updates          | 104          |\n",
      "|    policyGradLoss     | -0.00228     |\n",
      "|    value_loss         | 0.441        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 229376      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.001685527 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.854       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00271     |\n",
      "|    mean_step_reward   | 0.048874326 |\n",
      "|    n_updates          | 108         |\n",
      "|    policyGradLoss     | -0.000721   |\n",
      "|    value_loss         | 0.297       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 811          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 292          |\n",
      "|    total_timesteps    | 237568       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026911467 |\n",
      "|    entropy_loss       | -2.08        |\n",
      "|    explained_variance | 0.773        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0866       |\n",
      "|    mean_step_reward   | 0.053987525  |\n",
      "|    n_updates          | 112          |\n",
      "|    policyGradLoss     | -0.00111     |\n",
      "|    value_loss         | 0.472        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 810          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 303          |\n",
      "|    total_timesteps    | 245760       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0015943287 |\n",
      "|    entropy_loss       | -2.08        |\n",
      "|    explained_variance | 0.857        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0244       |\n",
      "|    mean_step_reward   | 0.045673408  |\n",
      "|    n_updates          | 116          |\n",
      "|    policyGradLoss     | -0.00176     |\n",
      "|    value_loss         | 0.296        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 314         |\n",
      "|    total_timesteps    | 253952      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003382245 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.907       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.000306    |\n",
      "|    mean_step_reward   | 0.044195622 |\n",
      "|    n_updates          | 120         |\n",
      "|    policyGradLoss     | -0.00253    |\n",
      "|    value_loss         | 0.152       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 807          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 324          |\n",
      "|    total_timesteps    | 262144       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0011116529 |\n",
      "|    entropy_loss       | -2.09        |\n",
      "|    explained_variance | 0.848        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0508       |\n",
      "|    mean_step_reward   | 0.04634437   |\n",
      "|    n_updates          | 124          |\n",
      "|    policyGradLoss     | -0.000861    |\n",
      "|    value_loss         | 0.258        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/S2K_0.zip\n",
      "[EVAL] Mean Return: -0.271, Best Return: -0.271\n",
      "Saved video to ./runs_smw/videos/S2K/S2K_0_-0.27.mp4\n",
      "\n",
      "=== Round 2 | Learn 262144 steps (Total trained: 262144) ===\n",
      "Logging to ./runs_smw/tb/S2K_0\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1408   |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 5      |\n",
      "|    total_timesteps | 270336 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 1105         |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 14           |\n",
      "|    total_timesteps    | 278528       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0014179387 |\n",
      "|    entropy_loss       | -2.05        |\n",
      "|    explained_variance | 0.833        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.123        |\n",
      "|    mean_step_reward   | 0.05143325   |\n",
      "|    n_updates          | 132          |\n",
      "|    policyGradLoss     | -0.0017      |\n",
      "|    value_loss         | 0.309        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 984          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 24           |\n",
      "|    total_timesteps    | 286720       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0021460464 |\n",
      "|    entropy_loss       | -2.06        |\n",
      "|    explained_variance | 0.805        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0615       |\n",
      "|    mean_step_reward   | 0.05454604   |\n",
      "|    n_updates          | 136          |\n",
      "|    policyGradLoss     | -0.000499    |\n",
      "|    value_loss         | 0.418        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 922          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 35           |\n",
      "|    total_timesteps    | 294912       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0011295432 |\n",
      "|    entropy_loss       | -2.08        |\n",
      "|    explained_variance | 0.865        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0334       |\n",
      "|    mean_step_reward   | 0.045583345  |\n",
      "|    n_updates          | 140          |\n",
      "|    policyGradLoss     | -0.000277    |\n",
      "|    value_loss         | 0.282        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 882          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 46           |\n",
      "|    total_timesteps    | 303104       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0011950632 |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.854        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0428       |\n",
      "|    mean_step_reward   | 0.04946534   |\n",
      "|    n_updates          | 144          |\n",
      "|    policyGradLoss     | -0.000772    |\n",
      "|    value_loss         | 0.382        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 863           |\n",
      "|    iterations         | 6             |\n",
      "|    time_elapsed       | 56            |\n",
      "|    total_timesteps    | 311296        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.00048890215 |\n",
      "|    entropy_loss       | -2.08         |\n",
      "|    explained_variance | 0.825         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.0914        |\n",
      "|    mean_step_reward   | 0.053167015   |\n",
      "|    n_updates          | 148           |\n",
      "|    policyGradLoss     | -0.000941     |\n",
      "|    value_loss         | 0.346         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 853           |\n",
      "|    iterations         | 7             |\n",
      "|    time_elapsed       | 67            |\n",
      "|    total_timesteps    | 319488        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.00084486656 |\n",
      "|    entropy_loss       | -2.07         |\n",
      "|    explained_variance | 0.867         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.0789        |\n",
      "|    mean_step_reward   | 0.048512105   |\n",
      "|    n_updates          | 152           |\n",
      "|    policyGradLoss     | -0.00085      |\n",
      "|    value_loss         | 0.293         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 845          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 77           |\n",
      "|    total_timesteps    | 327680       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0022733747 |\n",
      "|    entropy_loss       | -2.07        |\n",
      "|    explained_variance | 0.89         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0368      |\n",
      "|    mean_step_reward   | 0.04273154   |\n",
      "|    n_updates          | 156          |\n",
      "|    policyGradLoss     | -0.00198     |\n",
      "|    value_loss         | 0.177        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 832          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 88           |\n",
      "|    total_timesteps    | 335872       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0019934059 |\n",
      "|    entropy_loss       | -2.08        |\n",
      "|    explained_variance | 0.82         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0578       |\n",
      "|    mean_step_reward   | 0.059512883  |\n",
      "|    n_updates          | 160          |\n",
      "|    policyGradLoss     | -0.000144    |\n",
      "|    value_loss         | 0.384        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 831         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 344064      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002099298 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.88        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00112    |\n",
      "|    mean_step_reward   | 0.046324667 |\n",
      "|    n_updates          | 164         |\n",
      "|    policyGradLoss     | -0.00176    |\n",
      "|    value_loss         | 0.261       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 843          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 106          |\n",
      "|    total_timesteps    | 352256       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0009971883 |\n",
      "|    entropy_loss       | -2.07        |\n",
      "|    explained_variance | 0.833        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.064        |\n",
      "|    mean_step_reward   | 0.054060902  |\n",
      "|    n_updates          | 168          |\n",
      "|    policyGradLoss     | -0.00158     |\n",
      "|    value_loss         | 0.401        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 850           |\n",
      "|    iterations         | 12            |\n",
      "|    time_elapsed       | 115           |\n",
      "|    total_timesteps    | 360448        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.00094965077 |\n",
      "|    entropy_loss       | -2.09         |\n",
      "|    explained_variance | 0.807         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.343         |\n",
      "|    mean_step_reward   | 0.05541811    |\n",
      "|    n_updates          | 172           |\n",
      "|    policyGradLoss     | -0.000457     |\n",
      "|    value_loss         | 0.537         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 855         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 368640      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002991177 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.552       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.357       |\n",
      "|    mean_step_reward   | 0.06677503  |\n",
      "|    n_updates          | 176         |\n",
      "|    policyGradLoss     | 0.00109     |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 850          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 134          |\n",
      "|    total_timesteps    | 376832       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0010635396 |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.806        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.00382     |\n",
      "|    mean_step_reward   | 0.047092088  |\n",
      "|    n_updates          | 180          |\n",
      "|    policyGradLoss     | -0.00115     |\n",
      "|    value_loss         | 0.353        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 842          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 145          |\n",
      "|    total_timesteps    | 385024       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0007973056 |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.842        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.162        |\n",
      "|    mean_step_reward   | 0.048150707  |\n",
      "|    n_updates          | 184          |\n",
      "|    policyGradLoss     | -0.00118     |\n",
      "|    value_loss         | 0.38         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 839          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 156          |\n",
      "|    total_timesteps    | 393216       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0016534664 |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.877        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0159       |\n",
      "|    mean_step_reward   | 0.045996986  |\n",
      "|    n_updates          | 188          |\n",
      "|    policyGradLoss     | -0.000781    |\n",
      "|    value_loss         | 0.239        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 838          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 166          |\n",
      "|    total_timesteps    | 401408       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0013224988 |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.878        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0557       |\n",
      "|    mean_step_reward   | 0.050558798  |\n",
      "|    n_updates          | 192          |\n",
      "|    policyGradLoss     | -0.000927    |\n",
      "|    value_loss         | 0.282        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 834          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 176          |\n",
      "|    total_timesteps    | 409600       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0018744222 |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.805        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0121       |\n",
      "|    mean_step_reward   | 0.054046992  |\n",
      "|    n_updates          | 196          |\n",
      "|    policyGradLoss     | -0.00133     |\n",
      "|    value_loss         | 0.308        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 829          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 187          |\n",
      "|    total_timesteps    | 417792       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0022414008 |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.829        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0435       |\n",
      "|    mean_step_reward   | 0.05653084   |\n",
      "|    n_updates          | 200          |\n",
      "|    policyGradLoss     | -0.00197     |\n",
      "|    value_loss         | 0.359        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 826          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 198          |\n",
      "|    total_timesteps    | 425984       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0010446399 |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.764        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0983       |\n",
      "|    mean_step_reward   | 0.05767303   |\n",
      "|    n_updates          | 204          |\n",
      "|    policyGradLoss     | -0.0011      |\n",
      "|    value_loss         | 0.639        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 825          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 208          |\n",
      "|    total_timesteps    | 434176       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0011599419 |\n",
      "|    entropy_loss       | -2.09        |\n",
      "|    explained_variance | 0.829        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0252       |\n",
      "|    mean_step_reward   | 0.056656003  |\n",
      "|    n_updates          | 208          |\n",
      "|    policyGradLoss     | -0.00153     |\n",
      "|    value_loss         | 0.367        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 831          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 216          |\n",
      "|    total_timesteps    | 442368       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0013307615 |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.83         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.112        |\n",
      "|    mean_step_reward   | 0.048522517  |\n",
      "|    n_updates          | 212          |\n",
      "|    policyGradLoss     | -0.00103     |\n",
      "|    value_loss         | 0.417        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 832          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 226          |\n",
      "|    total_timesteps    | 450560       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0012445091 |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.83         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0805       |\n",
      "|    mean_step_reward   | 0.054457054  |\n",
      "|    n_updates          | 216          |\n",
      "|    policyGradLoss     | -0.00226     |\n",
      "|    value_loss         | 0.412        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 831          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 236          |\n",
      "|    total_timesteps    | 458752       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0011054109 |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.793        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0585       |\n",
      "|    mean_step_reward   | 0.055066235  |\n",
      "|    n_updates          | 220          |\n",
      "|    policyGradLoss     | -0.000724    |\n",
      "|    value_loss         | 0.426        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 830          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 246          |\n",
      "|    total_timesteps    | 466944       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0009880785 |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.778        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.137        |\n",
      "|    mean_step_reward   | 0.053693376  |\n",
      "|    n_updates          | 224          |\n",
      "|    policyGradLoss     | -0.000857    |\n",
      "|    value_loss         | 0.613        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 828          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 257          |\n",
      "|    total_timesteps    | 475136       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025059665 |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.852        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0108       |\n",
      "|    mean_step_reward   | 0.048125565  |\n",
      "|    n_updates          | 228          |\n",
      "|    policyGradLoss     | -0.00156     |\n",
      "|    value_loss         | 0.276        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 825          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 267          |\n",
      "|    total_timesteps    | 483328       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0010626523 |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.841        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.112        |\n",
      "|    mean_step_reward   | 0.057098232  |\n",
      "|    n_updates          | 232          |\n",
      "|    policyGradLoss     | -0.00178     |\n",
      "|    value_loss         | 0.499        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 823          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 278          |\n",
      "|    total_timesteps    | 491520       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0019999123 |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.871        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0362       |\n",
      "|    mean_step_reward   | 0.05272145   |\n",
      "|    n_updates          | 236          |\n",
      "|    policyGradLoss     | -0.00122     |\n",
      "|    value_loss         | 0.366        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 822          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 288          |\n",
      "|    total_timesteps    | 499712       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0009994739 |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.761        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.116        |\n",
      "|    mean_step_reward   | 0.05503923   |\n",
      "|    n_updates          | 240          |\n",
      "|    policyGradLoss     | -0.00138     |\n",
      "|    value_loss         | 0.585        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 299         |\n",
      "|    total_timesteps    | 507904      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.001877537 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.856       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00286     |\n",
      "|    mean_step_reward   | 0.047762018 |\n",
      "|    n_updates          | 244         |\n",
      "|    policyGradLoss     | -0.00198    |\n",
      "|    value_loss         | 0.278       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 822          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 308          |\n",
      "|    total_timesteps    | 516096       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0031090812 |\n",
      "|    entropy_loss       | -2.09        |\n",
      "|    explained_variance | 0.844        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0874       |\n",
      "|    mean_step_reward   | 0.061661363  |\n",
      "|    n_updates          | 248          |\n",
      "|    policyGradLoss     | -0.00254     |\n",
      "|    value_loss         | 0.461        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 826          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 317          |\n",
      "|    total_timesteps    | 524288       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0016749068 |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.878        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0551       |\n",
      "|    mean_step_reward   | 0.0495992    |\n",
      "|    n_updates          | 252          |\n",
      "|    policyGradLoss     | -0.00232     |\n",
      "|    value_loss         | 0.279        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/S2K_1.zip\n",
      "[EVAL] Mean Return: -0.294, Best Return: -0.294\n",
      "Saved video to ./runs_smw/videos/S2K/S2K_1_-0.29.mp4\n",
      "\n",
      "=== Round 3 | Learn 262144 steps (Total trained: 524288) ===\n",
      "Logging to ./runs_smw/tb/S2K_0\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1100   |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 7      |\n",
      "|    total_timesteps | 532480 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 914          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 540672       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026106616 |\n",
      "|    entropy_loss       | -2.08        |\n",
      "|    explained_variance | 0.854        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.102        |\n",
      "|    mean_step_reward   | 0.055601932  |\n",
      "|    n_updates          | 260          |\n",
      "|    policyGradLoss     | -0.00223     |\n",
      "|    value_loss         | 0.451        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 872          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 548864       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0014843307 |\n",
      "|    entropy_loss       | -2.08        |\n",
      "|    explained_variance | 0.812        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.254        |\n",
      "|    mean_step_reward   | 0.05853116   |\n",
      "|    n_updates          | 264          |\n",
      "|    policyGradLoss     | -0.00102     |\n",
      "|    value_loss         | 0.609        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 841          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 38           |\n",
      "|    total_timesteps    | 557056       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026491615 |\n",
      "|    entropy_loss       | -2.07        |\n",
      "|    explained_variance | 0.818        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0632       |\n",
      "|    mean_step_reward   | 0.05645502   |\n",
      "|    n_updates          | 268          |\n",
      "|    policyGradLoss     | -0.000908    |\n",
      "|    value_loss         | 0.378        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 824          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 49           |\n",
      "|    total_timesteps    | 565248       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023014294 |\n",
      "|    entropy_loss       | -2.09        |\n",
      "|    explained_variance | 0.824        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.124        |\n",
      "|    mean_step_reward   | 0.051930882  |\n",
      "|    n_updates          | 272          |\n",
      "|    policyGradLoss     | -0.00189     |\n",
      "|    value_loss         | 0.395        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 819          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 59           |\n",
      "|    total_timesteps    | 573440       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027986742 |\n",
      "|    entropy_loss       | -2.09        |\n",
      "|    explained_variance | 0.869        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0256       |\n",
      "|    mean_step_reward   | 0.053218555  |\n",
      "|    n_updates          | 276          |\n",
      "|    policyGradLoss     | -0.00131     |\n",
      "|    value_loss         | 0.313        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 826          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 69           |\n",
      "|    total_timesteps    | 581632       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0010365172 |\n",
      "|    entropy_loss       | -2.07        |\n",
      "|    explained_variance | 0.797        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.4          |\n",
      "|    mean_step_reward   | 0.06592631   |\n",
      "|    n_updates          | 280          |\n",
      "|    policyGradLoss     | -0.000922    |\n",
      "|    value_loss         | 0.781        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 819          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 79           |\n",
      "|    total_timesteps    | 589824       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0019111107 |\n",
      "|    entropy_loss       | -2.09        |\n",
      "|    explained_variance | 0.869        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0862       |\n",
      "|    mean_step_reward   | 0.05291797   |\n",
      "|    n_updates          | 284          |\n",
      "|    policyGradLoss     | -0.00334     |\n",
      "|    value_loss         | 0.34         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 819          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 89           |\n",
      "|    total_timesteps    | 598016       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0014320742 |\n",
      "|    entropy_loss       | -2.08        |\n",
      "|    explained_variance | 0.711        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.589        |\n",
      "|    mean_step_reward   | 0.061897755  |\n",
      "|    n_updates          | 288          |\n",
      "|    policyGradLoss     | -0.00101     |\n",
      "|    value_loss         | 1.19         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 816          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 100          |\n",
      "|    total_timesteps    | 606208       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0014758941 |\n",
      "|    entropy_loss       | -2.09        |\n",
      "|    explained_variance | 0.81         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.182        |\n",
      "|    mean_step_reward   | 0.05972777   |\n",
      "|    n_updates          | 292          |\n",
      "|    policyGradLoss     | -0.00215     |\n",
      "|    value_loss         | 0.637        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 811          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 111          |\n",
      "|    total_timesteps    | 614400       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0012826405 |\n",
      "|    entropy_loss       | -2.09        |\n",
      "|    explained_variance | 0.788        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0779       |\n",
      "|    mean_step_reward   | 0.057448283  |\n",
      "|    n_updates          | 296          |\n",
      "|    policyGradLoss     | -0.00203     |\n",
      "|    value_loss         | 0.614        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 806          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 121          |\n",
      "|    total_timesteps    | 622592       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0015071516 |\n",
      "|    entropy_loss       | -2.08        |\n",
      "|    explained_variance | 0.784        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0801       |\n",
      "|    mean_step_reward   | 0.055016175  |\n",
      "|    n_updates          | 300          |\n",
      "|    policyGradLoss     | -0.00125     |\n",
      "|    value_loss         | 0.47         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 804          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 132          |\n",
      "|    total_timesteps    | 630784       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0012447089 |\n",
      "|    entropy_loss       | -2.05        |\n",
      "|    explained_variance | 0.815        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.153        |\n",
      "|    mean_step_reward   | 0.060650084  |\n",
      "|    n_updates          | 304          |\n",
      "|    policyGradLoss     | -0.00187     |\n",
      "|    value_loss         | 0.619        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 804          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 142          |\n",
      "|    total_timesteps    | 638976       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0020355938 |\n",
      "|    entropy_loss       | -2.07        |\n",
      "|    explained_variance | 0.823        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.358        |\n",
      "|    mean_step_reward   | 0.060091548  |\n",
      "|    n_updates          | 308          |\n",
      "|    policyGradLoss     | -0.00117     |\n",
      "|    value_loss         | 0.633        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 152         |\n",
      "|    total_timesteps    | 647168      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.001675636 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.851       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0751      |\n",
      "|    mean_step_reward   | 0.05840882  |\n",
      "|    n_updates          | 312         |\n",
      "|    policyGradLoss     | -0.00179    |\n",
      "|    value_loss         | 0.458       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 806          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 162          |\n",
      "|    total_timesteps    | 655360       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0015829739 |\n",
      "|    entropy_loss       | -2.08        |\n",
      "|    explained_variance | 0.815        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.182        |\n",
      "|    mean_step_reward   | 0.06890154   |\n",
      "|    n_updates          | 316          |\n",
      "|    policyGradLoss     | -0.00158     |\n",
      "|    value_loss         | 0.697        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 806          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 172          |\n",
      "|    total_timesteps    | 663552       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0014263572 |\n",
      "|    entropy_loss       | -2.07        |\n",
      "|    explained_variance | 0.823        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.169        |\n",
      "|    mean_step_reward   | 0.06270757   |\n",
      "|    n_updates          | 320          |\n",
      "|    policyGradLoss     | -0.00153     |\n",
      "|    value_loss         | 0.573        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 804          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 183          |\n",
      "|    total_timesteps    | 671744       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0017230825 |\n",
      "|    entropy_loss       | -2.07        |\n",
      "|    explained_variance | 0.824        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0967       |\n",
      "|    mean_step_reward   | 0.067285374  |\n",
      "|    n_updates          | 324          |\n",
      "|    policyGradLoss     | -0.00164     |\n",
      "|    value_loss         | 0.589        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 801          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 194          |\n",
      "|    total_timesteps    | 679936       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0019811145 |\n",
      "|    entropy_loss       | -2.06        |\n",
      "|    explained_variance | 0.771        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.13         |\n",
      "|    mean_step_reward   | 0.05553748   |\n",
      "|    n_updates          | 328          |\n",
      "|    policyGradLoss     | -0.00211     |\n",
      "|    value_loss         | 0.54         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 800          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 204          |\n",
      "|    total_timesteps    | 688128       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0015890194 |\n",
      "|    entropy_loss       | -2.06        |\n",
      "|    explained_variance | 0.784        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.186        |\n",
      "|    mean_step_reward   | 0.06517765   |\n",
      "|    n_updates          | 332          |\n",
      "|    policyGradLoss     | -0.00174     |\n",
      "|    value_loss         | 0.676        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 799          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 215          |\n",
      "|    total_timesteps    | 696320       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0016057504 |\n",
      "|    entropy_loss       | -2.07        |\n",
      "|    explained_variance | 0.842        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0678       |\n",
      "|    mean_step_reward   | 0.059101157  |\n",
      "|    n_updates          | 336          |\n",
      "|    policyGradLoss     | -0.00221     |\n",
      "|    value_loss         | 0.486        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 798          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 225          |\n",
      "|    total_timesteps    | 704512       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030856598 |\n",
      "|    entropy_loss       | -2.07        |\n",
      "|    explained_variance | 0.833        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.177        |\n",
      "|    mean_step_reward   | 0.060173266  |\n",
      "|    n_updates          | 340          |\n",
      "|    policyGradLoss     | -0.00162     |\n",
      "|    value_loss         | 0.528        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 797          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 236          |\n",
      "|    total_timesteps    | 712704       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0014487833 |\n",
      "|    entropy_loss       | -2.04        |\n",
      "|    explained_variance | 0.814        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.221        |\n",
      "|    mean_step_reward   | 0.07334082   |\n",
      "|    n_updates          | 344          |\n",
      "|    policyGradLoss     | -0.00169     |\n",
      "|    value_loss         | 0.716        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 803          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 244          |\n",
      "|    total_timesteps    | 720896       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0016629333 |\n",
      "|    entropy_loss       | -2.04        |\n",
      "|    explained_variance | 0.825        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0987       |\n",
      "|    mean_step_reward   | 0.06064041   |\n",
      "|    n_updates          | 348          |\n",
      "|    policyGradLoss     | -0.00278     |\n",
      "|    value_loss         | 0.543        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 807          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 253          |\n",
      "|    total_timesteps    | 729088       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0032823596 |\n",
      "|    entropy_loss       | -2.06        |\n",
      "|    explained_variance | 0.854        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0455       |\n",
      "|    mean_step_reward   | 0.058688194  |\n",
      "|    n_updates          | 352          |\n",
      "|    policyGradLoss     | -0.00296     |\n",
      "|    value_loss         | 0.442        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 737280      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002332238 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.768       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.135       |\n",
      "|    mean_step_reward   | 0.058002412 |\n",
      "|    n_updates          | 356         |\n",
      "|    policyGradLoss     | -0.00408    |\n",
      "|    value_loss         | 0.688       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 809          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 273          |\n",
      "|    total_timesteps    | 745472       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023652536 |\n",
      "|    entropy_loss       | -2.08        |\n",
      "|    explained_variance | 0.849        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.134        |\n",
      "|    mean_step_reward   | 0.06129846   |\n",
      "|    n_updates          | 360          |\n",
      "|    policyGradLoss     | -0.00261     |\n",
      "|    value_loss         | 0.61         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 809          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 283          |\n",
      "|    total_timesteps    | 753664       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0029779137 |\n",
      "|    entropy_loss       | -2.08        |\n",
      "|    explained_variance | 0.843        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.179        |\n",
      "|    mean_step_reward   | 0.06897081   |\n",
      "|    n_updates          | 364          |\n",
      "|    policyGradLoss     | -0.00233     |\n",
      "|    value_loss         | 0.607        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 808          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 293          |\n",
      "|    total_timesteps    | 761856       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025394862 |\n",
      "|    entropy_loss       | -2.03        |\n",
      "|    explained_variance | 0.833        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.189        |\n",
      "|    mean_step_reward   | 0.07052073   |\n",
      "|    n_updates          | 368          |\n",
      "|    policyGradLoss     | -0.00459     |\n",
      "|    value_loss         | 0.67         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 806          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 304          |\n",
      "|    total_timesteps    | 770048       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025049185 |\n",
      "|    entropy_loss       | -2.05        |\n",
      "|    explained_variance | 0.768        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.183        |\n",
      "|    mean_step_reward   | 0.065606505  |\n",
      "|    n_updates          | 372          |\n",
      "|    policyGradLoss     | -0.00332     |\n",
      "|    value_loss         | 0.679        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 805          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 315          |\n",
      "|    total_timesteps    | 778240       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0031903177 |\n",
      "|    entropy_loss       | -2.06        |\n",
      "|    explained_variance | 0.849        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0791       |\n",
      "|    mean_step_reward   | 0.061651006  |\n",
      "|    n_updates          | 376          |\n",
      "|    policyGradLoss     | -0.00286     |\n",
      "|    value_loss         | 0.536        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 799          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 327          |\n",
      "|    total_timesteps    | 786432       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0019918303 |\n",
      "|    entropy_loss       | -2.07        |\n",
      "|    explained_variance | 0.811        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.16         |\n",
      "|    mean_step_reward   | 0.067858554  |\n",
      "|    n_updates          | 380          |\n",
      "|    policyGradLoss     | -0.00266     |\n",
      "|    value_loss         | 0.609        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/S2K_2.zip\n",
      "[EVAL] Mean Return: -0.281, Best Return: -0.281\n",
      "Saved video to ./runs_smw/videos/S2K/S2K_2_-0.28.mp4\n",
      "\n",
      "=== Round 4 | Learn 262144 steps (Total trained: 786432) ===\n",
      "Logging to ./runs_smw/tb/S2K_0\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1577   |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 5      |\n",
      "|    total_timesteps | 794624 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 1142         |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 14           |\n",
      "|    total_timesteps    | 802816       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023017398 |\n",
      "|    entropy_loss       | -2.06        |\n",
      "|    explained_variance | 0.806        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.111        |\n",
      "|    mean_step_reward   | 0.07227081   |\n",
      "|    n_updates          | 388          |\n",
      "|    policyGradLoss     | -0.0035      |\n",
      "|    value_loss         | 0.758        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 968        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 25         |\n",
      "|    total_timesteps    | 811008     |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00262657 |\n",
      "|    entropy_loss       | -2.07      |\n",
      "|    explained_variance | 0.852      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.201      |\n",
      "|    mean_step_reward   | 0.07256843 |\n",
      "|    n_updates          | 392        |\n",
      "|    policyGradLoss     | -0.00303   |\n",
      "|    value_loss         | 0.673      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 913          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 35           |\n",
      "|    total_timesteps    | 819200       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0032091495 |\n",
      "|    entropy_loss       | -2.07        |\n",
      "|    explained_variance | 0.863        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.199        |\n",
      "|    mean_step_reward   | 0.073493555  |\n",
      "|    n_updates          | 396          |\n",
      "|    policyGradLoss     | -0.00287     |\n",
      "|    value_loss         | 0.615        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 893         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 45          |\n",
      "|    total_timesteps    | 827392      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002312704 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.812       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.25        |\n",
      "|    mean_step_reward   | 0.0795311   |\n",
      "|    n_updates          | 400         |\n",
      "|    policyGradLoss     | -0.00367    |\n",
      "|    value_loss         | 0.941       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 875          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 56           |\n",
      "|    total_timesteps    | 835584       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0031967773 |\n",
      "|    entropy_loss       | -2.06        |\n",
      "|    explained_variance | 0.847        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.213        |\n",
      "|    mean_step_reward   | 0.07685433   |\n",
      "|    n_updates          | 404          |\n",
      "|    policyGradLoss     | -0.00334     |\n",
      "|    value_loss         | 0.798        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 854         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 67          |\n",
      "|    total_timesteps    | 843776      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002403217 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.822       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.235       |\n",
      "|    mean_step_reward   | 0.076266795 |\n",
      "|    n_updates          | 408         |\n",
      "|    policyGradLoss     | -0.00344    |\n",
      "|    value_loss         | 0.814       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 842          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 77           |\n",
      "|    total_timesteps    | 851968       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026837196 |\n",
      "|    entropy_loss       | -2.06        |\n",
      "|    explained_variance | 0.848        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.168        |\n",
      "|    mean_step_reward   | 0.069542155  |\n",
      "|    n_updates          | 412          |\n",
      "|    policyGradLoss     | -0.00332     |\n",
      "|    value_loss         | 0.634        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 836          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 88           |\n",
      "|    total_timesteps    | 860160       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0021257603 |\n",
      "|    entropy_loss       | -2.08        |\n",
      "|    explained_variance | 0.867        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0789       |\n",
      "|    mean_step_reward   | 0.060927935  |\n",
      "|    n_updates          | 416          |\n",
      "|    policyGradLoss     | -0.00349     |\n",
      "|    value_loss         | 0.519        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 841         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 868352      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002220393 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.849       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.214       |\n",
      "|    mean_step_reward   | 0.07424738  |\n",
      "|    n_updates          | 420         |\n",
      "|    policyGradLoss     | -0.00297    |\n",
      "|    value_loss         | 0.743       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 837          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 107          |\n",
      "|    total_timesteps    | 876544       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0021196578 |\n",
      "|    entropy_loss       | -2.04        |\n",
      "|    explained_variance | 0.845        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.262        |\n",
      "|    mean_step_reward   | 0.081935525  |\n",
      "|    n_updates          | 424          |\n",
      "|    policyGradLoss     | -0.00378     |\n",
      "|    value_loss         | 0.842        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 836         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 117         |\n",
      "|    total_timesteps    | 884736      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002918615 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.838       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.173       |\n",
      "|    mean_step_reward   | 0.06811923  |\n",
      "|    n_updates          | 428         |\n",
      "|    policyGradLoss     | -0.00397    |\n",
      "|    value_loss         | 0.731       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 832          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 127          |\n",
      "|    total_timesteps    | 892928       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035972148 |\n",
      "|    entropy_loss       | -2.03        |\n",
      "|    explained_variance | 0.82         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.175        |\n",
      "|    mean_step_reward   | 0.07000174   |\n",
      "|    n_updates          | 432          |\n",
      "|    policyGradLoss     | -0.00424     |\n",
      "|    value_loss         | 0.666        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 825          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 138          |\n",
      "|    total_timesteps    | 901120       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0032107825 |\n",
      "|    entropy_loss       | -2.05        |\n",
      "|    explained_variance | 0.834        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.157        |\n",
      "|    mean_step_reward   | 0.071892336  |\n",
      "|    n_updates          | 436          |\n",
      "|    policyGradLoss     | -0.00361     |\n",
      "|    value_loss         | 0.631        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 149         |\n",
      "|    total_timesteps    | 909312      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003988653 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.814       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.264       |\n",
      "|    mean_step_reward   | 0.08461261  |\n",
      "|    n_updates          | 440         |\n",
      "|    policyGradLoss     | -0.00425    |\n",
      "|    value_loss         | 0.88        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 821          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 159          |\n",
      "|    total_timesteps    | 917504       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028095564 |\n",
      "|    entropy_loss       | -2.03        |\n",
      "|    explained_variance | 0.87         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.142        |\n",
      "|    mean_step_reward   | 0.081019126  |\n",
      "|    n_updates          | 444          |\n",
      "|    policyGradLoss     | -0.00309     |\n",
      "|    value_loss         | 0.643        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 925696      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004293548 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.829       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.17        |\n",
      "|    mean_step_reward   | 0.08274695  |\n",
      "|    n_updates          | 448         |\n",
      "|    policyGradLoss     | -0.0023     |\n",
      "|    value_loss         | 0.828       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 815          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 180          |\n",
      "|    total_timesteps    | 933888       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033692438 |\n",
      "|    entropy_loss       | -2.05        |\n",
      "|    explained_variance | 0.801        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.274        |\n",
      "|    mean_step_reward   | 0.07816719   |\n",
      "|    n_updates          | 452          |\n",
      "|    policyGradLoss     | -0.00255     |\n",
      "|    value_loss         | 0.897        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 819          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 189          |\n",
      "|    total_timesteps    | 942080       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0037487913 |\n",
      "|    entropy_loss       | -2.05        |\n",
      "|    explained_variance | 0.686        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.61         |\n",
      "|    mean_step_reward   | 0.08091232   |\n",
      "|    n_updates          | 456          |\n",
      "|    policyGradLoss     | -0.00327     |\n",
      "|    value_loss         | 1.62         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 820          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 199          |\n",
      "|    total_timesteps    | 950272       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027723033 |\n",
      "|    entropy_loss       | -2.04        |\n",
      "|    explained_variance | 0.813        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.339        |\n",
      "|    mean_step_reward   | 0.08990702   |\n",
      "|    n_updates          | 460          |\n",
      "|    policyGradLoss     | -0.00304     |\n",
      "|    value_loss         | 1.01         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 820          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 209          |\n",
      "|    total_timesteps    | 958464       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0042694453 |\n",
      "|    entropy_loss       | -2.05        |\n",
      "|    explained_variance | 0.845        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.238        |\n",
      "|    mean_step_reward   | 0.070278     |\n",
      "|    n_updates          | 464          |\n",
      "|    policyGradLoss     | -0.00482     |\n",
      "|    value_loss         | 0.717        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 966656      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004865677 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.83        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.24        |\n",
      "|    mean_step_reward   | 0.0790134   |\n",
      "|    n_updates          | 468         |\n",
      "|    policyGradLoss     | -0.00343    |\n",
      "|    value_loss         | 0.8         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 817          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 230          |\n",
      "|    total_timesteps    | 974848       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0044095404 |\n",
      "|    entropy_loss       | -2.05        |\n",
      "|    explained_variance | 0.823        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.191        |\n",
      "|    mean_step_reward   | 0.07505326   |\n",
      "|    n_updates          | 472          |\n",
      "|    policyGradLoss     | -0.00393     |\n",
      "|    value_loss         | 0.824        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 983040      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004511649 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.841       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.292       |\n",
      "|    mean_step_reward   | 0.08828552  |\n",
      "|    n_updates          | 476         |\n",
      "|    policyGradLoss     | -0.00457    |\n",
      "|    value_loss         | 0.885       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 991232      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004820641 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.805       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.235       |\n",
      "|    mean_step_reward   | 0.100097716 |\n",
      "|    n_updates          | 480         |\n",
      "|    policyGradLoss     | -0.00316    |\n",
      "|    value_loss         | 1.02        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 814          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 261          |\n",
      "|    total_timesteps    | 999424       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0040899087 |\n",
      "|    entropy_loss       | -2.02        |\n",
      "|    explained_variance | 0.764        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.311        |\n",
      "|    mean_step_reward   | 0.090821445  |\n",
      "|    n_updates          | 484          |\n",
      "|    policyGradLoss     | -0.00505     |\n",
      "|    value_loss         | 0.903        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 813          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 272          |\n",
      "|    total_timesteps    | 1007616      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0040151435 |\n",
      "|    entropy_loss       | -2.05        |\n",
      "|    explained_variance | 0.757        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.332        |\n",
      "|    mean_step_reward   | 0.08294231   |\n",
      "|    n_updates          | 488          |\n",
      "|    policyGradLoss     | -0.00244     |\n",
      "|    value_loss         | 1.01         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 281         |\n",
      "|    total_timesteps    | 1015808     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004146011 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.836       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.189       |\n",
      "|    mean_step_reward   | 0.06689341  |\n",
      "|    n_updates          | 492         |\n",
      "|    policyGradLoss     | -0.00482    |\n",
      "|    value_loss         | 0.746       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 820          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 289          |\n",
      "|    total_timesteps    | 1024000      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0037587276 |\n",
      "|    entropy_loss       | -2.05        |\n",
      "|    explained_variance | 0.807        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.3          |\n",
      "|    mean_step_reward   | 0.07665829   |\n",
      "|    n_updates          | 496          |\n",
      "|    policyGradLoss     | -0.00366     |\n",
      "|    value_loss         | 0.828        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 819          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 300          |\n",
      "|    total_timesteps    | 1032192      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0039161285 |\n",
      "|    entropy_loss       | -2.04        |\n",
      "|    explained_variance | 0.791        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.155        |\n",
      "|    mean_step_reward   | 0.07718851   |\n",
      "|    n_updates          | 500          |\n",
      "|    policyGradLoss     | -0.00462     |\n",
      "|    value_loss         | 0.712        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 816          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 311          |\n",
      "|    total_timesteps    | 1040384      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0045788903 |\n",
      "|    entropy_loss       | -2.04        |\n",
      "|    explained_variance | 0.822        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.267        |\n",
      "|    mean_step_reward   | 0.079005815  |\n",
      "|    n_updates          | 504          |\n",
      "|    policyGradLoss     | -0.00344     |\n",
      "|    value_loss         | 0.778        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 815          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 321          |\n",
      "|    total_timesteps    | 1048576      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035110074 |\n",
      "|    entropy_loss       | -2.04        |\n",
      "|    explained_variance | 0.824        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.318        |\n",
      "|    mean_step_reward   | 0.086001515  |\n",
      "|    n_updates          | 508          |\n",
      "|    policyGradLoss     | -0.00459     |\n",
      "|    value_loss         | 0.849        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/S2K_3.zip\n",
      "[EVAL] Mean Return: 15.782, Best Return: 16.449\n",
      "Saved video to ./runs_smw/videos/S2K/S2K_3_15.78.mp4\n",
      "\n",
      "=== Round 5 | Learn 262144 steps (Total trained: 1048576) ===\n",
      "Logging to ./runs_smw/tb/S2K_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1080    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 1056768 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 906          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 1064960      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0047487654 |\n",
      "|    entropy_loss       | -2.06        |\n",
      "|    explained_variance | 0.768        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.11         |\n",
      "|    mean_step_reward   | 0.08039797   |\n",
      "|    n_updates          | 516          |\n",
      "|    policyGradLoss     | -0.00395     |\n",
      "|    value_loss         | 1.31         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 860         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 1073152     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003899303 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.812       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.128       |\n",
      "|    mean_step_reward   | 0.06517653  |\n",
      "|    n_updates          | 520         |\n",
      "|    policyGradLoss     | -0.00472    |\n",
      "|    value_loss         | 0.703       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 882         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 37          |\n",
      "|    total_timesteps    | 1081344     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003183861 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.802       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.229       |\n",
      "|    mean_step_reward   | 0.071553946 |\n",
      "|    n_updates          | 524         |\n",
      "|    policyGradLoss     | -0.00319    |\n",
      "|    value_loss         | 0.759       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 894          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 45           |\n",
      "|    total_timesteps    | 1089536      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0036319466 |\n",
      "|    entropy_loss       | -2.06        |\n",
      "|    explained_variance | 0.838        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.233        |\n",
      "|    mean_step_reward   | 0.07523945   |\n",
      "|    n_updates          | 528          |\n",
      "|    policyGradLoss     | -0.00445     |\n",
      "|    value_loss         | 0.711        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 901          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 54           |\n",
      "|    total_timesteps    | 1097728      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033576968 |\n",
      "|    entropy_loss       | -2.05        |\n",
      "|    explained_variance | 0.799        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.238        |\n",
      "|    mean_step_reward   | 0.08879801   |\n",
      "|    n_updates          | 532          |\n",
      "|    policyGradLoss     | -0.00288     |\n",
      "|    value_loss         | 0.921        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 884          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 64           |\n",
      "|    total_timesteps    | 1105920      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035543034 |\n",
      "|    entropy_loss       | -2.05        |\n",
      "|    explained_variance | 0.82         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.21         |\n",
      "|    mean_step_reward   | 0.072694264  |\n",
      "|    n_updates          | 536          |\n",
      "|    policyGradLoss     | -0.00319     |\n",
      "|    value_loss         | 0.853        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 867          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 75           |\n",
      "|    total_timesteps    | 1114112      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033258193 |\n",
      "|    entropy_loss       | -2.06        |\n",
      "|    explained_variance | 0.774        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.572        |\n",
      "|    mean_step_reward   | 0.0787846    |\n",
      "|    n_updates          | 540          |\n",
      "|    policyGradLoss     | -0.00324     |\n",
      "|    value_loss         | 1.61         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 853         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 1122304     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004829772 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.842       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.402       |\n",
      "|    mean_step_reward   | 0.092918225 |\n",
      "|    n_updates          | 544         |\n",
      "|    policyGradLoss     | -0.00463    |\n",
      "|    value_loss         | 0.905       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 848         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 96          |\n",
      "|    total_timesteps    | 1130496     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003628701 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.834       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.142       |\n",
      "|    mean_step_reward   | 0.07917528  |\n",
      "|    n_updates          | 548         |\n",
      "|    policyGradLoss     | -0.00467    |\n",
      "|    value_loss         | 0.84        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 843          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 106          |\n",
      "|    total_timesteps    | 1138688      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0047305077 |\n",
      "|    entropy_loss       | -2.06        |\n",
      "|    explained_variance | 0.802        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.237        |\n",
      "|    mean_step_reward   | 0.08529402   |\n",
      "|    n_updates          | 552          |\n",
      "|    policyGradLoss     | -0.00363     |\n",
      "|    value_loss         | 0.91         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 836          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 117          |\n",
      "|    total_timesteps    | 1146880      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0043792473 |\n",
      "|    entropy_loss       | -2.07        |\n",
      "|    explained_variance | 0.813        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.171        |\n",
      "|    mean_step_reward   | 0.08103042   |\n",
      "|    n_updates          | 556          |\n",
      "|    policyGradLoss     | -0.00437     |\n",
      "|    value_loss         | 0.74         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 829          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 128          |\n",
      "|    total_timesteps    | 1155072      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0048659192 |\n",
      "|    entropy_loss       | -2.06        |\n",
      "|    explained_variance | 0.727        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.293        |\n",
      "|    mean_step_reward   | 0.09082252   |\n",
      "|    n_updates          | 560          |\n",
      "|    policyGradLoss     | -0.00196     |\n",
      "|    value_loss         | 1.73         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 1163264     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005123777 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.823       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.238       |\n",
      "|    mean_step_reward   | 0.07526916  |\n",
      "|    n_updates          | 564         |\n",
      "|    policyGradLoss     | -0.00581    |\n",
      "|    value_loss         | 0.727       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 1171456     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004640895 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.803       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.208       |\n",
      "|    mean_step_reward   | 0.081084296 |\n",
      "|    n_updates          | 568         |\n",
      "|    policyGradLoss     | -0.00365    |\n",
      "|    value_loss         | 0.933       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 819          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 159          |\n",
      "|    total_timesteps    | 1179648      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0048954743 |\n",
      "|    entropy_loss       | -2.05        |\n",
      "|    explained_variance | 0.767        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.16         |\n",
      "|    mean_step_reward   | 0.08449409   |\n",
      "|    n_updates          | 572          |\n",
      "|    policyGradLoss     | -0.00358     |\n",
      "|    value_loss         | 0.846        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 817          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 170          |\n",
      "|    total_timesteps    | 1187840      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0043075914 |\n",
      "|    entropy_loss       | -2.05        |\n",
      "|    explained_variance | 0.797        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.353        |\n",
      "|    mean_step_reward   | 0.08911611   |\n",
      "|    n_updates          | 576          |\n",
      "|    policyGradLoss     | -0.00369     |\n",
      "|    value_loss         | 1.15         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 817          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 180          |\n",
      "|    total_timesteps    | 1196032      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0045128455 |\n",
      "|    entropy_loss       | -2.05        |\n",
      "|    explained_variance | 0.84         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.382        |\n",
      "|    mean_step_reward   | 0.083588645  |\n",
      "|    n_updates          | 580          |\n",
      "|    policyGradLoss     | -0.0062      |\n",
      "|    value_loss         | 0.85         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 816          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 190          |\n",
      "|    total_timesteps    | 1204224      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0047621857 |\n",
      "|    entropy_loss       | -2.05        |\n",
      "|    explained_variance | 0.831        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.282        |\n",
      "|    mean_step_reward   | 0.08213595   |\n",
      "|    n_updates          | 584          |\n",
      "|    policyGradLoss     | -0.00591     |\n",
      "|    value_loss         | 0.891        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 1212416     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004520022 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.809       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.301       |\n",
      "|    mean_step_reward   | 0.08863829  |\n",
      "|    n_updates          | 588         |\n",
      "|    policyGradLoss     | -0.0042     |\n",
      "|    value_loss         | 1.02        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 810          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 212          |\n",
      "|    total_timesteps    | 1220608      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035477611 |\n",
      "|    entropy_loss       | -2.05        |\n",
      "|    explained_variance | 0.821        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.305        |\n",
      "|    mean_step_reward   | 0.08556087   |\n",
      "|    n_updates          | 592          |\n",
      "|    policyGradLoss     | -0.00449     |\n",
      "|    value_loss         | 1.04         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 809          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 222          |\n",
      "|    total_timesteps    | 1228800      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0040652365 |\n",
      "|    entropy_loss       | -2.02        |\n",
      "|    explained_variance | 0.809        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.332        |\n",
      "|    mean_step_reward   | 0.10105218   |\n",
      "|    n_updates          | 596          |\n",
      "|    policyGradLoss     | -0.00508     |\n",
      "|    value_loss         | 1.06         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 1236992     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004855575 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.815       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.212       |\n",
      "|    mean_step_reward   | 0.07614725  |\n",
      "|    n_updates          | 600         |\n",
      "|    policyGradLoss     | -0.00487    |\n",
      "|    value_loss         | 0.799       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 1245184     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004250258 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.814       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.321       |\n",
      "|    mean_step_reward   | 0.078811266 |\n",
      "|    n_updates          | 604         |\n",
      "|    policyGradLoss     | -0.00419    |\n",
      "|    value_loss         | 1.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 1253376     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005484635 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.813       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.192       |\n",
      "|    mean_step_reward   | 0.09290354  |\n",
      "|    n_updates          | 608         |\n",
      "|    policyGradLoss     | -0.00353    |\n",
      "|    value_loss         | 0.96        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 810          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 262          |\n",
      "|    total_timesteps    | 1261568      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0050745145 |\n",
      "|    entropy_loss       | -1.98        |\n",
      "|    explained_variance | 0.835        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.186        |\n",
      "|    mean_step_reward   | 0.09353362   |\n",
      "|    n_updates          | 612          |\n",
      "|    policyGradLoss     | -0.00453     |\n",
      "|    value_loss         | 0.787        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 810          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 272          |\n",
      "|    total_timesteps    | 1269760      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0041672727 |\n",
      "|    entropy_loss       | -1.99        |\n",
      "|    explained_variance | 0.857        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.169        |\n",
      "|    mean_step_reward   | 0.07854442   |\n",
      "|    n_updates          | 616          |\n",
      "|    policyGradLoss     | -0.00408     |\n",
      "|    value_loss         | 0.817        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 810          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 282          |\n",
      "|    total_timesteps    | 1277952      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0056192167 |\n",
      "|    entropy_loss       | -1.99        |\n",
      "|    explained_variance | 0.832        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.259        |\n",
      "|    mean_step_reward   | 0.10413264   |\n",
      "|    n_updates          | 620          |\n",
      "|    policyGradLoss     | -0.00213     |\n",
      "|    value_loss         | 1.08         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 808          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 293          |\n",
      "|    total_timesteps    | 1286144      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0056990897 |\n",
      "|    entropy_loss       | -1.98        |\n",
      "|    explained_variance | 0.737        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.339        |\n",
      "|    mean_step_reward   | 0.09313175   |\n",
      "|    n_updates          | 624          |\n",
      "|    policyGradLoss     | -0.00267     |\n",
      "|    value_loss         | 1.6          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 1294336     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004220957 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.833       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.242       |\n",
      "|    mean_step_reward   | 0.09022261  |\n",
      "|    n_updates          | 628         |\n",
      "|    policyGradLoss     | -0.00388    |\n",
      "|    value_loss         | 0.961       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 807          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 314          |\n",
      "|    total_timesteps    | 1302528      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038508226 |\n",
      "|    entropy_loss       | -2           |\n",
      "|    explained_variance | 0.857        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.185        |\n",
      "|    mean_step_reward   | 0.08457284   |\n",
      "|    n_updates          | 632          |\n",
      "|    policyGradLoss     | -0.0052      |\n",
      "|    value_loss         | 0.78         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 811          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 322          |\n",
      "|    total_timesteps    | 1310720      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035443967 |\n",
      "|    entropy_loss       | -1.97        |\n",
      "|    explained_variance | 0.856        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.301        |\n",
      "|    mean_step_reward   | 0.10034555   |\n",
      "|    n_updates          | 636          |\n",
      "|    policyGradLoss     | -0.00397     |\n",
      "|    value_loss         | 0.942        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/S2K_4.zip\n",
      "[EVAL] Mean Return: 17.831, Best Return: 18.498\n",
      "Saved video to ./runs_smw/videos/S2K/S2K_4_17.83.mp4\n",
      "\n",
      "=== Round 6 | Learn 262144 steps (Total trained: 1310720) ===\n",
      "Logging to ./runs_smw/tb/S2K_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1126    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 1318912 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 952         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 1327104     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004559749 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.832       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.294       |\n",
      "|    mean_step_reward   | 0.10846791  |\n",
      "|    n_updates          | 644         |\n",
      "|    policyGradLoss     | -0.00199    |\n",
      "|    value_loss         | 1.09        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 894          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 1335296      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0046524536 |\n",
      "|    entropy_loss       | -1.98        |\n",
      "|    explained_variance | 0.847        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.272        |\n",
      "|    mean_step_reward   | 0.091157965  |\n",
      "|    n_updates          | 648          |\n",
      "|    policyGradLoss     | -0.00475     |\n",
      "|    value_loss         | 1.03         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 854        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 38         |\n",
      "|    total_timesteps    | 1343488    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00541563 |\n",
      "|    entropy_loss       | -1.99      |\n",
      "|    explained_variance | 0.813      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.303      |\n",
      "|    mean_step_reward   | 0.09415107 |\n",
      "|    n_updates          | 652        |\n",
      "|    policyGradLoss     | -0.00438   |\n",
      "|    value_loss         | 0.977      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 837          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 48           |\n",
      "|    total_timesteps    | 1351680      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0044560786 |\n",
      "|    entropy_loss       | -2.01        |\n",
      "|    explained_variance | 0.821        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.311        |\n",
      "|    mean_step_reward   | 0.0883518    |\n",
      "|    n_updates          | 656          |\n",
      "|    policyGradLoss     | -0.00487     |\n",
      "|    value_loss         | 0.966        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 834         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 1359872     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004789039 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.834       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.316       |\n",
      "|    mean_step_reward   | 0.10847969  |\n",
      "|    n_updates          | 660         |\n",
      "|    policyGradLoss     | -0.00541    |\n",
      "|    value_loss         | 1.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 830         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 69          |\n",
      "|    total_timesteps    | 1368064     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005007492 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.83        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.392       |\n",
      "|    mean_step_reward   | 0.08591963  |\n",
      "|    n_updates          | 664         |\n",
      "|    policyGradLoss     | -0.00473    |\n",
      "|    value_loss         | 0.963       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 828         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 79          |\n",
      "|    total_timesteps    | 1376256     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004996657 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.828       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.213       |\n",
      "|    mean_step_reward   | 0.09188369  |\n",
      "|    n_updates          | 668         |\n",
      "|    policyGradLoss     | -0.00546    |\n",
      "|    value_loss         | 0.958       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 834         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 88          |\n",
      "|    total_timesteps    | 1384448     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006930921 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.779       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.43        |\n",
      "|    mean_step_reward   | 0.094574735 |\n",
      "|    n_updates          | 672         |\n",
      "|    policyGradLoss     | -0.00398    |\n",
      "|    value_loss         | 1.06        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 826          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 99           |\n",
      "|    total_timesteps    | 1392640      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0047621774 |\n",
      "|    entropy_loss       | -2.02        |\n",
      "|    explained_variance | 0.812        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.238        |\n",
      "|    mean_step_reward   | 0.08902469   |\n",
      "|    n_updates          | 676          |\n",
      "|    policyGradLoss     | -0.00508     |\n",
      "|    value_loss         | 0.976        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 1400832     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004660195 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.823       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.316       |\n",
      "|    mean_step_reward   | 0.09670094  |\n",
      "|    n_updates          | 680         |\n",
      "|    policyGradLoss     | -0.00518    |\n",
      "|    value_loss         | 1.14        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 824          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 119          |\n",
      "|    total_timesteps    | 1409024      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0047943634 |\n",
      "|    entropy_loss       | -2.01        |\n",
      "|    explained_variance | 0.853        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.315        |\n",
      "|    mean_step_reward   | 0.085468695  |\n",
      "|    n_updates          | 684          |\n",
      "|    policyGradLoss     | -0.00536     |\n",
      "|    value_loss         | 0.943        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 129         |\n",
      "|    total_timesteps    | 1417216     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004224234 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.836       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.249       |\n",
      "|    mean_step_reward   | 0.08543606  |\n",
      "|    n_updates          | 688         |\n",
      "|    policyGradLoss     | -0.00413    |\n",
      "|    value_loss         | 0.935       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 815          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 140          |\n",
      "|    total_timesteps    | 1425408      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0060262154 |\n",
      "|    entropy_loss       | -2.02        |\n",
      "|    explained_variance | 0.814        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.27         |\n",
      "|    mean_step_reward   | 0.08996253   |\n",
      "|    n_updates          | 692          |\n",
      "|    policyGradLoss     | -0.00465     |\n",
      "|    value_loss         | 0.866        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 813          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 151          |\n",
      "|    total_timesteps    | 1433600      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0057251137 |\n",
      "|    entropy_loss       | -2.01        |\n",
      "|    explained_variance | 0.834        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.295        |\n",
      "|    mean_step_reward   | 0.0882047    |\n",
      "|    n_updates          | 696          |\n",
      "|    policyGradLoss     | -0.005       |\n",
      "|    value_loss         | 0.933        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 814          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 160          |\n",
      "|    total_timesteps    | 1441792      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0053296685 |\n",
      "|    entropy_loss       | -2           |\n",
      "|    explained_variance | 0.834        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.314        |\n",
      "|    mean_step_reward   | 0.10128994   |\n",
      "|    n_updates          | 700          |\n",
      "|    policyGradLoss     | -0.00499     |\n",
      "|    value_loss         | 1.06         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 1449984     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005241596 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.823       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.378       |\n",
      "|    mean_step_reward   | 0.09040317  |\n",
      "|    n_updates          | 704         |\n",
      "|    policyGradLoss     | -0.00601    |\n",
      "|    value_loss         | 1           |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 1458176     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007147406 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.81        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.495       |\n",
      "|    mean_step_reward   | 0.09681574  |\n",
      "|    n_updates          | 708         |\n",
      "|    policyGradLoss     | -0.00528    |\n",
      "|    value_loss         | 1.26        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 832          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 186          |\n",
      "|    total_timesteps    | 1466368      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0056357696 |\n",
      "|    entropy_loss       | -2           |\n",
      "|    explained_variance | 0.811        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.342        |\n",
      "|    mean_step_reward   | 0.099867955  |\n",
      "|    n_updates          | 712          |\n",
      "|    policyGradLoss     | -0.00315     |\n",
      "|    value_loss         | 1.01         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 837          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 195          |\n",
      "|    total_timesteps    | 1474560      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0048564384 |\n",
      "|    entropy_loss       | -2.01        |\n",
      "|    explained_variance | 0.83         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.391        |\n",
      "|    mean_step_reward   | 0.08292197   |\n",
      "|    n_updates          | 716          |\n",
      "|    policyGradLoss     | -0.00554     |\n",
      "|    value_loss         | 1.02         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 841          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 204          |\n",
      "|    total_timesteps    | 1482752      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0062186904 |\n",
      "|    entropy_loss       | -2.01        |\n",
      "|    explained_variance | 0.823        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.246        |\n",
      "|    mean_step_reward   | 0.095418185  |\n",
      "|    n_updates          | 720          |\n",
      "|    policyGradLoss     | -0.00187     |\n",
      "|    value_loss         | 0.863        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 842          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 214          |\n",
      "|    total_timesteps    | 1490944      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0054761507 |\n",
      "|    entropy_loss       | -2.02        |\n",
      "|    explained_variance | 0.846        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.264        |\n",
      "|    mean_step_reward   | 0.09250586   |\n",
      "|    n_updates          | 724          |\n",
      "|    policyGradLoss     | -0.00384     |\n",
      "|    value_loss         | 0.876        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 839          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 224          |\n",
      "|    total_timesteps    | 1499136      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0064524505 |\n",
      "|    entropy_loss       | -2           |\n",
      "|    explained_variance | 0.838        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.218        |\n",
      "|    mean_step_reward   | 0.08744417   |\n",
      "|    n_updates          | 728          |\n",
      "|    policyGradLoss     | -0.00251     |\n",
      "|    value_loss         | 0.919        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 835         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 235         |\n",
      "|    total_timesteps    | 1507328     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005934058 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.846       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.174       |\n",
      "|    mean_step_reward   | 0.08944342  |\n",
      "|    n_updates          | 732         |\n",
      "|    policyGradLoss     | -0.00406    |\n",
      "|    value_loss         | 0.765       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 833        |\n",
      "|    iterations         | 25         |\n",
      "|    time_elapsed       | 245        |\n",
      "|    total_timesteps    | 1515520    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00497839 |\n",
      "|    entropy_loss       | -2         |\n",
      "|    explained_variance | 0.858      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.15       |\n",
      "|    mean_step_reward   | 0.09636685 |\n",
      "|    n_updates          | 736        |\n",
      "|    policyGradLoss     | -0.00385   |\n",
      "|    value_loss         | 0.901      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 832          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 255          |\n",
      "|    total_timesteps    | 1523712      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0052976096 |\n",
      "|    entropy_loss       | -1.97        |\n",
      "|    explained_variance | 0.864        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.292        |\n",
      "|    mean_step_reward   | 0.10492797   |\n",
      "|    n_updates          | 740          |\n",
      "|    policyGradLoss     | -0.00335     |\n",
      "|    value_loss         | 0.992        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 830          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 266          |\n",
      "|    total_timesteps    | 1531904      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0061065657 |\n",
      "|    entropy_loss       | -1.96        |\n",
      "|    explained_variance | 0.866        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.566        |\n",
      "|    mean_step_reward   | 0.113411635  |\n",
      "|    n_updates          | 744          |\n",
      "|    policyGradLoss     | -0.00465     |\n",
      "|    value_loss         | 1.08         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 277         |\n",
      "|    total_timesteps    | 1540096     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005366982 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.84        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.277       |\n",
      "|    mean_step_reward   | 0.10528649  |\n",
      "|    n_updates          | 748         |\n",
      "|    policyGradLoss     | -0.0069     |\n",
      "|    value_loss         | 1.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 287         |\n",
      "|    total_timesteps    | 1548288     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006097495 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.745       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.267       |\n",
      "|    mean_step_reward   | 0.10510276  |\n",
      "|    n_updates          | 752         |\n",
      "|    policyGradLoss     | -0.00152    |\n",
      "|    value_loss         | 1.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 828         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 1556480     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006249747 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.816       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.282       |\n",
      "|    mean_step_reward   | 0.099385604 |\n",
      "|    n_updates          | 756         |\n",
      "|    policyGradLoss     | -0.0024     |\n",
      "|    value_loss         | 1.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 829         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 1564672     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006145657 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.885       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.276       |\n",
      "|    mean_step_reward   | 0.0975209   |\n",
      "|    n_updates          | 760         |\n",
      "|    policyGradLoss     | -0.00492    |\n",
      "|    value_loss         | 0.818       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 827          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 316          |\n",
      "|    total_timesteps    | 1572864      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0059688333 |\n",
      "|    entropy_loss       | -1.96        |\n",
      "|    explained_variance | 0.824        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.202        |\n",
      "|    mean_step_reward   | 0.1149746    |\n",
      "|    n_updates          | 764          |\n",
      "|    policyGradLoss     | -0.00469     |\n",
      "|    value_loss         | 1.11         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/S2K_5.zip\n",
      "[EVAL] Mean Return: 17.804, Best Return: 18.471\n",
      "Saved video to ./runs_smw/videos/S2K/S2K_5_17.80.mp4\n",
      "\n",
      "=== Round 7 | Learn 262144 steps (Total trained: 1572864) ===\n",
      "Logging to ./runs_smw/tb/S2K_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1164    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 1581056 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 928         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 1589248     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006293491 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.872       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.137       |\n",
      "|    mean_step_reward   | 0.10901237  |\n",
      "|    n_updates          | 772         |\n",
      "|    policyGradLoss     | -0.00461    |\n",
      "|    value_loss         | 0.951       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 861         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 1597440     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006251895 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.669       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.375       |\n",
      "|    mean_step_reward   | 0.11541328  |\n",
      "|    n_updates          | 776         |\n",
      "|    policyGradLoss     | -0.00364    |\n",
      "|    value_loss         | 2.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 845         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 1605632     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006079103 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.819       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.206       |\n",
      "|    mean_step_reward   | 0.08847969  |\n",
      "|    n_updates          | 780         |\n",
      "|    policyGradLoss     | -0.00522    |\n",
      "|    value_loss         | 0.931       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 841          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 48           |\n",
      "|    total_timesteps    | 1613824      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0069510797 |\n",
      "|    entropy_loss       | -1.99        |\n",
      "|    explained_variance | 0.84         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.221        |\n",
      "|    mean_step_reward   | 0.107656     |\n",
      "|    n_updates          | 784          |\n",
      "|    policyGradLoss     | -0.00456     |\n",
      "|    value_loss         | 0.948        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 862         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 56          |\n",
      "|    total_timesteps    | 1622016     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006659218 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.87        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.286       |\n",
      "|    mean_step_reward   | 0.099747844 |\n",
      "|    n_updates          | 788         |\n",
      "|    policyGradLoss     | -0.00358    |\n",
      "|    value_loss         | 0.966       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 879         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 65          |\n",
      "|    total_timesteps    | 1630208     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005893587 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.842       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.235       |\n",
      "|    mean_step_reward   | 0.08625015  |\n",
      "|    n_updates          | 792         |\n",
      "|    policyGradLoss     | -0.00438    |\n",
      "|    value_loss         | 0.821       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 866         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 75          |\n",
      "|    total_timesteps    | 1638400     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007055289 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.824       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.355       |\n",
      "|    mean_step_reward   | 0.111228704 |\n",
      "|    n_updates          | 796         |\n",
      "|    policyGradLoss     | -0.00478    |\n",
      "|    value_loss         | 0.924       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 858          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 85           |\n",
      "|    total_timesteps    | 1646592      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0068335794 |\n",
      "|    entropy_loss       | -1.99        |\n",
      "|    explained_variance | 0.824        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.206        |\n",
      "|    mean_step_reward   | 0.107201554  |\n",
      "|    n_updates          | 800          |\n",
      "|    policyGradLoss     | -0.00525     |\n",
      "|    value_loss         | 0.889        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 853         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 96          |\n",
      "|    total_timesteps    | 1654784     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006818362 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.856       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.213       |\n",
      "|    mean_step_reward   | 0.098165974 |\n",
      "|    n_updates          | 804         |\n",
      "|    policyGradLoss     | -0.00462    |\n",
      "|    value_loss         | 0.868       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 846         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 106         |\n",
      "|    total_timesteps    | 1662976     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008213559 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.823       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.245       |\n",
      "|    mean_step_reward   | 0.108086884 |\n",
      "|    n_updates          | 808         |\n",
      "|    policyGradLoss     | -0.00342    |\n",
      "|    value_loss         | 1.02        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 837          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 117          |\n",
      "|    total_timesteps    | 1671168      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0074704043 |\n",
      "|    entropy_loss       | -2.05        |\n",
      "|    explained_variance | 0.851        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.094        |\n",
      "|    mean_step_reward   | 0.08091393   |\n",
      "|    n_updates          | 812          |\n",
      "|    policyGradLoss     | -0.0057      |\n",
      "|    value_loss         | 0.639        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 831          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 128          |\n",
      "|    total_timesteps    | 1679360      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0069895484 |\n",
      "|    entropy_loss       | -2.03        |\n",
      "|    explained_variance | 0.762        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.166        |\n",
      "|    mean_step_reward   | 0.08299157   |\n",
      "|    n_updates          | 816          |\n",
      "|    policyGradLoss     | -0.00528     |\n",
      "|    value_loss         | 0.878        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 830         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 1687552     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006049365 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.82        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.242       |\n",
      "|    mean_step_reward   | 0.091622844 |\n",
      "|    n_updates          | 820         |\n",
      "|    policyGradLoss     | -0.00446    |\n",
      "|    value_loss         | 0.813       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 828         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 1695744     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008498754 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.842       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.219       |\n",
      "|    mean_step_reward   | 0.094718724 |\n",
      "|    n_updates          | 824         |\n",
      "|    policyGradLoss     | -0.0076     |\n",
      "|    value_loss         | 0.698       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 835         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 1703936     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008057075 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.863       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.169       |\n",
      "|    mean_step_reward   | 0.09279467  |\n",
      "|    n_updates          | 828         |\n",
      "|    policyGradLoss     | -0.00687    |\n",
      "|    value_loss         | 0.716       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 843          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 165          |\n",
      "|    total_timesteps    | 1712128      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0053173993 |\n",
      "|    entropy_loss       | -2.01        |\n",
      "|    explained_variance | 0.875        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.218        |\n",
      "|    mean_step_reward   | 0.08652456   |\n",
      "|    n_updates          | 832          |\n",
      "|    policyGradLoss     | -0.00563     |\n",
      "|    value_loss         | 0.841        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 846          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 174          |\n",
      "|    total_timesteps    | 1720320      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0062641515 |\n",
      "|    entropy_loss       | -2.01        |\n",
      "|    explained_variance | 0.889        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.175        |\n",
      "|    mean_step_reward   | 0.11230041   |\n",
      "|    n_updates          | 836          |\n",
      "|    policyGradLoss     | -0.00485     |\n",
      "|    value_loss         | 0.821        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 845          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 184          |\n",
      "|    total_timesteps    | 1728512      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0065224394 |\n",
      "|    entropy_loss       | -2.05        |\n",
      "|    explained_variance | 0.827        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.21         |\n",
      "|    mean_step_reward   | 0.08818188   |\n",
      "|    n_updates          | 840          |\n",
      "|    policyGradLoss     | -0.0052      |\n",
      "|    value_loss         | 0.936        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 842         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 194         |\n",
      "|    total_timesteps    | 1736704     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007067289 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.786       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.296       |\n",
      "|    mean_step_reward   | 0.0939673   |\n",
      "|    n_updates          | 844         |\n",
      "|    policyGradLoss     | -0.00718    |\n",
      "|    value_loss         | 0.992       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 837          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 205          |\n",
      "|    total_timesteps    | 1744896      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0054470925 |\n",
      "|    entropy_loss       | -2.03        |\n",
      "|    explained_variance | 0.751        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.696        |\n",
      "|    mean_step_reward   | 0.092249244  |\n",
      "|    n_updates          | 848          |\n",
      "|    policyGradLoss     | -0.00347     |\n",
      "|    value_loss         | 1.91         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 834         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 216         |\n",
      "|    total_timesteps    | 1753088     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005079394 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.847       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.24        |\n",
      "|    mean_step_reward   | 0.080201864 |\n",
      "|    n_updates          | 852         |\n",
      "|    policyGradLoss     | -0.00561    |\n",
      "|    value_loss         | 0.825       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 831          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 226          |\n",
      "|    total_timesteps    | 1761280      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0066410103 |\n",
      "|    entropy_loss       | -1.99        |\n",
      "|    explained_variance | 0.832        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.223        |\n",
      "|    mean_step_reward   | 0.098466605  |\n",
      "|    n_updates          | 856          |\n",
      "|    policyGradLoss     | -0.00617     |\n",
      "|    value_loss         | 0.911        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 830         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 236         |\n",
      "|    total_timesteps    | 1769472     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008397903 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.846       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.206       |\n",
      "|    mean_step_reward   | 0.08862295  |\n",
      "|    n_updates          | 860         |\n",
      "|    policyGradLoss     | -0.00524    |\n",
      "|    value_loss         | 0.919       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 247         |\n",
      "|    total_timesteps    | 1777664     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006592957 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.771       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.208       |\n",
      "|    mean_step_reward   | 0.10837017  |\n",
      "|    n_updates          | 864         |\n",
      "|    policyGradLoss     | -0.00309    |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 827         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 257         |\n",
      "|    total_timesteps    | 1785856     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007952835 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.84        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.24        |\n",
      "|    mean_step_reward   | 0.09471645  |\n",
      "|    n_updates          | 868         |\n",
      "|    policyGradLoss     | -0.00644    |\n",
      "|    value_loss         | 0.827       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 832          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 265          |\n",
      "|    total_timesteps    | 1794048      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0074141896 |\n",
      "|    entropy_loss       | -2.02        |\n",
      "|    explained_variance | 0.787        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.752        |\n",
      "|    mean_step_reward   | 0.09596522   |\n",
      "|    n_updates          | 872          |\n",
      "|    policyGradLoss     | -0.00406     |\n",
      "|    value_loss         | 1.31         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 1802240     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006424071 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.877       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.189       |\n",
      "|    mean_step_reward   | 0.08563129  |\n",
      "|    n_updates          | 876         |\n",
      "|    policyGradLoss     | -0.00627    |\n",
      "|    value_loss         | 1.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 835         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 1810432     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008236598 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.431       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.81        |\n",
      "|    mean_step_reward   | 0.07882137  |\n",
      "|    n_updates          | 880         |\n",
      "|    policyGradLoss     | -0.00156    |\n",
      "|    value_loss         | 4.9         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 832          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 295          |\n",
      "|    total_timesteps    | 1818624      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0066643674 |\n",
      "|    entropy_loss       | -2.02        |\n",
      "|    explained_variance | 0.792        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.479        |\n",
      "|    mean_step_reward   | 0.08463541   |\n",
      "|    n_updates          | 884          |\n",
      "|    policyGradLoss     | -0.004       |\n",
      "|    value_loss         | 1.12         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 831          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 305          |\n",
      "|    total_timesteps    | 1826816      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0075097526 |\n",
      "|    entropy_loss       | -2.03        |\n",
      "|    explained_variance | 0.847        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.262        |\n",
      "|    mean_step_reward   | 0.086211175  |\n",
      "|    n_updates          | 888          |\n",
      "|    policyGradLoss     | -0.00549     |\n",
      "|    value_loss         | 0.736        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 830          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 315          |\n",
      "|    total_timesteps    | 1835008      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0068270518 |\n",
      "|    entropy_loss       | -1.99        |\n",
      "|    explained_variance | 0.834        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.202        |\n",
      "|    mean_step_reward   | 0.10328541   |\n",
      "|    n_updates          | 892          |\n",
      "|    policyGradLoss     | -0.00418     |\n",
      "|    value_loss         | 0.862        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/S2K_6.zip\n",
      "[EVAL] Mean Return: 90.003, Best Return: 91.337\n",
      "Saved video to ./runs_smw/videos/S2K/S2K_6_90.00.mp4\n",
      "\n",
      "=== Round 8 | Learn 262144 steps (Total trained: 1835008) ===\n",
      "Logging to ./runs_smw/tb/S2K_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1175    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 6       |\n",
      "|    total_timesteps | 1843200 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 1054         |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 15           |\n",
      "|    total_timesteps    | 1851392      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0073518916 |\n",
      "|    entropy_loss       | -2.01        |\n",
      "|    explained_variance | 0.843        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.349        |\n",
      "|    mean_step_reward   | 0.101646334  |\n",
      "|    n_updates          | 900          |\n",
      "|    policyGradLoss     | -0.00552     |\n",
      "|    value_loss         | 0.997        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1028       |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 23         |\n",
      "|    total_timesteps    | 1859584    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00582309 |\n",
      "|    entropy_loss       | -2.04      |\n",
      "|    explained_variance | 0.876      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.144      |\n",
      "|    mean_step_reward   | 0.07830617 |\n",
      "|    n_updates          | 904        |\n",
      "|    policyGradLoss     | -0.00708   |\n",
      "|    value_loss         | 0.609      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 999         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 32          |\n",
      "|    total_timesteps    | 1867776     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006248307 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.825       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.258       |\n",
      "|    mean_step_reward   | 0.11175521  |\n",
      "|    n_updates          | 908         |\n",
      "|    policyGradLoss     | -0.00238    |\n",
      "|    value_loss         | 1.44        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 983          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 41           |\n",
      "|    total_timesteps    | 1875968      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0063148364 |\n",
      "|    entropy_loss       | -2.06        |\n",
      "|    explained_variance | 0.88         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0988       |\n",
      "|    mean_step_reward   | 0.06337738   |\n",
      "|    n_updates          | 912          |\n",
      "|    policyGradLoss     | -0.00672     |\n",
      "|    value_loss         | 0.583        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 945          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 51           |\n",
      "|    total_timesteps    | 1884160      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0070605325 |\n",
      "|    entropy_loss       | -2.01        |\n",
      "|    explained_variance | 0.851        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.246        |\n",
      "|    mean_step_reward   | 0.10535166   |\n",
      "|    n_updates          | 916          |\n",
      "|    policyGradLoss     | -0.00437     |\n",
      "|    value_loss         | 1.01         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 910         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 62          |\n",
      "|    total_timesteps    | 1892352     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008207775 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.759       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.257       |\n",
      "|    mean_step_reward   | 0.0891462   |\n",
      "|    n_updates          | 920         |\n",
      "|    policyGradLoss     | -0.00343    |\n",
      "|    value_loss         | 1.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 892         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 73          |\n",
      "|    total_timesteps    | 1900544     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006581355 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.857       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.122       |\n",
      "|    mean_step_reward   | 0.07935095  |\n",
      "|    n_updates          | 924         |\n",
      "|    policyGradLoss     | -0.00656    |\n",
      "|    value_loss         | 0.696       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 881          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 83           |\n",
      "|    total_timesteps    | 1908736      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0059800046 |\n",
      "|    entropy_loss       | -2.04        |\n",
      "|    explained_variance | 0.914        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.121        |\n",
      "|    mean_step_reward   | 0.092963666  |\n",
      "|    n_updates          | 928          |\n",
      "|    policyGradLoss     | -0.00665     |\n",
      "|    value_loss         | 0.528        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 870         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 94          |\n",
      "|    total_timesteps    | 1916928     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005583471 |\n",
      "|    entropy_loss       | -2.08       |\n",
      "|    explained_variance | 0.82        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.202       |\n",
      "|    mean_step_reward   | 0.08785596  |\n",
      "|    n_updates          | 932         |\n",
      "|    policyGradLoss     | -0.00349    |\n",
      "|    value_loss         | 1.46        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 857          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 105          |\n",
      "|    total_timesteps    | 1925120      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0071155285 |\n",
      "|    entropy_loss       | -2.06        |\n",
      "|    explained_variance | 0.833        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.43         |\n",
      "|    mean_step_reward   | 0.08982949   |\n",
      "|    n_updates          | 936          |\n",
      "|    policyGradLoss     | -0.00357     |\n",
      "|    value_loss         | 1.21         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 852          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 115          |\n",
      "|    total_timesteps    | 1933312      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0059270626 |\n",
      "|    entropy_loss       | -2           |\n",
      "|    explained_variance | 0.779        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.759        |\n",
      "|    mean_step_reward   | 0.10148073   |\n",
      "|    n_updates          | 940          |\n",
      "|    policyGradLoss     | -0.00221     |\n",
      "|    value_loss         | 1.93         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 848        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 125        |\n",
      "|    total_timesteps    | 1941504    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0083503  |\n",
      "|    entropy_loss       | -1.99      |\n",
      "|    explained_variance | 0.865      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.15       |\n",
      "|    mean_step_reward   | 0.10500879 |\n",
      "|    n_updates          | 944        |\n",
      "|    policyGradLoss     | -0.00548   |\n",
      "|    value_loss         | 0.773      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 855          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 134          |\n",
      "|    total_timesteps    | 1949696      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0071325377 |\n",
      "|    entropy_loss       | -2.01        |\n",
      "|    explained_variance | 0.828        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.142        |\n",
      "|    mean_step_reward   | 0.09493548   |\n",
      "|    n_updates          | 948          |\n",
      "|    policyGradLoss     | -0.00363     |\n",
      "|    value_loss         | 0.795        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 863          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 142          |\n",
      "|    total_timesteps    | 1957888      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0075641116 |\n",
      "|    entropy_loss       | -2.01        |\n",
      "|    explained_variance | 0.884        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.162        |\n",
      "|    mean_step_reward   | 0.11042601   |\n",
      "|    n_updates          | 952          |\n",
      "|    policyGradLoss     | -0.00691     |\n",
      "|    value_loss         | 0.764        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 863         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 151         |\n",
      "|    total_timesteps    | 1966080     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005916539 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.731       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.702       |\n",
      "|    mean_step_reward   | 0.12653042  |\n",
      "|    n_updates          | 956         |\n",
      "|    policyGradLoss     | -0.00208    |\n",
      "|    value_loss         | 2.47        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 858          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 162          |\n",
      "|    total_timesteps    | 1974272      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0071040187 |\n",
      "|    entropy_loss       | -1.99        |\n",
      "|    explained_variance | 0.8          |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.236        |\n",
      "|    mean_step_reward   | 0.09780477   |\n",
      "|    n_updates          | 960          |\n",
      "|    policyGradLoss     | -0.00208     |\n",
      "|    value_loss         | 1.25         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 856          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 172          |\n",
      "|    total_timesteps    | 1982464      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0067525627 |\n",
      "|    entropy_loss       | -1.98        |\n",
      "|    explained_variance | 0.871        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.22         |\n",
      "|    mean_step_reward   | 0.104594156  |\n",
      "|    n_updates          | 964          |\n",
      "|    policyGradLoss     | -0.0058      |\n",
      "|    value_loss         | 0.899        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 852         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 182         |\n",
      "|    total_timesteps    | 1990656     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005622401 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.872       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.559       |\n",
      "|    mean_step_reward   | 0.12944722  |\n",
      "|    n_updates          | 968         |\n",
      "|    policyGradLoss     | -0.00384    |\n",
      "|    value_loss         | 1.28        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 846        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 193        |\n",
      "|    total_timesteps    | 1998848    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00580328 |\n",
      "|    entropy_loss       | -2         |\n",
      "|    explained_variance | 0.82       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.185      |\n",
      "|    mean_step_reward   | 0.10722883 |\n",
      "|    n_updates          | 972        |\n",
      "|    policyGradLoss     | -0.00254   |\n",
      "|    value_loss         | 0.901      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 841          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 204          |\n",
      "|    total_timesteps    | 2007040      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0060240077 |\n",
      "|    entropy_loss       | -2           |\n",
      "|    explained_variance | 0.845        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.224        |\n",
      "|    mean_step_reward   | 0.106431425  |\n",
      "|    n_updates          | 976          |\n",
      "|    policyGradLoss     | -0.00377     |\n",
      "|    value_loss         | 1.2          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 840          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 214          |\n",
      "|    total_timesteps    | 2015232      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0064375997 |\n",
      "|    entropy_loss       | -1.96        |\n",
      "|    explained_variance | 0.841        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.344        |\n",
      "|    mean_step_reward   | 0.12342004   |\n",
      "|    n_updates          | 980          |\n",
      "|    policyGradLoss     | -0.00172     |\n",
      "|    value_loss         | 1.79         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 838         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 224         |\n",
      "|    total_timesteps    | 2023424     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005701054 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.2         |\n",
      "|    mean_step_reward   | 0.09671579  |\n",
      "|    n_updates          | 984         |\n",
      "|    policyGradLoss     | -0.00454    |\n",
      "|    value_loss         | 0.687       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 838         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 234         |\n",
      "|    total_timesteps    | 2031616     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005895489 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.832       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.126       |\n",
      "|    mean_step_reward   | 0.11095224  |\n",
      "|    n_updates          | 988         |\n",
      "|    policyGradLoss     | -0.00202    |\n",
      "|    value_loss         | 1.38        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 843          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 242          |\n",
      "|    total_timesteps    | 2039808      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0068061613 |\n",
      "|    entropy_loss       | -1.94        |\n",
      "|    explained_variance | 0.867        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.481        |\n",
      "|    mean_step_reward   | 0.12386302   |\n",
      "|    n_updates          | 992          |\n",
      "|    policyGradLoss     | -0.00365     |\n",
      "|    value_loss         | 1.65         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 847          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 251          |\n",
      "|    total_timesteps    | 2048000      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0065182745 |\n",
      "|    entropy_loss       | -1.94        |\n",
      "|    explained_variance | 0.867        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.16         |\n",
      "|    mean_step_reward   | 0.12447866   |\n",
      "|    n_updates          | 996          |\n",
      "|    policyGradLoss     | -0.00292     |\n",
      "|    value_loss         | 0.908        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 846         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 2056192     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006815723 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.85        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.156       |\n",
      "|    mean_step_reward   | 0.10683054  |\n",
      "|    n_updates          | 1000        |\n",
      "|    policyGradLoss     | -0.00739    |\n",
      "|    value_loss         | 1.09        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 844          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 271          |\n",
      "|    total_timesteps    | 2064384      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0054079425 |\n",
      "|    entropy_loss       | -2.02        |\n",
      "|    explained_variance | 0.859        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.507        |\n",
      "|    mean_step_reward   | 0.09543489   |\n",
      "|    n_updates          | 1004         |\n",
      "|    policyGradLoss     | -0.00473     |\n",
      "|    value_loss         | 1.34         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 840          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 282          |\n",
      "|    total_timesteps    | 2072576      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0063958913 |\n",
      "|    entropy_loss       | -2           |\n",
      "|    explained_variance | 0.855        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.369        |\n",
      "|    mean_step_reward   | 0.110568635  |\n",
      "|    n_updates          | 1008         |\n",
      "|    policyGradLoss     | -0.00284     |\n",
      "|    value_loss         | 1.6          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 838         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 2080768     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006289157 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.853       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.64        |\n",
      "|    mean_step_reward   | 0.09394791  |\n",
      "|    n_updates          | 1012        |\n",
      "|    policyGradLoss     | -0.00345    |\n",
      "|    value_loss         | 1.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 838         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 302         |\n",
      "|    total_timesteps    | 2088960     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006485354 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.859       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.481       |\n",
      "|    mean_step_reward   | 0.13891739  |\n",
      "|    n_updates          | 1016        |\n",
      "|    policyGradLoss     | -0.00245    |\n",
      "|    value_loss         | 1.78        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 836          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 313          |\n",
      "|    total_timesteps    | 2097152      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0065486394 |\n",
      "|    entropy_loss       | -1.98        |\n",
      "|    explained_variance | 0.868        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.424        |\n",
      "|    mean_step_reward   | 0.10319847   |\n",
      "|    n_updates          | 1020         |\n",
      "|    policyGradLoss     | -0.00524     |\n",
      "|    value_loss         | 1.01         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/S2K_7.zip\n",
      "[EVAL] Mean Return: 29.279, Best Return: 29.946\n",
      "Saved video to ./runs_smw/videos/S2K/S2K_7_29.28.mp4\n",
      "\n",
      "=== Round 9 | Learn 262144 steps (Total trained: 2097152) ===\n",
      "Logging to ./runs_smw/tb/S2K_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1357    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 6       |\n",
      "|    total_timesteps | 2105344 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1099        |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 14          |\n",
      "|    total_timesteps    | 2113536     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006369292 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.788       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.168       |\n",
      "|    mean_step_reward   | 0.08072801  |\n",
      "|    n_updates          | 1028        |\n",
      "|    policyGradLoss     | -0.00704    |\n",
      "|    value_loss         | 1.1         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 999          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 24           |\n",
      "|    total_timesteps    | 2121728      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0072028236 |\n",
      "|    entropy_loss       | -1.97        |\n",
      "|    explained_variance | 0.879        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.144        |\n",
      "|    mean_step_reward   | 0.1112384    |\n",
      "|    n_updates          | 1032         |\n",
      "|    policyGradLoss     | -0.00577     |\n",
      "|    value_loss         | 0.76         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 917         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 35          |\n",
      "|    total_timesteps    | 2129920     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.00822146  |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.873       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.149       |\n",
      "|    mean_step_reward   | 0.105888136 |\n",
      "|    n_updates          | 1036        |\n",
      "|    policyGradLoss     | -0.00422    |\n",
      "|    value_loss         | 0.821       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 886         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 46          |\n",
      "|    total_timesteps    | 2138112     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008311129 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.184       |\n",
      "|    mean_step_reward   | 0.118225284 |\n",
      "|    n_updates          | 1040        |\n",
      "|    policyGradLoss     | -0.00587    |\n",
      "|    value_loss         | 0.757       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 867         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 56          |\n",
      "|    total_timesteps    | 2146304     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006368914 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.787       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.169       |\n",
      "|    mean_step_reward   | 0.10627109  |\n",
      "|    n_updates          | 1044        |\n",
      "|    policyGradLoss     | -0.00484    |\n",
      "|    value_loss         | 1.45        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 845         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 67          |\n",
      "|    total_timesteps    | 2154496     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006295147 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.855       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.535       |\n",
      "|    mean_step_reward   | 0.13527319  |\n",
      "|    n_updates          | 1048        |\n",
      "|    policyGradLoss     | -0.00245    |\n",
      "|    value_loss         | 1.55        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 828          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 79           |\n",
      "|    total_timesteps    | 2162688      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0062143896 |\n",
      "|    entropy_loss       | -1.97        |\n",
      "|    explained_variance | 0.872        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.118        |\n",
      "|    mean_step_reward   | 0.11800706   |\n",
      "|    n_updates          | 1052         |\n",
      "|    policyGradLoss     | -0.00413     |\n",
      "|    value_loss         | 0.699        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 794          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 92           |\n",
      "|    total_timesteps    | 2170880      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0075455513 |\n",
      "|    entropy_loss       | -1.99        |\n",
      "|    explained_variance | 0.868        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.284        |\n",
      "|    mean_step_reward   | 0.10716806   |\n",
      "|    n_updates          | 1056         |\n",
      "|    policyGradLoss     | -0.00562     |\n",
      "|    value_loss         | 0.925        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 776          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 105          |\n",
      "|    total_timesteps    | 2179072      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0054337336 |\n",
      "|    entropy_loss       | -1.97        |\n",
      "|    explained_variance | 0.792        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.209        |\n",
      "|    mean_step_reward   | 0.10688931   |\n",
      "|    n_updates          | 1060         |\n",
      "|    policyGradLoss     | -0.00523     |\n",
      "|    value_loss         | 1.18         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 2187264     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007602784 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.138       |\n",
      "|    mean_step_reward   | 0.10188069  |\n",
      "|    n_updates          | 1064        |\n",
      "|    policyGradLoss     | -0.00603    |\n",
      "|    value_loss         | 0.63        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 803          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 122          |\n",
      "|    total_timesteps    | 2195456      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0061078165 |\n",
      "|    entropy_loss       | -1.99        |\n",
      "|    explained_variance | 0.818        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.182        |\n",
      "|    mean_step_reward   | 0.086156584  |\n",
      "|    n_updates          | 1068         |\n",
      "|    policyGradLoss     | -0.00583     |\n",
      "|    value_loss         | 0.956        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 810          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 131          |\n",
      "|    total_timesteps    | 2203648      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0058276365 |\n",
      "|    entropy_loss       | -1.98        |\n",
      "|    explained_variance | 0.858        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.149        |\n",
      "|    mean_step_reward   | 0.108105145  |\n",
      "|    n_updates          | 1072         |\n",
      "|    policyGradLoss     | -0.00428     |\n",
      "|    value_loss         | 0.85         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 141         |\n",
      "|    total_timesteps    | 2211840     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008849995 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.84        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0816      |\n",
      "|    mean_step_reward   | 0.09810116  |\n",
      "|    n_updates          | 1076        |\n",
      "|    policyGradLoss     | -0.00544    |\n",
      "|    value_loss         | 0.599       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 151         |\n",
      "|    total_timesteps    | 2220032     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006229682 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.859       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.201       |\n",
      "|    mean_step_reward   | 0.11460775  |\n",
      "|    n_updates          | 1080        |\n",
      "|    policyGradLoss     | -0.00346    |\n",
      "|    value_loss         | 0.842       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 162         |\n",
      "|    total_timesteps    | 2228224     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005687733 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0641      |\n",
      "|    mean_step_reward   | 0.11434504  |\n",
      "|    n_updates          | 1084        |\n",
      "|    policyGradLoss     | -0.00587    |\n",
      "|    value_loss         | 0.562       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 173         |\n",
      "|    total_timesteps    | 2236416     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007277469 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.877       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.121       |\n",
      "|    mean_step_reward   | 0.101711765 |\n",
      "|    n_updates          | 1088        |\n",
      "|    policyGradLoss     | -0.00636    |\n",
      "|    value_loss         | 0.768       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 801          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 183          |\n",
      "|    total_timesteps    | 2244608      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0061589046 |\n",
      "|    entropy_loss       | -1.98        |\n",
      "|    explained_variance | 0.855        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.174        |\n",
      "|    mean_step_reward   | 0.110389784  |\n",
      "|    n_updates          | 1092         |\n",
      "|    policyGradLoss     | -0.00592     |\n",
      "|    value_loss         | 0.731        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 194         |\n",
      "|    total_timesteps    | 2252800     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006401561 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.815       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.123       |\n",
      "|    mean_step_reward   | 0.11314078  |\n",
      "|    n_updates          | 1096        |\n",
      "|    policyGradLoss     | -0.00191    |\n",
      "|    value_loss         | 0.962       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 204         |\n",
      "|    total_timesteps    | 2260992     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006760845 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.861       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.779       |\n",
      "|    mean_step_reward   | 0.11482261  |\n",
      "|    n_updates          | 1100        |\n",
      "|    policyGradLoss     | -0.00306    |\n",
      "|    value_loss         | 1.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 214         |\n",
      "|    total_timesteps    | 2269184     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005814336 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.888       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.16        |\n",
      "|    mean_step_reward   | 0.1147424   |\n",
      "|    n_updates          | 1104        |\n",
      "|    policyGradLoss     | -0.00379    |\n",
      "|    value_loss         | 0.76        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 809          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 222          |\n",
      "|    total_timesteps    | 2277376      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0058864057 |\n",
      "|    entropy_loss       | -1.97        |\n",
      "|    explained_variance | 0.88         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.223        |\n",
      "|    mean_step_reward   | 0.12730174   |\n",
      "|    n_updates          | 1108         |\n",
      "|    policyGradLoss     | -0.00312     |\n",
      "|    value_loss         | 1.29         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 2285568     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007302475 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.881       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.11        |\n",
      "|    mean_step_reward   | 0.111045204 |\n",
      "|    n_updates          | 1112        |\n",
      "|    policyGradLoss     | -0.00547    |\n",
      "|    value_loss         | 0.687       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 239         |\n",
      "|    total_timesteps    | 2293760     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006595753 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.169       |\n",
      "|    mean_step_reward   | 0.12652977  |\n",
      "|    n_updates          | 1116        |\n",
      "|    policyGradLoss     | -0.00534    |\n",
      "|    value_loss         | 0.732       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 248         |\n",
      "|    total_timesteps    | 2301952     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005713271 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.88        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.183       |\n",
      "|    mean_step_reward   | 0.09516545  |\n",
      "|    n_updates          | 1120        |\n",
      "|    policyGradLoss     | -0.00541    |\n",
      "|    value_loss         | 0.834       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 827         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 257         |\n",
      "|    total_timesteps    | 2310144     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006137116 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.834       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.754       |\n",
      "|    mean_step_reward   | 0.1251452   |\n",
      "|    n_updates          | 1124        |\n",
      "|    policyGradLoss     | -0.0046     |\n",
      "|    value_loss         | 1.44        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 823        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 268        |\n",
      "|    total_timesteps    | 2318336    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00593092 |\n",
      "|    entropy_loss       | -1.96      |\n",
      "|    explained_variance | 0.793      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.197      |\n",
      "|    mean_step_reward   | 0.12097753 |\n",
      "|    n_updates          | 1128       |\n",
      "|    policyGradLoss     | -0.00455   |\n",
      "|    value_loss         | 1.16       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 822          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 278          |\n",
      "|    total_timesteps    | 2326528      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0059567215 |\n",
      "|    entropy_loss       | -1.97        |\n",
      "|    explained_variance | 0.837        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0936       |\n",
      "|    mean_step_reward   | 0.12326662   |\n",
      "|    n_updates          | 1132         |\n",
      "|    policyGradLoss     | -0.00503     |\n",
      "|    value_loss         | 1.31         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 288         |\n",
      "|    total_timesteps    | 2334720     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005982492 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.799       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.108       |\n",
      "|    mean_step_reward   | 0.09695593  |\n",
      "|    n_updates          | 1136        |\n",
      "|    policyGradLoss     | -0.00546    |\n",
      "|    value_loss         | 1.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 299         |\n",
      "|    total_timesteps    | 2342912     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005506448 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.774       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.2         |\n",
      "|    mean_step_reward   | 0.11124396  |\n",
      "|    n_updates          | 1140        |\n",
      "|    policyGradLoss     | -0.00149    |\n",
      "|    value_loss         | 1.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 310         |\n",
      "|    total_timesteps    | 2351104     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007206389 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.889       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0382      |\n",
      "|    mean_step_reward   | 0.11099789  |\n",
      "|    n_updates          | 1144        |\n",
      "|    policyGradLoss     | -0.00751    |\n",
      "|    value_loss         | 0.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 320         |\n",
      "|    total_timesteps    | 2359296     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009321973 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.907       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.124       |\n",
      "|    mean_step_reward   | 0.10725702  |\n",
      "|    n_updates          | 1148        |\n",
      "|    policyGradLoss     | -0.00524    |\n",
      "|    value_loss         | 0.639       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/S2K_8.zip\n",
      "[EVAL] Mean Return: 115.605, Best Return: 116.938\n",
      "Saved video to ./runs_smw/videos/S2K/S2K_8_115.60.mp4\n",
      "\n",
      "=== Round 10 | Learn 262144 steps (Total trained: 2359296) ===\n",
      "Logging to ./runs_smw/tb/S2K_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1102    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 2367488 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 902         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 2375680     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006530327 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.894       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.164       |\n",
      "|    mean_step_reward   | 0.11342655  |\n",
      "|    n_updates          | 1156        |\n",
      "|    policyGradLoss     | -0.00572    |\n",
      "|    value_loss         | 0.798       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 868          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 2383872      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0061703185 |\n",
      "|    entropy_loss       | -1.96        |\n",
      "|    explained_variance | 0.794        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.361        |\n",
      "|    mean_step_reward   | 0.108851254  |\n",
      "|    n_updates          | 1160         |\n",
      "|    policyGradLoss     | -0.00503     |\n",
      "|    value_loss         | 1.33         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 852         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 2392064     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007852525 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.861       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.145       |\n",
      "|    mean_step_reward   | 0.11145859  |\n",
      "|    n_updates          | 1164        |\n",
      "|    policyGradLoss     | -0.00483    |\n",
      "|    value_loss         | 0.984       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 836         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 48          |\n",
      "|    total_timesteps    | 2400256     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006921654 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.794       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.188       |\n",
      "|    mean_step_reward   | 0.109264396 |\n",
      "|    n_updates          | 1168        |\n",
      "|    policyGradLoss     | -0.000317   |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 2408448     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009691838 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.912       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.115       |\n",
      "|    mean_step_reward   | 0.12181143  |\n",
      "|    n_updates          | 1172        |\n",
      "|    policyGradLoss     | -0.00284    |\n",
      "|    value_loss         | 0.652       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 2416640     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006094694 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.861       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.19        |\n",
      "|    mean_step_reward   | 0.101810515 |\n",
      "|    n_updates          | 1176        |\n",
      "|    policyGradLoss     | -0.0054     |\n",
      "|    value_loss         | 1.09        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 79          |\n",
      "|    total_timesteps    | 2424832     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008265752 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.873       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.189       |\n",
      "|    mean_step_reward   | 0.12730023  |\n",
      "|    n_updates          | 1180        |\n",
      "|    policyGradLoss     | -0.00314    |\n",
      "|    value_loss         | 0.815       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 835          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 88           |\n",
      "|    total_timesteps    | 2433024      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0071910415 |\n",
      "|    entropy_loss       | -1.99        |\n",
      "|    explained_variance | 0.731        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.775        |\n",
      "|    mean_step_reward   | 0.123173     |\n",
      "|    n_updates          | 1184         |\n",
      "|    policyGradLoss     | -0.00246     |\n",
      "|    value_loss         | 2.03         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 847          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 96           |\n",
      "|    total_timesteps    | 2441216      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0067737987 |\n",
      "|    entropy_loss       | -1.98        |\n",
      "|    explained_variance | 0.871        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.198        |\n",
      "|    mean_step_reward   | 0.11814171   |\n",
      "|    n_updates          | 1188         |\n",
      "|    policyGradLoss     | -0.00611     |\n",
      "|    value_loss         | 0.914        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 842        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 106        |\n",
      "|    total_timesteps    | 2449408    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0065906  |\n",
      "|    entropy_loss       | -1.99      |\n",
      "|    explained_variance | 0.669      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.653      |\n",
      "|    mean_step_reward   | 0.12244324 |\n",
      "|    n_updates          | 1192       |\n",
      "|    policyGradLoss     | -0.0026    |\n",
      "|    value_loss         | 4.48       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 117         |\n",
      "|    total_timesteps    | 2457600     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007052822 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.844       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.311       |\n",
      "|    mean_step_reward   | 0.12020257  |\n",
      "|    n_updates          | 1196        |\n",
      "|    policyGradLoss     | -0.00665    |\n",
      "|    value_loss         | 1.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 834         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 127         |\n",
      "|    total_timesteps    | 2465792     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007734432 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.889       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0951      |\n",
      "|    mean_step_reward   | 0.0985439   |\n",
      "|    n_updates          | 1200        |\n",
      "|    policyGradLoss     | -0.00786    |\n",
      "|    value_loss         | 0.574       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 831          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 137          |\n",
      "|    total_timesteps    | 2473984      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0063112765 |\n",
      "|    entropy_loss       | -2.03        |\n",
      "|    explained_variance | 0.83         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.493        |\n",
      "|    mean_step_reward   | 0.10190494   |\n",
      "|    n_updates          | 1204         |\n",
      "|    policyGradLoss     | -0.00442     |\n",
      "|    value_loss         | 0.999        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 2482176     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007650515 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.9         |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0296      |\n",
      "|    mean_step_reward   | 0.08612426  |\n",
      "|    n_updates          | 1208        |\n",
      "|    policyGradLoss     | -0.00678    |\n",
      "|    value_loss         | 0.476       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 821          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 159          |\n",
      "|    total_timesteps    | 2490368      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0068138842 |\n",
      "|    entropy_loss       | -2.03        |\n",
      "|    explained_variance | 0.774        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.255        |\n",
      "|    mean_step_reward   | 0.096475825  |\n",
      "|    n_updates          | 1212         |\n",
      "|    policyGradLoss     | -0.00273     |\n",
      "|    value_loss         | 1.45         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 821        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 169        |\n",
      "|    total_timesteps    | 2498560    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00743734 |\n",
      "|    entropy_loss       | -2.04      |\n",
      "|    explained_variance | 0.887      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.074      |\n",
      "|    mean_step_reward   | 0.10055478 |\n",
      "|    n_updates          | 1216       |\n",
      "|    policyGradLoss     | -0.00568   |\n",
      "|    value_loss         | 0.58       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 2506752     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005411028 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.814       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.579       |\n",
      "|    mean_step_reward   | 0.10040416  |\n",
      "|    n_updates          | 1220        |\n",
      "|    policyGradLoss     | -0.00511    |\n",
      "|    value_loss         | 1.27        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 825          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 188          |\n",
      "|    total_timesteps    | 2514944      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0067950566 |\n",
      "|    entropy_loss       | -2.03        |\n",
      "|    explained_variance | 0.821        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.143        |\n",
      "|    mean_step_reward   | 0.08785028   |\n",
      "|    n_updates          | 1224         |\n",
      "|    policyGradLoss     | -0.00613     |\n",
      "|    value_loss         | 0.831        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 832          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 196          |\n",
      "|    total_timesteps    | 2523136      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0069630984 |\n",
      "|    entropy_loss       | -1.99        |\n",
      "|    explained_variance | 0.766        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.242        |\n",
      "|    mean_step_reward   | 0.10482855   |\n",
      "|    n_updates          | 1228         |\n",
      "|    policyGradLoss     | -0.00194     |\n",
      "|    value_loss         | 1.22         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 832          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 206          |\n",
      "|    total_timesteps    | 2531328      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0062845354 |\n",
      "|    entropy_loss       | -1.99        |\n",
      "|    explained_variance | 0.797        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.443        |\n",
      "|    mean_step_reward   | 0.12045297   |\n",
      "|    n_updates          | 1232         |\n",
      "|    policyGradLoss     | -0.00429     |\n",
      "|    value_loss         | 1.34         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 831          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 216          |\n",
      "|    total_timesteps    | 2539520      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0061987946 |\n",
      "|    entropy_loss       | -1.99        |\n",
      "|    explained_variance | 0.867        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.123        |\n",
      "|    mean_step_reward   | 0.090533026  |\n",
      "|    n_updates          | 1236         |\n",
      "|    policyGradLoss     | -0.00718     |\n",
      "|    value_loss         | 0.635        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 830         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 226         |\n",
      "|    total_timesteps    | 2547712     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006858555 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.798       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.2         |\n",
      "|    mean_step_reward   | 0.1185952   |\n",
      "|    n_updates          | 1240        |\n",
      "|    policyGradLoss     | -0.00504    |\n",
      "|    value_loss         | 1.18        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 828          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 237          |\n",
      "|    total_timesteps    | 2555904      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0059407772 |\n",
      "|    entropy_loss       | -1.99        |\n",
      "|    explained_variance | 0.756        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.568        |\n",
      "|    mean_step_reward   | 0.12042314   |\n",
      "|    n_updates          | 1244         |\n",
      "|    policyGradLoss     | -0.00405     |\n",
      "|    value_loss         | 1.36         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 825          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 248          |\n",
      "|    total_timesteps    | 2564096      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0067794155 |\n",
      "|    entropy_loss       | -2.01        |\n",
      "|    explained_variance | 0.8          |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.118        |\n",
      "|    mean_step_reward   | 0.100874014  |\n",
      "|    n_updates          | 1248         |\n",
      "|    policyGradLoss     | -0.00593     |\n",
      "|    value_loss         | 0.927        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 258         |\n",
      "|    total_timesteps    | 2572288     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006612311 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.717       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.32        |\n",
      "|    mean_step_reward   | 0.1055381   |\n",
      "|    n_updates          | 1252        |\n",
      "|    policyGradLoss     | -0.000855   |\n",
      "|    value_loss         | 1.71        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 268         |\n",
      "|    total_timesteps    | 2580480     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009098319 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.891       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.117       |\n",
      "|    mean_step_reward   | 0.11914676  |\n",
      "|    n_updates          | 1256        |\n",
      "|    policyGradLoss     | -0.00587    |\n",
      "|    value_loss         | 0.772       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 822          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 278          |\n",
      "|    total_timesteps    | 2588672      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0066789463 |\n",
      "|    entropy_loss       | -2           |\n",
      "|    explained_variance | 0.843        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.159        |\n",
      "|    mean_step_reward   | 0.12444794   |\n",
      "|    n_updates          | 1260         |\n",
      "|    policyGradLoss     | -0.00275     |\n",
      "|    value_loss         | 0.894        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 288         |\n",
      "|    total_timesteps    | 2596864     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006002481 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.836       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.51        |\n",
      "|    mean_step_reward   | 0.10750927  |\n",
      "|    n_updates          | 1264        |\n",
      "|    policyGradLoss     | -0.00244    |\n",
      "|    value_loss         | 1.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 829         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 2605056     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005683034 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.852       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.176       |\n",
      "|    mean_step_reward   | 0.10805589  |\n",
      "|    n_updates          | 1268        |\n",
      "|    policyGradLoss     | -0.00623    |\n",
      "|    value_loss         | 1.2         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 831          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 305          |\n",
      "|    total_timesteps    | 2613248      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0076442594 |\n",
      "|    entropy_loss       | -2.01        |\n",
      "|    explained_variance | 0.892        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0763       |\n",
      "|    mean_step_reward   | 0.123885214  |\n",
      "|    n_updates          | 1272         |\n",
      "|    policyGradLoss     | -0.00549     |\n",
      "|    value_loss         | 0.961        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 831         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 2621440     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006137221 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.859       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.126       |\n",
      "|    mean_step_reward   | 0.10313383  |\n",
      "|    n_updates          | 1276        |\n",
      "|    policyGradLoss     | -0.00443    |\n",
      "|    value_loss         | 1.06        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/S2K_9.zip\n",
      "[EVAL] Mean Return: 91.866, Best Return: 93.199\n",
      "Saved video to ./runs_smw/videos/S2K/S2K_9_91.87.mp4\n",
      "\n",
      "=== Round 11 | Learn 262144 steps (Total trained: 2621440) ===\n",
      "Logging to ./runs_smw/tb/S2K_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1182    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 6       |\n",
      "|    total_timesteps | 2629632 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 929         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 2637824     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005811628 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.81        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.162       |\n",
      "|    mean_step_reward   | 0.10863504  |\n",
      "|    n_updates          | 1284        |\n",
      "|    policyGradLoss     | -0.00375    |\n",
      "|    value_loss         | 1.26        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 862          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 2646016      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0071405936 |\n",
      "|    entropy_loss       | -2           |\n",
      "|    explained_variance | 0.805        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.472        |\n",
      "|    mean_step_reward   | 0.101464555  |\n",
      "|    n_updates          | 1288         |\n",
      "|    policyGradLoss     | -0.00522     |\n",
      "|    value_loss         | 0.98         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 846         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 2654208     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006665877 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.862       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0703      |\n",
      "|    mean_step_reward   | 0.091599986 |\n",
      "|    n_updates          | 1292        |\n",
      "|    policyGradLoss     | -0.00618    |\n",
      "|    value_loss         | 0.652       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 872         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 46          |\n",
      "|    total_timesteps    | 2662400     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006972773 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.799       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.55        |\n",
      "|    mean_step_reward   | 0.105598755 |\n",
      "|    n_updates          | 1296        |\n",
      "|    policyGradLoss     | -0.000838   |\n",
      "|    value_loss         | 1.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 889         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 55          |\n",
      "|    total_timesteps    | 2670592     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007707885 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.866       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.184       |\n",
      "|    mean_step_reward   | 0.11298828  |\n",
      "|    n_updates          | 1300        |\n",
      "|    policyGradLoss     | -0.00513    |\n",
      "|    value_loss         | 0.967       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 899         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 2678784     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007237075 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.786       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.725       |\n",
      "|    mean_step_reward   | 0.1485848   |\n",
      "|    n_updates          | 1304        |\n",
      "|    policyGradLoss     | -0.00053    |\n",
      "|    value_loss         | 1.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 902         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 2686976     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005961504 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.799       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.313       |\n",
      "|    mean_step_reward   | 0.10313656  |\n",
      "|    n_updates          | 1308        |\n",
      "|    policyGradLoss     | -0.00161    |\n",
      "|    value_loss         | 1.75        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 898         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 2695168     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006765129 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.693       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 5.05        |\n",
      "|    mean_step_reward   | 0.126346    |\n",
      "|    n_updates          | 1312        |\n",
      "|    policyGradLoss     | -0.0016     |\n",
      "|    value_loss         | 5.08        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 887          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 92           |\n",
      "|    total_timesteps    | 2703360      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0054045753 |\n",
      "|    entropy_loss       | -1.97        |\n",
      "|    explained_variance | 0.877        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.139        |\n",
      "|    mean_step_reward   | 0.113908604  |\n",
      "|    n_updates          | 1316         |\n",
      "|    policyGradLoss     | -0.00341     |\n",
      "|    value_loss         | 1.2          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 878          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 102          |\n",
      "|    total_timesteps    | 2711552      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0074479915 |\n",
      "|    entropy_loss       | -1.95        |\n",
      "|    explained_variance | 0.882        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.138        |\n",
      "|    mean_step_reward   | 0.118406646  |\n",
      "|    n_updates          | 1320         |\n",
      "|    policyGradLoss     | -0.00386     |\n",
      "|    value_loss         | 1.01         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 869         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 2719744     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010244292 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.87        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.212       |\n",
      "|    mean_step_reward   | 0.12279845  |\n",
      "|    n_updates          | 1324        |\n",
      "|    policyGradLoss     | -0.00206    |\n",
      "|    value_loss         | 0.968       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 860          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 123          |\n",
      "|    total_timesteps    | 2727936      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0077898027 |\n",
      "|    entropy_loss       | -1.94        |\n",
      "|    explained_variance | 0.873        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.137        |\n",
      "|    mean_step_reward   | 0.118867405  |\n",
      "|    n_updates          | 1328         |\n",
      "|    policyGradLoss     | -0.00389     |\n",
      "|    value_loss         | 0.839        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 855         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 2736128     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008882228 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.881       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.228       |\n",
      "|    mean_step_reward   | 0.13317743  |\n",
      "|    n_updates          | 1332        |\n",
      "|    policyGradLoss     | -0.00439    |\n",
      "|    value_loss         | 0.968       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 852          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 144          |\n",
      "|    total_timesteps    | 2744320      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0068046707 |\n",
      "|    entropy_loss       | -1.95        |\n",
      "|    explained_variance | 0.894        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.137        |\n",
      "|    mean_step_reward   | 0.12166013   |\n",
      "|    n_updates          | 1336         |\n",
      "|    policyGradLoss     | -0.00768     |\n",
      "|    value_loss         | 0.62         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 847         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 2752512     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007235589 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.773       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.263       |\n",
      "|    mean_step_reward   | 0.13454187  |\n",
      "|    n_updates          | 1340        |\n",
      "|    policyGradLoss     | -0.00201    |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 846          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 164          |\n",
      "|    total_timesteps    | 2760704      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0062877974 |\n",
      "|    entropy_loss       | -1.95        |\n",
      "|    explained_variance | 0.875        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.116        |\n",
      "|    mean_step_reward   | 0.1253738    |\n",
      "|    n_updates          | 1344         |\n",
      "|    policyGradLoss     | -0.00542     |\n",
      "|    value_loss         | 1.09         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 853         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 172         |\n",
      "|    total_timesteps    | 2768896     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006151763 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.876       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.17        |\n",
      "|    mean_step_reward   | 0.117081255 |\n",
      "|    n_updates          | 1348        |\n",
      "|    policyGradLoss     | -0.00425    |\n",
      "|    value_loss         | 0.719       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 859        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 180        |\n",
      "|    total_timesteps    | 2777088    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00842242 |\n",
      "|    entropy_loss       | -1.98      |\n",
      "|    explained_variance | 0.843      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.04       |\n",
      "|    mean_step_reward   | 0.11627054 |\n",
      "|    n_updates          | 1352       |\n",
      "|    policyGradLoss     | -0.00175   |\n",
      "|    value_loss         | 0.919      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 856         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 2785280     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006303205 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.852       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.451       |\n",
      "|    mean_step_reward   | 0.104516625 |\n",
      "|    n_updates          | 1356        |\n",
      "|    policyGradLoss     | -0.00487    |\n",
      "|    value_loss         | 0.918       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 850         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 202         |\n",
      "|    total_timesteps    | 2793472     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007057669 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.831       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.104       |\n",
      "|    mean_step_reward   | 0.11062908  |\n",
      "|    n_updates          | 1360        |\n",
      "|    policyGradLoss     | -0.00637    |\n",
      "|    value_loss         | 0.883       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 847          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 212          |\n",
      "|    total_timesteps    | 2801664      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0063417098 |\n",
      "|    entropy_loss       | -2.02        |\n",
      "|    explained_variance | 0.774        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.165        |\n",
      "|    mean_step_reward   | 0.092694454  |\n",
      "|    n_updates          | 1364         |\n",
      "|    policyGradLoss     | -0.00156     |\n",
      "|    value_loss         | 1.27         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 845         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 2809856     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005663017 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.824       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.231       |\n",
      "|    mean_step_reward   | 0.11175004  |\n",
      "|    n_updates          | 1368        |\n",
      "|    policyGradLoss     | -0.0069     |\n",
      "|    value_loss         | 1           |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 843         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 2818048     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006510156 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.877       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.11        |\n",
      "|    mean_step_reward   | 0.10380794  |\n",
      "|    n_updates          | 1372        |\n",
      "|    policyGradLoss     | -0.00606    |\n",
      "|    value_loss         | 0.688       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 839          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 243          |\n",
      "|    total_timesteps    | 2826240      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0050891815 |\n",
      "|    entropy_loss       | -2.03        |\n",
      "|    explained_variance | 0.702        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.277        |\n",
      "|    mean_step_reward   | 0.10829937   |\n",
      "|    n_updates          | 1376         |\n",
      "|    policyGradLoss     | -0.00271     |\n",
      "|    value_loss         | 1.67         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 836         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 254         |\n",
      "|    total_timesteps    | 2834432     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006456564 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.827       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.325       |\n",
      "|    mean_step_reward   | 0.11435943  |\n",
      "|    n_updates          | 1380        |\n",
      "|    policyGradLoss     | -0.00296    |\n",
      "|    value_loss         | 1.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 835         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 2842624     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007768691 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.819       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.143       |\n",
      "|    mean_step_reward   | 0.115790665 |\n",
      "|    n_updates          | 1384        |\n",
      "|    policyGradLoss     | -0.00667    |\n",
      "|    value_loss         | 0.782       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 835          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 274          |\n",
      "|    total_timesteps    | 2850816      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0069301464 |\n",
      "|    entropy_loss       | -1.99        |\n",
      "|    explained_variance | 0.828        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.2          |\n",
      "|    mean_step_reward   | 0.12186256   |\n",
      "|    n_updates          | 1388         |\n",
      "|    policyGradLoss     | -0.00485     |\n",
      "|    value_loss         | 1.15         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 832         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 2859008     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006921794 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.886       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.563       |\n",
      "|    mean_step_reward   | 0.11874138  |\n",
      "|    n_updates          | 1392        |\n",
      "|    policyGradLoss     | -0.00605    |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 831        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 295        |\n",
      "|    total_timesteps    | 2867200    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00759029 |\n",
      "|    entropy_loss       | -2.03      |\n",
      "|    explained_variance | 0.826      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0978     |\n",
      "|    mean_step_reward   | 0.09422589 |\n",
      "|    n_updates          | 1396       |\n",
      "|    policyGradLoss     | -0.00603   |\n",
      "|    value_loss         | 0.677      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 830          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 305          |\n",
      "|    total_timesteps    | 2875392      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0062941452 |\n",
      "|    entropy_loss       | -2.02        |\n",
      "|    explained_variance | 0.589        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.37         |\n",
      "|    mean_step_reward   | 0.13163728   |\n",
      "|    n_updates          | 1400         |\n",
      "|    policyGradLoss     | 0.00471      |\n",
      "|    value_loss         | 4.96         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 828          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 316          |\n",
      "|    total_timesteps    | 2883584      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0075680483 |\n",
      "|    entropy_loss       | -2.03        |\n",
      "|    explained_variance | 0.82         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.498        |\n",
      "|    mean_step_reward   | 0.12099716   |\n",
      "|    n_updates          | 1404         |\n",
      "|    policyGradLoss     | -0.0037      |\n",
      "|    value_loss         | 1.83         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/S2K_10.zip\n",
      "[EVAL] Mean Return: 45.350, Best Return: 46.016\n",
      "Saved video to ./runs_smw/videos/S2K/S2K_10_45.35.mp4\n",
      "\n",
      "=== Round 12 | Learn 262144 steps (Total trained: 2883584) ===\n",
      "Logging to ./runs_smw/tb/S2K_0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    while trained < TOTAL_STEPS:\n",
    "        round_idx += 1\n",
    "        chunk = min(TRAIN_CHUNK, TOTAL_STEPS - trained)\n",
    "        # chunk = 2000\n",
    "        label = \"S2K\" # smushed to killed\n",
    "        tagged_label = f\"{label}_{int(trained/TRAIN_CHUNK)}\"\n",
    "\n",
    "        print(f\"\\n=== Round {round_idx} | Learn {chunk} steps (Total trained: {trained}) ===\")\n",
    "        \n",
    "        # --- Train ---\n",
    "        model.learn(total_timesteps=chunk, reset_num_timesteps=False, tb_log_name=label)\n",
    "        trained += chunk\n",
    "\n",
    "        # --- Save Checkpoint ---\n",
    "        ckpt_path = os.path.join(CKPT_DIR, f\"{tagged_label}.zip\")\n",
    "        model.save(ckpt_path)\n",
    "        print(f\"Saved checkpoint: {ckpt_path}\")\n",
    "\n",
    "        # --- Evaluate ---\n",
    "        mean_ret, best_ret = evaluate_policy(\n",
    "            model,\n",
    "            GAME,\n",
    "            STATE,\n",
    "            n_episodes=EVAL_EPISODES,\n",
    "            max_steps=EVAL_MAX_STEPS,\n",
    "        )\n",
    "        print(f\"[EVAL] Mean Return: {mean_ret:.3f}, Best Return: {best_ret:.3f}\")\n",
    "\n",
    "        # --- Save Best Model ---\n",
    "        # if mean_ret > best_mean:\n",
    "        #     best_mean = mean_ret\n",
    "        #     best_path = os.path.join(LOG_DIR, \"best_model.zip\")\n",
    "        #     model.save(best_path)\n",
    "        #     print(f\"New best record. Saved to {best_path}\")\n",
    "\n",
    "        # --- Record Video ---\n",
    "        out_path = os.path.join(VIDEO_DIR, label)\n",
    "        os.makedirs(out_path,  exist_ok=True)\n",
    "        record_video(\n",
    "            model,\n",
    "            GAME,\n",
    "            STATE,\n",
    "            VIDEO_DIR,\n",
    "            video_len=RECORD_STEPS,\n",
    "            prefix=f\"{label}/{tagged_label}_{mean_ret:.2f}\",\n",
    "        )\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nTraining interrupted manually.\")\n",
    "\n",
    "finally:\n",
    "    train_env.close()\n",
    "    print(\"Training finished. Environment closed.\")\n",
    "    \n",
    "\"\"\"\n",
    "tensorboard --logdir=./runs_smw/tb\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f088b0b3-2418-4866-b332-0312c9f6467f",
   "metadata": {},
   "source": [
    "## Display Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73191bb-e875-4939-b04c-a4670abd9612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "import glob\n",
    "# label = \"Dec22A\"\n",
    "\n",
    "# list_of_files = glob.glob(os.path.join(VIDEO_DIR, label, '*.mp4')) \n",
    "# if list_of_files:\n",
    "#     latest_file = max(list_of_files, key=os.path.getctime)\n",
    "#     print(f\"Playing: {latest_file}\")\n",
    "#     latest_file = \"runs_smw/videos/Dec22A/Dec22A_73_596.54.mp4\"\n",
    "#     print(f\"Playing: {latest_file}\")\n",
    "#     display(Video(latest_file, embed=True, width=768))\n",
    "# else:\n",
    "#     print(\"No videos found yet.\")\n",
    "    \n",
    "video = \"./runs_smw/videos/Dec22A/Dec22A_73_596.54.mp4\"\n",
    "# display(Video(video, embed=True, width=768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942adf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(\"runs_smw/videos/test_16.mp4\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    cv2.imshow(\"Frame-by-Frame\", frame)\n",
    "\n",
    "    # ÈóúÈçµÔºöÈÄôË£°Á≠âÂæÖÊåâÈçµ„ÄÇÊåâ 'n' ÈçµË∑≥Âà∞‰∏ã‰∏ÄÂπÄÔºåÊåâ 'q' Èõ¢Èñã\n",
    "    key = cv2.waitKey(0) \n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('n'):\n",
    "        continue\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lab8 (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
