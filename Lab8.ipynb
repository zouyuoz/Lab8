{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dceedafe-2782-41a1-8119-50ee3d6c21fd",
   "metadata": {},
   "source": [
    "# 2025 DL Lab8: RL Assignment_Super Mario World"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fa555a-e61c-4fb3-b5d0-289b66570139",
   "metadata": {},
   "source": [
    "**Your Answer:**    \n",
    "Hi I'm XXX, XXXXXXXXXX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5b0974-9605-488a-9fd5-00816e7832cc",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This project implements a **Deep Reinforcement Learning** pipeline to train an autonomous agent for Super Mario World. Leveraging the **Proximal Policy Optimization (PPO)** algorithm, the system interacts with the **stable-retro** environment to master the YoshiIsland1 level. Key components include a custom Vision Backbone for extracting features from raw pixel data and a suite of Environment Wrappers that handle frame preprocessing, action discretization, and reward shaping to facilitate efficient learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02696447",
   "metadata": {},
   "source": [
    "Reward function implement  \n",
    "should do something in the beginning (monster attack)  \n",
    "Custom PPO implement  \n",
    "pre train weight 差不多，主要是 reward function  \n",
    "model weight capacity 1GB  \n",
    "class name 不要動 (可以新增，但是原本有的不要動)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8a0ab9-f86d-4038-833d-761ec81fc4f2",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00b10def-362c-4910-9ed0-f3d0904343ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import retro\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "\n",
    "from eval import evaluate_policy, record_video\n",
    "from custom_policy import VisionBackbonePolicy, CustomPPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10361fd-f291-4d93-b50d-cc749a3af588",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b4f6a25-738c-49dd-8e66-ae164b74a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game Settings\n",
    "GAME = \"SuperMarioWorld-Snes\"\n",
    "STATE = \"YoshiIsland1\"\n",
    "\n",
    "# Training Settings\n",
    "# TOTAL_STEPS = 0x1400000 # 20,971,520\n",
    "# TOTAL_STEPS = 0x0A00000 # 10,485,760\n",
    "TOTAL_STEPS = 0X3200000 # 52,428,800\n",
    "TRAIN_CHUNK = 0x0040000 #    262,144\n",
    "N_ENVS = 16\n",
    "\n",
    "# Evaluation & Recording Settings\n",
    "EVAL_EPISODES = 3\n",
    "EVAL_MAX_STEPS = 18000\n",
    "RECORD_STEPS = 1800\n",
    "\n",
    "# Directories\n",
    "LOG_DIR = \"./runs_smw\"\n",
    "VIDEO_DIR       = os.path.join(LOG_DIR, \"videos\")\n",
    "CKPT_DIR        = os.path.join(LOG_DIR, \"checkpoints\")\n",
    "TENSORBOARD_LOG = os.path.join(LOG_DIR, \"tb\")\n",
    "\n",
    "os.makedirs(LOG_DIR,   exist_ok=True)\n",
    "os.makedirs(CKPT_DIR,  exist_ok=True)\n",
    "os.makedirs(VIDEO_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a34b783-0273-4835-ad2e-f9186064f76f",
   "metadata": {},
   "source": [
    "## Environment Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c34213d-2c7c-42b8-922d-bafa285d1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrappers import make_base_env\n",
    "def _make_env_thunk(game: str, state: str):\n",
    "    \"\"\"Return a function that creates an environment (for multiprocessing).\"\"\"\n",
    "    def _thunk():\n",
    "        return make_base_env(game, state)\n",
    "    return _thunk\n",
    "\n",
    "def make_vec_env(game: str, state: str, n_envs: int, use_subproc: bool = True):\n",
    "    \"\"\"Create a vectorized environment (multiple envs running in parallel).\"\"\"\n",
    "    env_fns = [_make_env_thunk(game, state) for _ in range(n_envs)]\n",
    "    \n",
    "    if use_subproc and n_envs > 1:\n",
    "        vec_env = SubprocVecEnv(env_fns)\n",
    "    else:\n",
    "        vec_env = DummyVecEnv(env_fns)\n",
    "\n",
    "    return vec_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dff476-ea2e-4262-8780-afb32ef1b233",
   "metadata": {},
   "source": [
    "## Initialize Env & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c7c5fe-6421-4dbc-9bd8-822d61769c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment created: SuperMarioWorld-Snes - YoshiIsland1 with 16 parallel envs.\n",
      "[Sucess] Loaded model from runs_smw/preserved/Enc5_67.zip\n",
      "trained: 17825792, round_index: 68\n"
     ]
    }
   ],
   "source": [
    "# 1. Create Training Environment\n",
    "train_env = make_vec_env(GAME, STATE, n_envs=N_ENVS)\n",
    "# train_env = VecNormalize(train_env, norm_obs=True, norm_reward=True, clip_obs=10., clip_reward=10.)\n",
    "print(f\"Environment created: {GAME} - {STATE} with {N_ENVS} parallel envs.\")\n",
    "\n",
    "checkpoint_path = \"None\" # 6225920 (19) 有破壞\n",
    "checkpoint_path = \"runs_smw/preserved/Enc5_67.zip\"\n",
    "\n",
    "best_mean = -1e18\n",
    "trained = 0\n",
    "round_idx = 0\n",
    "\n",
    "# 2. Initialize Model\n",
    "if os.path.exists(checkpoint_path):\n",
    "    # 讀取現有模型\n",
    "    model = CustomPPO.load(\n",
    "        checkpoint_path, \n",
    "        env=train_env,\n",
    "        device=\"cuda:0\" # 確保使用 GPU\n",
    "    )\n",
    "    trained = model.num_timesteps\n",
    "    round_idx = int(trained / TRAIN_CHUNK)\n",
    "    print(f\"[Sucess] Loaded model from {checkpoint_path}\")\n",
    "    print(f\"trained: {trained}, round_index: {round_idx}\")\n",
    "else:\n",
    "    print(f\"[Fail] Can't load {checkpoint_path}. Will use new model\")\n",
    "    model = CustomPPO(\n",
    "        VisionBackbonePolicy,\n",
    "        train_env,\n",
    "        policy_kwargs   = dict(normalize_images=False),\n",
    "        n_epochs        = 4,\n",
    "        n_steps         = 512,\n",
    "        batch_size      = 512,\n",
    "        learning_rate   = 1e-4,\n",
    "        verbose         = 1,\n",
    "        gamma           = 0.96875,\n",
    "        kl_coef         = 1,\n",
    "        clip_range      = 0.125,\n",
    "        ent_coef        = 0.0375,\n",
    "        tensorboard_log = TENSORBOARD_LOG,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cb3d0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"policy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eb7a896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "# from custom_policy import CustomPPO\n",
    "# from eval import record_video  # 確保 eval.py 在同一目錄下\n",
    "\n",
    "# # ================= 設定區 =================\n",
    "# target_numbers = [59, 63, 67]\n",
    "\n",
    "# # ================= 執行迴圈 =================\n",
    "# print(f\"準備測試以下 Checkpoints: {target_numbers}\")\n",
    "\n",
    "# for num in target_numbers:\n",
    "#     model_path = os.path.join(CKPT_DIR, f\"Enc5_{num}.zip\")\n",
    "    \n",
    "#     # 檢查檔案是否存在\n",
    "#     if not os.path.exists(model_path):\n",
    "#         print(f\"⚠️ 找不到檔案: {model_path}，跳過。\")\n",
    "#         continue\n",
    "    \n",
    "#     print(f\"\\n[{num}] 正在載入模型: {model_path} ...\")\n",
    "    \n",
    "#     try:\n",
    "#         # 1. 載入模型 (不需要 env 參數也能載入權重)\n",
    "#         # 如果你有改過 CustomPPO 的參數，load 會自動讀取 zip 裡的設定\n",
    "#         model = CustomPPO.load(model_path, device=\"auto\") # device=\"auto\" 會自動用 GPU\n",
    "        \n",
    "#         # 2. 錄製影片\n",
    "#         prefix_name = f\"test_{num}\"\n",
    "#         print(f\"[{num}] 正在錄影 (長度 {RECORD_STEPS} steps)...\")\n",
    "        \n",
    "#         record_video(\n",
    "#             model=model,\n",
    "#             game=GAME,\n",
    "#             state=STATE,\n",
    "#             out_dir=VIDEO_DIR,\n",
    "#             video_len=RECORD_STEPS,\n",
    "#             prefix=prefix_name\n",
    "#         )\n",
    "#         print(f\"✅ 完成！影片已儲存為 {prefix_name}.mp4\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"❌ 發生錯誤 (Model: {num}): {e}\")\n",
    "\n",
    "# print(\"\\n所有測試結束。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f594e443-843f-42c1-9fc6-3fbc82962021",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af4932-c531-4113-a33a-defc6fb5858e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Round 69 | Learn 262144 steps (Total trained: 17825792) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1074     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 17833984 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 894         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 17842176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013940858 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.367       |\n",
      "|    mean_step_reward   | 0.28193492  |\n",
      "|    n_updates          | 8708        |\n",
      "|    policyGradLoss     | 0.00121     |\n",
      "|    value_loss         | 1.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 845         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 17850368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017454524 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.124       |\n",
      "|    mean_step_reward   | 0.4244149   |\n",
      "|    n_updates          | 8712        |\n",
      "|    policyGradLoss     | 0.00616     |\n",
      "|    value_loss         | 2.92        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 832         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 17858560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011777978 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.17        |\n",
      "|    mean_step_reward   | 0.31208032  |\n",
      "|    n_updates          | 8716        |\n",
      "|    policyGradLoss     | 0.0023      |\n",
      "|    value_loss         | 3.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 17866752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012947375 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.481       |\n",
      "|    mean_step_reward   | 0.4081847   |\n",
      "|    n_updates          | 8720        |\n",
      "|    policyGradLoss     | -0.00328    |\n",
      "|    value_loss         | 2.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 17874944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012518658 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.522       |\n",
      "|    mean_step_reward   | 0.37979358  |\n",
      "|    n_updates          | 8724        |\n",
      "|    policyGradLoss     | -0.00573    |\n",
      "|    value_loss         | 1.75        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 17883136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011766487 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.111       |\n",
      "|    mean_step_reward   | 0.3311075   |\n",
      "|    n_updates          | 8728        |\n",
      "|    policyGradLoss     | -0.00637    |\n",
      "|    value_loss         | 1.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 17891328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015624771 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 2.33        |\n",
      "|    mean_step_reward   | 0.37848362  |\n",
      "|    n_updates          | 8732        |\n",
      "|    policyGradLoss     | 0.00226     |\n",
      "|    value_loss         | 5.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 17899520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010931309 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.26        |\n",
      "|    mean_step_reward   | 0.3221234   |\n",
      "|    n_updates          | 8736        |\n",
      "|    policyGradLoss     | -0.000959   |\n",
      "|    value_loss         | 3.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 17907712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010301717 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.28        |\n",
      "|    mean_step_reward   | 0.33723986  |\n",
      "|    n_updates          | 8740        |\n",
      "|    policyGradLoss     | -0.000564   |\n",
      "|    value_loss         | 2.97        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 790        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 113        |\n",
      "|    total_timesteps    | 17915904   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00989352 |\n",
      "|    entropy_loss       | -1.71      |\n",
      "|    explained_variance | 0.974      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.849      |\n",
      "|    mean_step_reward   | 0.34806854 |\n",
      "|    n_updates          | 8744       |\n",
      "|    policyGradLoss     | -0.00454   |\n",
      "|    value_loss         | 2.02       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 17924096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015442469 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.567       |\n",
      "|    mean_step_reward   | 0.31591833  |\n",
      "|    n_updates          | 8748        |\n",
      "|    policyGradLoss     | -0.00414    |\n",
      "|    value_loss         | 1.5         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 17932288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012112937 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.324       |\n",
      "|    mean_step_reward   | 0.32138908  |\n",
      "|    n_updates          | 8752        |\n",
      "|    policyGradLoss     | -0.00401    |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 17940480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012388319 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.553       |\n",
      "|    mean_step_reward   | 0.40826607  |\n",
      "|    n_updates          | 8756        |\n",
      "|    policyGradLoss     | -0.00245    |\n",
      "|    value_loss         | 2.46        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 785        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 156        |\n",
      "|    total_timesteps    | 17948672   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.011474   |\n",
      "|    entropy_loss       | -1.74      |\n",
      "|    explained_variance | 0.979      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.01       |\n",
      "|    mean_step_reward   | 0.32283062 |\n",
      "|    n_updates          | 8760       |\n",
      "|    policyGradLoss     | -0.00343   |\n",
      "|    value_loss         | 2.21       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 17956864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013368331 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.84        |\n",
      "|    mean_step_reward   | 0.41906637  |\n",
      "|    n_updates          | 8764        |\n",
      "|    policyGradLoss     | -0.00431    |\n",
      "|    value_loss         | 1.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 17965056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008411147 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.779       |\n",
      "|    mean_step_reward   | 0.3516072   |\n",
      "|    n_updates          | 8768        |\n",
      "|    policyGradLoss     | -0.00344    |\n",
      "|    value_loss         | 2.3         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 786          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 187          |\n",
      "|    total_timesteps    | 17973248     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0091541745 |\n",
      "|    entropy_loss       | -1.71        |\n",
      "|    explained_variance | 0.981        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.629        |\n",
      "|    mean_step_reward   | 0.34049043   |\n",
      "|    n_updates          | 8772         |\n",
      "|    policyGradLoss     | -0.00548     |\n",
      "|    value_loss         | 1.69         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 17981440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015727896 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.189       |\n",
      "|    mean_step_reward   | 0.38801     |\n",
      "|    n_updates          | 8776        |\n",
      "|    policyGradLoss     | -0.00795    |\n",
      "|    value_loss         | 0.997       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 17989632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011288008 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.922       |\n",
      "|    mean_step_reward   | 0.37465528  |\n",
      "|    n_updates          | 8780        |\n",
      "|    policyGradLoss     | -0.00155    |\n",
      "|    value_loss         | 1.99        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 784          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 219          |\n",
      "|    total_timesteps    | 17997824     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0075820116 |\n",
      "|    entropy_loss       | -1.68        |\n",
      "|    explained_variance | 0.988        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.35         |\n",
      "|    mean_step_reward   | 0.40357372   |\n",
      "|    n_updates          | 8784         |\n",
      "|    policyGradLoss     | -0.00458     |\n",
      "|    value_loss         | 1.85         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 18006016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016459376 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.589       |\n",
      "|    mean_step_reward   | 0.36041003  |\n",
      "|    n_updates          | 8788        |\n",
      "|    policyGradLoss     | -0.00745    |\n",
      "|    value_loss         | 1.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 18014208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011586869 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.844       |\n",
      "|    mean_step_reward   | 0.38815373  |\n",
      "|    n_updates          | 8792        |\n",
      "|    policyGradLoss     | -0.00791    |\n",
      "|    value_loss         | 1.86        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 18022400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009071708 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.48        |\n",
      "|    mean_step_reward   | 0.3336116   |\n",
      "|    n_updates          | 8796        |\n",
      "|    policyGradLoss     | -0.0056     |\n",
      "|    value_loss         | 1.8         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 18030592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010826277 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.483       |\n",
      "|    mean_step_reward   | 0.39753866  |\n",
      "|    n_updates          | 8800        |\n",
      "|    policyGradLoss     | -0.00266    |\n",
      "|    value_loss         | 2.12        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 781          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 272          |\n",
      "|    total_timesteps    | 18038784     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0101126665 |\n",
      "|    entropy_loss       | -1.7         |\n",
      "|    explained_variance | 0.965        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.562        |\n",
      "|    mean_step_reward   | 0.38618997   |\n",
      "|    n_updates          | 8804         |\n",
      "|    policyGradLoss     | -0.00382     |\n",
      "|    value_loss         | 3.14         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 18046976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009701076 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.423       |\n",
      "|    mean_step_reward   | 0.36737782  |\n",
      "|    n_updates          | 8808        |\n",
      "|    policyGradLoss     | -0.00559    |\n",
      "|    value_loss         | 1.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 18055168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010845505 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.521       |\n",
      "|    mean_step_reward   | 0.3514567   |\n",
      "|    n_updates          | 8812        |\n",
      "|    policyGradLoss     | -0.00156    |\n",
      "|    value_loss         | 2.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 18063360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011125724 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.503       |\n",
      "|    mean_step_reward   | 0.35230342  |\n",
      "|    n_updates          | 8816        |\n",
      "|    policyGradLoss     | 0.00309     |\n",
      "|    value_loss         | 2.65        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 18071552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008500015 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.883       |\n",
      "|    mean_step_reward   | 0.35836926  |\n",
      "|    n_updates          | 8820        |\n",
      "|    policyGradLoss     | -0.00329    |\n",
      "|    value_loss         | 1.83        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 18079744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013212847 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.698       |\n",
      "|    mean_step_reward   | 0.33766186  |\n",
      "|    n_updates          | 8824        |\n",
      "|    policyGradLoss     | -0.00231    |\n",
      "|    value_loss         | 2.46        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 18087936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012493126 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.952       |\n",
      "|    mean_step_reward   | 0.38431376  |\n",
      "|    n_updates          | 8828        |\n",
      "|    policyGradLoss     | 0.000609    |\n",
      "|    value_loss         | 3.13        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_68.zip\n",
      "[EVAL] Mean Return: 520.960, Best Return: 525.627\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_68_520.96.mp4\n",
      "\n",
      "=== Round 70 | Learn 262144 steps (Total trained: 18087936) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1106     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 18096128 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 894         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 18104320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011413626 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.09        |\n",
      "|    mean_step_reward   | 0.3134743   |\n",
      "|    n_updates          | 8836        |\n",
      "|    policyGradLoss     | -0.000194   |\n",
      "|    value_loss         | 2.53        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 845         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 18112512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017725103 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.566       |\n",
      "|    mean_step_reward   | 0.3549978   |\n",
      "|    n_updates          | 8840        |\n",
      "|    policyGradLoss     | 0.000178    |\n",
      "|    value_loss         | 3.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 18120704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010669896 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.435       |\n",
      "|    mean_step_reward   | 0.36398688  |\n",
      "|    n_updates          | 8844        |\n",
      "|    policyGradLoss     | -0.00471    |\n",
      "|    value_loss         | 1.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 18128896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011873654 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.641       |\n",
      "|    mean_step_reward   | 0.36764473  |\n",
      "|    n_updates          | 8848        |\n",
      "|    policyGradLoss     | -0.00311    |\n",
      "|    value_loss         | 2.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 18137088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009365433 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.08        |\n",
      "|    mean_step_reward   | 0.38305783  |\n",
      "|    n_updates          | 8852        |\n",
      "|    policyGradLoss     | -0.00394    |\n",
      "|    value_loss         | 2.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 18145280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012076134 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.974       |\n",
      "|    mean_step_reward   | 0.3631462   |\n",
      "|    n_updates          | 8856        |\n",
      "|    policyGradLoss     | -0.00218    |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 18153472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012724112 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.367       |\n",
      "|    mean_step_reward   | 0.40164515  |\n",
      "|    n_updates          | 8860        |\n",
      "|    policyGradLoss     | -0.00629    |\n",
      "|    value_loss         | 1.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 18161664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009588774 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.561       |\n",
      "|    mean_step_reward   | 0.36375773  |\n",
      "|    n_updates          | 8864        |\n",
      "|    policyGradLoss     | -0.0049     |\n",
      "|    value_loss         | 2.73        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 789        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 103        |\n",
      "|    total_timesteps    | 18169856   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01566312 |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.956      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.314      |\n",
      "|    mean_step_reward   | 0.3985302  |\n",
      "|    n_updates          | 8868       |\n",
      "|    policyGradLoss     | -0.00397   |\n",
      "|    value_loss         | 2.04       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 18178048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013027577 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.546       |\n",
      "|    mean_step_reward   | 0.35974836  |\n",
      "|    n_updates          | 8872        |\n",
      "|    policyGradLoss     | -0.00148    |\n",
      "|    value_loss         | 1.74        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 18186240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013492099 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.69        |\n",
      "|    mean_step_reward   | 0.37573344  |\n",
      "|    n_updates          | 8876        |\n",
      "|    policyGradLoss     | 0.000329    |\n",
      "|    value_loss         | 4.65        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 18194432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013909595 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.49        |\n",
      "|    mean_step_reward   | 0.40026996  |\n",
      "|    n_updates          | 8880        |\n",
      "|    policyGradLoss     | 0.00151     |\n",
      "|    value_loss         | 4.67        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 780        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 146        |\n",
      "|    total_timesteps    | 18202624   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01826289 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.97       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.799      |\n",
      "|    mean_step_reward   | 0.32777244 |\n",
      "|    n_updates          | 8884       |\n",
      "|    policyGradLoss     | -0.000982  |\n",
      "|    value_loss         | 2.12       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 18210816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012158565 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.778       |\n",
      "|    mean_step_reward   | 0.37463585  |\n",
      "|    n_updates          | 8888        |\n",
      "|    policyGradLoss     | -0.00348    |\n",
      "|    value_loss         | 2.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 18219008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014519107 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.386       |\n",
      "|    mean_step_reward   | 0.32968003  |\n",
      "|    n_updates          | 8892        |\n",
      "|    policyGradLoss     | -0.00536    |\n",
      "|    value_loss         | 1.76        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 18227200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010887941 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.643       |\n",
      "|    mean_step_reward   | 0.39133793  |\n",
      "|    n_updates          | 8896        |\n",
      "|    policyGradLoss     | -0.00474    |\n",
      "|    value_loss         | 1.86        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 18235392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008859388 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.407       |\n",
      "|    mean_step_reward   | 0.3376271   |\n",
      "|    n_updates          | 8900        |\n",
      "|    policyGradLoss     | -0.00688    |\n",
      "|    value_loss         | 1.96        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 18243584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014196027 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.377       |\n",
      "|    mean_step_reward   | 0.36546394  |\n",
      "|    n_updates          | 8904        |\n",
      "|    policyGradLoss     | -0.000696   |\n",
      "|    value_loss         | 3.48        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 779          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 210          |\n",
      "|    total_timesteps    | 18251776     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0152066685 |\n",
      "|    entropy_loss       | -1.66        |\n",
      "|    explained_variance | 0.98         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.313        |\n",
      "|    mean_step_reward   | 0.3207365    |\n",
      "|    n_updates          | 8908         |\n",
      "|    policyGradLoss     | -0.00551     |\n",
      "|    value_loss         | 1.24         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 221        |\n",
      "|    total_timesteps    | 18259968   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01069759 |\n",
      "|    entropy_loss       | -1.65      |\n",
      "|    explained_variance | 0.988      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.181      |\n",
      "|    mean_step_reward   | 0.405983   |\n",
      "|    n_updates          | 8912       |\n",
      "|    policyGradLoss     | -0.00401   |\n",
      "|    value_loss         | 1.13       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 18268160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008489641 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.724       |\n",
      "|    mean_step_reward   | 0.40702918  |\n",
      "|    n_updates          | 8916        |\n",
      "|    policyGradLoss     | -0.00723    |\n",
      "|    value_loss         | 1.8         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 18276352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007589576 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.727       |\n",
      "|    mean_step_reward   | 0.37607777  |\n",
      "|    n_updates          | 8920        |\n",
      "|    policyGradLoss     | -0.0042     |\n",
      "|    value_loss         | 2.12        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 777          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 252          |\n",
      "|    total_timesteps    | 18284544     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0111929625 |\n",
      "|    entropy_loss       | -1.63        |\n",
      "|    explained_variance | 0.991        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.585        |\n",
      "|    mean_step_reward   | 0.37524158   |\n",
      "|    n_updates          | 8924         |\n",
      "|    policyGradLoss     | -0.00672     |\n",
      "|    value_loss         | 1.13         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 18292736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010159891 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.03        |\n",
      "|    mean_step_reward   | 0.35680404  |\n",
      "|    n_updates          | 8928        |\n",
      "|    policyGradLoss     | -0.00549    |\n",
      "|    value_loss         | 2.11        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 18300928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008209983 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.901       |\n",
      "|    mean_step_reward   | 0.32416528  |\n",
      "|    n_updates          | 8932        |\n",
      "|    policyGradLoss     | -0.00317    |\n",
      "|    value_loss         | 2.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 18309120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012160011 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.327       |\n",
      "|    mean_step_reward   | 0.36847863  |\n",
      "|    n_updates          | 8936        |\n",
      "|    policyGradLoss     | -0.00408    |\n",
      "|    value_loss         | 1.83        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 776        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 295        |\n",
      "|    total_timesteps    | 18317312   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00911759 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.986      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.802      |\n",
      "|    mean_step_reward   | 0.3274988  |\n",
      "|    n_updates          | 8940       |\n",
      "|    policyGradLoss     | -0.00544   |\n",
      "|    value_loss         | 1.42       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 305        |\n",
      "|    total_timesteps    | 18325504   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01659707 |\n",
      "|    entropy_loss       | -1.62      |\n",
      "|    explained_variance | 0.992      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.114      |\n",
      "|    mean_step_reward   | 0.37042361 |\n",
      "|    n_updates          | 8944       |\n",
      "|    policyGradLoss     | -0.00863   |\n",
      "|    value_loss         | 0.757      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 18333696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009846116 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.06        |\n",
      "|    mean_step_reward   | 0.3436339   |\n",
      "|    n_updates          | 8948        |\n",
      "|    policyGradLoss     | -0.00288    |\n",
      "|    value_loss         | 2.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 18341888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014649701 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.34        |\n",
      "|    mean_step_reward   | 0.3294638   |\n",
      "|    n_updates          | 8952        |\n",
      "|    policyGradLoss     | -0.00469    |\n",
      "|    value_loss         | 1.93        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 18350080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013011266 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.618       |\n",
      "|    mean_step_reward   | 0.35947403  |\n",
      "|    n_updates          | 8956        |\n",
      "|    policyGradLoss     | -0.00596    |\n",
      "|    value_loss         | 1.17        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_69.zip\n",
      "[EVAL] Mean Return: 524.401, Best Return: 530.401\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_69_524.40.mp4\n",
      "\n",
      "=== Round 71 | Learn 262144 steps (Total trained: 18350080) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1131     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 18358272 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 921         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 18366464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009198898 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.832       |\n",
      "|    mean_step_reward   | 0.38171086  |\n",
      "|    n_updates          | 8964        |\n",
      "|    policyGradLoss     | -0.000393   |\n",
      "|    value_loss         | 2.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 857         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 18374656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010978136 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.55        |\n",
      "|    mean_step_reward   | 0.399112    |\n",
      "|    n_updates          | 8968        |\n",
      "|    policyGradLoss     | -0.00127    |\n",
      "|    value_loss         | 2.64        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 833         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 18382848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009397853 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.77        |\n",
      "|    mean_step_reward   | 0.38857728  |\n",
      "|    n_updates          | 8972        |\n",
      "|    policyGradLoss     | 0.00219     |\n",
      "|    value_loss         | 3.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 18391040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012218166 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.579       |\n",
      "|    mean_step_reward   | 0.35586533  |\n",
      "|    n_updates          | 8976        |\n",
      "|    policyGradLoss     | -0.00423    |\n",
      "|    value_loss         | 2.11        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 18399232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014337786 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.409       |\n",
      "|    mean_step_reward   | 0.38809472  |\n",
      "|    n_updates          | 8980        |\n",
      "|    policyGradLoss     | -0.00202    |\n",
      "|    value_loss         | 2.04        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 18407424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009972412 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.51        |\n",
      "|    mean_step_reward   | 0.4009027   |\n",
      "|    n_updates          | 8984        |\n",
      "|    policyGradLoss     | -0.00212    |\n",
      "|    value_loss         | 2.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 18415616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013272949 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.446       |\n",
      "|    mean_step_reward   | 0.31654507  |\n",
      "|    n_updates          | 8988        |\n",
      "|    policyGradLoss     | 0.00337     |\n",
      "|    value_loss         | 3.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 18423808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011668224 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.652       |\n",
      "|    mean_step_reward   | 0.3529095   |\n",
      "|    n_updates          | 8992        |\n",
      "|    policyGradLoss     | -0.000864   |\n",
      "|    value_loss         | 2.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 18432000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011491745 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.949       |\n",
      "|    mean_step_reward   | 0.34531134  |\n",
      "|    n_updates          | 8996        |\n",
      "|    policyGradLoss     | 0.000524    |\n",
      "|    value_loss         | 4.88        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 18440192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008796999 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.81        |\n",
      "|    mean_step_reward   | 0.368796    |\n",
      "|    n_updates          | 9000        |\n",
      "|    policyGradLoss     | -0.00319    |\n",
      "|    value_loss         | 3.52        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 18448384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008763888 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.442       |\n",
      "|    mean_step_reward   | 0.3743512   |\n",
      "|    n_updates          | 9004        |\n",
      "|    policyGradLoss     | -0.00474    |\n",
      "|    value_loss         | 1.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 18456576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008600678 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.835       |\n",
      "|    mean_step_reward   | 0.32569635  |\n",
      "|    n_updates          | 9008        |\n",
      "|    policyGradLoss     | -0.0025     |\n",
      "|    value_loss         | 2.04        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 18464768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012293154 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.695       |\n",
      "|    mean_step_reward   | 0.4060501   |\n",
      "|    n_updates          | 9012        |\n",
      "|    policyGradLoss     | 0.00418     |\n",
      "|    value_loss         | 3.88        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 18472960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012032967 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.24        |\n",
      "|    mean_step_reward   | 0.35588062  |\n",
      "|    n_updates          | 9016        |\n",
      "|    policyGradLoss     | -0.00373    |\n",
      "|    value_loss         | 2.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 18481152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016573673 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.44        |\n",
      "|    mean_step_reward   | 0.3888718   |\n",
      "|    n_updates          | 9020        |\n",
      "|    policyGradLoss     | -0.00418    |\n",
      "|    value_loss         | 1.83        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 18489344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010553157 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.748       |\n",
      "|    mean_step_reward   | 0.3585308   |\n",
      "|    n_updates          | 9024        |\n",
      "|    policyGradLoss     | -0.00392    |\n",
      "|    value_loss         | 2.53        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 18497536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010945016 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.365       |\n",
      "|    mean_step_reward   | 0.3628155   |\n",
      "|    n_updates          | 9028        |\n",
      "|    policyGradLoss     | -0.00547    |\n",
      "|    value_loss         | 2.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 18505728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008479864 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.492       |\n",
      "|    mean_step_reward   | 0.39812526  |\n",
      "|    n_updates          | 9032        |\n",
      "|    policyGradLoss     | -0.00666    |\n",
      "|    value_loss         | 1.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 18513920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010424301 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.218       |\n",
      "|    mean_step_reward   | 0.32161045  |\n",
      "|    n_updates          | 9036        |\n",
      "|    policyGradLoss     | -0.00443    |\n",
      "|    value_loss         | 1.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 18522112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012215027 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.919       |\n",
      "|    mean_step_reward   | 0.37367862  |\n",
      "|    n_updates          | 9040        |\n",
      "|    policyGradLoss     | -0.00209    |\n",
      "|    value_loss         | 4.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 18530304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011879899 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.706       |\n",
      "|    mean_step_reward   | 0.3398204   |\n",
      "|    n_updates          | 9044        |\n",
      "|    policyGradLoss     | -0.000898   |\n",
      "|    value_loss         | 3.78        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 782        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 240        |\n",
      "|    total_timesteps    | 18538496   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0111843  |\n",
      "|    entropy_loss       | -1.72      |\n",
      "|    explained_variance | 0.941      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.335      |\n",
      "|    mean_step_reward   | 0.33607316 |\n",
      "|    n_updates          | 9048       |\n",
      "|    policyGradLoss     | -8.18e-05  |\n",
      "|    value_loss         | 3.17       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 18546688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011305709 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.44        |\n",
      "|    mean_step_reward   | 0.35603735  |\n",
      "|    n_updates          | 9052        |\n",
      "|    policyGradLoss     | -0.00575    |\n",
      "|    value_loss         | 1.65        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 18554880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010548471 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.03        |\n",
      "|    mean_step_reward   | 0.2979078   |\n",
      "|    n_updates          | 9056        |\n",
      "|    policyGradLoss     | -0.0045     |\n",
      "|    value_loss         | 2.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 18563072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011141882 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.225       |\n",
      "|    mean_step_reward   | 0.33449376  |\n",
      "|    n_updates          | 9060        |\n",
      "|    policyGradLoss     | -0.00472    |\n",
      "|    value_loss         | 1.55        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 18571264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011676392 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.266       |\n",
      "|    mean_step_reward   | 0.3112415   |\n",
      "|    n_updates          | 9064        |\n",
      "|    policyGradLoss     | -0.0023     |\n",
      "|    value_loss         | 3.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 18579456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015485644 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.242       |\n",
      "|    mean_step_reward   | 0.3418001   |\n",
      "|    n_updates          | 9068        |\n",
      "|    policyGradLoss     | 0.00298     |\n",
      "|    value_loss         | 4.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 18587648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012885558 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.225       |\n",
      "|    mean_step_reward   | 0.28427     |\n",
      "|    n_updates          | 9072        |\n",
      "|    policyGradLoss     | 0.00115     |\n",
      "|    value_loss         | 2.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 18595840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010023331 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.349       |\n",
      "|    mean_step_reward   | 0.33885342  |\n",
      "|    n_updates          | 9076        |\n",
      "|    policyGradLoss     | -0.00175    |\n",
      "|    value_loss         | 1.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 18604032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012640059 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.86        |\n",
      "|    mean_step_reward   | 0.32525942  |\n",
      "|    n_updates          | 9080        |\n",
      "|    policyGradLoss     | -0.00382    |\n",
      "|    value_loss         | 3.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 18612224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011829471 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.206       |\n",
      "|    mean_step_reward   | 0.3677879   |\n",
      "|    n_updates          | 9084        |\n",
      "|    policyGradLoss     | -0.00329    |\n",
      "|    value_loss         | 2           |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_70.zip\n",
      "[EVAL] Mean Return: 49.000, Best Return: 49.667\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_70_49.00.mp4\n",
      "\n",
      "=== Round 72 | Learn 262144 steps (Total trained: 18612224) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1159     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 18620416 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 902        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 18628608   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00921548 |\n",
      "|    entropy_loss       | -1.71      |\n",
      "|    explained_variance | 0.954      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.53       |\n",
      "|    mean_step_reward   | 0.32696962 |\n",
      "|    n_updates          | 9092       |\n",
      "|    policyGradLoss     | -0.00139   |\n",
      "|    value_loss         | 2.8        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 850         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 18636800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009996135 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.18        |\n",
      "|    mean_step_reward   | 0.45847726  |\n",
      "|    n_updates          | 9096        |\n",
      "|    policyGradLoss     | -0.00462    |\n",
      "|    value_loss         | 0.989       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 829         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 18644992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009012612 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.09        |\n",
      "|    mean_step_reward   | 0.33678478  |\n",
      "|    n_updates          | 9100        |\n",
      "|    policyGradLoss     | -0.00362    |\n",
      "|    value_loss         | 2.19        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 811        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 50         |\n",
      "|    total_timesteps    | 18653184   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01149231 |\n",
      "|    entropy_loss       | -1.72      |\n",
      "|    explained_variance | 0.978      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.487      |\n",
      "|    mean_step_reward   | 0.34112683 |\n",
      "|    n_updates          | 9104       |\n",
      "|    policyGradLoss     | -0.00581   |\n",
      "|    value_loss         | 1.95       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 18661376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008739764 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.77        |\n",
      "|    mean_step_reward   | 0.35678875  |\n",
      "|    n_updates          | 9108        |\n",
      "|    policyGradLoss     | -0.00387    |\n",
      "|    value_loss         | 1.75        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 18669568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010819728 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.489       |\n",
      "|    mean_step_reward   | 0.34250027  |\n",
      "|    n_updates          | 9112        |\n",
      "|    policyGradLoss     | -0.00531    |\n",
      "|    value_loss         | 2.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 18677760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011679605 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.648       |\n",
      "|    mean_step_reward   | 0.38622606  |\n",
      "|    n_updates          | 9116        |\n",
      "|    policyGradLoss     | -0.00828    |\n",
      "|    value_loss         | 1.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 18685952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014203325 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.55        |\n",
      "|    mean_step_reward   | 0.34483892  |\n",
      "|    n_updates          | 9120        |\n",
      "|    policyGradLoss     | -0.000637   |\n",
      "|    value_loss         | 2.83        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 18694144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013874643 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.366       |\n",
      "|    mean_step_reward   | 0.3588264   |\n",
      "|    n_updates          | 9124        |\n",
      "|    policyGradLoss     | -0.00305    |\n",
      "|    value_loss         | 1.95        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 782        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 115        |\n",
      "|    total_timesteps    | 18702336   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00913861 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.346      |\n",
      "|    mean_step_reward   | 0.3446187  |\n",
      "|    n_updates          | 9128       |\n",
      "|    policyGradLoss     | -0.00548   |\n",
      "|    value_loss         | 1.64       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 126         |\n",
      "|    total_timesteps    | 18710528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011400201 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.514       |\n",
      "|    mean_step_reward   | 0.37176237  |\n",
      "|    n_updates          | 9132        |\n",
      "|    policyGradLoss     | -0.00456    |\n",
      "|    value_loss         | 2.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 18718720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011708515 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.242       |\n",
      "|    mean_step_reward   | 0.33290875  |\n",
      "|    n_updates          | 9136        |\n",
      "|    policyGradLoss     | -0.00736    |\n",
      "|    value_loss         | 1.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 18726912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011662509 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.576       |\n",
      "|    mean_step_reward   | 0.3486395   |\n",
      "|    n_updates          | 9140        |\n",
      "|    policyGradLoss     | -0.00333    |\n",
      "|    value_loss         | 1.99        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 18735104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010302259 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.32        |\n",
      "|    mean_step_reward   | 0.37399712  |\n",
      "|    n_updates          | 9144        |\n",
      "|    policyGradLoss     | -0.00372    |\n",
      "|    value_loss         | 2.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 18743296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010930766 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.14        |\n",
      "|    mean_step_reward   | 0.33306158  |\n",
      "|    n_updates          | 9148        |\n",
      "|    policyGradLoss     | -0.00569    |\n",
      "|    value_loss         | 1.38        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 775          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 179          |\n",
      "|    total_timesteps    | 18751488     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0117491335 |\n",
      "|    entropy_loss       | -1.68        |\n",
      "|    explained_variance | 0.992        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.239        |\n",
      "|    mean_step_reward   | 0.39365578   |\n",
      "|    n_updates          | 9152         |\n",
      "|    policyGradLoss     | -0.0071      |\n",
      "|    value_loss         | 1.14         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 18759680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009196633 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.675       |\n",
      "|    mean_step_reward   | 0.37720472  |\n",
      "|    n_updates          | 9156        |\n",
      "|    policyGradLoss     | -0.000953   |\n",
      "|    value_loss         | 2.84        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 775        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 200        |\n",
      "|    total_timesteps    | 18767872   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01098519 |\n",
      "|    entropy_loss       | -1.72      |\n",
      "|    explained_variance | 0.979      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.734      |\n",
      "|    mean_step_reward   | 0.415011   |\n",
      "|    n_updates          | 9160       |\n",
      "|    policyGradLoss     | -0.00341   |\n",
      "|    value_loss         | 2.5        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 18776064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011069337 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.99        |\n",
      "|    mean_step_reward   | 0.3388769   |\n",
      "|    n_updates          | 9164        |\n",
      "|    policyGradLoss     | -0.00528    |\n",
      "|    value_loss         | 1.74        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 776        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 221        |\n",
      "|    total_timesteps    | 18784256   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00893097 |\n",
      "|    entropy_loss       | -1.65      |\n",
      "|    explained_variance | 0.983      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.835      |\n",
      "|    mean_step_reward   | 0.395457   |\n",
      "|    n_updates          | 9168       |\n",
      "|    policyGradLoss     | -0.00393   |\n",
      "|    value_loss         | 1.81       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 18792448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008224972 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.702       |\n",
      "|    mean_step_reward   | 0.37681967  |\n",
      "|    n_updates          | 9172        |\n",
      "|    policyGradLoss     | -0.00317    |\n",
      "|    value_loss         | 1.98        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 18800640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011954072 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.483       |\n",
      "|    mean_step_reward   | 0.40946275  |\n",
      "|    n_updates          | 9176        |\n",
      "|    policyGradLoss     | -0.00679    |\n",
      "|    value_loss         | 1.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 254         |\n",
      "|    total_timesteps    | 18808832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008453151 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.518       |\n",
      "|    mean_step_reward   | 0.34813285  |\n",
      "|    n_updates          | 9180        |\n",
      "|    policyGradLoss     | -0.00539    |\n",
      "|    value_loss         | 1.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 18817024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013019597 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.952       |\n",
      "|    mean_step_reward   | 0.36336958  |\n",
      "|    n_updates          | 9184        |\n",
      "|    policyGradLoss     | -0.000746   |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 275         |\n",
      "|    total_timesteps    | 18825216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011829037 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.435       |\n",
      "|    mean_step_reward   | 0.35649467  |\n",
      "|    n_updates          | 9188        |\n",
      "|    policyGradLoss     | -0.00907    |\n",
      "|    value_loss         | 1.59        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 773          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 285          |\n",
      "|    total_timesteps    | 18833408     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0132200215 |\n",
      "|    entropy_loss       | -1.72        |\n",
      "|    explained_variance | 0.944        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.16         |\n",
      "|    mean_step_reward   | 0.34151256   |\n",
      "|    n_updates          | 9192         |\n",
      "|    policyGradLoss     | -0.00537     |\n",
      "|    value_loss         | 3.71         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 18841600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010012207 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.25        |\n",
      "|    mean_step_reward   | 0.38055855  |\n",
      "|    n_updates          | 9196        |\n",
      "|    policyGradLoss     | -3.7e-06    |\n",
      "|    value_loss         | 3.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 307         |\n",
      "|    total_timesteps    | 18849792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014100341 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.479       |\n",
      "|    mean_step_reward   | 0.3902985   |\n",
      "|    n_updates          | 9200        |\n",
      "|    policyGradLoss     | -0.0032     |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 772          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 318          |\n",
      "|    total_timesteps    | 18857984     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0140923485 |\n",
      "|    entropy_loss       | -1.69        |\n",
      "|    explained_variance | 0.901        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.641        |\n",
      "|    mean_step_reward   | 0.37534997   |\n",
      "|    n_updates          | 9204         |\n",
      "|    policyGradLoss     | 0.00209      |\n",
      "|    value_loss         | 5.61         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 18866176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010743223 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.991       |\n",
      "|    mean_step_reward   | 0.3019126   |\n",
      "|    n_updates          | 9208        |\n",
      "|    policyGradLoss     | -0.00247    |\n",
      "|    value_loss         | 2.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 18874368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013133188 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.673       |\n",
      "|    mean_step_reward   | 0.33453164  |\n",
      "|    n_updates          | 9212        |\n",
      "|    policyGradLoss     | 0.00356     |\n",
      "|    value_loss         | 2.87        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_71.zip\n",
      "[EVAL] Mean Return: 94.215, Best Return: 95.548\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_71_94.22.mp4\n",
      "\n",
      "=== Round 73 | Learn 262144 steps (Total trained: 18874368) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1120     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 18882560 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 902         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 18890752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011234842 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.565       |\n",
      "|    mean_step_reward   | 0.37386417  |\n",
      "|    n_updates          | 9220        |\n",
      "|    policyGradLoss     | -0.00268    |\n",
      "|    value_loss         | 2.56        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 854        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 18898944   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00980934 |\n",
      "|    entropy_loss       | -1.72      |\n",
      "|    explained_variance | 0.961      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.391      |\n",
      "|    mean_step_reward   | 0.32130867 |\n",
      "|    n_updates          | 9224       |\n",
      "|    policyGradLoss     | -0.00306   |\n",
      "|    value_loss         | 2.21       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 835         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 18907136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010856349 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.606       |\n",
      "|    mean_step_reward   | 0.318183    |\n",
      "|    n_updates          | 9228        |\n",
      "|    policyGradLoss     | -0.00481    |\n",
      "|    value_loss         | 1.67        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 819          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 49           |\n",
      "|    total_timesteps    | 18915328     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0097344145 |\n",
      "|    entropy_loss       | -1.73        |\n",
      "|    explained_variance | 0.953        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.15         |\n",
      "|    mean_step_reward   | 0.3913867    |\n",
      "|    n_updates          | 9232         |\n",
      "|    policyGradLoss     | 0.000648     |\n",
      "|    value_loss         | 3.6          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 18923520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008545479 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.04        |\n",
      "|    mean_step_reward   | 0.34226274  |\n",
      "|    n_updates          | 9236        |\n",
      "|    policyGradLoss     | -0.00606    |\n",
      "|    value_loss         | 1.93        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 805        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 71         |\n",
      "|    total_timesteps    | 18931712   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01045684 |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.977      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.479      |\n",
      "|    mean_step_reward   | 0.3876992  |\n",
      "|    n_updates          | 9240       |\n",
      "|    policyGradLoss     | -0.00364   |\n",
      "|    value_loss         | 2.74       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 18939904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008876158 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.421       |\n",
      "|    mean_step_reward   | 0.34658578  |\n",
      "|    n_updates          | 9244        |\n",
      "|    policyGradLoss     | -0.00277    |\n",
      "|    value_loss         | 3.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 18948096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015491049 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.193       |\n",
      "|    mean_step_reward   | 0.2919202   |\n",
      "|    n_updates          | 9248        |\n",
      "|    policyGradLoss     | -0.00459    |\n",
      "|    value_loss         | 1.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 18956288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011917716 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.916       |\n",
      "|    mean_step_reward   | 0.37623286  |\n",
      "|    n_updates          | 9252        |\n",
      "|    policyGradLoss     | -0.00214    |\n",
      "|    value_loss         | 2.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 18964480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011536529 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.07        |\n",
      "|    mean_step_reward   | 0.33880508  |\n",
      "|    n_updates          | 9256        |\n",
      "|    policyGradLoss     | -0.00726    |\n",
      "|    value_loss         | 1.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 18972672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013779916 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.275       |\n",
      "|    mean_step_reward   | 0.37095112  |\n",
      "|    n_updates          | 9260        |\n",
      "|    policyGradLoss     | -0.00628    |\n",
      "|    value_loss         | 1.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 18980864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013459679 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.295       |\n",
      "|    mean_step_reward   | 0.37337562  |\n",
      "|    n_updates          | 9264        |\n",
      "|    policyGradLoss     | -0.00407    |\n",
      "|    value_loss         | 1.71        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 784          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 146          |\n",
      "|    total_timesteps    | 18989056     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0090033095 |\n",
      "|    entropy_loss       | -1.72        |\n",
      "|    explained_variance | 0.981        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.649        |\n",
      "|    mean_step_reward   | 0.38046348   |\n",
      "|    n_updates          | 9268         |\n",
      "|    policyGradLoss     | -0.0057      |\n",
      "|    value_loss         | 1.94         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 18997248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015709428 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.774       |\n",
      "|    mean_step_reward   | 0.35741025  |\n",
      "|    n_updates          | 9272        |\n",
      "|    policyGradLoss     | -0.00108    |\n",
      "|    value_loss         | 3.77        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 780          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 168          |\n",
      "|    total_timesteps    | 19005440     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0099542765 |\n",
      "|    entropy_loss       | -1.7         |\n",
      "|    explained_variance | 0.971        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.314        |\n",
      "|    mean_step_reward   | 0.3657541    |\n",
      "|    n_updates          | 9276         |\n",
      "|    policyGradLoss     | -0.000654    |\n",
      "|    value_loss         | 1.92         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 19013632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010636821 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.707       |\n",
      "|    mean_step_reward   | 0.32649833  |\n",
      "|    n_updates          | 9280        |\n",
      "|    policyGradLoss     | -0.00537    |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 19021824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011983614 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.512       |\n",
      "|    mean_step_reward   | 0.41482037  |\n",
      "|    n_updates          | 9284        |\n",
      "|    policyGradLoss     | -0.00534    |\n",
      "|    value_loss         | 1.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 19030016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017102495 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.405       |\n",
      "|    mean_step_reward   | 0.34776786  |\n",
      "|    n_updates          | 9288        |\n",
      "|    policyGradLoss     | -0.00412    |\n",
      "|    value_loss         | 1.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 19038208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009986749 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.959       |\n",
      "|    mean_step_reward   | 0.36117333  |\n",
      "|    n_updates          | 9292        |\n",
      "|    policyGradLoss     | -0.000643   |\n",
      "|    value_loss         | 3.02        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 220        |\n",
      "|    total_timesteps    | 19046400   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01494598 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.984      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.275      |\n",
      "|    mean_step_reward   | 0.34447926 |\n",
      "|    n_updates          | 9296       |\n",
      "|    policyGradLoss     | -0.00783   |\n",
      "|    value_loss         | 1.13       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 19054592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014895776 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.453       |\n",
      "|    mean_step_reward   | 0.3891888   |\n",
      "|    n_updates          | 9300        |\n",
      "|    policyGradLoss     | 0.00634     |\n",
      "|    value_loss         | 4.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 19062784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014151228 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.3         |\n",
      "|    mean_step_reward   | 0.33236912  |\n",
      "|    n_updates          | 9304        |\n",
      "|    policyGradLoss     | -0.0041     |\n",
      "|    value_loss         | 2.05        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 252        |\n",
      "|    total_timesteps    | 19070976   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01626502 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.971      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.427      |\n",
      "|    mean_step_reward   | 0.34298474 |\n",
      "|    n_updates          | 9308       |\n",
      "|    policyGradLoss     | -0.000788  |\n",
      "|    value_loss         | 1.74       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 19079168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009899958 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.199       |\n",
      "|    mean_step_reward   | 0.27932096  |\n",
      "|    n_updates          | 9312        |\n",
      "|    policyGradLoss     | -0.00456    |\n",
      "|    value_loss         | 1.2         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 777          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 273          |\n",
      "|    total_timesteps    | 19087360     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0124028055 |\n",
      "|    entropy_loss       | -1.72        |\n",
      "|    explained_variance | 0.974        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.719        |\n",
      "|    mean_step_reward   | 0.382878     |\n",
      "|    n_updates          | 9316         |\n",
      "|    policyGradLoss     | -0.000979    |\n",
      "|    value_loss         | 2.1          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 777          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 284          |\n",
      "|    total_timesteps    | 19095552     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0132109495 |\n",
      "|    entropy_loss       | -1.69        |\n",
      "|    explained_variance | 0.98         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.94         |\n",
      "|    mean_step_reward   | 0.3562044    |\n",
      "|    n_updates          | 9320         |\n",
      "|    policyGradLoss     | -0.00573     |\n",
      "|    value_loss         | 1.66         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 19103744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013573621 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.143       |\n",
      "|    mean_step_reward   | 0.34444156  |\n",
      "|    n_updates          | 9324        |\n",
      "|    policyGradLoss     | -0.00809    |\n",
      "|    value_loss         | 1.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 19111936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009876635 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.465       |\n",
      "|    mean_step_reward   | 0.32721853  |\n",
      "|    n_updates          | 9328        |\n",
      "|    policyGradLoss     | -0.00371    |\n",
      "|    value_loss         | 2.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 19120128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012265731 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.345       |\n",
      "|    mean_step_reward   | 0.32461244  |\n",
      "|    n_updates          | 9332        |\n",
      "|    policyGradLoss     | -0.00699    |\n",
      "|    value_loss         | 1.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 19128320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015595623 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.176       |\n",
      "|    mean_step_reward   | 0.45142975  |\n",
      "|    n_updates          | 9336        |\n",
      "|    policyGradLoss     | -0.00271    |\n",
      "|    value_loss         | 1.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 19136512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011390632 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.37        |\n",
      "|    mean_step_reward   | 0.35695463  |\n",
      "|    n_updates          | 9340        |\n",
      "|    policyGradLoss     | -0.00589    |\n",
      "|    value_loss         | 2.27        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_72.zip\n",
      "[EVAL] Mean Return: 527.612, Best Return: 532.279\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_72_527.61.mp4\n",
      "\n",
      "=== Round 74 | Learn 262144 steps (Total trained: 19136512) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1137     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 19144704 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 910         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 19152896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011578826 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.378       |\n",
      "|    mean_step_reward   | 0.35758385  |\n",
      "|    n_updates          | 9348        |\n",
      "|    policyGradLoss     | -0.00763    |\n",
      "|    value_loss         | 1.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 854         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 19161088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011648651 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.623       |\n",
      "|    mean_step_reward   | 0.37990028  |\n",
      "|    n_updates          | 9352        |\n",
      "|    policyGradLoss     | -0.00662    |\n",
      "|    value_loss         | 1.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 827         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 19169280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009088747 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.958       |\n",
      "|    mean_step_reward   | 0.3449983   |\n",
      "|    n_updates          | 9356        |\n",
      "|    policyGradLoss     | -0.00487    |\n",
      "|    value_loss         | 1.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 19177472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011990705 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.479       |\n",
      "|    mean_step_reward   | 0.35657737  |\n",
      "|    n_updates          | 9360        |\n",
      "|    policyGradLoss     | -0.00736    |\n",
      "|    value_loss         | 1.21        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 809        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 19185664   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01217662 |\n",
      "|    entropy_loss       | -1.7       |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.723      |\n",
      "|    mean_step_reward   | 0.34321022 |\n",
      "|    n_updates          | 9364       |\n",
      "|    policyGradLoss     | -0.00589   |\n",
      "|    value_loss         | 1.23       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 19193856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018169768 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.141       |\n",
      "|    mean_step_reward   | 0.34879324  |\n",
      "|    n_updates          | 9368        |\n",
      "|    policyGradLoss     | -0.00494    |\n",
      "|    value_loss         | 1.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 19202048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020582918 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.981       |\n",
      "|    mean_step_reward   | 0.36382073  |\n",
      "|    n_updates          | 9372        |\n",
      "|    policyGradLoss     | -0.000471   |\n",
      "|    value_loss         | 2.84        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 19210240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015577203 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.68        |\n",
      "|    mean_step_reward   | 0.3642681   |\n",
      "|    n_updates          | 9376        |\n",
      "|    policyGradLoss     | -0.00851    |\n",
      "|    value_loss         | 1.37        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 793          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 103          |\n",
      "|    total_timesteps    | 19218432     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0128649995 |\n",
      "|    entropy_loss       | -1.71        |\n",
      "|    explained_variance | 0.95         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.574        |\n",
      "|    mean_step_reward   | 0.34359768   |\n",
      "|    n_updates          | 9380         |\n",
      "|    policyGradLoss     | -0.0024      |\n",
      "|    value_loss         | 2.96         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 19226624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011997114 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.513       |\n",
      "|    mean_step_reward   | 0.33635065  |\n",
      "|    n_updates          | 9384        |\n",
      "|    policyGradLoss     | -0.00738    |\n",
      "|    value_loss         | 1.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 19234816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010823943 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.38        |\n",
      "|    mean_step_reward   | 0.3783207   |\n",
      "|    n_updates          | 9388        |\n",
      "|    policyGradLoss     | -0.00692    |\n",
      "|    value_loss         | 1.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 19243008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015319839 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.915       |\n",
      "|    mean_step_reward   | 0.36905402  |\n",
      "|    n_updates          | 9392        |\n",
      "|    policyGradLoss     | -0.00818    |\n",
      "|    value_loss         | 1.66        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 19251200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009830657 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.622       |\n",
      "|    mean_step_reward   | 0.39476788  |\n",
      "|    n_updates          | 9396        |\n",
      "|    policyGradLoss     | -0.00492    |\n",
      "|    value_loss         | 1.81        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 19259392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011254736 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.881       |\n",
      "|    mean_step_reward   | 0.41631788  |\n",
      "|    n_updates          | 9400        |\n",
      "|    policyGradLoss     | -0.00444    |\n",
      "|    value_loss         | 2.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 19267584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012057035 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.802       |\n",
      "|    mean_step_reward   | 0.39859456  |\n",
      "|    n_updates          | 9404        |\n",
      "|    policyGradLoss     | -0.00672    |\n",
      "|    value_loss         | 1.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 19275776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012336068 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.594       |\n",
      "|    mean_step_reward   | 0.37215933  |\n",
      "|    n_updates          | 9408        |\n",
      "|    policyGradLoss     | -0.00389    |\n",
      "|    value_loss         | 1.5         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 19283968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013774435 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.412       |\n",
      "|    mean_step_reward   | 0.39608234  |\n",
      "|    n_updates          | 9412        |\n",
      "|    policyGradLoss     | -0.00243    |\n",
      "|    value_loss         | 2.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 19292160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012152551 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.635       |\n",
      "|    mean_step_reward   | 0.3820659   |\n",
      "|    n_updates          | 9416        |\n",
      "|    policyGradLoss     | -0.00422    |\n",
      "|    value_loss         | 2.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 19300352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013870586 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.861       |\n",
      "|    mean_step_reward   | 0.3979602   |\n",
      "|    n_updates          | 9420        |\n",
      "|    policyGradLoss     | -0.00458    |\n",
      "|    value_loss         | 2.16        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 780          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 220          |\n",
      "|    total_timesteps    | 19308544     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0132772885 |\n",
      "|    entropy_loss       | -1.67        |\n",
      "|    explained_variance | 0.984        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.88         |\n",
      "|    mean_step_reward   | 0.39353204   |\n",
      "|    n_updates          | 9424         |\n",
      "|    policyGradLoss     | -0.00881     |\n",
      "|    value_loss         | 1.71         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 19316736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018991284 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.387       |\n",
      "|    mean_step_reward   | 0.35127354  |\n",
      "|    n_updates          | 9428        |\n",
      "|    policyGradLoss     | -0.00021    |\n",
      "|    value_loss         | 2.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 19324928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016578043 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.822       |\n",
      "|    mean_step_reward   | 0.37620145  |\n",
      "|    n_updates          | 9432        |\n",
      "|    policyGradLoss     | 0.00338     |\n",
      "|    value_loss         | 2.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 19333120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011216285 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.392       |\n",
      "|    mean_step_reward   | 0.3765332   |\n",
      "|    n_updates          | 9436        |\n",
      "|    policyGradLoss     | -0.00396    |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 19341312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014456855 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.322       |\n",
      "|    mean_step_reward   | 0.358703    |\n",
      "|    n_updates          | 9440        |\n",
      "|    policyGradLoss     | -0.00187    |\n",
      "|    value_loss         | 1.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 19349504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011469016 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.52        |\n",
      "|    mean_step_reward   | 0.38978708  |\n",
      "|    n_updates          | 9444        |\n",
      "|    policyGradLoss     | -0.00515    |\n",
      "|    value_loss         | 1.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 19357696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011021801 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.877       |\n",
      "|    mean_step_reward   | 0.38169152  |\n",
      "|    n_updates          | 9448        |\n",
      "|    policyGradLoss     | -0.0059     |\n",
      "|    value_loss         | 1.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 19365888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015742147 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.147       |\n",
      "|    mean_step_reward   | 0.3888666   |\n",
      "|    n_updates          | 9452        |\n",
      "|    policyGradLoss     | -0.0071     |\n",
      "|    value_loss         | 1.55        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 19374080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012524718 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.673       |\n",
      "|    mean_step_reward   | 0.41685164  |\n",
      "|    n_updates          | 9456        |\n",
      "|    policyGradLoss     | -0.00525    |\n",
      "|    value_loss         | 1.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 19382272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010369802 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.547       |\n",
      "|    mean_step_reward   | 0.34998873  |\n",
      "|    n_updates          | 9460        |\n",
      "|    policyGradLoss     | -0.00647    |\n",
      "|    value_loss         | 1.59        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 19390464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017574161 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.336       |\n",
      "|    mean_step_reward   | 0.4440034   |\n",
      "|    n_updates          | 9464        |\n",
      "|    policyGradLoss     | 0.0051      |\n",
      "|    value_loss         | 2.72        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 19398656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011380358 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.469       |\n",
      "|    mean_step_reward   | 0.3816473   |\n",
      "|    n_updates          | 9468        |\n",
      "|    policyGradLoss     | -0.00497    |\n",
      "|    value_loss         | 1.87        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_73.zip\n",
      "[EVAL] Mean Return: 530.211, Best Return: 536.211\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_73_530.21.mp4\n",
      "\n",
      "=== Round 75 | Learn 262144 steps (Total trained: 19398656) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1147     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 19406848 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 926         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 19415040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014457919 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.573       |\n",
      "|    mean_step_reward   | 0.40418988  |\n",
      "|    n_updates          | 9476        |\n",
      "|    policyGradLoss     | -0.000605   |\n",
      "|    value_loss         | 2.71        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 862         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 19423232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012294129 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.367       |\n",
      "|    mean_step_reward   | 0.3378608   |\n",
      "|    n_updates          | 9480        |\n",
      "|    policyGradLoss     | -0.00598    |\n",
      "|    value_loss         | 2.03        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 838          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 39           |\n",
      "|    total_timesteps    | 19431424     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0142553095 |\n",
      "|    entropy_loss       | -1.67        |\n",
      "|    explained_variance | 0.948        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.429        |\n",
      "|    mean_step_reward   | 0.35144877   |\n",
      "|    n_updates          | 9484         |\n",
      "|    policyGradLoss     | -0.00213     |\n",
      "|    value_loss         | 2.45         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 19439616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016200727 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.197       |\n",
      "|    mean_step_reward   | 0.4074361   |\n",
      "|    n_updates          | 9488        |\n",
      "|    policyGradLoss     | -0.00561    |\n",
      "|    value_loss         | 1.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 19447808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012380328 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.313       |\n",
      "|    mean_step_reward   | 0.36939985  |\n",
      "|    n_updates          | 9492        |\n",
      "|    policyGradLoss     | -0.00425    |\n",
      "|    value_loss         | 2.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 19456000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016771797 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.09        |\n",
      "|    mean_step_reward   | 0.38308883  |\n",
      "|    n_updates          | 9496        |\n",
      "|    policyGradLoss     | -0.00371    |\n",
      "|    value_loss         | 1.75        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 19464192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016048392 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.06        |\n",
      "|    mean_step_reward   | 0.36348847  |\n",
      "|    n_updates          | 9500        |\n",
      "|    policyGradLoss     | 0.000219    |\n",
      "|    value_loss         | 4.74        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 798          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 92           |\n",
      "|    total_timesteps    | 19472384     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0120883025 |\n",
      "|    entropy_loss       | -1.7         |\n",
      "|    explained_variance | 0.974        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.406        |\n",
      "|    mean_step_reward   | 0.35125273   |\n",
      "|    n_updates          | 9504         |\n",
      "|    policyGradLoss     | -0.0016      |\n",
      "|    value_loss         | 2.17         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 19480576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012016712 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.464       |\n",
      "|    mean_step_reward   | 0.42934698  |\n",
      "|    n_updates          | 9508        |\n",
      "|    policyGradLoss     | 0.000653    |\n",
      "|    value_loss         | 2.69        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 794          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 113          |\n",
      "|    total_timesteps    | 19488768     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0099358605 |\n",
      "|    entropy_loss       | -1.72        |\n",
      "|    explained_variance | 0.979        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.675        |\n",
      "|    mean_step_reward   | 0.33550522   |\n",
      "|    n_updates          | 9512         |\n",
      "|    policyGradLoss     | 2.81e-05     |\n",
      "|    value_loss         | 2.27         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 19496960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015627515 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.548       |\n",
      "|    mean_step_reward   | 0.4329531   |\n",
      "|    n_updates          | 9516        |\n",
      "|    policyGradLoss     | -0.00264    |\n",
      "|    value_loss         | 1.71        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 19505152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012064815 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.377       |\n",
      "|    mean_step_reward   | 0.3450691   |\n",
      "|    n_updates          | 9520        |\n",
      "|    policyGradLoss     | -0.00276    |\n",
      "|    value_loss         | 2.45        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 788          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 145          |\n",
      "|    total_timesteps    | 19513344     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0096757505 |\n",
      "|    entropy_loss       | -1.67        |\n",
      "|    explained_variance | 0.988        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.367        |\n",
      "|    mean_step_reward   | 0.40686885   |\n",
      "|    n_updates          | 9524         |\n",
      "|    policyGradLoss     | -0.00438     |\n",
      "|    value_loss         | 1.62         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 19521536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011079143 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.654       |\n",
      "|    mean_step_reward   | 0.4241159   |\n",
      "|    n_updates          | 9528        |\n",
      "|    policyGradLoss     | -0.00394    |\n",
      "|    value_loss         | 1.61        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 19529728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014947935 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.215       |\n",
      "|    mean_step_reward   | 0.34120995  |\n",
      "|    n_updates          | 9532        |\n",
      "|    policyGradLoss     | -0.00734    |\n",
      "|    value_loss         | 1.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 19537920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020038925 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.256       |\n",
      "|    mean_step_reward   | 0.36682415  |\n",
      "|    n_updates          | 9536        |\n",
      "|    policyGradLoss     | -0.00407    |\n",
      "|    value_loss         | 1.5         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 782        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 188        |\n",
      "|    total_timesteps    | 19546112   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01452757 |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.883      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.479      |\n",
      "|    mean_step_reward   | 0.30180055 |\n",
      "|    n_updates          | 9540       |\n",
      "|    policyGradLoss     | 0.0132     |\n",
      "|    value_loss         | 3.52       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 19554304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015598198 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.534       |\n",
      "|    mean_step_reward   | 0.4024726   |\n",
      "|    n_updates          | 9544        |\n",
      "|    policyGradLoss     | 0.00429     |\n",
      "|    value_loss         | 3.64        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 19562496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009555797 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.807       |\n",
      "|    mean_step_reward   | 0.3447414   |\n",
      "|    n_updates          | 9548        |\n",
      "|    policyGradLoss     | -0.00314    |\n",
      "|    value_loss         | 2.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 19570688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010893922 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.268       |\n",
      "|    mean_step_reward   | 0.42681777  |\n",
      "|    n_updates          | 9552        |\n",
      "|    policyGradLoss     | -0.000396   |\n",
      "|    value_loss         | 1.5         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 19578880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008104972 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.01        |\n",
      "|    mean_step_reward   | 0.3808458   |\n",
      "|    n_updates          | 9556        |\n",
      "|    policyGradLoss     | -0.00264    |\n",
      "|    value_loss         | 2.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 19587072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015479737 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.314       |\n",
      "|    mean_step_reward   | 0.35186553  |\n",
      "|    n_updates          | 9560        |\n",
      "|    policyGradLoss     | -0.00528    |\n",
      "|    value_loss         | 1.42        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 252        |\n",
      "|    total_timesteps    | 19595264   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01582001 |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.992      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.298      |\n",
      "|    mean_step_reward   | 0.40476945 |\n",
      "|    n_updates          | 9564       |\n",
      "|    policyGradLoss     | -0.00722   |\n",
      "|    value_loss         | 1.01       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 19603456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009231629 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.505       |\n",
      "|    mean_step_reward   | 0.37166488  |\n",
      "|    n_updates          | 9568        |\n",
      "|    policyGradLoss     | -0.00176    |\n",
      "|    value_loss         | 1.83        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 19611648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014514565 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.43        |\n",
      "|    mean_step_reward   | 0.36949262  |\n",
      "|    n_updates          | 9572        |\n",
      "|    policyGradLoss     | -0.00509    |\n",
      "|    value_loss         | 1.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 19619840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012342928 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.465       |\n",
      "|    mean_step_reward   | 0.35793245  |\n",
      "|    n_updates          | 9576        |\n",
      "|    policyGradLoss     | -0.00267    |\n",
      "|    value_loss         | 1.96        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 19628032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010864457 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.443       |\n",
      "|    mean_step_reward   | 0.41582304  |\n",
      "|    n_updates          | 9580        |\n",
      "|    policyGradLoss     | -0.00353    |\n",
      "|    value_loss         | 1.52        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 305        |\n",
      "|    total_timesteps    | 19636224   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01319012 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.962      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.849      |\n",
      "|    mean_step_reward   | 0.33904454 |\n",
      "|    n_updates          | 9584       |\n",
      "|    policyGradLoss     | -0.00341   |\n",
      "|    value_loss         | 2.49       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 19644416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011666359 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.26        |\n",
      "|    mean_step_reward   | 0.36380166  |\n",
      "|    n_updates          | 9588        |\n",
      "|    policyGradLoss     | -0.00261    |\n",
      "|    value_loss         | 2.07        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 19652608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009015579 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.434       |\n",
      "|    mean_step_reward   | 0.44248873  |\n",
      "|    n_updates          | 9592        |\n",
      "|    policyGradLoss     | -0.00391    |\n",
      "|    value_loss         | 1.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 19660800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008631762 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.391       |\n",
      "|    mean_step_reward   | 0.36704773  |\n",
      "|    n_updates          | 9596        |\n",
      "|    policyGradLoss     | -0.00309    |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_74.zip\n",
      "[EVAL] Mean Return: 525.601, Best Return: 529.601\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_74_525.60.mp4\n",
      "\n",
      "=== Round 76 | Learn 262144 steps (Total trained: 19660800) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1137     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 19668992 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 914         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 19677184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015082724 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.378       |\n",
      "|    mean_step_reward   | 0.37734014  |\n",
      "|    n_updates          | 9604        |\n",
      "|    policyGradLoss     | -0.0057     |\n",
      "|    value_loss         | 1.64        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 861        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 19685376   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01584448 |\n",
      "|    entropy_loss       | -1.71      |\n",
      "|    explained_variance | 0.986      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.856      |\n",
      "|    mean_step_reward   | 0.37276894 |\n",
      "|    n_updates          | 9608       |\n",
      "|    policyGradLoss     | -0.00626   |\n",
      "|    value_loss         | 1.67       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 830         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 19693568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011510573 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.291       |\n",
      "|    mean_step_reward   | 0.36240202  |\n",
      "|    n_updates          | 9612        |\n",
      "|    policyGradLoss     | -0.00841    |\n",
      "|    value_loss         | 1.72        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 824          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 49           |\n",
      "|    total_timesteps    | 19701760     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0142044695 |\n",
      "|    entropy_loss       | -1.66        |\n",
      "|    explained_variance | 0.944        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.902        |\n",
      "|    mean_step_reward   | 0.34382123   |\n",
      "|    n_updates          | 9616         |\n",
      "|    policyGradLoss     | -0.00283     |\n",
      "|    value_loss         | 3.09         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 19709952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011265915 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.97        |\n",
      "|    mean_step_reward   | 0.36981946  |\n",
      "|    n_updates          | 9620        |\n",
      "|    policyGradLoss     | -0.00212    |\n",
      "|    value_loss         | 5.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 19718144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013547399 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.18        |\n",
      "|    mean_step_reward   | 0.3748945   |\n",
      "|    n_updates          | 9624        |\n",
      "|    policyGradLoss     | 0.00752     |\n",
      "|    value_loss         | 5.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 19726336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010470438 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.796       |\n",
      "|    mean_step_reward   | 0.3515731   |\n",
      "|    n_updates          | 9628        |\n",
      "|    policyGradLoss     | -0.00265    |\n",
      "|    value_loss         | 2.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 19734528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015282045 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.452       |\n",
      "|    mean_step_reward   | 0.33253735  |\n",
      "|    n_updates          | 9632        |\n",
      "|    policyGradLoss     | -0.00322    |\n",
      "|    value_loss         | 1.84        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 790          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 103          |\n",
      "|    total_timesteps    | 19742720     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0124287205 |\n",
      "|    entropy_loss       | -1.67        |\n",
      "|    explained_variance | 0.84         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.811        |\n",
      "|    mean_step_reward   | 0.3524418    |\n",
      "|    n_updates          | 9636         |\n",
      "|    policyGradLoss     | 0.00173      |\n",
      "|    value_loss         | 4.87         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 19750912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012509639 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.665       |\n",
      "|    mean_step_reward   | 0.4365799   |\n",
      "|    n_updates          | 9640        |\n",
      "|    policyGradLoss     | -0.00071    |\n",
      "|    value_loss         | 4.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 19759104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009454516 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.45        |\n",
      "|    mean_step_reward   | 0.31278968  |\n",
      "|    n_updates          | 9644        |\n",
      "|    policyGradLoss     | -0.00256    |\n",
      "|    value_loss         | 2.23        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 782        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 136        |\n",
      "|    total_timesteps    | 19767296   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.014736   |\n",
      "|    entropy_loss       | -1.71      |\n",
      "|    explained_variance | 0.938      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.452      |\n",
      "|    mean_step_reward   | 0.33109674 |\n",
      "|    n_updates          | 9648       |\n",
      "|    policyGradLoss     | -0.000115  |\n",
      "|    value_loss         | 2.49       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 19775488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014943761 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.489       |\n",
      "|    mean_step_reward   | 0.33798367  |\n",
      "|    n_updates          | 9652        |\n",
      "|    policyGradLoss     | -0.0104     |\n",
      "|    value_loss         | 1.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 19783680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010587163 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.642       |\n",
      "|    mean_step_reward   | 0.33914995  |\n",
      "|    n_updates          | 9656        |\n",
      "|    policyGradLoss     | -0.00543    |\n",
      "|    value_loss         | 2.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 19791872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012357388 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.329       |\n",
      "|    mean_step_reward   | 0.3653667   |\n",
      "|    n_updates          | 9660        |\n",
      "|    policyGradLoss     | -0.00379    |\n",
      "|    value_loss         | 1.93        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 19800064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014256619 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.643       |\n",
      "|    mean_step_reward   | 0.36001498  |\n",
      "|    n_updates          | 9664        |\n",
      "|    policyGradLoss     | -0.005      |\n",
      "|    value_loss         | 1.51        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 780        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 188        |\n",
      "|    total_timesteps    | 19808256   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01441513 |\n",
      "|    entropy_loss       | -1.7       |\n",
      "|    explained_variance | 0.947      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.597      |\n",
      "|    mean_step_reward   | 0.37535572 |\n",
      "|    n_updates          | 9668       |\n",
      "|    policyGradLoss     | 0.00131    |\n",
      "|    value_loss         | 4.14       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 199        |\n",
      "|    total_timesteps    | 19816448   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01345543 |\n",
      "|    entropy_loss       | -1.72      |\n",
      "|    explained_variance | 0.961      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.417      |\n",
      "|    mean_step_reward   | 0.35653692 |\n",
      "|    n_updates          | 9672       |\n",
      "|    policyGradLoss     | -0.00207   |\n",
      "|    value_loss         | 2.34       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 19824640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019408068 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.847       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.328       |\n",
      "|    mean_step_reward   | 0.2579596   |\n",
      "|    n_updates          | 9676        |\n",
      "|    policyGradLoss     | 0.00478     |\n",
      "|    value_loss         | 3.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 19832832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021337107 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.892       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.28        |\n",
      "|    mean_step_reward   | 0.3754477   |\n",
      "|    n_updates          | 9680        |\n",
      "|    policyGradLoss     | 0.0051      |\n",
      "|    value_loss         | 5.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 19841024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012364319 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.655       |\n",
      "|    mean_step_reward   | 0.28468716  |\n",
      "|    n_updates          | 9684        |\n",
      "|    policyGradLoss     | 0.000523    |\n",
      "|    value_loss         | 2.9         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 775          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 242          |\n",
      "|    total_timesteps    | 19849216     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0142725725 |\n",
      "|    entropy_loss       | -1.78        |\n",
      "|    explained_variance | 0.962        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.1          |\n",
      "|    mean_step_reward   | 0.26562196   |\n",
      "|    n_updates          | 9688         |\n",
      "|    policyGradLoss     | -0.00242     |\n",
      "|    value_loss         | 1.87         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 19857408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013143331 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.91        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.564       |\n",
      "|    mean_step_reward   | 0.28946495  |\n",
      "|    n_updates          | 9692        |\n",
      "|    policyGradLoss     | 0.00342     |\n",
      "|    value_loss         | 3.81        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 19865600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010805988 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.89        |\n",
      "|    mean_step_reward   | 0.28123897  |\n",
      "|    n_updates          | 9696        |\n",
      "|    policyGradLoss     | -0.000986   |\n",
      "|    value_loss         | 2.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 19873792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014114151 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.41        |\n",
      "|    mean_step_reward   | 0.32423925  |\n",
      "|    n_updates          | 9700        |\n",
      "|    policyGradLoss     | -0.00423    |\n",
      "|    value_loss         | 1.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 19881984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011513829 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.769       |\n",
      "|    mean_step_reward   | 0.29631475  |\n",
      "|    n_updates          | 9704        |\n",
      "|    policyGradLoss     | -0.00557    |\n",
      "|    value_loss         | 1.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 19890176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012753895 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.431       |\n",
      "|    mean_step_reward   | 0.33245867  |\n",
      "|    n_updates          | 9708        |\n",
      "|    policyGradLoss     | -0.00317    |\n",
      "|    value_loss         | 2.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 19898368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014032967 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.414       |\n",
      "|    mean_step_reward   | 0.35697454  |\n",
      "|    n_updates          | 9712        |\n",
      "|    policyGradLoss     | -0.00257    |\n",
      "|    value_loss         | 1.66        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 19906560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007931811 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.888       |\n",
      "|    mean_step_reward   | 0.31435078  |\n",
      "|    n_updates          | 9716        |\n",
      "|    policyGradLoss     | 0.00224     |\n",
      "|    value_loss         | 3.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 19914752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013539751 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.64        |\n",
      "|    mean_step_reward   | 0.4027458   |\n",
      "|    n_updates          | 9720        |\n",
      "|    policyGradLoss     | 0.00395     |\n",
      "|    value_loss         | 3.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 19922944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011936117 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.901       |\n",
      "|    mean_step_reward   | 0.30939093  |\n",
      "|    n_updates          | 9724        |\n",
      "|    policyGradLoss     | -0.00212    |\n",
      "|    value_loss         | 2.32        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_75.zip\n",
      "[EVAL] Mean Return: 409.562, Best Return: 414.228\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_75_409.56.mp4\n",
      "\n",
      "=== Round 77 | Learn 262144 steps (Total trained: 19922944) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1134     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 19931136 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 907         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 19939328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009883723 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.599       |\n",
      "|    mean_step_reward   | 0.33531582  |\n",
      "|    n_updates          | 9732        |\n",
      "|    policyGradLoss     | -0.00107    |\n",
      "|    value_loss         | 1.92        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 863        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 19947520   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00892692 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.969      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.305      |\n",
      "|    mean_step_reward   | 0.3384383  |\n",
      "|    n_updates          | 9736       |\n",
      "|    policyGradLoss     | 0.00203    |\n",
      "|    value_loss         | 1.67       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 836         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 19955712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012790899 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.465       |\n",
      "|    mean_step_reward   | 0.39774883  |\n",
      "|    n_updates          | 9740        |\n",
      "|    policyGradLoss     | -0.00522    |\n",
      "|    value_loss         | 1.74        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 823         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 19963904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012925575 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.929       |\n",
      "|    mean_step_reward   | 0.41953546  |\n",
      "|    n_updates          | 9744        |\n",
      "|    policyGradLoss     | -0.00618    |\n",
      "|    value_loss         | 1.74        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 19972096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012327992 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.02        |\n",
      "|    mean_step_reward   | 0.36908868  |\n",
      "|    n_updates          | 9748        |\n",
      "|    policyGradLoss     | -0.000626   |\n",
      "|    value_loss         | 3.98        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 19980288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010681265 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.386       |\n",
      "|    mean_step_reward   | 0.36572197  |\n",
      "|    n_updates          | 9752        |\n",
      "|    policyGradLoss     | -0.00482    |\n",
      "|    value_loss         | 1.9         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 19988480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009416139 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.883       |\n",
      "|    mean_step_reward   | 0.44195575  |\n",
      "|    n_updates          | 9756        |\n",
      "|    policyGradLoss     | -0.000428   |\n",
      "|    value_loss         | 3.61        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 19996672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008361829 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.24        |\n",
      "|    mean_step_reward   | 0.37422964  |\n",
      "|    n_updates          | 9760        |\n",
      "|    policyGradLoss     | -0.00537    |\n",
      "|    value_loss         | 2.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 20004864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012326365 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.645       |\n",
      "|    mean_step_reward   | 0.4030438   |\n",
      "|    n_updates          | 9764        |\n",
      "|    policyGradLoss     | -0.00625    |\n",
      "|    value_loss         | 1.59        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 20013056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016980976 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.816       |\n",
      "|    mean_step_reward   | 0.3373273   |\n",
      "|    n_updates          | 9768        |\n",
      "|    policyGradLoss     | 0.000126    |\n",
      "|    value_loss         | 4.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 20021248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011694936 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.475       |\n",
      "|    mean_step_reward   | 0.36465386  |\n",
      "|    n_updates          | 9772        |\n",
      "|    policyGradLoss     | -0.00189    |\n",
      "|    value_loss         | 2.11        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 787        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 135        |\n",
      "|    total_timesteps    | 20029440   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01604344 |\n",
      "|    entropy_loss       | -1.65      |\n",
      "|    explained_variance | 0.924      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.206      |\n",
      "|    mean_step_reward   | 0.3452943  |\n",
      "|    n_updates          | 9776       |\n",
      "|    policyGradLoss     | 0.00393    |\n",
      "|    value_loss         | 3.28       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 20037632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012299231 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.23        |\n",
      "|    mean_step_reward   | 0.3750328   |\n",
      "|    n_updates          | 9780        |\n",
      "|    policyGradLoss     | -0.00383    |\n",
      "|    value_loss         | 2.11        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 20045824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008668734 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.97        |\n",
      "|    mean_step_reward   | 0.3847258   |\n",
      "|    n_updates          | 9784        |\n",
      "|    policyGradLoss     | -0.00331    |\n",
      "|    value_loss         | 1.74        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 20054016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012269118 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.813       |\n",
      "|    mean_step_reward   | 0.3374978   |\n",
      "|    n_updates          | 9788        |\n",
      "|    policyGradLoss     | 0.00318     |\n",
      "|    value_loss         | 2.59        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 20062208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012824968 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.715       |\n",
      "|    mean_step_reward   | 0.35490403  |\n",
      "|    n_updates          | 9792        |\n",
      "|    policyGradLoss     | -0.0055     |\n",
      "|    value_loss         | 1.61        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 778          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 189          |\n",
      "|    total_timesteps    | 20070400     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0128748845 |\n",
      "|    entropy_loss       | -1.7         |\n",
      "|    explained_variance | 0.963        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.47         |\n",
      "|    mean_step_reward   | 0.31188488   |\n",
      "|    n_updates          | 9796         |\n",
      "|    policyGradLoss     | -0.00679     |\n",
      "|    value_loss         | 2.49         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 200        |\n",
      "|    total_timesteps    | 20078592   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01149912 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.976      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.932      |\n",
      "|    mean_step_reward   | 0.35900044 |\n",
      "|    n_updates          | 9800       |\n",
      "|    policyGradLoss     | -0.00247   |\n",
      "|    value_loss         | 1.93       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 776          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 210          |\n",
      "|    total_timesteps    | 20086784     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0107876435 |\n",
      "|    entropy_loss       | -1.7         |\n",
      "|    explained_variance | 0.964        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.13         |\n",
      "|    mean_step_reward   | 0.32726032   |\n",
      "|    n_updates          | 9804         |\n",
      "|    policyGradLoss     | -0.00344     |\n",
      "|    value_loss         | 2.52         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 20094976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012370078 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.478       |\n",
      "|    mean_step_reward   | 0.40511954  |\n",
      "|    n_updates          | 9808        |\n",
      "|    policyGradLoss     | 7.11e-05    |\n",
      "|    value_loss         | 3.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 20103168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011585768 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.617       |\n",
      "|    mean_step_reward   | 0.31364733  |\n",
      "|    n_updates          | 9812        |\n",
      "|    policyGradLoss     | -0.00479    |\n",
      "|    value_loss         | 1.88        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 20111360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008681728 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.745       |\n",
      "|    mean_step_reward   | 0.37824005  |\n",
      "|    n_updates          | 9816        |\n",
      "|    policyGradLoss     | -0.00375    |\n",
      "|    value_loss         | 2.04        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 20119552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007432306 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.58        |\n",
      "|    mean_step_reward   | 0.36487326  |\n",
      "|    n_updates          | 9820        |\n",
      "|    policyGradLoss     | -0.00575    |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 20127744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010903799 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.264       |\n",
      "|    mean_step_reward   | 0.37049598  |\n",
      "|    n_updates          | 9824        |\n",
      "|    policyGradLoss     | -0.00532    |\n",
      "|    value_loss         | 1.65        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 20135936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017209938 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.594       |\n",
      "|    mean_step_reward   | 0.3358335   |\n",
      "|    n_updates          | 9828        |\n",
      "|    policyGradLoss     | -0.00653    |\n",
      "|    value_loss         | 1.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 20144128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011636689 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.356       |\n",
      "|    mean_step_reward   | 0.32952026  |\n",
      "|    n_updates          | 9832        |\n",
      "|    policyGradLoss     | -0.00204    |\n",
      "|    value_loss         | 1.72        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 773        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 296        |\n",
      "|    total_timesteps    | 20152320   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01274596 |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.982      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.551      |\n",
      "|    mean_step_reward   | 0.38017714 |\n",
      "|    n_updates          | 9836       |\n",
      "|    policyGradLoss     | -0.0046    |\n",
      "|    value_loss         | 1.7        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 307         |\n",
      "|    total_timesteps    | 20160512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009636695 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.351       |\n",
      "|    mean_step_reward   | 0.3739241   |\n",
      "|    n_updates          | 9840        |\n",
      "|    policyGradLoss     | -0.00303    |\n",
      "|    value_loss         | 1.55        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 772        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 318        |\n",
      "|    total_timesteps    | 20168704   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00948606 |\n",
      "|    entropy_loss       | -1.66      |\n",
      "|    explained_variance | 0.971      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.733      |\n",
      "|    mean_step_reward   | 0.31369466 |\n",
      "|    n_updates          | 9844       |\n",
      "|    policyGradLoss     | -0.00249   |\n",
      "|    value_loss         | 1.94       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 772        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 328        |\n",
      "|    total_timesteps    | 20176896   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00936193 |\n",
      "|    entropy_loss       | -1.68      |\n",
      "|    explained_variance | 0.975      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.763      |\n",
      "|    mean_step_reward   | 0.35969713 |\n",
      "|    n_updates          | 9848       |\n",
      "|    policyGradLoss     | 0.000481   |\n",
      "|    value_loss         | 2.14       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 20185088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008902808 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.727       |\n",
      "|    mean_step_reward   | 0.37009856  |\n",
      "|    n_updates          | 9852        |\n",
      "|    policyGradLoss     | -0.00188    |\n",
      "|    value_loss         | 2.4         |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_76.zip\n",
      "[EVAL] Mean Return: 471.768, Best Return: 474.435\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_76_471.77.mp4\n",
      "\n",
      "=== Round 78 | Learn 262144 steps (Total trained: 20185088) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1136     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 20193280 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 922         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 20201472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009860938 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.48        |\n",
      "|    mean_step_reward   | 0.34948543  |\n",
      "|    n_updates          | 9860        |\n",
      "|    policyGradLoss     | -0.00789    |\n",
      "|    value_loss         | 1.74        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 872         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 20209664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011394922 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.486       |\n",
      "|    mean_step_reward   | 0.37710625  |\n",
      "|    n_updates          | 9864        |\n",
      "|    policyGradLoss     | -0.00521    |\n",
      "|    value_loss         | 2.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 839         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 20217856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009837999 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.338       |\n",
      "|    mean_step_reward   | 0.3624823   |\n",
      "|    n_updates          | 9868        |\n",
      "|    policyGradLoss     | -0.00439    |\n",
      "|    value_loss         | 1.86        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 20226048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014884493 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.429       |\n",
      "|    mean_step_reward   | 0.28749     |\n",
      "|    n_updates          | 9872        |\n",
      "|    policyGradLoss     | 0.00246     |\n",
      "|    value_loss         | 4.5         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 20234240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014960952 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.644       |\n",
      "|    mean_step_reward   | 0.33628476  |\n",
      "|    n_updates          | 9876        |\n",
      "|    policyGradLoss     | 0.0014      |\n",
      "|    value_loss         | 3.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 20242432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010633968 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.656       |\n",
      "|    mean_step_reward   | 0.31522888  |\n",
      "|    n_updates          | 9880        |\n",
      "|    policyGradLoss     | -0.00322    |\n",
      "|    value_loss         | 2.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 20250624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007747748 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.37        |\n",
      "|    mean_step_reward   | 0.327484    |\n",
      "|    n_updates          | 9884        |\n",
      "|    policyGradLoss     | -0.00473    |\n",
      "|    value_loss         | 2.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 20258816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012232531 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.386       |\n",
      "|    mean_step_reward   | 0.30586147  |\n",
      "|    n_updates          | 9888        |\n",
      "|    policyGradLoss     | -0.0013     |\n",
      "|    value_loss         | 2.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 20267008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010318913 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.406       |\n",
      "|    mean_step_reward   | 0.34516865  |\n",
      "|    n_updates          | 9892        |\n",
      "|    policyGradLoss     | -0.00203    |\n",
      "|    value_loss         | 2.23        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 792          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 113          |\n",
      "|    total_timesteps    | 20275200     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0107720215 |\n",
      "|    entropy_loss       | -1.72        |\n",
      "|    explained_variance | 0.962        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.761        |\n",
      "|    mean_step_reward   | 0.35846013   |\n",
      "|    n_updates          | 9896         |\n",
      "|    policyGradLoss     | -0.00312     |\n",
      "|    value_loss         | 2.58         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 20283392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008932609 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.508       |\n",
      "|    mean_step_reward   | 0.36872208  |\n",
      "|    n_updates          | 9900        |\n",
      "|    policyGradLoss     | -0.00375    |\n",
      "|    value_loss         | 2.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 20291584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009822957 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.472       |\n",
      "|    mean_step_reward   | 0.3507582   |\n",
      "|    n_updates          | 9904        |\n",
      "|    policyGradLoss     | -0.00366    |\n",
      "|    value_loss         | 2.2         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 786        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 145        |\n",
      "|    total_timesteps    | 20299776   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01356846 |\n",
      "|    entropy_loss       | -1.7       |\n",
      "|    explained_variance | 0.95       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.491      |\n",
      "|    mean_step_reward   | 0.35995737 |\n",
      "|    n_updates          | 9908       |\n",
      "|    policyGradLoss     | -0.00142   |\n",
      "|    value_loss         | 3.15       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 20307968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009174661 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.53        |\n",
      "|    mean_step_reward   | 0.39232516  |\n",
      "|    n_updates          | 9912        |\n",
      "|    policyGradLoss     | -0.00232    |\n",
      "|    value_loss         | 2.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 20316160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012559664 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.858       |\n",
      "|    mean_step_reward   | 0.29971802  |\n",
      "|    n_updates          | 9916        |\n",
      "|    policyGradLoss     | -0.000315   |\n",
      "|    value_loss         | 4.72        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 20324352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014894325 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.457       |\n",
      "|    mean_step_reward   | 0.28845194  |\n",
      "|    n_updates          | 9920        |\n",
      "|    policyGradLoss     | -0.00304    |\n",
      "|    value_loss         | 1.66        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 20332544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010084387 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.214       |\n",
      "|    mean_step_reward   | 0.34161872  |\n",
      "|    n_updates          | 9924        |\n",
      "|    policyGradLoss     | -0.00677    |\n",
      "|    value_loss         | 1.55        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 20340736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011920892 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.92        |\n",
      "|    mean_step_reward   | 0.2929665   |\n",
      "|    n_updates          | 9928        |\n",
      "|    policyGradLoss     | -0.00753    |\n",
      "|    value_loss         | 1.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 20348928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015144158 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.45        |\n",
      "|    mean_step_reward   | 0.32631367  |\n",
      "|    n_updates          | 9932        |\n",
      "|    policyGradLoss     | -0.00685    |\n",
      "|    value_loss         | 0.987       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 20357120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014015646 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.785       |\n",
      "|    mean_step_reward   | 0.3555648   |\n",
      "|    n_updates          | 9936        |\n",
      "|    policyGradLoss     | 0.00224     |\n",
      "|    value_loss         | 3.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 20365312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008099505 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.743       |\n",
      "|    mean_step_reward   | 0.35479355  |\n",
      "|    n_updates          | 9940        |\n",
      "|    policyGradLoss     | -0.00332    |\n",
      "|    value_loss         | 1.74        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 20373504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010018544 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.21        |\n",
      "|    mean_step_reward   | 0.35831636  |\n",
      "|    n_updates          | 9944        |\n",
      "|    policyGradLoss     | -0.00522    |\n",
      "|    value_loss         | 1.76        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 782        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 251        |\n",
      "|    total_timesteps    | 20381696   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01142535 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.977      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.842      |\n",
      "|    mean_step_reward   | 0.37435356 |\n",
      "|    n_updates          | 9948       |\n",
      "|    policyGradLoss     | -0.0028    |\n",
      "|    value_loss         | 1.76       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 20389888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011681609 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.04        |\n",
      "|    mean_step_reward   | 0.3927068   |\n",
      "|    n_updates          | 9952        |\n",
      "|    policyGradLoss     | 0.000346    |\n",
      "|    value_loss         | 3.96        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 20398080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010252627 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.502       |\n",
      "|    mean_step_reward   | 0.3594455   |\n",
      "|    n_updates          | 9956        |\n",
      "|    policyGradLoss     | -0.000364   |\n",
      "|    value_loss         | 2.05        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 781        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 282        |\n",
      "|    total_timesteps    | 20406272   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00992794 |\n",
      "|    entropy_loss       | -1.71      |\n",
      "|    explained_variance | 0.977      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.551      |\n",
      "|    mean_step_reward   | 0.3503933  |\n",
      "|    n_updates          | 9960       |\n",
      "|    policyGradLoss     | -0.00642   |\n",
      "|    value_loss         | 1.81       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 20414464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012274778 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.719       |\n",
      "|    mean_step_reward   | 0.36687762  |\n",
      "|    n_updates          | 9964        |\n",
      "|    policyGradLoss     | -0.0062     |\n",
      "|    value_loss         | 1.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 20422656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013183754 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.093       |\n",
      "|    mean_step_reward   | 0.27171376  |\n",
      "|    n_updates          | 9968        |\n",
      "|    policyGradLoss     | -0.00861    |\n",
      "|    value_loss         | 1.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 314         |\n",
      "|    total_timesteps    | 20430848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011030807 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.43        |\n",
      "|    mean_step_reward   | 0.26397362  |\n",
      "|    n_updates          | 9972        |\n",
      "|    policyGradLoss     | -0.00218    |\n",
      "|    value_loss         | 3.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 20439040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013501517 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.476       |\n",
      "|    mean_step_reward   | 0.30669558  |\n",
      "|    n_updates          | 9976        |\n",
      "|    policyGradLoss     | -0.00145    |\n",
      "|    value_loss         | 1.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 20447232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012108086 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.545       |\n",
      "|    mean_step_reward   | 0.2778054   |\n",
      "|    n_updates          | 9980        |\n",
      "|    policyGradLoss     | -0.00518    |\n",
      "|    value_loss         | 1.66        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_77.zip\n",
      "[EVAL] Mean Return: 49.050, Best Return: 49.717\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_77_49.05.mp4\n",
      "\n",
      "=== Round 79 | Learn 262144 steps (Total trained: 20447232) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1090     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 20455424 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 900        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 20463616   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01050523 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.984      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.768      |\n",
      "|    mean_step_reward   | 0.3575962  |\n",
      "|    n_updates          | 9988       |\n",
      "|    policyGradLoss     | -0.00581   |\n",
      "|    value_loss         | 1.43       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 847         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 20471808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010607803 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.852       |\n",
      "|    mean_step_reward   | 0.35736638  |\n",
      "|    n_updates          | 9992        |\n",
      "|    policyGradLoss     | -0.00625    |\n",
      "|    value_loss         | 1.71        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 830          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 39           |\n",
      "|    total_timesteps    | 20480000     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0098818755 |\n",
      "|    entropy_loss       | -1.78        |\n",
      "|    explained_variance | 0.973        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.465        |\n",
      "|    mean_step_reward   | 0.28846925   |\n",
      "|    n_updates          | 9996         |\n",
      "|    policyGradLoss     | -0.0022      |\n",
      "|    value_loss         | 2.13         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 814        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 50         |\n",
      "|    total_timesteps    | 20488192   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01304133 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.978      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.289      |\n",
      "|    mean_step_reward   | 0.32930136 |\n",
      "|    n_updates          | 10000      |\n",
      "|    policyGradLoss     | -0.00244   |\n",
      "|    value_loss         | 1.44       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 20496384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013583977 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.339       |\n",
      "|    mean_step_reward   | 0.31046265  |\n",
      "|    n_updates          | 10004       |\n",
      "|    policyGradLoss     | -0.00684    |\n",
      "|    value_loss         | 1.89        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 20504576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008552779 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.507       |\n",
      "|    mean_step_reward   | 0.3217657   |\n",
      "|    n_updates          | 10008       |\n",
      "|    policyGradLoss     | -0.00429    |\n",
      "|    value_loss         | 1.88        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 20512768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011202069 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.321       |\n",
      "|    mean_step_reward   | 0.38135177  |\n",
      "|    n_updates          | 10012       |\n",
      "|    policyGradLoss     | 0.00223     |\n",
      "|    value_loss         | 2.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 20520960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012207644 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.11        |\n",
      "|    mean_step_reward   | 0.34626472  |\n",
      "|    n_updates          | 10016       |\n",
      "|    policyGradLoss     | 0.00876     |\n",
      "|    value_loss         | 4.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 20529152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008374945 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.68        |\n",
      "|    mean_step_reward   | 0.3328023   |\n",
      "|    n_updates          | 10020       |\n",
      "|    policyGradLoss     | -0.00147    |\n",
      "|    value_loss         | 1.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 20537344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012745252 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.3         |\n",
      "|    mean_step_reward   | 0.392107    |\n",
      "|    n_updates          | 10024       |\n",
      "|    policyGradLoss     | 7.2e-05     |\n",
      "|    value_loss         | 3.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 20545536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012642866 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.277       |\n",
      "|    mean_step_reward   | 0.31275865  |\n",
      "|    n_updates          | 10028       |\n",
      "|    policyGradLoss     | 0.00293     |\n",
      "|    value_loss         | 2.34        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 20553728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012406524 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.47        |\n",
      "|    mean_step_reward   | 0.39200556  |\n",
      "|    n_updates          | 10032       |\n",
      "|    policyGradLoss     | 0.00283     |\n",
      "|    value_loss         | 7.35        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 783          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 146          |\n",
      "|    total_timesteps    | 20561920     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0135191865 |\n",
      "|    entropy_loss       | -1.71        |\n",
      "|    explained_variance | 0.945        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.546        |\n",
      "|    mean_step_reward   | 0.3336445    |\n",
      "|    n_updates          | 10036        |\n",
      "|    policyGradLoss     | -3.58e-05    |\n",
      "|    value_loss         | 2.71         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 20570112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016722403 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.849       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.693       |\n",
      "|    mean_step_reward   | 0.3118617   |\n",
      "|    n_updates          | 10040       |\n",
      "|    policyGradLoss     | 0.00367     |\n",
      "|    value_loss         | 5.09        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 20578304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011295774 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.557       |\n",
      "|    mean_step_reward   | 0.3189301   |\n",
      "|    n_updates          | 10044       |\n",
      "|    policyGradLoss     | 0.00254     |\n",
      "|    value_loss         | 2.97        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 20586496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011037083 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.445       |\n",
      "|    mean_step_reward   | 0.354292    |\n",
      "|    n_updates          | 10048       |\n",
      "|    policyGradLoss     | -0.00497    |\n",
      "|    value_loss         | 2.2         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 778          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 189          |\n",
      "|    total_timesteps    | 20594688     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0139091415 |\n",
      "|    entropy_loss       | -1.7         |\n",
      "|    explained_variance | 0.915        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.763        |\n",
      "|    mean_step_reward   | 0.35033795   |\n",
      "|    n_updates          | 10052        |\n",
      "|    policyGradLoss     | 0.00441      |\n",
      "|    value_loss         | 3.04         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 20602880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016958766 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.934       |\n",
      "|    mean_step_reward   | 0.32648274  |\n",
      "|    n_updates          | 10056       |\n",
      "|    policyGradLoss     | 0.00291     |\n",
      "|    value_loss         | 4.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 20611072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014898382 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.892       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.995       |\n",
      "|    mean_step_reward   | 0.34528053  |\n",
      "|    n_updates          | 10060       |\n",
      "|    policyGradLoss     | 0.00461     |\n",
      "|    value_loss         | 7.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 20619264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013109279 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.04        |\n",
      "|    mean_step_reward   | 0.33697575  |\n",
      "|    n_updates          | 10064       |\n",
      "|    policyGradLoss     | -0.00181    |\n",
      "|    value_loss         | 2.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 20627456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012800537 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.232       |\n",
      "|    mean_step_reward   | 0.26928127  |\n",
      "|    n_updates          | 10068       |\n",
      "|    policyGradLoss     | -0.00199    |\n",
      "|    value_loss         | 2.6         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 774        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 243        |\n",
      "|    total_timesteps    | 20635648   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01115465 |\n",
      "|    entropy_loss       | -1.72      |\n",
      "|    explained_variance | 0.951      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.426      |\n",
      "|    mean_step_reward   | 0.33179218 |\n",
      "|    n_updates          | 10072      |\n",
      "|    policyGradLoss     | -0.00236   |\n",
      "|    value_loss         | 2.48       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 20643840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010686736 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.12        |\n",
      "|    mean_step_reward   | 0.32084417  |\n",
      "|    n_updates          | 10076       |\n",
      "|    policyGradLoss     | 0.00459     |\n",
      "|    value_loss         | 5.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 20652032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009973437 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.699       |\n",
      "|    mean_step_reward   | 0.3930999   |\n",
      "|    n_updates          | 10080       |\n",
      "|    policyGradLoss     | -0.00449    |\n",
      "|    value_loss         | 2.04        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 774          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 274          |\n",
      "|    total_timesteps    | 20660224     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0063503785 |\n",
      "|    entropy_loss       | -1.72        |\n",
      "|    explained_variance | 0.983        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.08         |\n",
      "|    mean_step_reward   | 0.40923405   |\n",
      "|    n_updates          | 10084        |\n",
      "|    policyGradLoss     | -0.00398     |\n",
      "|    value_loss         | 2.1          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 20668416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010759772 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.428       |\n",
      "|    mean_step_reward   | 0.3342205   |\n",
      "|    n_updates          | 10088       |\n",
      "|    policyGradLoss     | -0.000853   |\n",
      "|    value_loss         | 2.94        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 20676608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013540358 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.154       |\n",
      "|    mean_step_reward   | 0.3649876   |\n",
      "|    n_updates          | 10092       |\n",
      "|    policyGradLoss     | -0.00291    |\n",
      "|    value_loss         | 1.39        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 773        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 307        |\n",
      "|    total_timesteps    | 20684800   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0113337  |\n",
      "|    entropy_loss       | -1.74      |\n",
      "|    explained_variance | 0.953      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.863      |\n",
      "|    mean_step_reward   | 0.34391433 |\n",
      "|    n_updates          | 10096      |\n",
      "|    policyGradLoss     | 0.00122    |\n",
      "|    value_loss         | 3.39       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 20692992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009039032 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.719       |\n",
      "|    mean_step_reward   | 0.30876213  |\n",
      "|    n_updates          | 10100       |\n",
      "|    policyGradLoss     | -0.00509    |\n",
      "|    value_loss         | 2.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 20701184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012750072 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.642       |\n",
      "|    mean_step_reward   | 0.39621955  |\n",
      "|    n_updates          | 10104       |\n",
      "|    policyGradLoss     | -0.000379   |\n",
      "|    value_loss         | 3.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 20709376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007556297 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.755       |\n",
      "|    mean_step_reward   | 0.34537432  |\n",
      "|    n_updates          | 10108       |\n",
      "|    policyGradLoss     | -0.0033     |\n",
      "|    value_loss         | 2.45        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_78.zip\n",
      "[EVAL] Mean Return: 522.132, Best Return: 527.465\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_78_522.13.mp4\n",
      "\n",
      "=== Round 80 | Learn 262144 steps (Total trained: 20709376) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1119     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 20717568 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 924         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 20725760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010909084 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.219       |\n",
      "|    mean_step_reward   | 0.41590738  |\n",
      "|    n_updates          | 10116       |\n",
      "|    policyGradLoss     | -0.00396    |\n",
      "|    value_loss         | 2.35        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 871          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 20733952     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0077088047 |\n",
      "|    entropy_loss       | -1.73        |\n",
      "|    explained_variance | 0.982        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.38         |\n",
      "|    mean_step_reward   | 0.31034058   |\n",
      "|    n_updates          | 10120        |\n",
      "|    policyGradLoss     | -0.00414     |\n",
      "|    value_loss         | 2.05         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 840         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 20742144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009938642 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.599       |\n",
      "|    mean_step_reward   | 0.38108552  |\n",
      "|    n_updates          | 10124       |\n",
      "|    policyGradLoss     | -0.00259    |\n",
      "|    value_loss         | 2.83        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 829         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 20750336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010386808 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.235       |\n",
      "|    mean_step_reward   | 0.42675582  |\n",
      "|    n_updates          | 10128       |\n",
      "|    policyGradLoss     | -0.00217    |\n",
      "|    value_loss         | 1.93        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 20758528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014714584 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.822       |\n",
      "|    mean_step_reward   | 0.39584935  |\n",
      "|    n_updates          | 10132       |\n",
      "|    policyGradLoss     | 0.00693     |\n",
      "|    value_loss         | 5.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 20766720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010258348 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.168       |\n",
      "|    mean_step_reward   | 0.35384905  |\n",
      "|    n_updates          | 10136       |\n",
      "|    policyGradLoss     | -0.00399    |\n",
      "|    value_loss         | 1.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 20774912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009662351 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.444       |\n",
      "|    mean_step_reward   | 0.38021713  |\n",
      "|    n_updates          | 10140       |\n",
      "|    policyGradLoss     | -0.00317    |\n",
      "|    value_loss         | 1.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 20783104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010263933 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.724       |\n",
      "|    mean_step_reward   | 0.35647923  |\n",
      "|    n_updates          | 10144       |\n",
      "|    policyGradLoss     | -0.00376    |\n",
      "|    value_loss         | 2.26        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 795        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 102        |\n",
      "|    total_timesteps    | 20791296   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01077154 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.98       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.156      |\n",
      "|    mean_step_reward   | 0.38240054 |\n",
      "|    n_updates          | 10148      |\n",
      "|    policyGradLoss     | -0.00367   |\n",
      "|    value_loss         | 1.94       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 792        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 113        |\n",
      "|    total_timesteps    | 20799488   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00967706 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.988      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.907      |\n",
      "|    mean_step_reward   | 0.35756457 |\n",
      "|    n_updates          | 10152      |\n",
      "|    policyGradLoss     | -0.00431   |\n",
      "|    value_loss         | 1.55       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 20807680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010090048 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.11        |\n",
      "|    mean_step_reward   | 0.38473815  |\n",
      "|    n_updates          | 10156       |\n",
      "|    policyGradLoss     | -0.00529    |\n",
      "|    value_loss         | 1.95        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 20815872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014980061 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.304       |\n",
      "|    mean_step_reward   | 0.33528817  |\n",
      "|    n_updates          | 10160       |\n",
      "|    policyGradLoss     | -0.00595    |\n",
      "|    value_loss         | 1.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 20824064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009712009 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.87        |\n",
      "|    mean_step_reward   | 0.44317693  |\n",
      "|    n_updates          | 10164       |\n",
      "|    policyGradLoss     | -0.00534    |\n",
      "|    value_loss         | 1.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 20832256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011549616 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.824       |\n",
      "|    mean_step_reward   | 0.3379783   |\n",
      "|    n_updates          | 10168       |\n",
      "|    policyGradLoss     | -0.003      |\n",
      "|    value_loss         | 3.93        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 20840448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012296434 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.464       |\n",
      "|    mean_step_reward   | 0.3397234   |\n",
      "|    n_updates          | 10172       |\n",
      "|    policyGradLoss     | 0.000286    |\n",
      "|    value_loss         | 2.71        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 20848640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008687683 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.1         |\n",
      "|    mean_step_reward   | 0.36321276  |\n",
      "|    n_updates          | 10176       |\n",
      "|    policyGradLoss     | -0.00534    |\n",
      "|    value_loss         | 2.13        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 783          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 188          |\n",
      "|    total_timesteps    | 20856832     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0098279305 |\n",
      "|    entropy_loss       | -1.7         |\n",
      "|    explained_variance | 0.921        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.446        |\n",
      "|    mean_step_reward   | 0.3441307    |\n",
      "|    n_updates          | 10180        |\n",
      "|    policyGradLoss     | 0.000957     |\n",
      "|    value_loss         | 2.7          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 20865024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013231431 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.342       |\n",
      "|    mean_step_reward   | 0.3897888   |\n",
      "|    n_updates          | 10184       |\n",
      "|    policyGradLoss     | -0.00293    |\n",
      "|    value_loss         | 1.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 20873216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011435354 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.608       |\n",
      "|    mean_step_reward   | 0.32077956  |\n",
      "|    n_updates          | 10188       |\n",
      "|    policyGradLoss     | -0.00906    |\n",
      "|    value_loss         | 1.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 20881408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008741529 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.394       |\n",
      "|    mean_step_reward   | 0.34634352  |\n",
      "|    n_updates          | 10192       |\n",
      "|    policyGradLoss     | -0.00639    |\n",
      "|    value_loss         | 1.41        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 779          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 231          |\n",
      "|    total_timesteps    | 20889600     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0072395187 |\n",
      "|    entropy_loss       | -1.73        |\n",
      "|    explained_variance | 0.976        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.329        |\n",
      "|    mean_step_reward   | 0.30671376   |\n",
      "|    n_updates          | 10196        |\n",
      "|    policyGradLoss     | 0.000777     |\n",
      "|    value_loss         | 1.82         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 20897792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010819097 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.181       |\n",
      "|    mean_step_reward   | 0.37707716  |\n",
      "|    n_updates          | 10200       |\n",
      "|    policyGradLoss     | -0.00684    |\n",
      "|    value_loss         | 1.11        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 777          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 252          |\n",
      "|    total_timesteps    | 20905984     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0117921885 |\n",
      "|    entropy_loss       | -1.7         |\n",
      "|    explained_variance | 0.992        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.291        |\n",
      "|    mean_step_reward   | 0.3512286    |\n",
      "|    n_updates          | 10204        |\n",
      "|    policyGradLoss     | -0.00716     |\n",
      "|    value_loss         | 1.11         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 20914176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010224312 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.743       |\n",
      "|    mean_step_reward   | 0.40337384  |\n",
      "|    n_updates          | 10208       |\n",
      "|    policyGradLoss     | -0.00468    |\n",
      "|    value_loss         | 1.71        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 20922368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015964024 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.737       |\n",
      "|    mean_step_reward   | 0.38878658  |\n",
      "|    n_updates          | 10212       |\n",
      "|    policyGradLoss     | -0.00766    |\n",
      "|    value_loss         | 1.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 20930560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009153169 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.757       |\n",
      "|    mean_step_reward   | 0.39219007  |\n",
      "|    n_updates          | 10216       |\n",
      "|    policyGradLoss     | -0.00572    |\n",
      "|    value_loss         | 2.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 20938752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008985495 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.456       |\n",
      "|    mean_step_reward   | 0.33370307  |\n",
      "|    n_updates          | 10220       |\n",
      "|    policyGradLoss     | -0.00861    |\n",
      "|    value_loss         | 1.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 20946944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010704089 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.439       |\n",
      "|    mean_step_reward   | 0.43813005  |\n",
      "|    n_updates          | 10224       |\n",
      "|    policyGradLoss     | -0.00605    |\n",
      "|    value_loss         | 1.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 20955136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009382816 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.932       |\n",
      "|    mean_step_reward   | 0.3726622   |\n",
      "|    n_updates          | 10228       |\n",
      "|    policyGradLoss     | -0.00619    |\n",
      "|    value_loss         | 2.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 20963328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016857661 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.45        |\n",
      "|    mean_step_reward   | 0.33406478  |\n",
      "|    n_updates          | 10232       |\n",
      "|    policyGradLoss     | -0.00148    |\n",
      "|    value_loss         | 1.98        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 20971520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012942798 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.04        |\n",
      "|    mean_step_reward   | 0.3782209   |\n",
      "|    n_updates          | 10236       |\n",
      "|    policyGradLoss     | -0.00178    |\n",
      "|    value_loss         | 2.76        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_79.zip\n",
      "[EVAL] Mean Return: 517.467, Best Return: 524.133\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_79_517.47.mp4\n",
      "\n",
      "=== Round 81 | Learn 262144 steps (Total trained: 20971520) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1096     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 20979712 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 898         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 20987904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008871691 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.587       |\n",
      "|    mean_step_reward   | 0.3824342   |\n",
      "|    n_updates          | 10244       |\n",
      "|    policyGradLoss     | -0.00387    |\n",
      "|    value_loss         | 1.92        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 855          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 20996096     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0074557094 |\n",
      "|    entropy_loss       | -1.73        |\n",
      "|    explained_variance | 0.98         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.32         |\n",
      "|    mean_step_reward   | 0.36354652   |\n",
      "|    n_updates          | 10248        |\n",
      "|    policyGradLoss     | -0.00437     |\n",
      "|    value_loss         | 2.31         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 831         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 21004288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012887659 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.67        |\n",
      "|    mean_step_reward   | 0.33974314  |\n",
      "|    n_updates          | 10252       |\n",
      "|    policyGradLoss     | -0.0018     |\n",
      "|    value_loss         | 1.94        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 21012480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014583258 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.194       |\n",
      "|    mean_step_reward   | 0.34279072  |\n",
      "|    n_updates          | 10256       |\n",
      "|    policyGradLoss     | -0.00155    |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 21020672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012866575 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.712       |\n",
      "|    mean_step_reward   | 0.3314734   |\n",
      "|    n_updates          | 10260       |\n",
      "|    policyGradLoss     | -0.00497    |\n",
      "|    value_loss         | 3.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 21028864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017451378 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.963       |\n",
      "|    mean_step_reward   | 0.39585137  |\n",
      "|    n_updates          | 10264       |\n",
      "|    policyGradLoss     | 0.00245     |\n",
      "|    value_loss         | 4.82        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 793        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 82         |\n",
      "|    total_timesteps    | 21037056   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01743986 |\n",
      "|    entropy_loss       | -1.7       |\n",
      "|    explained_variance | 0.928      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 3.31       |\n",
      "|    mean_step_reward   | 0.36618158 |\n",
      "|    n_updates          | 10268      |\n",
      "|    policyGradLoss     | 0.00351    |\n",
      "|    value_loss         | 7.42       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 21045248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011158638 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.785       |\n",
      "|    mean_step_reward   | 0.34774894  |\n",
      "|    n_updates          | 10272       |\n",
      "|    policyGradLoss     | -0.00316    |\n",
      "|    value_loss         | 2.88        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 21053440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011377141 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.822       |\n",
      "|    mean_step_reward   | 0.36354738  |\n",
      "|    n_updates          | 10276       |\n",
      "|    policyGradLoss     | -0.00624    |\n",
      "|    value_loss         | 1.63        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 785        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 114        |\n",
      "|    total_timesteps    | 21061632   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01492029 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.96       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.72       |\n",
      "|    mean_step_reward   | 0.36830676 |\n",
      "|    n_updates          | 10280      |\n",
      "|    policyGradLoss     | 0.00203    |\n",
      "|    value_loss         | 2.94       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 21069824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012841387 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.7         |\n",
      "|    mean_step_reward   | 0.3495603   |\n",
      "|    n_updates          | 10284       |\n",
      "|    policyGradLoss     | -0.00358    |\n",
      "|    value_loss         | 1.93        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 21078016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009547763 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.445       |\n",
      "|    mean_step_reward   | 0.4449724   |\n",
      "|    n_updates          | 10288       |\n",
      "|    policyGradLoss     | -0.00502    |\n",
      "|    value_loss         | 1.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 21086208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012790881 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.07        |\n",
      "|    mean_step_reward   | 0.3168722   |\n",
      "|    n_updates          | 10292       |\n",
      "|    policyGradLoss     | -0.00309    |\n",
      "|    value_loss         | 1.95        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 21094400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012022161 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.57        |\n",
      "|    mean_step_reward   | 0.39732683  |\n",
      "|    n_updates          | 10296       |\n",
      "|    policyGradLoss     | -0.00672    |\n",
      "|    value_loss         | 1.37        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 780        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 167        |\n",
      "|    total_timesteps    | 21102592   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01600782 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.958      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.16       |\n",
      "|    mean_step_reward   | 0.39822954 |\n",
      "|    n_updates          | 10300      |\n",
      "|    policyGradLoss     | 0.00174    |\n",
      "|    value_loss         | 3.11       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 21110784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012809878 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.14        |\n",
      "|    mean_step_reward   | 0.36319387  |\n",
      "|    n_updates          | 10304       |\n",
      "|    policyGradLoss     | -0.000156   |\n",
      "|    value_loss         | 4.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 21118976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010478556 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.357       |\n",
      "|    mean_step_reward   | 0.37856287  |\n",
      "|    n_updates          | 10308       |\n",
      "|    policyGradLoss     | -0.00518    |\n",
      "|    value_loss         | 1.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 21127168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014486583 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.482       |\n",
      "|    mean_step_reward   | 0.36830634  |\n",
      "|    n_updates          | 10312       |\n",
      "|    policyGradLoss     | -0.00586    |\n",
      "|    value_loss         | 1.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 21135360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008842792 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.706       |\n",
      "|    mean_step_reward   | 0.36001503  |\n",
      "|    n_updates          | 10316       |\n",
      "|    policyGradLoss     | -0.00664    |\n",
      "|    value_loss         | 1.9         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 21143552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012053886 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.626       |\n",
      "|    mean_step_reward   | 0.40103954  |\n",
      "|    n_updates          | 10320       |\n",
      "|    policyGradLoss     | -0.00852    |\n",
      "|    value_loss         | 1.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 21151744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009681267 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.36        |\n",
      "|    mean_step_reward   | 0.33282745  |\n",
      "|    n_updates          | 10324       |\n",
      "|    policyGradLoss     | -0.00314    |\n",
      "|    value_loss         | 2.48        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 776        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 242        |\n",
      "|    total_timesteps    | 21159936   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00892423 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.98       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.26       |\n",
      "|    mean_step_reward   | 0.3967675  |\n",
      "|    n_updates          | 10328      |\n",
      "|    policyGradLoss     | -0.00246   |\n",
      "|    value_loss         | 1.67       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 21168128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009549096 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.71        |\n",
      "|    mean_step_reward   | 0.35205352  |\n",
      "|    n_updates          | 10332       |\n",
      "|    policyGradLoss     | -0.00414    |\n",
      "|    value_loss         | 1.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 21176320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010464542 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.838       |\n",
      "|    mean_step_reward   | 0.32241043  |\n",
      "|    n_updates          | 10336       |\n",
      "|    policyGradLoss     | -0.00309    |\n",
      "|    value_loss         | 1.59        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 21184512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013309935 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.467       |\n",
      "|    mean_step_reward   | 0.3735352   |\n",
      "|    n_updates          | 10340       |\n",
      "|    policyGradLoss     | -0.0084     |\n",
      "|    value_loss         | 1.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 21192704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011300549 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.665       |\n",
      "|    mean_step_reward   | 0.3746235   |\n",
      "|    n_updates          | 10344       |\n",
      "|    policyGradLoss     | -0.00658    |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 21200896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009462088 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.754       |\n",
      "|    mean_step_reward   | 0.3902604   |\n",
      "|    n_updates          | 10348       |\n",
      "|    policyGradLoss     | -0.00592    |\n",
      "|    value_loss         | 1.94        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 21209088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011853274 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.02        |\n",
      "|    mean_step_reward   | 0.37143493  |\n",
      "|    n_updates          | 10352       |\n",
      "|    policyGradLoss     | -0.00845    |\n",
      "|    value_loss         | 1.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 21217280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011744158 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.514       |\n",
      "|    mean_step_reward   | 0.40971786  |\n",
      "|    n_updates          | 10356       |\n",
      "|    policyGradLoss     | -0.00675    |\n",
      "|    value_loss         | 1.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 21225472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008191487 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.83        |\n",
      "|    mean_step_reward   | 0.35173768  |\n",
      "|    n_updates          | 10360       |\n",
      "|    policyGradLoss     | -0.00579    |\n",
      "|    value_loss         | 1.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 21233664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010862281 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.717       |\n",
      "|    mean_step_reward   | 0.4306363   |\n",
      "|    n_updates          | 10364       |\n",
      "|    policyGradLoss     | -0.00417    |\n",
      "|    value_loss         | 2.98        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_80.zip\n",
      "[EVAL] Mean Return: 515.396, Best Return: 524.396\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_80_515.40.mp4\n",
      "\n",
      "=== Round 82 | Learn 262144 steps (Total trained: 21233664) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1158     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 21241856 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 923         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 21250048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016539535 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.741       |\n",
      "|    mean_step_reward   | 0.4119072   |\n",
      "|    n_updates          | 10372       |\n",
      "|    policyGradLoss     | 0.00231     |\n",
      "|    value_loss         | 5.16        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 865        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 21258240   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00876595 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.977      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.9        |\n",
      "|    mean_step_reward   | 0.3441082  |\n",
      "|    n_updates          | 10376      |\n",
      "|    policyGradLoss     | -0.0046    |\n",
      "|    value_loss         | 1.82       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 21266432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009713961 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.604       |\n",
      "|    mean_step_reward   | 0.39500606  |\n",
      "|    n_updates          | 10380       |\n",
      "|    policyGradLoss     | -0.00468    |\n",
      "|    value_loss         | 1.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 21274624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011520829 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.35        |\n",
      "|    mean_step_reward   | 0.38970056  |\n",
      "|    n_updates          | 10384       |\n",
      "|    policyGradLoss     | -0.00141    |\n",
      "|    value_loss         | 4.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 21282816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010887339 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.514       |\n",
      "|    mean_step_reward   | 0.34862003  |\n",
      "|    n_updates          | 10388       |\n",
      "|    policyGradLoss     | -0.00365    |\n",
      "|    value_loss         | 2.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 21291008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010380698 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.655       |\n",
      "|    mean_step_reward   | 0.39700925  |\n",
      "|    n_updates          | 10392       |\n",
      "|    policyGradLoss     | -0.00241    |\n",
      "|    value_loss         | 2.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 21299200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010014979 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.247       |\n",
      "|    mean_step_reward   | 0.40209454  |\n",
      "|    n_updates          | 10396       |\n",
      "|    policyGradLoss     | -0.00704    |\n",
      "|    value_loss         | 1.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 21307392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010745343 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.769       |\n",
      "|    mean_step_reward   | 0.38665742  |\n",
      "|    n_updates          | 10400       |\n",
      "|    policyGradLoss     | -0.00431    |\n",
      "|    value_loss         | 2.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 21315584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012059066 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.06        |\n",
      "|    mean_step_reward   | 0.3394823   |\n",
      "|    n_updates          | 10404       |\n",
      "|    policyGradLoss     | -0.00456    |\n",
      "|    value_loss         | 1.52        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 21323776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011545482 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.905       |\n",
      "|    mean_step_reward   | 0.3246051   |\n",
      "|    n_updates          | 10408       |\n",
      "|    policyGradLoss     | -0.00434    |\n",
      "|    value_loss         | 2.94        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 21331968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010173504 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.38        |\n",
      "|    mean_step_reward   | 0.37329823  |\n",
      "|    n_updates          | 10412       |\n",
      "|    policyGradLoss     | -0.00802    |\n",
      "|    value_loss         | 2.14        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 782          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 136          |\n",
      "|    total_timesteps    | 21340160     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0077853077 |\n",
      "|    entropy_loss       | -1.67        |\n",
      "|    explained_variance | 0.987        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.373        |\n",
      "|    mean_step_reward   | 0.43846086   |\n",
      "|    n_updates          | 10416        |\n",
      "|    policyGradLoss     | -0.00687     |\n",
      "|    value_loss         | 1.58         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 21348352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011770885 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.377       |\n",
      "|    mean_step_reward   | 0.28230807  |\n",
      "|    n_updates          | 10420       |\n",
      "|    policyGradLoss     | -0.00354    |\n",
      "|    value_loss         | 1.84        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 21356544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013177529 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.564       |\n",
      "|    mean_step_reward   | 0.45985934  |\n",
      "|    n_updates          | 10424       |\n",
      "|    policyGradLoss     | -0.00467    |\n",
      "|    value_loss         | 1.43        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 779          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 168          |\n",
      "|    total_timesteps    | 21364736     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0136392545 |\n",
      "|    entropy_loss       | -1.72        |\n",
      "|    explained_variance | 0.963        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.34         |\n",
      "|    mean_step_reward   | 0.32191312   |\n",
      "|    n_updates          | 10428        |\n",
      "|    policyGradLoss     | 0.00039      |\n",
      "|    value_loss         | 3.49         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 21372928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009991045 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.646       |\n",
      "|    mean_step_reward   | 0.39829034  |\n",
      "|    n_updates          | 10432       |\n",
      "|    policyGradLoss     | -0.00169    |\n",
      "|    value_loss         | 1.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 21381120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011949869 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.697       |\n",
      "|    mean_step_reward   | 0.42838246  |\n",
      "|    n_updates          | 10436       |\n",
      "|    policyGradLoss     | -0.00306    |\n",
      "|    value_loss         | 1.93        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 21389312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013487678 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.553       |\n",
      "|    mean_step_reward   | 0.33097547  |\n",
      "|    n_updates          | 10440       |\n",
      "|    policyGradLoss     | -0.00326    |\n",
      "|    value_loss         | 2.83        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 21397504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013704334 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.214       |\n",
      "|    mean_step_reward   | 0.3887502   |\n",
      "|    n_updates          | 10444       |\n",
      "|    policyGradLoss     | -0.00327    |\n",
      "|    value_loss         | 1.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 21405696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010678211 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.04        |\n",
      "|    mean_step_reward   | 0.37013465  |\n",
      "|    n_updates          | 10448       |\n",
      "|    policyGradLoss     | 0.0011      |\n",
      "|    value_loss         | 5.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 21413888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010049339 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.472       |\n",
      "|    mean_step_reward   | 0.37115425  |\n",
      "|    n_updates          | 10452       |\n",
      "|    policyGradLoss     | -0.00234    |\n",
      "|    value_loss         | 2.64        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 21422080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012906329 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 2.05        |\n",
      "|    mean_step_reward   | 0.34038627  |\n",
      "|    n_updates          | 10456       |\n",
      "|    policyGradLoss     | 0.000153    |\n",
      "|    value_loss         | 3.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 21430272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010902558 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.462       |\n",
      "|    mean_step_reward   | 0.3483728   |\n",
      "|    n_updates          | 10460       |\n",
      "|    policyGradLoss     | -0.00494    |\n",
      "|    value_loss         | 2.23        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 776          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 263          |\n",
      "|    total_timesteps    | 21438464     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0110835545 |\n",
      "|    entropy_loss       | -1.71        |\n",
      "|    explained_variance | 0.974        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.445        |\n",
      "|    mean_step_reward   | 0.38224757   |\n",
      "|    n_updates          | 10464        |\n",
      "|    policyGradLoss     | -0.00425     |\n",
      "|    value_loss         | 2.73         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 21446656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010972314 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.4         |\n",
      "|    mean_step_reward   | 0.32045507  |\n",
      "|    n_updates          | 10468       |\n",
      "|    policyGradLoss     | -0.00289    |\n",
      "|    value_loss         | 2.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 21454848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011871487 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.243       |\n",
      "|    mean_step_reward   | 0.35604396  |\n",
      "|    n_updates          | 10472       |\n",
      "|    policyGradLoss     | -0.00237    |\n",
      "|    value_loss         | 1.41        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 776          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 295          |\n",
      "|    total_timesteps    | 21463040     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0100883655 |\n",
      "|    entropy_loss       | -1.72        |\n",
      "|    explained_variance | 0.97         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.66         |\n",
      "|    mean_step_reward   | 0.38333106   |\n",
      "|    n_updates          | 10476        |\n",
      "|    policyGradLoss     | -0.00378     |\n",
      "|    value_loss         | 2.43         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 21471232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012028975 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.598       |\n",
      "|    mean_step_reward   | 0.3368154   |\n",
      "|    n_updates          | 10480       |\n",
      "|    policyGradLoss     | -0.00443    |\n",
      "|    value_loss         | 2.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 21479424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012799118 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.466       |\n",
      "|    mean_step_reward   | 0.32996655  |\n",
      "|    n_updates          | 10484       |\n",
      "|    policyGradLoss     | -0.00501    |\n",
      "|    value_loss         | 1.78        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 775        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 327        |\n",
      "|    total_timesteps    | 21487616   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01165462 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.976      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.884      |\n",
      "|    mean_step_reward   | 0.3678063  |\n",
      "|    n_updates          | 10488      |\n",
      "|    policyGradLoss     | -0.00184   |\n",
      "|    value_loss         | 1.92       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 21495808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010495889 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.208       |\n",
      "|    mean_step_reward   | 0.4037518   |\n",
      "|    n_updates          | 10492       |\n",
      "|    policyGradLoss     | -0.0057     |\n",
      "|    value_loss         | 0.993       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_81.zip\n",
      "[EVAL] Mean Return: 527.530, Best Return: 536.196\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_81_527.53.mp4\n",
      "\n",
      "=== Round 83 | Learn 262144 steps (Total trained: 21495808) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1132     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 21504000 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 918         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 21512192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013084386 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.08        |\n",
      "|    mean_step_reward   | 0.42502955  |\n",
      "|    n_updates          | 10500       |\n",
      "|    policyGradLoss     | 0.0018      |\n",
      "|    value_loss         | 3.96        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 861         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 21520384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010739307 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.676       |\n",
      "|    mean_step_reward   | 0.4253012   |\n",
      "|    n_updates          | 10504       |\n",
      "|    policyGradLoss     | -0.000656   |\n",
      "|    value_loss         | 2.54        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 836          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 39           |\n",
      "|    total_timesteps    | 21528576     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0120300455 |\n",
      "|    entropy_loss       | -1.72        |\n",
      "|    explained_variance | 0.958        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.07         |\n",
      "|    mean_step_reward   | 0.34444758   |\n",
      "|    n_updates          | 10508        |\n",
      "|    policyGradLoss     | -0.00659     |\n",
      "|    value_loss         | 2.12         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 21536768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011231515 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.419       |\n",
      "|    mean_step_reward   | 0.34877038  |\n",
      "|    n_updates          | 10512       |\n",
      "|    policyGradLoss     | -0.00612    |\n",
      "|    value_loss         | 1.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 21544960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012633551 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.746       |\n",
      "|    mean_step_reward   | 0.36431494  |\n",
      "|    n_updates          | 10516       |\n",
      "|    policyGradLoss     | -0.00733    |\n",
      "|    value_loss         | 1.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 21553152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010995291 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.624       |\n",
      "|    mean_step_reward   | 0.3490697   |\n",
      "|    n_updates          | 10520       |\n",
      "|    policyGradLoss     | -0.00632    |\n",
      "|    value_loss         | 1.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 21561344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012292321 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.407       |\n",
      "|    mean_step_reward   | 0.35488543  |\n",
      "|    n_updates          | 10524       |\n",
      "|    policyGradLoss     | -0.0045     |\n",
      "|    value_loss         | 2.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 21569536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009949727 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.964       |\n",
      "|    mean_step_reward   | 0.3891582   |\n",
      "|    n_updates          | 10528       |\n",
      "|    policyGradLoss     | -0.00364    |\n",
      "|    value_loss         | 2.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 21577728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007786889 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.33        |\n",
      "|    mean_step_reward   | 0.3719911   |\n",
      "|    n_updates          | 10532       |\n",
      "|    policyGradLoss     | -0.00429    |\n",
      "|    value_loss         | 1.96        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 21585920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008361716 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.667       |\n",
      "|    mean_step_reward   | 0.3241349   |\n",
      "|    n_updates          | 10536       |\n",
      "|    policyGradLoss     | -0.0063     |\n",
      "|    value_loss         | 2.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 21594112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009158593 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.183       |\n",
      "|    mean_step_reward   | 0.37953705  |\n",
      "|    n_updates          | 10540       |\n",
      "|    policyGradLoss     | -0.00545    |\n",
      "|    value_loss         | 1.65        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 21602304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009159608 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.16        |\n",
      "|    mean_step_reward   | 0.3940902   |\n",
      "|    n_updates          | 10544       |\n",
      "|    policyGradLoss     | -0.00224    |\n",
      "|    value_loss         | 2.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 21610496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011900521 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.966       |\n",
      "|    mean_step_reward   | 0.35540932  |\n",
      "|    n_updates          | 10548       |\n",
      "|    policyGradLoss     | -0.00415    |\n",
      "|    value_loss         | 2.44        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 782          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 156          |\n",
      "|    total_timesteps    | 21618688     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0126885185 |\n",
      "|    entropy_loss       | -1.67        |\n",
      "|    explained_variance | 0.975        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.76         |\n",
      "|    mean_step_reward   | 0.4085508    |\n",
      "|    n_updates          | 10552        |\n",
      "|    policyGradLoss     | -0.00334     |\n",
      "|    value_loss         | 1.95         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 21626880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013202157 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.398       |\n",
      "|    mean_step_reward   | 0.33895737  |\n",
      "|    n_updates          | 10556       |\n",
      "|    policyGradLoss     | 0.00294     |\n",
      "|    value_loss         | 3.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 21635072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010127995 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.455       |\n",
      "|    mean_step_reward   | 0.40244377  |\n",
      "|    n_updates          | 10560       |\n",
      "|    policyGradLoss     | -0.00562    |\n",
      "|    value_loss         | 1.72        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 781        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 188        |\n",
      "|    total_timesteps    | 21643264   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01144412 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.963      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.864      |\n",
      "|    mean_step_reward   | 0.36535627 |\n",
      "|    n_updates          | 10564      |\n",
      "|    policyGradLoss     | -0.00126   |\n",
      "|    value_loss         | 2.64       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 780        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 199        |\n",
      "|    total_timesteps    | 21651456   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01245754 |\n",
      "|    entropy_loss       | -1.7       |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.39       |\n",
      "|    mean_step_reward   | 0.37790245 |\n",
      "|    n_updates          | 10568      |\n",
      "|    policyGradLoss     | -0.00393   |\n",
      "|    value_loss         | 1.7        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 21659648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011822577 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.43        |\n",
      "|    mean_step_reward   | 0.40564573  |\n",
      "|    n_updates          | 10572       |\n",
      "|    policyGradLoss     | -0.00601    |\n",
      "|    value_loss         | 1.74        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 21667840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012177317 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.3         |\n",
      "|    mean_step_reward   | 0.3225603   |\n",
      "|    n_updates          | 10576       |\n",
      "|    policyGradLoss     | -0.00334    |\n",
      "|    value_loss         | 3.8         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 21676032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010071026 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.462       |\n",
      "|    mean_step_reward   | 0.42487907  |\n",
      "|    n_updates          | 10580       |\n",
      "|    policyGradLoss     | -0.00472    |\n",
      "|    value_loss         | 1.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 21684224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009346295 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.771       |\n",
      "|    mean_step_reward   | 0.39912117  |\n",
      "|    n_updates          | 10584       |\n",
      "|    policyGradLoss     | -0.0024     |\n",
      "|    value_loss         | 2.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 21692416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013568099 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.701       |\n",
      "|    mean_step_reward   | 0.37873882  |\n",
      "|    n_updates          | 10588       |\n",
      "|    policyGradLoss     | -0.00632    |\n",
      "|    value_loss         | 1.59        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 21700608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011785899 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.709       |\n",
      "|    mean_step_reward   | 0.39938766  |\n",
      "|    n_updates          | 10592       |\n",
      "|    policyGradLoss     | -0.00602    |\n",
      "|    value_loss         | 1.53        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 21708800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006786985 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.51        |\n",
      "|    mean_step_reward   | 0.38278115  |\n",
      "|    n_updates          | 10596       |\n",
      "|    policyGradLoss     | -0.00481    |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 21716992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010869986 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.657       |\n",
      "|    mean_step_reward   | 0.43306836  |\n",
      "|    n_updates          | 10600       |\n",
      "|    policyGradLoss     | -0.00337    |\n",
      "|    value_loss         | 1.95        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 21725184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009081457 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.44        |\n",
      "|    mean_step_reward   | 0.33476135  |\n",
      "|    n_updates          | 10604       |\n",
      "|    policyGradLoss     | -0.0058     |\n",
      "|    value_loss         | 1.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 21733376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012405431 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.143       |\n",
      "|    mean_step_reward   | 0.38930625  |\n",
      "|    n_updates          | 10608       |\n",
      "|    policyGradLoss     | -0.00708    |\n",
      "|    value_loss         | 1.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 21741568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006653486 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 2.03        |\n",
      "|    mean_step_reward   | 0.3899662   |\n",
      "|    n_updates          | 10612       |\n",
      "|    policyGradLoss     | -0.00436    |\n",
      "|    value_loss         | 2.02        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 775        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 327        |\n",
      "|    total_timesteps    | 21749760   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01419927 |\n",
      "|    entropy_loss       | -1.66      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.132      |\n",
      "|    mean_step_reward   | 0.45360905 |\n",
      "|    n_updates          | 10616      |\n",
      "|    policyGradLoss     | -0.00731   |\n",
      "|    value_loss         | 1.46       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 21757952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022157818 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.898       |\n",
      "|    mean_step_reward   | 0.38778546  |\n",
      "|    n_updates          | 10620       |\n",
      "|    policyGradLoss     | 0.00154     |\n",
      "|    value_loss         | 3.61        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_82.zip\n",
      "[EVAL] Mean Return: 527.822, Best Return: 535.822\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_82_527.82.mp4\n",
      "\n",
      "=== Round 84 | Learn 262144 steps (Total trained: 21757952) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1126     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 21766144 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 923         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 21774336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023399739 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.32        |\n",
      "|    mean_step_reward   | 0.4031958   |\n",
      "|    n_updates          | 10628       |\n",
      "|    policyGradLoss     | -0.000836   |\n",
      "|    value_loss         | 4.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 865         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 21782528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011411503 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.373       |\n",
      "|    mean_step_reward   | 0.39327478  |\n",
      "|    n_updates          | 10632       |\n",
      "|    policyGradLoss     | -0.00383    |\n",
      "|    value_loss         | 2.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 843         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 21790720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012792368 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.44        |\n",
      "|    mean_step_reward   | 0.36689395  |\n",
      "|    n_updates          | 10636       |\n",
      "|    policyGradLoss     | 0.00363     |\n",
      "|    value_loss         | 3.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 828         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 21798912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011157345 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.699       |\n",
      "|    mean_step_reward   | 0.37670794  |\n",
      "|    n_updates          | 10640       |\n",
      "|    policyGradLoss     | -0.00679    |\n",
      "|    value_loss         | 1.53        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 21807104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010998949 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.561       |\n",
      "|    mean_step_reward   | 0.3949408   |\n",
      "|    n_updates          | 10644       |\n",
      "|    policyGradLoss     | -0.00833    |\n",
      "|    value_loss         | 1.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 21815296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011007389 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.877       |\n",
      "|    mean_step_reward   | 0.3543058   |\n",
      "|    n_updates          | 10648       |\n",
      "|    policyGradLoss     | -0.0055     |\n",
      "|    value_loss         | 1.93        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 21823488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015068943 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.43        |\n",
      "|    mean_step_reward   | 0.3630522   |\n",
      "|    n_updates          | 10652       |\n",
      "|    policyGradLoss     | -0.000324   |\n",
      "|    value_loss         | 3.92        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 21831680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012268774 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.682       |\n",
      "|    mean_step_reward   | 0.3429041   |\n",
      "|    n_updates          | 10656       |\n",
      "|    policyGradLoss     | -0.00289    |\n",
      "|    value_loss         | 2.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 21839872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013573108 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.672       |\n",
      "|    mean_step_reward   | 0.38655972  |\n",
      "|    n_updates          | 10660       |\n",
      "|    policyGradLoss     | -0.00245    |\n",
      "|    value_loss         | 1.94        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 21848064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010102552 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.732       |\n",
      "|    mean_step_reward   | 0.3635726   |\n",
      "|    n_updates          | 10664       |\n",
      "|    policyGradLoss     | -0.00539    |\n",
      "|    value_loss         | 1.82        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 21856256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012227015 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.562       |\n",
      "|    mean_step_reward   | 0.35583338  |\n",
      "|    n_updates          | 10668       |\n",
      "|    policyGradLoss     | -0.00473    |\n",
      "|    value_loss         | 1.86        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 21864448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016618196 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.384       |\n",
      "|    mean_step_reward   | 0.30514416  |\n",
      "|    n_updates          | 10672       |\n",
      "|    policyGradLoss     | -0.00309    |\n",
      "|    value_loss         | 1.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 21872640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012446043 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.494       |\n",
      "|    mean_step_reward   | 0.39007568  |\n",
      "|    n_updates          | 10676       |\n",
      "|    policyGradLoss     | -0.0023     |\n",
      "|    value_loss         | 1.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 21880832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011196743 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.512       |\n",
      "|    mean_step_reward   | 0.41459683  |\n",
      "|    n_updates          | 10680       |\n",
      "|    policyGradLoss     | -0.0075     |\n",
      "|    value_loss         | 1.45        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 21889024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014669639 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.593       |\n",
      "|    mean_step_reward   | 0.351506    |\n",
      "|    n_updates          | 10684       |\n",
      "|    policyGradLoss     | -0.00175    |\n",
      "|    value_loss         | 2.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 21897216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012057623 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.371       |\n",
      "|    mean_step_reward   | 0.3727194   |\n",
      "|    n_updates          | 10688       |\n",
      "|    policyGradLoss     | -0.00693    |\n",
      "|    value_loss         | 1.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 21905408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012736197 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.848       |\n",
      "|    mean_step_reward   | 0.31328025  |\n",
      "|    n_updates          | 10692       |\n",
      "|    policyGradLoss     | -0.00761    |\n",
      "|    value_loss         | 1.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 21913600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011489134 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.735       |\n",
      "|    mean_step_reward   | 0.37947112  |\n",
      "|    n_updates          | 10696       |\n",
      "|    policyGradLoss     | -0.00281    |\n",
      "|    value_loss         | 2.99        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 21921792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011857938 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.638       |\n",
      "|    mean_step_reward   | 0.42059743  |\n",
      "|    n_updates          | 10700       |\n",
      "|    policyGradLoss     | -0.00496    |\n",
      "|    value_loss         | 2.19        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 221        |\n",
      "|    total_timesteps    | 21929984   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01060932 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.985      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.408      |\n",
      "|    mean_step_reward   | 0.3356759  |\n",
      "|    n_updates          | 10704      |\n",
      "|    policyGradLoss     | -0.0058    |\n",
      "|    value_loss         | 1.37       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 21938176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016096916 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.902       |\n",
      "|    mean_step_reward   | 0.43626395  |\n",
      "|    n_updates          | 10708       |\n",
      "|    policyGradLoss     | -0.000888   |\n",
      "|    value_loss         | 2.12        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 776          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 242          |\n",
      "|    total_timesteps    | 21946368     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0108690495 |\n",
      "|    entropy_loss       | -1.72        |\n",
      "|    explained_variance | 0.984        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.08         |\n",
      "|    mean_step_reward   | 0.32699528   |\n",
      "|    n_updates          | 10712        |\n",
      "|    policyGradLoss     | -0.00456     |\n",
      "|    value_loss         | 2.28         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 21954560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010260388 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.431       |\n",
      "|    mean_step_reward   | 0.41957918  |\n",
      "|    n_updates          | 10716       |\n",
      "|    policyGradLoss     | 0.00125     |\n",
      "|    value_loss         | 1.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 21962752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008493603 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.409       |\n",
      "|    mean_step_reward   | 0.37946182  |\n",
      "|    n_updates          | 10720       |\n",
      "|    policyGradLoss     | -1.71e-05   |\n",
      "|    value_loss         | 1.99        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 21970944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013183761 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.973       |\n",
      "|    mean_step_reward   | 0.35239786  |\n",
      "|    n_updates          | 10724       |\n",
      "|    policyGradLoss     | 0.000781    |\n",
      "|    value_loss         | 3.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 21979136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020485446 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.738       |\n",
      "|    mean_step_reward   | 0.3622371   |\n",
      "|    n_updates          | 10728       |\n",
      "|    policyGradLoss     | -0.0034     |\n",
      "|    value_loss         | 2.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 21987328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012026082 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.44        |\n",
      "|    mean_step_reward   | 0.36446327  |\n",
      "|    n_updates          | 10732       |\n",
      "|    policyGradLoss     | -0.00786    |\n",
      "|    value_loss         | 1.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 21995520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017206082 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.172       |\n",
      "|    mean_step_reward   | 0.38355505  |\n",
      "|    n_updates          | 10736       |\n",
      "|    policyGradLoss     | -0.00969    |\n",
      "|    value_loss         | 1.1         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 775          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 316          |\n",
      "|    total_timesteps    | 22003712     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0129708145 |\n",
      "|    entropy_loss       | -1.64        |\n",
      "|    explained_variance | 0.993        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.285        |\n",
      "|    mean_step_reward   | 0.42664236   |\n",
      "|    n_updates          | 10740        |\n",
      "|    policyGradLoss     | -0.00581     |\n",
      "|    value_loss         | 1.14         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 22011904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014104149 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.26        |\n",
      "|    mean_step_reward   | 0.38841897  |\n",
      "|    n_updates          | 10744       |\n",
      "|    policyGradLoss     | 0.000715    |\n",
      "|    value_loss         | 3.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 22020096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018095918 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.628       |\n",
      "|    mean_step_reward   | 0.42706662  |\n",
      "|    n_updates          | 10748       |\n",
      "|    policyGradLoss     | -0.000131   |\n",
      "|    value_loss         | 4.01        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_83.zip\n",
      "[EVAL] Mean Return: 71.849, Best Return: 73.182\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_83_71.85.mp4\n",
      "\n",
      "=== Round 85 | Learn 262144 steps (Total trained: 22020096) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1126     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 22028288 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 921         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 22036480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013919337 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.308       |\n",
      "|    mean_step_reward   | 0.3343202   |\n",
      "|    n_updates          | 10756       |\n",
      "|    policyGradLoss     | -0.00249    |\n",
      "|    value_loss         | 1.52        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 863         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 22044672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013127494 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.307       |\n",
      "|    mean_step_reward   | 0.42707855  |\n",
      "|    n_updates          | 10760       |\n",
      "|    policyGradLoss     | -0.00579    |\n",
      "|    value_loss         | 1.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 836         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 22052864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010489428 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.924       |\n",
      "|    mean_step_reward   | 0.38354447  |\n",
      "|    n_updates          | 10764       |\n",
      "|    policyGradLoss     | -0.00521    |\n",
      "|    value_loss         | 1.98        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 22061056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010194983 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.183       |\n",
      "|    mean_step_reward   | 0.33411664  |\n",
      "|    n_updates          | 10768       |\n",
      "|    policyGradLoss     | -0.00241    |\n",
      "|    value_loss         | 1.8         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 22069248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010892142 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.42        |\n",
      "|    mean_step_reward   | 0.39305913  |\n",
      "|    n_updates          | 10772       |\n",
      "|    policyGradLoss     | -0.00356    |\n",
      "|    value_loss         | 1.46        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 22077440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015894413 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.18        |\n",
      "|    mean_step_reward   | 0.36675665  |\n",
      "|    n_updates          | 10776       |\n",
      "|    policyGradLoss     | -0.0028     |\n",
      "|    value_loss         | 3.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 22085632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015857792 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.584       |\n",
      "|    mean_step_reward   | 0.334397    |\n",
      "|    n_updates          | 10780       |\n",
      "|    policyGradLoss     | 0.00226     |\n",
      "|    value_loss         | 2.09        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 22093824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019263746 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.677       |\n",
      "|    mean_step_reward   | 0.41922888  |\n",
      "|    n_updates          | 10784       |\n",
      "|    policyGradLoss     | 0.00085     |\n",
      "|    value_loss         | 2.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 22102016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009648109 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.909       |\n",
      "|    mean_step_reward   | 0.309448    |\n",
      "|    n_updates          | 10788       |\n",
      "|    policyGradLoss     | -0.00368    |\n",
      "|    value_loss         | 2.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 22110208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011710944 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.507       |\n",
      "|    mean_step_reward   | 0.40523884  |\n",
      "|    n_updates          | 10792       |\n",
      "|    policyGradLoss     | -0.0044     |\n",
      "|    value_loss         | 1.65        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 22118400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009217399 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.763       |\n",
      "|    mean_step_reward   | 0.33335042  |\n",
      "|    n_updates          | 10796       |\n",
      "|    policyGradLoss     | -0.00395    |\n",
      "|    value_loss         | 2.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 22126592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012961101 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.512       |\n",
      "|    mean_step_reward   | 0.39268625  |\n",
      "|    n_updates          | 10800       |\n",
      "|    policyGradLoss     | -0.00534    |\n",
      "|    value_loss         | 1.49        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 784          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 146          |\n",
      "|    total_timesteps    | 22134784     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0116418805 |\n",
      "|    entropy_loss       | -1.71        |\n",
      "|    explained_variance | 0.984        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.769        |\n",
      "|    mean_step_reward   | 0.34392264   |\n",
      "|    n_updates          | 10804        |\n",
      "|    policyGradLoss     | -0.00442     |\n",
      "|    value_loss         | 1.56         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 22142976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009094532 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.752       |\n",
      "|    mean_step_reward   | 0.3002177   |\n",
      "|    n_updates          | 10808       |\n",
      "|    policyGradLoss     | -0.00648    |\n",
      "|    value_loss         | 1.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 22151168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012331726 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.179       |\n",
      "|    mean_step_reward   | 0.3373381   |\n",
      "|    n_updates          | 10812       |\n",
      "|    policyGradLoss     | -0.00552    |\n",
      "|    value_loss         | 1.09        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 22159360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011226162 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.01        |\n",
      "|    mean_step_reward   | 0.29941818  |\n",
      "|    n_updates          | 10816       |\n",
      "|    policyGradLoss     | -0.00288    |\n",
      "|    value_loss         | 2.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 22167552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012646046 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.467       |\n",
      "|    mean_step_reward   | 0.43049923  |\n",
      "|    n_updates          | 10820       |\n",
      "|    policyGradLoss     | 0.000467    |\n",
      "|    value_loss         | 1.78        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 782          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 198          |\n",
      "|    total_timesteps    | 22175744     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0130065605 |\n",
      "|    entropy_loss       | -1.74        |\n",
      "|    explained_variance | 0.988        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.12         |\n",
      "|    mean_step_reward   | 0.36235732   |\n",
      "|    n_updates          | 10824        |\n",
      "|    policyGradLoss     | -0.00566     |\n",
      "|    value_loss         | 1.93         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 22183936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013892885 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.831       |\n",
      "|    mean_step_reward   | 0.3064419   |\n",
      "|    n_updates          | 10828       |\n",
      "|    policyGradLoss     | -0.00788    |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 22192128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014379609 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.548       |\n",
      "|    mean_step_reward   | 0.40733454  |\n",
      "|    n_updates          | 10832       |\n",
      "|    policyGradLoss     | -0.00786    |\n",
      "|    value_loss         | 1.2         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 779          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 231          |\n",
      "|    total_timesteps    | 22200320     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0130333025 |\n",
      "|    entropy_loss       | -1.67        |\n",
      "|    explained_variance | 0.988        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.719        |\n",
      "|    mean_step_reward   | 0.36588496   |\n",
      "|    n_updates          | 10836        |\n",
      "|    policyGradLoss     | -0.00928     |\n",
      "|    value_loss         | 1.33         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 22208512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010742413 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.501       |\n",
      "|    mean_step_reward   | 0.43331504  |\n",
      "|    n_updates          | 10840       |\n",
      "|    policyGradLoss     | -0.00639    |\n",
      "|    value_loss         | 1.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 22216704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011723386 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.93        |\n",
      "|    mean_step_reward   | 0.3351021   |\n",
      "|    n_updates          | 10844       |\n",
      "|    policyGradLoss     | -0.00478    |\n",
      "|    value_loss         | 1.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 22224896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013561479 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.441       |\n",
      "|    mean_step_reward   | 0.38695893  |\n",
      "|    n_updates          | 10848       |\n",
      "|    policyGradLoss     | -0.000903   |\n",
      "|    value_loss         | 2.11        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 777          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 273          |\n",
      "|    total_timesteps    | 22233088     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0122012235 |\n",
      "|    entropy_loss       | -1.74        |\n",
      "|    explained_variance | 0.988        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.806        |\n",
      "|    mean_step_reward   | 0.327623     |\n",
      "|    n_updates          | 10852        |\n",
      "|    policyGradLoss     | -0.00521     |\n",
      "|    value_loss         | 1.87         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 777          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 284          |\n",
      "|    total_timesteps    | 22241280     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0140817175 |\n",
      "|    entropy_loss       | -1.65        |\n",
      "|    explained_variance | 0.978        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.298        |\n",
      "|    mean_step_reward   | 0.34317297   |\n",
      "|    n_updates          | 10856        |\n",
      "|    policyGradLoss     | -0.00298     |\n",
      "|    value_loss         | 1.74         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 776        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 295        |\n",
      "|    total_timesteps    | 22249472   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.020597   |\n",
      "|    entropy_loss       | -1.62      |\n",
      "|    explained_variance | 0.995      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0558     |\n",
      "|    mean_step_reward   | 0.39193124 |\n",
      "|    n_updates          | 10860      |\n",
      "|    policyGradLoss     | -0.00623   |\n",
      "|    value_loss         | 0.414      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 22257664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012880672 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.467       |\n",
      "|    mean_step_reward   | 0.34741676  |\n",
      "|    n_updates          | 10864       |\n",
      "|    policyGradLoss     | -0.00444    |\n",
      "|    value_loss         | 2.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 22265856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016880136 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.121       |\n",
      "|    mean_step_reward   | 0.38311008  |\n",
      "|    n_updates          | 10868       |\n",
      "|    policyGradLoss     | -0.00702    |\n",
      "|    value_loss         | 0.812       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 326        |\n",
      "|    total_timesteps    | 22274048   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00995626 |\n",
      "|    entropy_loss       | -1.72      |\n",
      "|    explained_variance | 0.982      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.656      |\n",
      "|    mean_step_reward   | 0.3634816  |\n",
      "|    n_updates          | 10872      |\n",
      "|    policyGradLoss     | -0.00296   |\n",
      "|    value_loss         | 2.21       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 22282240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012618257 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.639       |\n",
      "|    mean_step_reward   | 0.38106894  |\n",
      "|    n_updates          | 10876       |\n",
      "|    policyGradLoss     | -0.00263    |\n",
      "|    value_loss         | 1.88        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_84.zip\n",
      "[EVAL] Mean Return: 409.886, Best Return: 415.219\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_84_409.89.mp4\n",
      "\n",
      "=== Round 86 | Learn 262144 steps (Total trained: 22282240) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1137     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 22290432 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 920         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 22298624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012365309 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.549       |\n",
      "|    mean_step_reward   | 0.38364354  |\n",
      "|    n_updates          | 10884       |\n",
      "|    policyGradLoss     | -0.00439    |\n",
      "|    value_loss         | 1.98        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 862         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 22306816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014820185 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.16        |\n",
      "|    mean_step_reward   | 0.3785984   |\n",
      "|    n_updates          | 10888       |\n",
      "|    policyGradLoss     | -0.000293   |\n",
      "|    value_loss         | 1.83        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 833        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 39         |\n",
      "|    total_timesteps    | 22315008   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01420667 |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.99       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.498      |\n",
      "|    mean_step_reward   | 0.38418615 |\n",
      "|    n_updates          | 10892      |\n",
      "|    policyGradLoss     | -0.00626   |\n",
      "|    value_loss         | 1.08       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 22323200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016275434 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.895       |\n",
      "|    mean_step_reward   | 0.371085    |\n",
      "|    n_updates          | 10896       |\n",
      "|    policyGradLoss     | -0.00216    |\n",
      "|    value_loss         | 3           |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 22331392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017518897 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.59        |\n",
      "|    mean_step_reward   | 0.40402934  |\n",
      "|    n_updates          | 10900       |\n",
      "|    policyGradLoss     | -0.00212    |\n",
      "|    value_loss         | 1.84        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 22339584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013036221 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.287       |\n",
      "|    mean_step_reward   | 0.4158021   |\n",
      "|    n_updates          | 10904       |\n",
      "|    policyGradLoss     | -0.00708    |\n",
      "|    value_loss         | 1.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 22347776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014232872 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.42        |\n",
      "|    mean_step_reward   | 0.39748478  |\n",
      "|    n_updates          | 10908       |\n",
      "|    policyGradLoss     | -0.00659    |\n",
      "|    value_loss         | 1.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 22355968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013212454 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.264       |\n",
      "|    mean_step_reward   | 0.29974413  |\n",
      "|    n_updates          | 10912       |\n",
      "|    policyGradLoss     | -0.00206    |\n",
      "|    value_loss         | 1.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 22364160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016545324 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.107       |\n",
      "|    mean_step_reward   | 0.35514677  |\n",
      "|    n_updates          | 10916       |\n",
      "|    policyGradLoss     | -0.00314    |\n",
      "|    value_loss         | 0.823       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 22372352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013857769 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.573       |\n",
      "|    mean_step_reward   | 0.30689436  |\n",
      "|    n_updates          | 10920       |\n",
      "|    policyGradLoss     | -0.00655    |\n",
      "|    value_loss         | 1.43        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 22380544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015894234 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.485       |\n",
      "|    mean_step_reward   | 0.3531304   |\n",
      "|    n_updates          | 10924       |\n",
      "|    policyGradLoss     | -0.00271    |\n",
      "|    value_loss         | 2.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 22388736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015040569 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.672       |\n",
      "|    mean_step_reward   | 0.3695656   |\n",
      "|    n_updates          | 10928       |\n",
      "|    policyGradLoss     | -0.00493    |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 22396928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011365456 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.946       |\n",
      "|    mean_step_reward   | 0.33922005  |\n",
      "|    n_updates          | 10932       |\n",
      "|    policyGradLoss     | -0.00565    |\n",
      "|    value_loss         | 1.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 22405120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015349925 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.749       |\n",
      "|    mean_step_reward   | 0.3554268   |\n",
      "|    n_updates          | 10936       |\n",
      "|    policyGradLoss     | -0.00123    |\n",
      "|    value_loss         | 2.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 22413312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012054235 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.925       |\n",
      "|    mean_step_reward   | 0.31503803  |\n",
      "|    n_updates          | 10940       |\n",
      "|    policyGradLoss     | -0.00362    |\n",
      "|    value_loss         | 2.8         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 178        |\n",
      "|    total_timesteps    | 22421504   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01822028 |\n",
      "|    entropy_loss       | -1.7       |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.323      |\n",
      "|    mean_step_reward   | 0.38120377 |\n",
      "|    n_updates          | 10944      |\n",
      "|    policyGradLoss     | -0.0023    |\n",
      "|    value_loss         | 1.65       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 22429696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013658403 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.185       |\n",
      "|    mean_step_reward   | 0.3520041   |\n",
      "|    n_updates          | 10948       |\n",
      "|    policyGradLoss     | -0.00718    |\n",
      "|    value_loss         | 1.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 22437888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011489486 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.282       |\n",
      "|    mean_step_reward   | 0.36549634  |\n",
      "|    n_updates          | 10952       |\n",
      "|    policyGradLoss     | -0.00681    |\n",
      "|    value_loss         | 1.45        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 22446080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014776124 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.167       |\n",
      "|    mean_step_reward   | 0.32154524  |\n",
      "|    n_updates          | 10956       |\n",
      "|    policyGradLoss     | -0.00931    |\n",
      "|    value_loss         | 1.04        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 22454272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016118627 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.44        |\n",
      "|    mean_step_reward   | 0.36116484  |\n",
      "|    n_updates          | 10960       |\n",
      "|    policyGradLoss     | 0.00156     |\n",
      "|    value_loss         | 2.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 22462464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014809626 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.823       |\n",
      "|    mean_step_reward   | 0.3630122   |\n",
      "|    n_updates          | 10964       |\n",
      "|    policyGradLoss     | -0.00192    |\n",
      "|    value_loss         | 3.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 22470656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011326158 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.06        |\n",
      "|    mean_step_reward   | 0.36683193  |\n",
      "|    n_updates          | 10968       |\n",
      "|    policyGradLoss     | -0.0014     |\n",
      "|    value_loss         | 3.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 22478848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012791176 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.825       |\n",
      "|    mean_step_reward   | 0.3658446   |\n",
      "|    n_updates          | 10972       |\n",
      "|    policyGradLoss     | -0.000657   |\n",
      "|    value_loss         | 2.64        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 22487040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013513219 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.65        |\n",
      "|    mean_step_reward   | 0.3713952   |\n",
      "|    n_updates          | 10976       |\n",
      "|    policyGradLoss     | 0.00102     |\n",
      "|    value_loss         | 3.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 22495232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012110658 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.36        |\n",
      "|    mean_step_reward   | 0.3743204   |\n",
      "|    n_updates          | 10980       |\n",
      "|    policyGradLoss     | -0.000728   |\n",
      "|    value_loss         | 3.61        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 22503424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012128163 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.631       |\n",
      "|    mean_step_reward   | 0.36239415  |\n",
      "|    n_updates          | 10984       |\n",
      "|    policyGradLoss     | -0.00376    |\n",
      "|    value_loss         | 2.95        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 775        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 295        |\n",
      "|    total_timesteps    | 22511616   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01228593 |\n",
      "|    entropy_loss       | -1.68      |\n",
      "|    explained_variance | 0.976      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.477      |\n",
      "|    mean_step_reward   | 0.38444299 |\n",
      "|    n_updates          | 10988      |\n",
      "|    policyGradLoss     | -0.00603   |\n",
      "|    value_loss         | 1.49       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 22519808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014916368 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.723       |\n",
      "|    mean_step_reward   | 0.34830472  |\n",
      "|    n_updates          | 10992       |\n",
      "|    policyGradLoss     | -0.00294    |\n",
      "|    value_loss         | 3.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 22528000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010967204 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.807       |\n",
      "|    mean_step_reward   | 0.41308632  |\n",
      "|    n_updates          | 10996       |\n",
      "|    policyGradLoss     | -0.000734   |\n",
      "|    value_loss         | 3.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 22536192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010051709 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.615       |\n",
      "|    mean_step_reward   | 0.32429653  |\n",
      "|    n_updates          | 11000       |\n",
      "|    policyGradLoss     | -0.0026     |\n",
      "|    value_loss         | 3.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 22544384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011547392 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.403       |\n",
      "|    mean_step_reward   | 0.41557634  |\n",
      "|    n_updates          | 11004       |\n",
      "|    policyGradLoss     | -0.00278    |\n",
      "|    value_loss         | 1.84        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_85.zip\n",
      "[EVAL] Mean Return: 532.862, Best Return: 540.862\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_85_532.86.mp4\n",
      "\n",
      "=== Round 87 | Learn 262144 steps (Total trained: 22544384) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1092     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 22552576 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 901         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 22560768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010254516 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.13        |\n",
      "|    mean_step_reward   | 0.32226455  |\n",
      "|    n_updates          | 11012       |\n",
      "|    policyGradLoss     | -0.00451    |\n",
      "|    value_loss         | 1.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 845         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 22568960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013457311 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.532       |\n",
      "|    mean_step_reward   | 0.3754877   |\n",
      "|    n_updates          | 11016       |\n",
      "|    policyGradLoss     | 0.000509    |\n",
      "|    value_loss         | 4           |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 823         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 22577152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011636105 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.743       |\n",
      "|    mean_step_reward   | 0.35363227  |\n",
      "|    n_updates          | 11020       |\n",
      "|    policyGradLoss     | -0.00435    |\n",
      "|    value_loss         | 2.04        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 22585344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014351014 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.613       |\n",
      "|    mean_step_reward   | 0.40578848  |\n",
      "|    n_updates          | 11024       |\n",
      "|    policyGradLoss     | -0.00655    |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 22593536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014683829 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.275       |\n",
      "|    mean_step_reward   | 0.3616693   |\n",
      "|    n_updates          | 11028       |\n",
      "|    policyGradLoss     | -0.00725    |\n",
      "|    value_loss         | 1.29        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 798          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 71           |\n",
      "|    total_timesteps    | 22601728     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0107867345 |\n",
      "|    entropy_loss       | -1.7         |\n",
      "|    explained_variance | 0.962        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.72         |\n",
      "|    mean_step_reward   | 0.41039324   |\n",
      "|    n_updates          | 11032        |\n",
      "|    policyGradLoss     | -0.000879    |\n",
      "|    value_loss         | 3.19         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 22609920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010617018 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.354       |\n",
      "|    mean_step_reward   | 0.41986758  |\n",
      "|    n_updates          | 11036       |\n",
      "|    policyGradLoss     | -0.00201    |\n",
      "|    value_loss         | 1.47        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 786          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 93           |\n",
      "|    total_timesteps    | 22618112     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0068362243 |\n",
      "|    entropy_loss       | -1.76        |\n",
      "|    explained_variance | 0.985        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.697        |\n",
      "|    mean_step_reward   | 0.3206103    |\n",
      "|    n_updates          | 11040        |\n",
      "|    policyGradLoss     | -0.00264     |\n",
      "|    value_loss         | 1.79         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 22626304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010449531 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.423       |\n",
      "|    mean_step_reward   | 0.33436966  |\n",
      "|    n_updates          | 11044       |\n",
      "|    policyGradLoss     | -0.00561    |\n",
      "|    value_loss         | 1.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 22634496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014113357 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.386       |\n",
      "|    mean_step_reward   | 0.37546474  |\n",
      "|    n_updates          | 11048       |\n",
      "|    policyGradLoss     | -0.00235    |\n",
      "|    value_loss         | 2.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 22642688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014501844 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.44        |\n",
      "|    mean_step_reward   | 0.3724815   |\n",
      "|    n_updates          | 11052       |\n",
      "|    policyGradLoss     | -0.0022     |\n",
      "|    value_loss         | 3.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 22650880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010647152 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.01        |\n",
      "|    mean_step_reward   | 0.37471098  |\n",
      "|    n_updates          | 11056       |\n",
      "|    policyGradLoss     | -0.00585    |\n",
      "|    value_loss         | 1.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 22659072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012802161 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.706       |\n",
      "|    mean_step_reward   | 0.3811741   |\n",
      "|    n_updates          | 11060       |\n",
      "|    policyGradLoss     | -0.00391    |\n",
      "|    value_loss         | 1.92        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 22667264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014200622 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.495       |\n",
      "|    mean_step_reward   | 0.31357908  |\n",
      "|    n_updates          | 11064       |\n",
      "|    policyGradLoss     | -0.00606    |\n",
      "|    value_loss         | 1.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 22675456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013530392 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.47        |\n",
      "|    mean_step_reward   | 0.3009165   |\n",
      "|    n_updates          | 11068       |\n",
      "|    policyGradLoss     | -0.00542    |\n",
      "|    value_loss         | 1.52        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 22683648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015230203 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.34        |\n",
      "|    mean_step_reward   | 0.35140276  |\n",
      "|    n_updates          | 11072       |\n",
      "|    policyGradLoss     | -0.000606   |\n",
      "|    value_loss         | 3.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 22691840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013273247 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.05        |\n",
      "|    mean_step_reward   | 0.37434322  |\n",
      "|    n_updates          | 11076       |\n",
      "|    policyGradLoss     | -0.00166    |\n",
      "|    value_loss         | 3.57        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 775        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 200        |\n",
      "|    total_timesteps    | 22700032   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01609363 |\n",
      "|    entropy_loss       | -1.74      |\n",
      "|    explained_variance | 0.965      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1          |\n",
      "|    mean_step_reward   | 0.3313579  |\n",
      "|    n_updates          | 11080      |\n",
      "|    policyGradLoss     | -0.00213   |\n",
      "|    value_loss         | 2.19       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 22708224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011762001 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.805       |\n",
      "|    mean_step_reward   | 0.32233226  |\n",
      "|    n_updates          | 11084       |\n",
      "|    policyGradLoss     | -0.00573    |\n",
      "|    value_loss         | 1.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 22716416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018913321 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.427       |\n",
      "|    mean_step_reward   | 0.30532625  |\n",
      "|    n_updates          | 11088       |\n",
      "|    policyGradLoss     | -0.0072     |\n",
      "|    value_loss         | 1.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 22724608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010152543 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.496       |\n",
      "|    mean_step_reward   | 0.29313093  |\n",
      "|    n_updates          | 11092       |\n",
      "|    policyGradLoss     | -0.006      |\n",
      "|    value_loss         | 1.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 22732800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013068836 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.376       |\n",
      "|    mean_step_reward   | 0.41177034  |\n",
      "|    n_updates          | 11096       |\n",
      "|    policyGradLoss     | -0.00545    |\n",
      "|    value_loss         | 1.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 254         |\n",
      "|    total_timesteps    | 22740992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011617327 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.652       |\n",
      "|    mean_step_reward   | 0.31040424  |\n",
      "|    n_updates          | 11100       |\n",
      "|    policyGradLoss     | -0.0041     |\n",
      "|    value_loss         | 2.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 22749184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013472568 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.593       |\n",
      "|    mean_step_reward   | 0.431213    |\n",
      "|    n_updates          | 11104       |\n",
      "|    policyGradLoss     | -0.00472    |\n",
      "|    value_loss         | 1.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 275         |\n",
      "|    total_timesteps    | 22757376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016737936 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.599       |\n",
      "|    mean_step_reward   | 0.31128907  |\n",
      "|    n_updates          | 11108       |\n",
      "|    policyGradLoss     | -0.00141    |\n",
      "|    value_loss         | 2.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 22765568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011164732 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.22        |\n",
      "|    mean_step_reward   | 0.32444847  |\n",
      "|    n_updates          | 11112       |\n",
      "|    policyGradLoss     | -0.00375    |\n",
      "|    value_loss         | 1.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 22773760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012866702 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.286       |\n",
      "|    mean_step_reward   | 0.39391953  |\n",
      "|    n_updates          | 11116       |\n",
      "|    policyGradLoss     | -0.00471    |\n",
      "|    value_loss         | 1.81        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 307         |\n",
      "|    total_timesteps    | 22781952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011822177 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.29        |\n",
      "|    mean_step_reward   | 0.35329664  |\n",
      "|    n_updates          | 11120       |\n",
      "|    policyGradLoss     | -0.00595    |\n",
      "|    value_loss         | 1.76        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 22790144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014018287 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.376       |\n",
      "|    mean_step_reward   | 0.33554035  |\n",
      "|    n_updates          | 11124       |\n",
      "|    policyGradLoss     | -0.00706    |\n",
      "|    value_loss         | 1.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 22798336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014234862 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.444       |\n",
      "|    mean_step_reward   | 0.39152408  |\n",
      "|    n_updates          | 11128       |\n",
      "|    policyGradLoss     | -0.00412    |\n",
      "|    value_loss         | 1.42        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 772        |\n",
      "|    iterations         | 32         |\n",
      "|    time_elapsed       | 339        |\n",
      "|    total_timesteps    | 22806528   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0116312  |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.988      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.576      |\n",
      "|    mean_step_reward   | 0.38774455 |\n",
      "|    n_updates          | 11132      |\n",
      "|    policyGradLoss     | -0.0045    |\n",
      "|    value_loss         | 1.57       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_86.zip\n",
      "[EVAL] Mean Return: 526.936, Best Return: 533.602\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_86_526.94.mp4\n",
      "\n",
      "=== Round 88 | Learn 262144 steps (Total trained: 22806528) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1154     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 22814720 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 941         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 22822912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011648541 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.193       |\n",
      "|    mean_step_reward   | 0.35637003  |\n",
      "|    n_updates          | 11140       |\n",
      "|    policyGradLoss     | -0.00769    |\n",
      "|    value_loss         | 1.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 884         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 22831104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015810838 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.381       |\n",
      "|    mean_step_reward   | 0.40328592  |\n",
      "|    n_updates          | 11144       |\n",
      "|    policyGradLoss     | -0.0062     |\n",
      "|    value_loss         | 1.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 852         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 22839296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016001808 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.456       |\n",
      "|    mean_step_reward   | 0.34886858  |\n",
      "|    n_updates          | 11148       |\n",
      "|    policyGradLoss     | -0.00445    |\n",
      "|    value_loss         | 1.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 834         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 22847488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015933458 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.382       |\n",
      "|    mean_step_reward   | 0.35802045  |\n",
      "|    n_updates          | 11152       |\n",
      "|    policyGradLoss     | -0.00619    |\n",
      "|    value_loss         | 1.09        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 823         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 22855680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012739731 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.676       |\n",
      "|    mean_step_reward   | 0.3373838   |\n",
      "|    n_updates          | 11156       |\n",
      "|    policyGradLoss     | -0.00267    |\n",
      "|    value_loss         | 1.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 22863872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009736335 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.704       |\n",
      "|    mean_step_reward   | 0.3766268   |\n",
      "|    n_updates          | 11160       |\n",
      "|    policyGradLoss     | -0.00653    |\n",
      "|    value_loss         | 1.67        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 807        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 81         |\n",
      "|    total_timesteps    | 22872064   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00952675 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.988      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.279      |\n",
      "|    mean_step_reward   | 0.34495902 |\n",
      "|    n_updates          | 11164      |\n",
      "|    policyGradLoss     | -0.00645   |\n",
      "|    value_loss         | 1.63       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 22880256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011127713 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.433       |\n",
      "|    mean_step_reward   | 0.36437547  |\n",
      "|    n_updates          | 11168       |\n",
      "|    policyGradLoss     | -0.00438    |\n",
      "|    value_loss         | 2.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 22888448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011334227 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.731       |\n",
      "|    mean_step_reward   | 0.4095546   |\n",
      "|    n_updates          | 11172       |\n",
      "|    policyGradLoss     | -0.00544    |\n",
      "|    value_loss         | 1.9         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 797          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 112          |\n",
      "|    total_timesteps    | 22896640     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0083211735 |\n",
      "|    entropy_loss       | -1.68        |\n",
      "|    explained_variance | 0.985        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.555        |\n",
      "|    mean_step_reward   | 0.38402492   |\n",
      "|    n_updates          | 11176        |\n",
      "|    policyGradLoss     | -0.00263     |\n",
      "|    value_loss         | 2.02         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 22904832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012316314 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.439       |\n",
      "|    mean_step_reward   | 0.43221495  |\n",
      "|    n_updates          | 11180       |\n",
      "|    policyGradLoss     | -0.00514    |\n",
      "|    value_loss         | 1.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 22913024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012751831 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.426       |\n",
      "|    mean_step_reward   | 0.39718845  |\n",
      "|    n_updates          | 11184       |\n",
      "|    policyGradLoss     | -0.00696    |\n",
      "|    value_loss         | 1.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 22921216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012211328 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.787       |\n",
      "|    mean_step_reward   | 0.37889418  |\n",
      "|    n_updates          | 11188       |\n",
      "|    policyGradLoss     | -0.00118    |\n",
      "|    value_loss         | 4.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 22929408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012267891 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.704       |\n",
      "|    mean_step_reward   | 0.3785355   |\n",
      "|    n_updates          | 11192       |\n",
      "|    policyGradLoss     | -0.00272    |\n",
      "|    value_loss         | 3.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 22937600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011156419 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.02        |\n",
      "|    mean_step_reward   | 0.37596494  |\n",
      "|    n_updates          | 11196       |\n",
      "|    policyGradLoss     | -0.000824   |\n",
      "|    value_loss         | 3.81        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 22945792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010008207 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.743       |\n",
      "|    mean_step_reward   | 0.3958654   |\n",
      "|    n_updates          | 11200       |\n",
      "|    policyGradLoss     | -0.00348    |\n",
      "|    value_loss         | 2.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 22953984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011788072 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.24        |\n",
      "|    mean_step_reward   | 0.3810594   |\n",
      "|    n_updates          | 11204       |\n",
      "|    policyGradLoss     | -0.000692   |\n",
      "|    value_loss         | 3.41        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 785          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 198          |\n",
      "|    total_timesteps    | 22962176     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0145414425 |\n",
      "|    entropy_loss       | -1.69        |\n",
      "|    explained_variance | 0.983        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.789        |\n",
      "|    mean_step_reward   | 0.37630436   |\n",
      "|    n_updates          | 11208        |\n",
      "|    policyGradLoss     | -0.0058      |\n",
      "|    value_loss         | 1.73         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 22970368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009579759 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.61        |\n",
      "|    mean_step_reward   | 0.3179234   |\n",
      "|    n_updates          | 11212       |\n",
      "|    policyGradLoss     | -0.0022     |\n",
      "|    value_loss         | 1.46        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 22978560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009562019 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.187       |\n",
      "|    mean_step_reward   | 0.41529182  |\n",
      "|    n_updates          | 11216       |\n",
      "|    policyGradLoss     | -0.00426    |\n",
      "|    value_loss         | 1.22        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 783        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 230        |\n",
      "|    total_timesteps    | 22986752   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00980063 |\n",
      "|    entropy_loss       | -1.72      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.788      |\n",
      "|    mean_step_reward   | 0.3484974  |\n",
      "|    n_updates          | 11220      |\n",
      "|    policyGradLoss     | -0.00705   |\n",
      "|    value_loss         | 1.62       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 22994944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010179536 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.879       |\n",
      "|    mean_step_reward   | 0.34640074  |\n",
      "|    n_updates          | 11224       |\n",
      "|    policyGradLoss     | -0.0036     |\n",
      "|    value_loss         | 3.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 23003136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013260681 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.936       |\n",
      "|    mean_step_reward   | 0.40568733  |\n",
      "|    n_updates          | 11228       |\n",
      "|    policyGradLoss     | -0.00065    |\n",
      "|    value_loss         | 2.98        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 781        |\n",
      "|    iterations         | 25         |\n",
      "|    time_elapsed       | 261        |\n",
      "|    total_timesteps    | 23011328   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01064351 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.985      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.669      |\n",
      "|    mean_step_reward   | 0.3449679  |\n",
      "|    n_updates          | 11232      |\n",
      "|    policyGradLoss     | -0.00711   |\n",
      "|    value_loss         | 1.45       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 23019520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012239213 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.404       |\n",
      "|    mean_step_reward   | 0.34474415  |\n",
      "|    n_updates          | 11236       |\n",
      "|    policyGradLoss     | -0.0084     |\n",
      "|    value_loss         | 0.987       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 23027712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013430243 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.953       |\n",
      "|    mean_step_reward   | 0.35108146  |\n",
      "|    n_updates          | 11240       |\n",
      "|    policyGradLoss     | 0.000245    |\n",
      "|    value_loss         | 5.45        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 23035904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013892146 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.412       |\n",
      "|    mean_step_reward   | 0.36968815  |\n",
      "|    n_updates          | 11244       |\n",
      "|    policyGradLoss     | 0.00382     |\n",
      "|    value_loss         | 2.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 23044096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015751805 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.341       |\n",
      "|    mean_step_reward   | 0.36718354  |\n",
      "|    n_updates          | 11248       |\n",
      "|    policyGradLoss     | 0.00113     |\n",
      "|    value_loss         | 3           |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 315        |\n",
      "|    total_timesteps    | 23052288   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01456225 |\n",
      "|    entropy_loss       | -1.72      |\n",
      "|    explained_variance | 0.965      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.581      |\n",
      "|    mean_step_reward   | 0.3455614  |\n",
      "|    n_updates          | 11252      |\n",
      "|    policyGradLoss     | -0.0032    |\n",
      "|    value_loss         | 2.73       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 23060480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015684515 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.15        |\n",
      "|    mean_step_reward   | 0.31353676  |\n",
      "|    n_updates          | 11256       |\n",
      "|    policyGradLoss     | 0.00214     |\n",
      "|    value_loss         | 3.11        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 32         |\n",
      "|    time_elapsed       | 336        |\n",
      "|    total_timesteps    | 23068672   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00997187 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.971      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.725      |\n",
      "|    mean_step_reward   | 0.27131125 |\n",
      "|    n_updates          | 11260      |\n",
      "|    policyGradLoss     | -0.00449   |\n",
      "|    value_loss         | 1.92       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_87.zip\n",
      "[EVAL] Mean Return: 529.723, Best Return: 537.723\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_87_529.72.mp4\n",
      "\n",
      "=== Round 89 | Learn 262144 steps (Total trained: 23068672) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1122     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 23076864 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 923         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 23085056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015934218 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.512       |\n",
      "|    mean_step_reward   | 0.34297585  |\n",
      "|    n_updates          | 11268       |\n",
      "|    policyGradLoss     | 0.00913     |\n",
      "|    value_loss         | 2.92        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 864          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 23093248     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0126484595 |\n",
      "|    entropy_loss       | -1.72        |\n",
      "|    explained_variance | 0.983        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.367        |\n",
      "|    mean_step_reward   | 0.32279593   |\n",
      "|    n_updates          | 11272        |\n",
      "|    policyGradLoss     | -0.00663     |\n",
      "|    value_loss         | 1.51         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 23101440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010847797 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.316       |\n",
      "|    mean_step_reward   | 0.42379725  |\n",
      "|    n_updates          | 11276       |\n",
      "|    policyGradLoss     | 0.000862    |\n",
      "|    value_loss         | 2.64        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 822          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 49           |\n",
      "|    total_timesteps    | 23109632     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0149965305 |\n",
      "|    entropy_loss       | -1.79        |\n",
      "|    explained_variance | 0.975        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.37         |\n",
      "|    mean_step_reward   | 0.33315676   |\n",
      "|    n_updates          | 11280        |\n",
      "|    policyGradLoss     | -0.00333     |\n",
      "|    value_loss         | 3.06         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 23117824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019197073 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.896       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.85        |\n",
      "|    mean_step_reward   | 0.33203584  |\n",
      "|    n_updates          | 11284       |\n",
      "|    policyGradLoss     | 0.00583     |\n",
      "|    value_loss         | 4.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 23126016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015659738 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.169       |\n",
      "|    mean_step_reward   | 0.32679033  |\n",
      "|    n_updates          | 11288       |\n",
      "|    policyGradLoss     | 0.00509     |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 800        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 81         |\n",
      "|    total_timesteps    | 23134208   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01746029 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.982      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.446      |\n",
      "|    mean_step_reward   | 0.378059   |\n",
      "|    n_updates          | 11292      |\n",
      "|    policyGradLoss     | -0.00162   |\n",
      "|    value_loss         | 2.06       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 23142400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009841722 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.398       |\n",
      "|    mean_step_reward   | 0.40963742  |\n",
      "|    n_updates          | 11296       |\n",
      "|    policyGradLoss     | -0.00699    |\n",
      "|    value_loss         | 1.75        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 23150592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013803418 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.212       |\n",
      "|    mean_step_reward   | 0.30376193  |\n",
      "|    n_updates          | 11300       |\n",
      "|    policyGradLoss     | -0.00792    |\n",
      "|    value_loss         | 1.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 23158784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012887217 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.454       |\n",
      "|    mean_step_reward   | 0.33404762  |\n",
      "|    n_updates          | 11304       |\n",
      "|    policyGradLoss     | -0.00733    |\n",
      "|    value_loss         | 1.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 23166976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011864049 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.453       |\n",
      "|    mean_step_reward   | 0.35609826  |\n",
      "|    n_updates          | 11308       |\n",
      "|    policyGradLoss     | -0.00245    |\n",
      "|    value_loss         | 2.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 23175168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016688246 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.96        |\n",
      "|    mean_step_reward   | 0.41391173  |\n",
      "|    n_updates          | 11312       |\n",
      "|    policyGradLoss     | 0.00665     |\n",
      "|    value_loss         | 4.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 23183360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010662819 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.192       |\n",
      "|    mean_step_reward   | 0.34758478  |\n",
      "|    n_updates          | 11316       |\n",
      "|    policyGradLoss     | -0.00646    |\n",
      "|    value_loss         | 1.61        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 23191552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016605346 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.906       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.638       |\n",
      "|    mean_step_reward   | 0.38736963  |\n",
      "|    n_updates          | 11320       |\n",
      "|    policyGradLoss     | 0.00232     |\n",
      "|    value_loss         | 4.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 23199744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011090594 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.136       |\n",
      "|    mean_step_reward   | 0.3270591   |\n",
      "|    n_updates          | 11324       |\n",
      "|    policyGradLoss     | -0.00608    |\n",
      "|    value_loss         | 1.14        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 783          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 177          |\n",
      "|    total_timesteps    | 23207936     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0124786105 |\n",
      "|    entropy_loss       | -1.69        |\n",
      "|    explained_variance | 0.952        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.47         |\n",
      "|    mean_step_reward   | 0.37282833   |\n",
      "|    n_updates          | 11328        |\n",
      "|    policyGradLoss     | -0.000929    |\n",
      "|    value_loss         | 4.99         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 23216128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014694108 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.896       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 2.68        |\n",
      "|    mean_step_reward   | 0.35915557  |\n",
      "|    n_updates          | 11332       |\n",
      "|    policyGradLoss     | 0.00751     |\n",
      "|    value_loss         | 7.82        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 23224320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011808921 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.08        |\n",
      "|    mean_step_reward   | 0.40329602  |\n",
      "|    n_updates          | 11336       |\n",
      "|    policyGradLoss     | -0.00125    |\n",
      "|    value_loss         | 3.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 23232512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009584616 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.04        |\n",
      "|    mean_step_reward   | 0.3342979   |\n",
      "|    n_updates          | 11340       |\n",
      "|    policyGradLoss     | -0.00571    |\n",
      "|    value_loss         | 1.89        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 23240704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016906109 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.22        |\n",
      "|    mean_step_reward   | 0.35659352  |\n",
      "|    n_updates          | 11344       |\n",
      "|    policyGradLoss     | -0.0028     |\n",
      "|    value_loss         | 1.88        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 23248896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012777286 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.26        |\n",
      "|    mean_step_reward   | 0.2836969   |\n",
      "|    n_updates          | 11348       |\n",
      "|    policyGradLoss     | 0.000939    |\n",
      "|    value_loss         | 2.65        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 781        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 241        |\n",
      "|    total_timesteps    | 23257088   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00944931 |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.964      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.526      |\n",
      "|    mean_step_reward   | 0.2780469  |\n",
      "|    n_updates          | 11352      |\n",
      "|    policyGradLoss     | -0.00361   |\n",
      "|    value_loss         | 1.62       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 23265280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012717353 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.316       |\n",
      "|    mean_step_reward   | 0.39571443  |\n",
      "|    n_updates          | 11356       |\n",
      "|    policyGradLoss     | -0.000296   |\n",
      "|    value_loss         | 3.11        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 23273472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016977401 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.367       |\n",
      "|    mean_step_reward   | 0.26345348  |\n",
      "|    n_updates          | 11360       |\n",
      "|    policyGradLoss     | -0.00909    |\n",
      "|    value_loss         | 0.847       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 23281664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011206811 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.594       |\n",
      "|    mean_step_reward   | 0.32546085  |\n",
      "|    n_updates          | 11364       |\n",
      "|    policyGradLoss     | -0.00616    |\n",
      "|    value_loss         | 1.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 23289856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012542769 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.884       |\n",
      "|    mean_step_reward   | 0.32641214  |\n",
      "|    n_updates          | 11368       |\n",
      "|    policyGradLoss     | -0.00499    |\n",
      "|    value_loss         | 2.61        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 23298048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012429012 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.501       |\n",
      "|    mean_step_reward   | 0.39180592  |\n",
      "|    n_updates          | 11372       |\n",
      "|    policyGradLoss     | -0.000353   |\n",
      "|    value_loss         | 1.75        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 23306240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009358479 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.475       |\n",
      "|    mean_step_reward   | 0.34181964  |\n",
      "|    n_updates          | 11376       |\n",
      "|    policyGradLoss     | -0.00596    |\n",
      "|    value_loss         | 1.82        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 23314432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011413659 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.06        |\n",
      "|    mean_step_reward   | 0.33262795  |\n",
      "|    n_updates          | 11380       |\n",
      "|    policyGradLoss     | -0.00162    |\n",
      "|    value_loss         | 2.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 23322624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010694273 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.536       |\n",
      "|    mean_step_reward   | 0.40411896  |\n",
      "|    n_updates          | 11384       |\n",
      "|    policyGradLoss     | -0.00592    |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 23330816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011861007 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.455       |\n",
      "|    mean_step_reward   | 0.34690076  |\n",
      "|    n_updates          | 11388       |\n",
      "|    policyGradLoss     | -0.00465    |\n",
      "|    value_loss         | 1.88        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_88.zip\n",
      "[EVAL] Mean Return: 526.996, Best Return: 534.330\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_88_527.00.mp4\n",
      "\n",
      "=== Round 90 | Learn 262144 steps (Total trained: 23330816) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1154     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 23339008 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 926         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 23347200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010986377 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.362       |\n",
      "|    mean_step_reward   | 0.3754235   |\n",
      "|    n_updates          | 11396       |\n",
      "|    policyGradLoss     | -0.00578    |\n",
      "|    value_loss         | 1.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 872         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 23355392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008770755 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.315       |\n",
      "|    mean_step_reward   | 0.326029    |\n",
      "|    n_updates          | 11400       |\n",
      "|    policyGradLoss     | -0.00474    |\n",
      "|    value_loss         | 1.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 844         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 23363584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011941327 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.516       |\n",
      "|    mean_step_reward   | 0.36682037  |\n",
      "|    n_updates          | 11404       |\n",
      "|    policyGradLoss     | -0.00479    |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 829         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 23371776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010417409 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.418       |\n",
      "|    mean_step_reward   | 0.33072907  |\n",
      "|    n_updates          | 11408       |\n",
      "|    policyGradLoss     | -0.00684    |\n",
      "|    value_loss         | 1.67        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 818        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 23379968   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01225647 |\n",
      "|    entropy_loss       | -1.65      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.229      |\n",
      "|    mean_step_reward   | 0.42842063 |\n",
      "|    n_updates          | 11412      |\n",
      "|    policyGradLoss     | -0.00628   |\n",
      "|    value_loss         | 1.27       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 808        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 70         |\n",
      "|    total_timesteps    | 23388160   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01084003 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.983      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.843      |\n",
      "|    mean_step_reward   | 0.34265986 |\n",
      "|    n_updates          | 11416      |\n",
      "|    policyGradLoss     | -0.00753   |\n",
      "|    value_loss         | 1.49       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 23396352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016815923 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.848       |\n",
      "|    mean_step_reward   | 0.41115087  |\n",
      "|    n_updates          | 11420       |\n",
      "|    policyGradLoss     | 0.00167     |\n",
      "|    value_loss         | 3.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 23404544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009678122 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.597       |\n",
      "|    mean_step_reward   | 0.33380908  |\n",
      "|    n_updates          | 11424       |\n",
      "|    policyGradLoss     | -0.00761    |\n",
      "|    value_loss         | 1.5         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 795        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 102        |\n",
      "|    total_timesteps    | 23412736   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01169008 |\n",
      "|    entropy_loss       | -1.68      |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.563      |\n",
      "|    mean_step_reward   | 0.3564701  |\n",
      "|    n_updates          | 11428      |\n",
      "|    policyGradLoss     | -0.00672   |\n",
      "|    value_loss         | 1.74       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 23420928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010304151 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.643       |\n",
      "|    mean_step_reward   | 0.32829183  |\n",
      "|    n_updates          | 11432       |\n",
      "|    policyGradLoss     | -0.00586    |\n",
      "|    value_loss         | 2.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 23429120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014654875 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.381       |\n",
      "|    mean_step_reward   | 0.33186036  |\n",
      "|    n_updates          | 11436       |\n",
      "|    policyGradLoss     | -0.000777   |\n",
      "|    value_loss         | 2.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 23437312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009951948 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.563       |\n",
      "|    mean_step_reward   | 0.40572184  |\n",
      "|    n_updates          | 11440       |\n",
      "|    policyGradLoss     | 0.000841    |\n",
      "|    value_loss         | 5.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 23445504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011516517 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.949       |\n",
      "|    mean_step_reward   | 0.36738375  |\n",
      "|    n_updates          | 11444       |\n",
      "|    policyGradLoss     | 0.00285     |\n",
      "|    value_loss         | 3.27        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 787        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 155        |\n",
      "|    total_timesteps    | 23453696   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01161143 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.982      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.184      |\n",
      "|    mean_step_reward   | 0.35468116 |\n",
      "|    n_updates          | 11448      |\n",
      "|    policyGradLoss     | -0.0053    |\n",
      "|    value_loss         | 1.35       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 23461888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012631014 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.18        |\n",
      "|    mean_step_reward   | 0.37856567  |\n",
      "|    n_updates          | 11452       |\n",
      "|    policyGradLoss     | -0.0063     |\n",
      "|    value_loss         | 1.14        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 785          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 177          |\n",
      "|    total_timesteps    | 23470080     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0145950485 |\n",
      "|    entropy_loss       | -1.65        |\n",
      "|    explained_variance | 0.99         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.313        |\n",
      "|    mean_step_reward   | 0.41135317   |\n",
      "|    n_updates          | 11456        |\n",
      "|    policyGradLoss     | -0.00323     |\n",
      "|    value_loss         | 1.49         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 23478272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013027488 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.861       |\n",
      "|    mean_step_reward   | 0.39252657  |\n",
      "|    n_updates          | 11460       |\n",
      "|    policyGradLoss     | -0.00262    |\n",
      "|    value_loss         | 2.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 23486464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012354996 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.955       |\n",
      "|    mean_step_reward   | 0.37837043  |\n",
      "|    n_updates          | 11464       |\n",
      "|    policyGradLoss     | -0.007      |\n",
      "|    value_loss         | 2.04        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 23494656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013936587 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.146       |\n",
      "|    mean_step_reward   | 0.3881764   |\n",
      "|    n_updates          | 11468       |\n",
      "|    policyGradLoss     | -0.00452    |\n",
      "|    value_loss         | 0.804       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 783        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 219        |\n",
      "|    total_timesteps    | 23502848   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01765855 |\n",
      "|    entropy_loss       | -1.65      |\n",
      "|    explained_variance | 0.965      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.53       |\n",
      "|    mean_step_reward   | 0.39170972 |\n",
      "|    n_updates          | 11472      |\n",
      "|    policyGradLoss     | 0.00171    |\n",
      "|    value_loss         | 4.63       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 782          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 230          |\n",
      "|    total_timesteps    | 23511040     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0128051825 |\n",
      "|    entropy_loss       | -1.7         |\n",
      "|    explained_variance | 0.957        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.835        |\n",
      "|    mean_step_reward   | 0.37598205   |\n",
      "|    n_updates          | 11476        |\n",
      "|    policyGradLoss     | 0.00371      |\n",
      "|    value_loss         | 2.74         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 23519232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013852196 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.347       |\n",
      "|    mean_step_reward   | 0.39262146  |\n",
      "|    n_updates          | 11480       |\n",
      "|    policyGradLoss     | -0.00465    |\n",
      "|    value_loss         | 1.5         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 23527424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016555186 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.16        |\n",
      "|    mean_step_reward   | 0.33681083  |\n",
      "|    n_updates          | 11484       |\n",
      "|    policyGradLoss     | -0.00486    |\n",
      "|    value_loss         | 1.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 23535616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011827819 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.186       |\n",
      "|    mean_step_reward   | 0.3586998   |\n",
      "|    n_updates          | 11488       |\n",
      "|    policyGradLoss     | -0.00577    |\n",
      "|    value_loss         | 1.19        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 780        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 272        |\n",
      "|    total_timesteps    | 23543808   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01209537 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.963      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.864      |\n",
      "|    mean_step_reward   | 0.33405742 |\n",
      "|    n_updates          | 11492      |\n",
      "|    policyGradLoss     | -0.00106   |\n",
      "|    value_loss         | 2.44       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 23552000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010489313 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.83        |\n",
      "|    mean_step_reward   | 0.35073864  |\n",
      "|    n_updates          | 11496       |\n",
      "|    policyGradLoss     | -0.00401    |\n",
      "|    value_loss         | 2.11        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 23560192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015306823 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.319       |\n",
      "|    mean_step_reward   | 0.3551737   |\n",
      "|    n_updates          | 11500       |\n",
      "|    policyGradLoss     | -0.00555    |\n",
      "|    value_loss         | 1.11        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 778          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 305          |\n",
      "|    total_timesteps    | 23568384     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0104870405 |\n",
      "|    entropy_loss       | -1.69        |\n",
      "|    explained_variance | 0.956        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.33         |\n",
      "|    mean_step_reward   | 0.34791914   |\n",
      "|    n_updates          | 11504        |\n",
      "|    policyGradLoss     | 0.00183      |\n",
      "|    value_loss         | 2.95         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 23576576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011946023 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.822       |\n",
      "|    mean_step_reward   | 0.3898424   |\n",
      "|    n_updates          | 11508       |\n",
      "|    policyGradLoss     | -0.00114    |\n",
      "|    value_loss         | 1.76        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 326        |\n",
      "|    total_timesteps    | 23584768   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00966738 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.983      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.06       |\n",
      "|    mean_step_reward   | 0.34549367 |\n",
      "|    n_updates          | 11512      |\n",
      "|    policyGradLoss     | -0.00464   |\n",
      "|    value_loss         | 1.95       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 23592960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012348391 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.731       |\n",
      "|    mean_step_reward   | 0.4191873   |\n",
      "|    n_updates          | 11516       |\n",
      "|    policyGradLoss     | 0.000106    |\n",
      "|    value_loss         | 1.24        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_89.zip\n",
      "[EVAL] Mean Return: 345.122, Best Return: 349.789\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_89_345.12.mp4\n",
      "\n",
      "=== Round 91 | Learn 262144 steps (Total trained: 23592960) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1098     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 23601152 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 911         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 23609344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010429395 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.398       |\n",
      "|    mean_step_reward   | 0.33935857  |\n",
      "|    n_updates          | 11524       |\n",
      "|    policyGradLoss     | 0.0148      |\n",
      "|    value_loss         | 2.66        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 850         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 23617536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012060382 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.718       |\n",
      "|    mean_step_reward   | 0.4494379   |\n",
      "|    n_updates          | 11528       |\n",
      "|    policyGradLoss     | -0.00373    |\n",
      "|    value_loss         | 1.74        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 23625728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009329338 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.19        |\n",
      "|    mean_step_reward   | 0.3297511   |\n",
      "|    n_updates          | 11532       |\n",
      "|    policyGradLoss     | -0.00544    |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 23633920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008275191 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.334       |\n",
      "|    mean_step_reward   | 0.40251377  |\n",
      "|    n_updates          | 11536       |\n",
      "|    policyGradLoss     | -0.00441    |\n",
      "|    value_loss         | 1.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 23642112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008706765 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.495       |\n",
      "|    mean_step_reward   | 0.3876263   |\n",
      "|    n_updates          | 11540       |\n",
      "|    policyGradLoss     | -0.00734    |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 23650304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009899702 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.751       |\n",
      "|    mean_step_reward   | 0.3701229   |\n",
      "|    n_updates          | 11544       |\n",
      "|    policyGradLoss     | -0.00525    |\n",
      "|    value_loss         | 2.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 23658496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011634463 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.522       |\n",
      "|    mean_step_reward   | 0.32288116  |\n",
      "|    n_updates          | 11548       |\n",
      "|    policyGradLoss     | -0.00619    |\n",
      "|    value_loss         | 1.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 23666688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012090687 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.451       |\n",
      "|    mean_step_reward   | 0.34631544  |\n",
      "|    n_updates          | 11552       |\n",
      "|    policyGradLoss     | -0.00533    |\n",
      "|    value_loss         | 1.11        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 789        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 103        |\n",
      "|    total_timesteps    | 23674880   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01359041 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.988      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.458      |\n",
      "|    mean_step_reward   | 0.4186313  |\n",
      "|    n_updates          | 11556      |\n",
      "|    policyGradLoss     | -0.00516   |\n",
      "|    value_loss         | 1.73       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 788        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 114        |\n",
      "|    total_timesteps    | 23683072   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0127426  |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.949      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.654      |\n",
      "|    mean_step_reward   | 0.35941473 |\n",
      "|    n_updates          | 11560      |\n",
      "|    policyGradLoss     | -0.00048   |\n",
      "|    value_loss         | 3.43       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 23691264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012698625 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.416       |\n",
      "|    mean_step_reward   | 0.36470008  |\n",
      "|    n_updates          | 11564       |\n",
      "|    policyGradLoss     | -0.00396    |\n",
      "|    value_loss         | 1.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 23699456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015218743 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.537       |\n",
      "|    mean_step_reward   | 0.41023582  |\n",
      "|    n_updates          | 11568       |\n",
      "|    policyGradLoss     | -0.00226    |\n",
      "|    value_loss         | 1.07        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 23707648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010581633 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.272       |\n",
      "|    mean_step_reward   | 0.40817204  |\n",
      "|    n_updates          | 11572       |\n",
      "|    policyGradLoss     | -0.00323    |\n",
      "|    value_loss         | 1.86        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 785          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 156          |\n",
      "|    total_timesteps    | 23715840     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0077920896 |\n",
      "|    entropy_loss       | -1.71        |\n",
      "|    explained_variance | 0.988        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.375        |\n",
      "|    mean_step_reward   | 0.3913358    |\n",
      "|    n_updates          | 11576        |\n",
      "|    policyGradLoss     | -0.00442     |\n",
      "|    value_loss         | 1.61         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 23724032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014968568 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.184       |\n",
      "|    mean_step_reward   | 0.42218935  |\n",
      "|    n_updates          | 11580       |\n",
      "|    policyGradLoss     | -0.00543    |\n",
      "|    value_loss         | 0.856       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 23732224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008877659 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.39        |\n",
      "|    mean_step_reward   | 0.36047322  |\n",
      "|    n_updates          | 11584       |\n",
      "|    policyGradLoss     | -0.00192    |\n",
      "|    value_loss         | 3.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 23740416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015059442 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.757       |\n",
      "|    mean_step_reward   | 0.36505598  |\n",
      "|    n_updates          | 11588       |\n",
      "|    policyGradLoss     | -0.00334    |\n",
      "|    value_loss         | 2.72        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 23748608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016281385 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.351       |\n",
      "|    mean_step_reward   | 0.3569227   |\n",
      "|    n_updates          | 11592       |\n",
      "|    policyGradLoss     | -0.00401    |\n",
      "|    value_loss         | 1.89        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 23756800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014552243 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.276       |\n",
      "|    mean_step_reward   | 0.32706857  |\n",
      "|    n_updates          | 11596       |\n",
      "|    policyGradLoss     | -0.00623    |\n",
      "|    value_loss         | 1.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 23764992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014425819 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.731       |\n",
      "|    mean_step_reward   | 0.41175473  |\n",
      "|    n_updates          | 11600       |\n",
      "|    policyGradLoss     | -0.00645    |\n",
      "|    value_loss         | 1.72        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 23773184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016069893 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 2.34        |\n",
      "|    mean_step_reward   | 0.35986775  |\n",
      "|    n_updates          | 11604       |\n",
      "|    policyGradLoss     | 0.00218     |\n",
      "|    value_loss         | 4.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 23781376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014767994 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.569       |\n",
      "|    mean_step_reward   | 0.33613858  |\n",
      "|    n_updates          | 11608       |\n",
      "|    policyGradLoss     | -0.00537    |\n",
      "|    value_loss         | 1.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 23789568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016569562 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.39        |\n",
      "|    mean_step_reward   | 0.35193026  |\n",
      "|    n_updates          | 11612       |\n",
      "|    policyGradLoss     | -0.00773    |\n",
      "|    value_loss         | 1.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 23797760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014451686 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.968       |\n",
      "|    mean_step_reward   | 0.35431793  |\n",
      "|    n_updates          | 11616       |\n",
      "|    policyGradLoss     | 0.0155      |\n",
      "|    value_loss         | 3.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 23805952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011943085 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.478       |\n",
      "|    mean_step_reward   | 0.37567312  |\n",
      "|    n_updates          | 11620       |\n",
      "|    policyGradLoss     | -0.00704    |\n",
      "|    value_loss         | 2.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 23814144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014584589 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.46        |\n",
      "|    mean_step_reward   | 0.3456331   |\n",
      "|    n_updates          | 11624       |\n",
      "|    policyGradLoss     | -0.00467    |\n",
      "|    value_loss         | 1.03        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 775          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 295          |\n",
      "|    total_timesteps    | 23822336     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0128746815 |\n",
      "|    entropy_loss       | -1.71        |\n",
      "|    explained_variance | 0.953        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.341        |\n",
      "|    mean_step_reward   | 0.31204394   |\n",
      "|    n_updates          | 11628        |\n",
      "|    policyGradLoss     | 0.000313     |\n",
      "|    value_loss         | 2.59         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 774          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 306          |\n",
      "|    total_timesteps    | 23830528     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0124567095 |\n",
      "|    entropy_loss       | -1.71        |\n",
      "|    explained_variance | 0.985        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.351        |\n",
      "|    mean_step_reward   | 0.3328787    |\n",
      "|    n_updates          | 11632        |\n",
      "|    policyGradLoss     | -0.00889     |\n",
      "|    value_loss         | 1.34         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 774        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 317        |\n",
      "|    total_timesteps    | 23838720   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01665747 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.975      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.826      |\n",
      "|    mean_step_reward   | 0.3159461  |\n",
      "|    n_updates          | 11636      |\n",
      "|    policyGradLoss     | -0.00195   |\n",
      "|    value_loss         | 1.78       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 23846912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019194737 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.09        |\n",
      "|    mean_step_reward   | 0.35527217  |\n",
      "|    n_updates          | 11640       |\n",
      "|    policyGradLoss     | 0.000531    |\n",
      "|    value_loss         | 5.34        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 23855104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021640506 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.271       |\n",
      "|    mean_step_reward   | 0.35422605  |\n",
      "|    n_updates          | 11644       |\n",
      "|    policyGradLoss     | 0.000318    |\n",
      "|    value_loss         | 1.64        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_90.zip\n",
      "[EVAL] Mean Return: 389.660, Best Return: 395.660\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_90_389.66.mp4\n",
      "\n",
      "=== Round 92 | Learn 262144 steps (Total trained: 23855104) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1110     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 23863296 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 915        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 23871488   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01068051 |\n",
      "|    entropy_loss       | -1.76      |\n",
      "|    explained_variance | 0.956      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.323      |\n",
      "|    mean_step_reward   | 0.3038082  |\n",
      "|    n_updates          | 11652      |\n",
      "|    policyGradLoss     | -0.00139   |\n",
      "|    value_loss         | 2.43       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 856         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 23879680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012780865 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.582       |\n",
      "|    mean_step_reward   | 0.3527679   |\n",
      "|    n_updates          | 11656       |\n",
      "|    policyGradLoss     | -0.0011     |\n",
      "|    value_loss         | 3.04        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 836         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 23887872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009131137 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.994       |\n",
      "|    mean_step_reward   | 0.33355033  |\n",
      "|    n_updates          | 11660       |\n",
      "|    policyGradLoss     | 0.00281     |\n",
      "|    value_loss         | 2.93        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 23896064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011002386 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.962       |\n",
      "|    mean_step_reward   | 0.4237342   |\n",
      "|    n_updates          | 11664       |\n",
      "|    policyGradLoss     | -4.25e-05   |\n",
      "|    value_loss         | 2.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 23904256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010250855 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.996       |\n",
      "|    mean_step_reward   | 0.3819405   |\n",
      "|    n_updates          | 11668       |\n",
      "|    policyGradLoss     | -0.00131    |\n",
      "|    value_loss         | 2.66        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 796        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 71         |\n",
      "|    total_timesteps    | 23912448   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01198495 |\n",
      "|    entropy_loss       | -1.72      |\n",
      "|    explained_variance | 0.98       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.471      |\n",
      "|    mean_step_reward   | 0.36686778 |\n",
      "|    n_updates          | 11672      |\n",
      "|    policyGradLoss     | -0.0037    |\n",
      "|    value_loss         | 1.95       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 23920640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011839276 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.304       |\n",
      "|    mean_step_reward   | 0.3516909   |\n",
      "|    n_updates          | 11676       |\n",
      "|    policyGradLoss     | -0.0061     |\n",
      "|    value_loss         | 1.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 23928832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017948577 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.635       |\n",
      "|    mean_step_reward   | 0.32823095  |\n",
      "|    n_updates          | 11680       |\n",
      "|    policyGradLoss     | 0.00238     |\n",
      "|    value_loss         | 2.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 23937024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011028459 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.608       |\n",
      "|    mean_step_reward   | 0.31462693  |\n",
      "|    n_updates          | 11684       |\n",
      "|    policyGradLoss     | -0.00432    |\n",
      "|    value_loss         | 1.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 23945216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011489086 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.322       |\n",
      "|    mean_step_reward   | 0.35753816  |\n",
      "|    n_updates          | 11688       |\n",
      "|    policyGradLoss     | -0.00508    |\n",
      "|    value_loss         | 1.81        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 23953408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012238589 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.363       |\n",
      "|    mean_step_reward   | 0.37729508  |\n",
      "|    n_updates          | 11692       |\n",
      "|    policyGradLoss     | -0.00294    |\n",
      "|    value_loss         | 1.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 23961600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012527144 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.509       |\n",
      "|    mean_step_reward   | 0.36040276  |\n",
      "|    n_updates          | 11696       |\n",
      "|    policyGradLoss     | -0.00806    |\n",
      "|    value_loss         | 1.55        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 23969792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011608245 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.279       |\n",
      "|    mean_step_reward   | 0.33280468  |\n",
      "|    n_updates          | 11700       |\n",
      "|    policyGradLoss     | -0.00472    |\n",
      "|    value_loss         | 1.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 23977984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011766007 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.644       |\n",
      "|    mean_step_reward   | 0.38992     |\n",
      "|    n_updates          | 11704       |\n",
      "|    policyGradLoss     | 0.00234     |\n",
      "|    value_loss         | 3.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 23986176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012357381 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.798       |\n",
      "|    mean_step_reward   | 0.33728522  |\n",
      "|    n_updates          | 11708       |\n",
      "|    policyGradLoss     | -0.00282    |\n",
      "|    value_loss         | 1.88        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 23994368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012759146 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.606       |\n",
      "|    mean_step_reward   | 0.3655885   |\n",
      "|    n_updates          | 11712       |\n",
      "|    policyGradLoss     | -0.00636    |\n",
      "|    value_loss         | 1.66        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 776          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 189          |\n",
      "|    total_timesteps    | 24002560     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0138526615 |\n",
      "|    entropy_loss       | -1.69        |\n",
      "|    explained_variance | 0.988        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.438        |\n",
      "|    mean_step_reward   | 0.40822265   |\n",
      "|    n_updates          | 11716        |\n",
      "|    policyGradLoss     | -0.00383     |\n",
      "|    value_loss         | 1.42         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 24010752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017372636 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.4         |\n",
      "|    mean_step_reward   | 0.32074887  |\n",
      "|    n_updates          | 11720       |\n",
      "|    policyGradLoss     | -0.00233    |\n",
      "|    value_loss         | 1.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 24018944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018756574 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.46        |\n",
      "|    mean_step_reward   | 0.4425136   |\n",
      "|    n_updates          | 11724       |\n",
      "|    policyGradLoss     | 0.00395     |\n",
      "|    value_loss         | 5.9         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 24027136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012662666 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.704       |\n",
      "|    mean_step_reward   | 0.38329136  |\n",
      "|    n_updates          | 11728       |\n",
      "|    policyGradLoss     | -0.00266    |\n",
      "|    value_loss         | 2.19        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 231        |\n",
      "|    total_timesteps    | 24035328   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01402049 |\n",
      "|    entropy_loss       | -1.66      |\n",
      "|    explained_variance | 0.979      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.552      |\n",
      "|    mean_step_reward   | 0.40198913 |\n",
      "|    n_updates          | 11732      |\n",
      "|    policyGradLoss     | -0.00418   |\n",
      "|    value_loss         | 1.63       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 24043520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014079796 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.756       |\n",
      "|    mean_step_reward   | 0.37479818  |\n",
      "|    n_updates          | 11736       |\n",
      "|    policyGradLoss     | 0.00396     |\n",
      "|    value_loss         | 5.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 24051712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014006261 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.11        |\n",
      "|    mean_step_reward   | 0.34152442  |\n",
      "|    n_updates          | 11740       |\n",
      "|    policyGradLoss     | 0.00523     |\n",
      "|    value_loss         | 4.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 24059904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014023375 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.386       |\n",
      "|    mean_step_reward   | 0.37446982  |\n",
      "|    n_updates          | 11744       |\n",
      "|    policyGradLoss     | 0.00496     |\n",
      "|    value_loss         | 2.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 24068096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016796246 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.71        |\n",
      "|    mean_step_reward   | 0.2586698   |\n",
      "|    n_updates          | 11748       |\n",
      "|    policyGradLoss     | 0.00683     |\n",
      "|    value_loss         | 3.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 24076288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012545682 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.34        |\n",
      "|    mean_step_reward   | 0.3037567   |\n",
      "|    n_updates          | 11752       |\n",
      "|    policyGradLoss     | -0.00457    |\n",
      "|    value_loss         | 1.84        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 24084480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010916004 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.628       |\n",
      "|    mean_step_reward   | 0.30979404  |\n",
      "|    n_updates          | 11756       |\n",
      "|    policyGradLoss     | 0.00197     |\n",
      "|    value_loss         | 2.89        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 24092672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012413085 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.404       |\n",
      "|    mean_step_reward   | 0.29411155  |\n",
      "|    n_updates          | 11760       |\n",
      "|    policyGradLoss     | 0.00388     |\n",
      "|    value_loss         | 3.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 24100864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013078516 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.356       |\n",
      "|    mean_step_reward   | 0.4209338   |\n",
      "|    n_updates          | 11764       |\n",
      "|    policyGradLoss     | 0.000955    |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 24109056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010984318 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.276       |\n",
      "|    mean_step_reward   | 0.26726997  |\n",
      "|    n_updates          | 11768       |\n",
      "|    policyGradLoss     | -0.00592    |\n",
      "|    value_loss         | 1.45        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 24117248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015386628 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.358       |\n",
      "|    mean_step_reward   | 0.35489732  |\n",
      "|    n_updates          | 11772       |\n",
      "|    policyGradLoss     | -0.00291    |\n",
      "|    value_loss         | 1.67        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_91.zip\n",
      "[EVAL] Mean Return: 527.492, Best Return: 534.826\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_91_527.49.mp4\n",
      "\n",
      "=== Round 93 | Learn 262144 steps (Total trained: 24117248) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1110     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 24125440 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 903         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 24133632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013272627 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.536       |\n",
      "|    mean_step_reward   | 0.3917929   |\n",
      "|    n_updates          | 11780       |\n",
      "|    policyGradLoss     | -0.00236    |\n",
      "|    value_loss         | 1.96        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 857          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 24141824     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0131320795 |\n",
      "|    entropy_loss       | -1.73        |\n",
      "|    explained_variance | 0.971        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.176        |\n",
      "|    mean_step_reward   | 0.34656918   |\n",
      "|    n_updates          | 11784        |\n",
      "|    policyGradLoss     | -0.00637     |\n",
      "|    value_loss         | 2.26         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 840         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 24150016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009182213 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.426       |\n",
      "|    mean_step_reward   | 0.33945507  |\n",
      "|    n_updates          | 11788       |\n",
      "|    policyGradLoss     | -0.00118    |\n",
      "|    value_loss         | 3.21        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 823          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 49           |\n",
      "|    total_timesteps    | 24158208     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0139191765 |\n",
      "|    entropy_loss       | -1.74        |\n",
      "|    explained_variance | 0.987        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.15         |\n",
      "|    mean_step_reward   | 0.3841404    |\n",
      "|    n_updates          | 11792        |\n",
      "|    policyGradLoss     | -0.00588     |\n",
      "|    value_loss         | 1.74         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 812        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 24166400   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01278741 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.481      |\n",
      "|    mean_step_reward   | 0.3811114  |\n",
      "|    n_updates          | 11796      |\n",
      "|    policyGradLoss     | -0.00748   |\n",
      "|    value_loss         | 1.11       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 24174592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017755028 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.448       |\n",
      "|    mean_step_reward   | 0.34673685  |\n",
      "|    n_updates          | 11800       |\n",
      "|    policyGradLoss     | -0.00588    |\n",
      "|    value_loss         | 1.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 24182784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020616636 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.838       |\n",
      "|    mean_step_reward   | 0.40431637  |\n",
      "|    n_updates          | 11804       |\n",
      "|    policyGradLoss     | 0.00111     |\n",
      "|    value_loss         | 2.75        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 24190976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010783756 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.72        |\n",
      "|    mean_step_reward   | 0.34892866  |\n",
      "|    n_updates          | 11808       |\n",
      "|    policyGradLoss     | -0.00668    |\n",
      "|    value_loss         | 1.48        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 790        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 103        |\n",
      "|    total_timesteps    | 24199168   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01616852 |\n",
      "|    entropy_loss       | -1.68      |\n",
      "|    explained_variance | 0.954      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.596      |\n",
      "|    mean_step_reward   | 0.36588043 |\n",
      "|    n_updates          | 11812      |\n",
      "|    policyGradLoss     | -0.000909  |\n",
      "|    value_loss         | 3.26       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 24207360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015577383 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.854       |\n",
      "|    mean_step_reward   | 0.3453204   |\n",
      "|    n_updates          | 11816       |\n",
      "|    policyGradLoss     | -0.00581    |\n",
      "|    value_loss         | 1.59        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 24215552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012346644 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.346       |\n",
      "|    mean_step_reward   | 0.40235388  |\n",
      "|    n_updates          | 11820       |\n",
      "|    policyGradLoss     | -0.00932    |\n",
      "|    value_loss         | 1.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 24223744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011656651 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.889       |\n",
      "|    mean_step_reward   | 0.37079376  |\n",
      "|    n_updates          | 11824       |\n",
      "|    policyGradLoss     | -0.00216    |\n",
      "|    value_loss         | 2.88        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 24231936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008565117 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.618       |\n",
      "|    mean_step_reward   | 0.39342618  |\n",
      "|    n_updates          | 11828       |\n",
      "|    policyGradLoss     | -0.00335    |\n",
      "|    value_loss         | 2.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 24240128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020265961 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.735       |\n",
      "|    mean_step_reward   | 0.31801695  |\n",
      "|    n_updates          | 11832       |\n",
      "|    policyGradLoss     | -0.000968   |\n",
      "|    value_loss         | 4.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 24248320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012334777 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.969       |\n",
      "|    mean_step_reward   | 0.36289996  |\n",
      "|    n_updates          | 11836       |\n",
      "|    policyGradLoss     | 0.00135     |\n",
      "|    value_loss         | 2.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 24256512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009333193 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.892       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.959       |\n",
      "|    mean_step_reward   | 0.34827337  |\n",
      "|    n_updates          | 11840       |\n",
      "|    policyGradLoss     | 0.00582     |\n",
      "|    value_loss         | 4.84        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 24264704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008720472 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.296       |\n",
      "|    mean_step_reward   | 0.28378737  |\n",
      "|    n_updates          | 11844       |\n",
      "|    policyGradLoss     | -0.00079    |\n",
      "|    value_loss         | 2.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 24272896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008970976 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.658       |\n",
      "|    mean_step_reward   | 0.38176405  |\n",
      "|    n_updates          | 11848       |\n",
      "|    policyGradLoss     | -0.000392   |\n",
      "|    value_loss         | 2.55        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 24281088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009172503 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.3         |\n",
      "|    mean_step_reward   | 0.28909287  |\n",
      "|    n_updates          | 11852       |\n",
      "|    policyGradLoss     | 0.000612    |\n",
      "|    value_loss         | 2.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 24289280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011444077 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.323       |\n",
      "|    mean_step_reward   | 0.33385205  |\n",
      "|    n_updates          | 11856       |\n",
      "|    policyGradLoss     | -0.00377    |\n",
      "|    value_loss         | 1.96        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 24297472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008528645 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.611       |\n",
      "|    mean_step_reward   | 0.36397338  |\n",
      "|    n_updates          | 11860       |\n",
      "|    policyGradLoss     | -0.00566    |\n",
      "|    value_loss         | 2.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 24305664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011069063 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.852       |\n",
      "|    mean_step_reward   | 0.31170058  |\n",
      "|    n_updates          | 11864       |\n",
      "|    policyGradLoss     | -0.00721    |\n",
      "|    value_loss         | 1.99        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 24313856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013415807 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.167       |\n",
      "|    mean_step_reward   | 0.29472315  |\n",
      "|    n_updates          | 11868       |\n",
      "|    policyGradLoss     | -0.00324    |\n",
      "|    value_loss         | 1.73        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 777          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 263          |\n",
      "|    total_timesteps    | 24322048     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0106882565 |\n",
      "|    entropy_loss       | -1.71        |\n",
      "|    explained_variance | 0.946        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.477        |\n",
      "|    mean_step_reward   | 0.3436557    |\n",
      "|    n_updates          | 11872        |\n",
      "|    policyGradLoss     | 0.000631     |\n",
      "|    value_loss         | 3.16         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 273        |\n",
      "|    total_timesteps    | 24330240   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00917608 |\n",
      "|    entropy_loss       | -1.7       |\n",
      "|    explained_variance | 0.967      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.602      |\n",
      "|    mean_step_reward   | 0.34210777 |\n",
      "|    n_updates          | 11876      |\n",
      "|    policyGradLoss     | -0.00484   |\n",
      "|    value_loss         | 2.15       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 24338432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012982468 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.708       |\n",
      "|    mean_step_reward   | 0.37449592  |\n",
      "|    n_updates          | 11880       |\n",
      "|    policyGradLoss     | 0.00531     |\n",
      "|    value_loss         | 4.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 24346624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009159014 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.683       |\n",
      "|    mean_step_reward   | 0.3525492   |\n",
      "|    n_updates          | 11884       |\n",
      "|    policyGradLoss     | -0.00221    |\n",
      "|    value_loss         | 2.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 24354816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012827374 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.64        |\n",
      "|    mean_step_reward   | 0.35120305  |\n",
      "|    n_updates          | 11888       |\n",
      "|    policyGradLoss     | 0.00074     |\n",
      "|    value_loss         | 5           |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 24363008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011858319 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.725       |\n",
      "|    mean_step_reward   | 0.29631177  |\n",
      "|    n_updates          | 11892       |\n",
      "|    policyGradLoss     | -0.00607    |\n",
      "|    value_loss         | 1.59        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 24371200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017175712 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.489       |\n",
      "|    mean_step_reward   | 0.36879867  |\n",
      "|    n_updates          | 11896       |\n",
      "|    policyGradLoss     | -0.0016     |\n",
      "|    value_loss         | 2.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 24379392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010271054 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.408       |\n",
      "|    mean_step_reward   | 0.37732142  |\n",
      "|    n_updates          | 11900       |\n",
      "|    policyGradLoss     | -0.00209    |\n",
      "|    value_loss         | 2.22        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_92.zip\n",
      "[EVAL] Mean Return: 527.336, Best Return: 533.336\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_92_527.34.mp4\n",
      "\n",
      "=== Round 94 | Learn 262144 steps (Total trained: 24379392) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1172     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 24387584 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 922         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 24395776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010383885 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.276       |\n",
      "|    mean_step_reward   | 0.355871    |\n",
      "|    n_updates          | 11908       |\n",
      "|    policyGradLoss     | -0.00545    |\n",
      "|    value_loss         | 1.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 864         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 24403968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010153423 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.478       |\n",
      "|    mean_step_reward   | 0.32554632  |\n",
      "|    n_updates          | 11912       |\n",
      "|    policyGradLoss     | -0.0056     |\n",
      "|    value_loss         | 1.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 24412160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012730989 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.278       |\n",
      "|    mean_step_reward   | 0.39289135  |\n",
      "|    n_updates          | 11916       |\n",
      "|    policyGradLoss     | -0.00522    |\n",
      "|    value_loss         | 1.07        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 822          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 49           |\n",
      "|    total_timesteps    | 24420352     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0116726365 |\n",
      "|    entropy_loss       | -1.74        |\n",
      "|    explained_variance | 0.989        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.919        |\n",
      "|    mean_step_reward   | 0.3682959    |\n",
      "|    n_updates          | 11920        |\n",
      "|    policyGradLoss     | -0.00652     |\n",
      "|    value_loss         | 1.7          |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 810        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 24428544   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00980869 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.978      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.607      |\n",
      "|    mean_step_reward   | 0.35711354 |\n",
      "|    n_updates          | 11924      |\n",
      "|    policyGradLoss     | -0.00728   |\n",
      "|    value_loss         | 1.57       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 24436736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011315329 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.443       |\n",
      "|    mean_step_reward   | 0.35317844  |\n",
      "|    n_updates          | 11928       |\n",
      "|    policyGradLoss     | -0.00516    |\n",
      "|    value_loss         | 1.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 24444928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010017879 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.771       |\n",
      "|    mean_step_reward   | 0.39277098  |\n",
      "|    n_updates          | 11932       |\n",
      "|    policyGradLoss     | -0.0023     |\n",
      "|    value_loss         | 4.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 24453120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015380951 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.334       |\n",
      "|    mean_step_reward   | 0.40704232  |\n",
      "|    n_updates          | 11936       |\n",
      "|    policyGradLoss     | 0.00121     |\n",
      "|    value_loss         | 2.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 24461312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008806258 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.623       |\n",
      "|    mean_step_reward   | 0.37624252  |\n",
      "|    n_updates          | 11940       |\n",
      "|    policyGradLoss     | -0.00518    |\n",
      "|    value_loss         | 2.37        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 786        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 114        |\n",
      "|    total_timesteps    | 24469504   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00846374 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.985      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.552      |\n",
      "|    mean_step_reward   | 0.3939564  |\n",
      "|    n_updates          | 11944      |\n",
      "|    policyGradLoss     | -0.00565   |\n",
      "|    value_loss         | 2          |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 24477696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011021195 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.328       |\n",
      "|    mean_step_reward   | 0.3309592   |\n",
      "|    n_updates          | 11948       |\n",
      "|    policyGradLoss     | -0.00508    |\n",
      "|    value_loss         | 1.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 24485888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008324189 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.745       |\n",
      "|    mean_step_reward   | 0.3867483   |\n",
      "|    n_updates          | 11952       |\n",
      "|    policyGradLoss     | -0.00509    |\n",
      "|    value_loss         | 1.86        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 24494080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013961813 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.473       |\n",
      "|    mean_step_reward   | 0.36750677  |\n",
      "|    n_updates          | 11956       |\n",
      "|    policyGradLoss     | -0.005      |\n",
      "|    value_loss         | 1.46        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 24502272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009154785 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.35        |\n",
      "|    mean_step_reward   | 0.38334996  |\n",
      "|    n_updates          | 11960       |\n",
      "|    policyGradLoss     | -0.00513    |\n",
      "|    value_loss         | 1.64        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 24510464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011096685 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.19        |\n",
      "|    mean_step_reward   | 0.39398053  |\n",
      "|    n_updates          | 11964       |\n",
      "|    policyGradLoss     | -0.00214    |\n",
      "|    value_loss         | 5.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 24518656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014573003 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.359       |\n",
      "|    mean_step_reward   | 0.39870548  |\n",
      "|    n_updates          | 11968       |\n",
      "|    policyGradLoss     | -0.00627    |\n",
      "|    value_loss         | 1.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 24526848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012003733 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.864       |\n",
      "|    mean_step_reward   | 0.3521061   |\n",
      "|    n_updates          | 11972       |\n",
      "|    policyGradLoss     | -0.00521    |\n",
      "|    value_loss         | 1.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 24535040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011030426 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.574       |\n",
      "|    mean_step_reward   | 0.3698632   |\n",
      "|    n_updates          | 11976       |\n",
      "|    policyGradLoss     | -0.00617    |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 24543232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012865063 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.466       |\n",
      "|    mean_step_reward   | 0.3254029   |\n",
      "|    n_updates          | 11980       |\n",
      "|    policyGradLoss     | -0.00682    |\n",
      "|    value_loss         | 1.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 24551424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010663709 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.638       |\n",
      "|    mean_step_reward   | 0.33506685  |\n",
      "|    n_updates          | 11984       |\n",
      "|    policyGradLoss     | -0.00499    |\n",
      "|    value_loss         | 1.59        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 24559616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012085682 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.109       |\n",
      "|    mean_step_reward   | 0.29586685  |\n",
      "|    n_updates          | 11988       |\n",
      "|    policyGradLoss     | -0.00941    |\n",
      "|    value_loss         | 0.857       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 24567808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012347533 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.299       |\n",
      "|    mean_step_reward   | 0.3741945   |\n",
      "|    n_updates          | 11992       |\n",
      "|    policyGradLoss     | -0.00783    |\n",
      "|    value_loss         | 1.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 24576000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010725889 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.416       |\n",
      "|    mean_step_reward   | 0.3367911   |\n",
      "|    n_updates          | 11996       |\n",
      "|    policyGradLoss     | -0.00611    |\n",
      "|    value_loss         | 1.27        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 774        |\n",
      "|    iterations         | 25         |\n",
      "|    time_elapsed       | 264        |\n",
      "|    total_timesteps    | 24584192   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01687558 |\n",
      "|    entropy_loss       | -1.65      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.142      |\n",
      "|    mean_step_reward   | 0.3382942  |\n",
      "|    n_updates          | 12000      |\n",
      "|    policyGradLoss     | -0.00922   |\n",
      "|    value_loss         | 0.711      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 275         |\n",
      "|    total_timesteps    | 24592384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009738968 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.605       |\n",
      "|    mean_step_reward   | 0.33774647  |\n",
      "|    n_updates          | 12004       |\n",
      "|    policyGradLoss     | -0.00783    |\n",
      "|    value_loss         | 1.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 286         |\n",
      "|    total_timesteps    | 24600576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010949137 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.319       |\n",
      "|    mean_step_reward   | 0.3134325   |\n",
      "|    n_updates          | 12008       |\n",
      "|    policyGradLoss     | 0.00313     |\n",
      "|    value_loss         | 2.09        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 24608768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010772448 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.358       |\n",
      "|    mean_step_reward   | 0.36778882  |\n",
      "|    n_updates          | 12012       |\n",
      "|    policyGradLoss     | -0.00463    |\n",
      "|    value_loss         | 1.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 307         |\n",
      "|    total_timesteps    | 24616960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011739252 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.693       |\n",
      "|    mean_step_reward   | 0.30947813  |\n",
      "|    n_updates          | 12016       |\n",
      "|    policyGradLoss     | -0.0019     |\n",
      "|    value_loss         | 2.83        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 771        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 318        |\n",
      "|    total_timesteps    | 24625152   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01112484 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.988      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.131      |\n",
      "|    mean_step_reward   | 0.3878108  |\n",
      "|    n_updates          | 12020      |\n",
      "|    policyGradLoss     | -0.00425   |\n",
      "|    value_loss         | 1.23       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 771        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 329        |\n",
      "|    total_timesteps    | 24633344   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01551044 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.959      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.227      |\n",
      "|    mean_step_reward   | 0.28524134 |\n",
      "|    n_updates          | 12024      |\n",
      "|    policyGradLoss     | 0.00202    |\n",
      "|    value_loss         | 2.15       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 340         |\n",
      "|    total_timesteps    | 24641536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013859354 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 2.19        |\n",
      "|    mean_step_reward   | 0.37755612  |\n",
      "|    n_updates          | 12028       |\n",
      "|    policyGradLoss     | -0.00225    |\n",
      "|    value_loss         | 4.29        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_93.zip\n",
      "[EVAL] Mean Return: 53.854, Best Return: 54.521\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_93_53.85.mp4\n",
      "\n",
      "=== Round 95 | Learn 262144 steps (Total trained: 24641536) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1096     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 24649728 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 903         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 24657920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011684719 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.243       |\n",
      "|    mean_step_reward   | 0.28110766  |\n",
      "|    n_updates          | 12036       |\n",
      "|    policyGradLoss     | -0.00612    |\n",
      "|    value_loss         | 1.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 858         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 24666112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010997161 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.193       |\n",
      "|    mean_step_reward   | 0.38940558  |\n",
      "|    n_updates          | 12040       |\n",
      "|    policyGradLoss     | -0.00297    |\n",
      "|    value_loss         | 1.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 834         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 24674304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011155177 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.95        |\n",
      "|    mean_step_reward   | 0.29482985  |\n",
      "|    n_updates          | 12044       |\n",
      "|    policyGradLoss     | 8.83e-06    |\n",
      "|    value_loss         | 4.88        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 24682496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014812326 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.127       |\n",
      "|    mean_step_reward   | 0.40043688  |\n",
      "|    n_updates          | 12048       |\n",
      "|    policyGradLoss     | -0.00197    |\n",
      "|    value_loss         | 1.07        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 24690688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010989705 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.363       |\n",
      "|    mean_step_reward   | 0.33587712  |\n",
      "|    n_updates          | 12052       |\n",
      "|    policyGradLoss     | -0.00368    |\n",
      "|    value_loss         | 1.73        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 810          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 70           |\n",
      "|    total_timesteps    | 24698880     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0075505516 |\n",
      "|    entropy_loss       | -1.73        |\n",
      "|    explained_variance | 0.987        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.534        |\n",
      "|    mean_step_reward   | 0.35860848   |\n",
      "|    n_updates          | 12056        |\n",
      "|    policyGradLoss     | -0.0042      |\n",
      "|    value_loss         | 1.53         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 805        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 81         |\n",
      "|    total_timesteps    | 24707072   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01521475 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.963      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.485      |\n",
      "|    mean_step_reward   | 0.332007   |\n",
      "|    n_updates          | 12060      |\n",
      "|    policyGradLoss     | -2.43e-05  |\n",
      "|    value_loss         | 3.35       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 24715264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010220768 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.432       |\n",
      "|    mean_step_reward   | 0.37494394  |\n",
      "|    n_updates          | 12064       |\n",
      "|    policyGradLoss     | -0.00423    |\n",
      "|    value_loss         | 2           |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 24723456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014228425 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.358       |\n",
      "|    mean_step_reward   | 0.32557738  |\n",
      "|    n_updates          | 12068       |\n",
      "|    policyGradLoss     | -0.00367    |\n",
      "|    value_loss         | 2.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 24731648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014613072 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.307       |\n",
      "|    mean_step_reward   | 0.3890912   |\n",
      "|    n_updates          | 12072       |\n",
      "|    policyGradLoss     | -0.00746    |\n",
      "|    value_loss         | 1.11        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 24739840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013128804 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.713       |\n",
      "|    mean_step_reward   | 0.37050685  |\n",
      "|    n_updates          | 12076       |\n",
      "|    policyGradLoss     | -0.00173    |\n",
      "|    value_loss         | 3.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 24748032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010366015 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.36        |\n",
      "|    mean_step_reward   | 0.35654268  |\n",
      "|    n_updates          | 12080       |\n",
      "|    policyGradLoss     | -0.00733    |\n",
      "|    value_loss         | 2.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 24756224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015434161 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.773       |\n",
      "|    mean_step_reward   | 0.4442422   |\n",
      "|    n_updates          | 12084       |\n",
      "|    policyGradLoss     | -0.00158    |\n",
      "|    value_loss         | 2.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 24764416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009574228 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.688       |\n",
      "|    mean_step_reward   | 0.36315823  |\n",
      "|    n_updates          | 12088       |\n",
      "|    policyGradLoss     | -0.00508    |\n",
      "|    value_loss         | 2.04        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 24772608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010142654 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.77        |\n",
      "|    mean_step_reward   | 0.3759607   |\n",
      "|    n_updates          | 12092       |\n",
      "|    policyGradLoss     | -0.00607    |\n",
      "|    value_loss         | 1.93        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 24780800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014470173 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.24        |\n",
      "|    mean_step_reward   | 0.35012433  |\n",
      "|    n_updates          | 12096       |\n",
      "|    policyGradLoss     | -0.002      |\n",
      "|    value_loss         | 2.67        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 783        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 188        |\n",
      "|    total_timesteps    | 24788992   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01564228 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.985      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.835      |\n",
      "|    mean_step_reward   | 0.35862052 |\n",
      "|    n_updates          | 12100      |\n",
      "|    policyGradLoss     | -0.00505   |\n",
      "|    value_loss         | 1.57       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 24797184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011249377 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.584       |\n",
      "|    mean_step_reward   | 0.4016008   |\n",
      "|    n_updates          | 12104       |\n",
      "|    policyGradLoss     | -0.0048     |\n",
      "|    value_loss         | 1.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 24805376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010842885 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.22        |\n",
      "|    mean_step_reward   | 0.3427794   |\n",
      "|    n_updates          | 12108       |\n",
      "|    policyGradLoss     | -0.00382    |\n",
      "|    value_loss         | 2.66        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 780        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 220        |\n",
      "|    total_timesteps    | 24813568   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01423149 |\n",
      "|    entropy_loss       | -1.62      |\n",
      "|    explained_variance | 0.985      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.115      |\n",
      "|    mean_step_reward   | 0.37709907 |\n",
      "|    n_updates          | 12112      |\n",
      "|    policyGradLoss     | -0.00769   |\n",
      "|    value_loss         | 0.814      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 24821760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010080814 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.496       |\n",
      "|    mean_step_reward   | 0.4143821   |\n",
      "|    n_updates          | 12116       |\n",
      "|    policyGradLoss     | -0.00453    |\n",
      "|    value_loss         | 1.94        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 24829952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012747055 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.571       |\n",
      "|    mean_step_reward   | 0.3703395   |\n",
      "|    n_updates          | 12120       |\n",
      "|    policyGradLoss     | -0.00132    |\n",
      "|    value_loss         | 3.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 24838144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010622663 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.561       |\n",
      "|    mean_step_reward   | 0.35522288  |\n",
      "|    n_updates          | 12124       |\n",
      "|    policyGradLoss     | 0.000706    |\n",
      "|    value_loss         | 4.48        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 778          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 262          |\n",
      "|    total_timesteps    | 24846336     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0112941135 |\n",
      "|    entropy_loss       | -1.73        |\n",
      "|    explained_variance | 0.98         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.595        |\n",
      "|    mean_step_reward   | 0.33580774   |\n",
      "|    n_updates          | 12128        |\n",
      "|    policyGradLoss     | -0.00488     |\n",
      "|    value_loss         | 1.48         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 24854528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010228738 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.63        |\n",
      "|    mean_step_reward   | 0.39793223  |\n",
      "|    n_updates          | 12132       |\n",
      "|    policyGradLoss     | -0.00137    |\n",
      "|    value_loss         | 3.84        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 24862720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014790681 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.362       |\n",
      "|    mean_step_reward   | 0.37863407  |\n",
      "|    n_updates          | 12136       |\n",
      "|    policyGradLoss     | -0.00178    |\n",
      "|    value_loss         | 1.94        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 294        |\n",
      "|    total_timesteps    | 24870912   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01001493 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.973      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.201      |\n",
      "|    mean_step_reward   | 0.29752082 |\n",
      "|    n_updates          | 12140      |\n",
      "|    policyGradLoss     | -0.00616   |\n",
      "|    value_loss         | 1.43       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 24879104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013968917 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.895       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.818       |\n",
      "|    mean_step_reward   | 0.34455234  |\n",
      "|    n_updates          | 12144       |\n",
      "|    policyGradLoss     | 0.00982     |\n",
      "|    value_loss         | 5.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 24887296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010222142 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.482       |\n",
      "|    mean_step_reward   | 0.37499744  |\n",
      "|    n_updates          | 12148       |\n",
      "|    policyGradLoss     | 0.000442    |\n",
      "|    value_loss         | 2.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 24895488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012409609 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.675       |\n",
      "|    mean_step_reward   | 0.35587117  |\n",
      "|    n_updates          | 12152       |\n",
      "|    policyGradLoss     | -0.00584    |\n",
      "|    value_loss         | 2.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 24903680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012948956 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.332       |\n",
      "|    mean_step_reward   | 0.35640746  |\n",
      "|    n_updates          | 12156       |\n",
      "|    policyGradLoss     | -0.00699    |\n",
      "|    value_loss         | 1.46        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_94.zip\n",
      "[EVAL] Mean Return: 528.300, Best Return: 532.966\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_94_528.30.mp4\n",
      "\n",
      "=== Round 96 | Learn 262144 steps (Total trained: 24903680) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1103     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 24911872 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 903         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 24920064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012420714 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.599       |\n",
      "|    mean_step_reward   | 0.33724314  |\n",
      "|    n_updates          | 12164       |\n",
      "|    policyGradLoss     | -0.00636    |\n",
      "|    value_loss         | 1.96        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 856         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 24928256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008980578 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.434       |\n",
      "|    mean_step_reward   | 0.3836577   |\n",
      "|    n_updates          | 12168       |\n",
      "|    policyGradLoss     | -0.00394    |\n",
      "|    value_loss         | 2.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 830         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 24936448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011084252 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.83        |\n",
      "|    mean_step_reward   | 0.3414589   |\n",
      "|    n_updates          | 12172       |\n",
      "|    policyGradLoss     | -0.00246    |\n",
      "|    value_loss         | 3.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 24944640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008884736 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.871       |\n",
      "|    mean_step_reward   | 0.36821392  |\n",
      "|    n_updates          | 12176       |\n",
      "|    policyGradLoss     | -0.00131    |\n",
      "|    value_loss         | 3.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 24952832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010685597 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.175       |\n",
      "|    mean_step_reward   | 0.32066506  |\n",
      "|    n_updates          | 12180       |\n",
      "|    policyGradLoss     | 0.00597     |\n",
      "|    value_loss         | 2.34        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 24961024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012054967 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.344       |\n",
      "|    mean_step_reward   | 0.4015232   |\n",
      "|    n_updates          | 12184       |\n",
      "|    policyGradLoss     | -0.00433    |\n",
      "|    value_loss         | 1.53        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 24969216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009234311 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.983       |\n",
      "|    mean_step_reward   | 0.3778978   |\n",
      "|    n_updates          | 12188       |\n",
      "|    policyGradLoss     | -0.00473    |\n",
      "|    value_loss         | 2.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 24977408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010336304 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.181       |\n",
      "|    mean_step_reward   | 0.34533393  |\n",
      "|    n_updates          | 12192       |\n",
      "|    policyGradLoss     | -0.00165    |\n",
      "|    value_loss         | 1.09        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 24985600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010465251 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.774       |\n",
      "|    mean_step_reward   | 0.4245907   |\n",
      "|    n_updates          | 12196       |\n",
      "|    policyGradLoss     | -0.00497    |\n",
      "|    value_loss         | 1.82        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 24993792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009619868 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 2           |\n",
      "|    mean_step_reward   | 0.3785597   |\n",
      "|    n_updates          | 12200       |\n",
      "|    policyGradLoss     | 0.00275     |\n",
      "|    value_loss         | 4.89        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 25001984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014917872 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1           |\n",
      "|    mean_step_reward   | 0.3077299   |\n",
      "|    n_updates          | 12204       |\n",
      "|    policyGradLoss     | -0.00483    |\n",
      "|    value_loss         | 1.86        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 25010176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010090206 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.05        |\n",
      "|    mean_step_reward   | 0.3424579   |\n",
      "|    n_updates          | 12208       |\n",
      "|    policyGradLoss     | -0.00211    |\n",
      "|    value_loss         | 2.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 25018368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010066796 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.442       |\n",
      "|    mean_step_reward   | 0.3809233   |\n",
      "|    n_updates          | 12212       |\n",
      "|    policyGradLoss     | -0.00082    |\n",
      "|    value_loss         | 2.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 25026560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014323293 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.16        |\n",
      "|    mean_step_reward   | 0.33476394  |\n",
      "|    n_updates          | 12216       |\n",
      "|    policyGradLoss     | -0.00184    |\n",
      "|    value_loss         | 3.07        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 25034752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010258308 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.954       |\n",
      "|    mean_step_reward   | 0.39192685  |\n",
      "|    n_updates          | 12220       |\n",
      "|    policyGradLoss     | -0.000918   |\n",
      "|    value_loss         | 2.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 25042944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011717251 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.669       |\n",
      "|    mean_step_reward   | 0.32591134  |\n",
      "|    n_updates          | 12224       |\n",
      "|    policyGradLoss     | -0.0087     |\n",
      "|    value_loss         | 1.09        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 189        |\n",
      "|    total_timesteps    | 25051136   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00985962 |\n",
      "|    entropy_loss       | -1.74      |\n",
      "|    explained_variance | 0.985      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.298      |\n",
      "|    mean_step_reward   | 0.3007953  |\n",
      "|    n_updates          | 12228      |\n",
      "|    policyGradLoss     | -0.00784   |\n",
      "|    value_loss         | 1.28       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 776          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 200          |\n",
      "|    total_timesteps    | 25059328     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0097858785 |\n",
      "|    entropy_loss       | -1.73        |\n",
      "|    explained_variance | 0.966        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.817        |\n",
      "|    mean_step_reward   | 0.3827251    |\n",
      "|    n_updates          | 12232        |\n",
      "|    policyGradLoss     | -0.0035      |\n",
      "|    value_loss         | 2.55         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 25067520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009107269 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.974       |\n",
      "|    mean_step_reward   | 0.35525265  |\n",
      "|    n_updates          | 12236       |\n",
      "|    policyGradLoss     | -0.00705    |\n",
      "|    value_loss         | 1.46        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 773          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 222          |\n",
      "|    total_timesteps    | 25075712     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0107050715 |\n",
      "|    entropy_loss       | -1.74        |\n",
      "|    explained_variance | 0.988        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.591        |\n",
      "|    mean_step_reward   | 0.33873096   |\n",
      "|    n_updates          | 12240        |\n",
      "|    policyGradLoss     | -0.00918     |\n",
      "|    value_loss         | 1.27         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 25083904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009485319 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.662       |\n",
      "|    mean_step_reward   | 0.39773318  |\n",
      "|    n_updates          | 12244       |\n",
      "|    policyGradLoss     | -0.00475    |\n",
      "|    value_loss         | 2.52        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 25092096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014200841 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.706       |\n",
      "|    mean_step_reward   | 0.34072503  |\n",
      "|    n_updates          | 12248       |\n",
      "|    policyGradLoss     | -0.00859    |\n",
      "|    value_loss         | 1.26        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 772        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 254        |\n",
      "|    total_timesteps    | 25100288   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01091314 |\n",
      "|    entropy_loss       | -1.7       |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.283      |\n",
      "|    mean_step_reward   | 0.37441254 |\n",
      "|    n_updates          | 12252      |\n",
      "|    policyGradLoss     | -0.00731   |\n",
      "|    value_loss         | 1.24       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 265         |\n",
      "|    total_timesteps    | 25108480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008912826 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.22        |\n",
      "|    mean_step_reward   | 0.31094858  |\n",
      "|    n_updates          | 12256       |\n",
      "|    policyGradLoss     | -0.00433    |\n",
      "|    value_loss         | 2.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 275         |\n",
      "|    total_timesteps    | 25116672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009638799 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.736       |\n",
      "|    mean_step_reward   | 0.37324363  |\n",
      "|    n_updates          | 12260       |\n",
      "|    policyGradLoss     | -0.00184    |\n",
      "|    value_loss         | 3.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 286         |\n",
      "|    total_timesteps    | 25124864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012799486 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.859       |\n",
      "|    mean_step_reward   | 0.32081044  |\n",
      "|    n_updates          | 12264       |\n",
      "|    policyGradLoss     | -0.00137    |\n",
      "|    value_loss         | 2.13        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 771          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 297          |\n",
      "|    total_timesteps    | 25133056     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0076702842 |\n",
      "|    entropy_loss       | -1.69        |\n",
      "|    explained_variance | 0.981        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.898        |\n",
      "|    mean_step_reward   | 0.4181402    |\n",
      "|    n_updates          | 12268        |\n",
      "|    policyGradLoss     | -0.00268     |\n",
      "|    value_loss         | 2.46         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 308         |\n",
      "|    total_timesteps    | 25141248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008385638 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.623       |\n",
      "|    mean_step_reward   | 0.35501757  |\n",
      "|    n_updates          | 12272       |\n",
      "|    policyGradLoss     | -0.00637    |\n",
      "|    value_loss         | 1.81        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 25149440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010175567 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.496       |\n",
      "|    mean_step_reward   | 0.36281937  |\n",
      "|    n_updates          | 12276       |\n",
      "|    policyGradLoss     | -0.00556    |\n",
      "|    value_loss         | 1.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 329         |\n",
      "|    total_timesteps    | 25157632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010339532 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.676       |\n",
      "|    mean_step_reward   | 0.41666096  |\n",
      "|    n_updates          | 12280       |\n",
      "|    policyGradLoss     | -0.00588    |\n",
      "|    value_loss         | 2.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 25165824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011379181 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.671       |\n",
      "|    mean_step_reward   | 0.36245942  |\n",
      "|    n_updates          | 12284       |\n",
      "|    policyGradLoss     | -0.00375    |\n",
      "|    value_loss         | 2.75        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_95.zip\n",
      "[EVAL] Mean Return: 533.717, Best Return: 540.383\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_95_533.72.mp4\n",
      "\n",
      "=== Round 97 | Learn 262144 steps (Total trained: 25165824) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1122     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 25174016 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 898         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 25182208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011162633 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.272       |\n",
      "|    mean_step_reward   | 0.38945258  |\n",
      "|    n_updates          | 12292       |\n",
      "|    policyGradLoss     | -0.00466    |\n",
      "|    value_loss         | 1.53        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 855         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 25190400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007849595 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.37        |\n",
      "|    mean_step_reward   | 0.3383668   |\n",
      "|    n_updates          | 12296       |\n",
      "|    policyGradLoss     | -0.00616    |\n",
      "|    value_loss         | 2.21        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 829          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 39           |\n",
      "|    total_timesteps    | 25198592     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0117946705 |\n",
      "|    entropy_loss       | -1.64        |\n",
      "|    explained_variance | 0.976        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.358        |\n",
      "|    mean_step_reward   | 0.42307442   |\n",
      "|    n_updates          | 12300        |\n",
      "|    policyGradLoss     | 0.000478     |\n",
      "|    value_loss         | 2.28         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 25206784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012363816 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.124       |\n",
      "|    mean_step_reward   | 0.36985716  |\n",
      "|    n_updates          | 12304       |\n",
      "|    policyGradLoss     | -0.00654    |\n",
      "|    value_loss         | 0.905       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 25214976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013857325 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.495       |\n",
      "|    mean_step_reward   | 0.37455273  |\n",
      "|    n_updates          | 12308       |\n",
      "|    policyGradLoss     | -0.00706    |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 25223168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009581508 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.939       |\n",
      "|    mean_step_reward   | 0.38651007  |\n",
      "|    n_updates          | 12312       |\n",
      "|    policyGradLoss     | -0.00559    |\n",
      "|    value_loss         | 1.89        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 25231360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014870974 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.612       |\n",
      "|    mean_step_reward   | 0.38183397  |\n",
      "|    n_updates          | 12316       |\n",
      "|    policyGradLoss     | -0.00689    |\n",
      "|    value_loss         | 1.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 25239552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013948242 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.329       |\n",
      "|    mean_step_reward   | 0.32982528  |\n",
      "|    n_updates          | 12320       |\n",
      "|    policyGradLoss     | -0.00745    |\n",
      "|    value_loss         | 1.07        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 25247744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010893544 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.683       |\n",
      "|    mean_step_reward   | 0.3558131   |\n",
      "|    n_updates          | 12324       |\n",
      "|    policyGradLoss     | -0.00273    |\n",
      "|    value_loss         | 2.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 25255936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012642454 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.02        |\n",
      "|    mean_step_reward   | 0.37033057  |\n",
      "|    n_updates          | 12328       |\n",
      "|    policyGradLoss     | -0.00307    |\n",
      "|    value_loss         | 2.98        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 25264128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011124269 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.347       |\n",
      "|    mean_step_reward   | 0.3581987   |\n",
      "|    n_updates          | 12332       |\n",
      "|    policyGradLoss     | -0.000685   |\n",
      "|    value_loss         | 3.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 25272320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014164343 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.695       |\n",
      "|    mean_step_reward   | 0.3844969   |\n",
      "|    n_updates          | 12336       |\n",
      "|    policyGradLoss     | -0.00276    |\n",
      "|    value_loss         | 2.74        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 25280512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009860007 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.453       |\n",
      "|    mean_step_reward   | 0.3424986   |\n",
      "|    n_updates          | 12340       |\n",
      "|    policyGradLoss     | -0.00528    |\n",
      "|    value_loss         | 1.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 25288704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014979204 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.775       |\n",
      "|    mean_step_reward   | 0.3874398   |\n",
      "|    n_updates          | 12344       |\n",
      "|    policyGradLoss     | -0.00304    |\n",
      "|    value_loss         | 1.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 25296896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009824921 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.46        |\n",
      "|    mean_step_reward   | 0.31825733  |\n",
      "|    n_updates          | 12348       |\n",
      "|    policyGradLoss     | -0.00192    |\n",
      "|    value_loss         | 3.04        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 25305088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011748137 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.724       |\n",
      "|    mean_step_reward   | 0.3727224   |\n",
      "|    n_updates          | 12352       |\n",
      "|    policyGradLoss     | -0.00397    |\n",
      "|    value_loss         | 1.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 25313280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011319715 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.179       |\n",
      "|    mean_step_reward   | 0.37194526  |\n",
      "|    n_updates          | 12356       |\n",
      "|    policyGradLoss     | -0.00382    |\n",
      "|    value_loss         | 2.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 25321472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015270089 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.319       |\n",
      "|    mean_step_reward   | 0.36468554  |\n",
      "|    n_updates          | 12360       |\n",
      "|    policyGradLoss     | -0.00108    |\n",
      "|    value_loss         | 1.91        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 210        |\n",
      "|    total_timesteps    | 25329664   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.009197   |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.823      |\n",
      "|    mean_step_reward   | 0.38892794 |\n",
      "|    n_updates          | 12364      |\n",
      "|    policyGradLoss     | -0.0052    |\n",
      "|    value_loss         | 1.66       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 221        |\n",
      "|    total_timesteps    | 25337856   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00947337 |\n",
      "|    entropy_loss       | -1.72      |\n",
      "|    explained_variance | 0.99       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.333      |\n",
      "|    mean_step_reward   | 0.36650243 |\n",
      "|    n_updates          | 12368      |\n",
      "|    policyGradLoss     | -0.00536   |\n",
      "|    value_loss         | 1.4        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 25346048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010681365 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.412       |\n",
      "|    mean_step_reward   | 0.32615888  |\n",
      "|    n_updates          | 12372       |\n",
      "|    policyGradLoss     | -0.00318    |\n",
      "|    value_loss         | 1.96        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 25354240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013432123 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.355       |\n",
      "|    mean_step_reward   | 0.42569792  |\n",
      "|    n_updates          | 12376       |\n",
      "|    policyGradLoss     | -0.00597    |\n",
      "|    value_loss         | 1.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 25362432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013047401 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.368       |\n",
      "|    mean_step_reward   | 0.36507118  |\n",
      "|    n_updates          | 12380       |\n",
      "|    policyGradLoss     | -0.00535    |\n",
      "|    value_loss         | 2           |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 25370624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011563448 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.611       |\n",
      "|    mean_step_reward   | 0.41498065  |\n",
      "|    n_updates          | 12384       |\n",
      "|    policyGradLoss     | -0.00278    |\n",
      "|    value_loss         | 2.94        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 25378816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010695201 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.354       |\n",
      "|    mean_step_reward   | 0.36634636  |\n",
      "|    n_updates          | 12388       |\n",
      "|    policyGradLoss     | 0.00124     |\n",
      "|    value_loss         | 1.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 25387008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010255076 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.631       |\n",
      "|    mean_step_reward   | 0.41396984  |\n",
      "|    n_updates          | 12392       |\n",
      "|    policyGradLoss     | -0.00334    |\n",
      "|    value_loss         | 2.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 25395200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010519415 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.298       |\n",
      "|    mean_step_reward   | 0.33872452  |\n",
      "|    n_updates          | 12396       |\n",
      "|    policyGradLoss     | -0.00596    |\n",
      "|    value_loss         | 1.64        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 25403392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011775272 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.31        |\n",
      "|    mean_step_reward   | 0.39261764  |\n",
      "|    n_updates          | 12400       |\n",
      "|    policyGradLoss     | -0.00731    |\n",
      "|    value_loss         | 1.76        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 25411584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011048108 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.353       |\n",
      "|    mean_step_reward   | 0.3231367   |\n",
      "|    n_updates          | 12404       |\n",
      "|    policyGradLoss     | -0.00617    |\n",
      "|    value_loss         | 1.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 25419776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011436119 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.249       |\n",
      "|    mean_step_reward   | 0.3697161   |\n",
      "|    n_updates          | 12408       |\n",
      "|    policyGradLoss     | -0.00868    |\n",
      "|    value_loss         | 1.46        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 25427968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008181268 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.732       |\n",
      "|    mean_step_reward   | 0.3300255   |\n",
      "|    n_updates          | 12412       |\n",
      "|    policyGradLoss     | -0.00601    |\n",
      "|    value_loss         | 1.67        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_96.zip\n",
      "[EVAL] Mean Return: 406.007, Best Return: 411.341\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_96_406.01.mp4\n",
      "\n",
      "=== Round 98 | Learn 262144 steps (Total trained: 25427968) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1109     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 25436160 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 904         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 25444352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011430012 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.543       |\n",
      "|    mean_step_reward   | 0.36664099  |\n",
      "|    n_updates          | 12420       |\n",
      "|    policyGradLoss     | -0.00399    |\n",
      "|    value_loss         | 1.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 846         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 25452544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010607833 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.7         |\n",
      "|    mean_step_reward   | 0.37928796  |\n",
      "|    n_updates          | 12424       |\n",
      "|    policyGradLoss     | -0.00566    |\n",
      "|    value_loss         | 1.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 25460736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013107944 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.877       |\n",
      "|    mean_step_reward   | 0.33981293  |\n",
      "|    n_updates          | 12428       |\n",
      "|    policyGradLoss     | -0.00881    |\n",
      "|    value_loss         | 1.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 25468928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012230241 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.525       |\n",
      "|    mean_step_reward   | 0.35346532  |\n",
      "|    n_updates          | 12432       |\n",
      "|    policyGradLoss     | -0.00814    |\n",
      "|    value_loss         | 1.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 25477120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011017848 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.837       |\n",
      "|    mean_step_reward   | 0.3271912   |\n",
      "|    n_updates          | 12436       |\n",
      "|    policyGradLoss     | -0.00586    |\n",
      "|    value_loss         | 2.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 25485312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011551791 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.645       |\n",
      "|    mean_step_reward   | 0.312454    |\n",
      "|    n_updates          | 12440       |\n",
      "|    policyGradLoss     | -0.00528    |\n",
      "|    value_loss         | 2.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 25493504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013279048 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.958       |\n",
      "|    mean_step_reward   | 0.37060457  |\n",
      "|    n_updates          | 12444       |\n",
      "|    policyGradLoss     | -0.00501    |\n",
      "|    value_loss         | 1.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 25501696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010563335 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.713       |\n",
      "|    mean_step_reward   | 0.3813192   |\n",
      "|    n_updates          | 12448       |\n",
      "|    policyGradLoss     | -0.00507    |\n",
      "|    value_loss         | 1.73        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 796        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 102        |\n",
      "|    total_timesteps    | 25509888   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01352388 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.512      |\n",
      "|    mean_step_reward   | 0.42131573 |\n",
      "|    n_updates          | 12452      |\n",
      "|    policyGradLoss     | -0.00524   |\n",
      "|    value_loss         | 1.79       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 25518080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010749923 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.595       |\n",
      "|    mean_step_reward   | 0.36718386  |\n",
      "|    n_updates          | 12456       |\n",
      "|    policyGradLoss     | -0.00486    |\n",
      "|    value_loss         | 2.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 25526272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010667474 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.295       |\n",
      "|    mean_step_reward   | 0.41317177  |\n",
      "|    n_updates          | 12460       |\n",
      "|    policyGradLoss     | -0.00449    |\n",
      "|    value_loss         | 2.34        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 792        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 134        |\n",
      "|    total_timesteps    | 25534464   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01054626 |\n",
      "|    entropy_loss       | -1.71      |\n",
      "|    explained_variance | 0.982      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.74       |\n",
      "|    mean_step_reward   | 0.38025457 |\n",
      "|    n_updates          | 12464      |\n",
      "|    policyGradLoss     | -0.00443   |\n",
      "|    value_loss         | 1.94       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 790          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 145          |\n",
      "|    total_timesteps    | 25542656     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0138325915 |\n",
      "|    entropy_loss       | -1.7         |\n",
      "|    explained_variance | 0.966        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.85         |\n",
      "|    mean_step_reward   | 0.33119923   |\n",
      "|    n_updates          | 12468        |\n",
      "|    policyGradLoss     | 0.00703      |\n",
      "|    value_loss         | 2.26         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 25550848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012422519 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.424       |\n",
      "|    mean_step_reward   | 0.38485047  |\n",
      "|    n_updates          | 12472       |\n",
      "|    policyGradLoss     | -0.0078     |\n",
      "|    value_loss         | 1.43        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 789          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 166          |\n",
      "|    total_timesteps    | 25559040     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0136627015 |\n",
      "|    entropy_loss       | -1.71        |\n",
      "|    explained_variance | 0.968        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.682        |\n",
      "|    mean_step_reward   | 0.38943756   |\n",
      "|    n_updates          | 12476        |\n",
      "|    policyGradLoss     | -0.000234    |\n",
      "|    value_loss         | 2.33         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 25567232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012352982 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.01        |\n",
      "|    mean_step_reward   | 0.373581    |\n",
      "|    n_updates          | 12480       |\n",
      "|    policyGradLoss     | -0.00304    |\n",
      "|    value_loss         | 5.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 25575424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013059404 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.141       |\n",
      "|    mean_step_reward   | 0.33403224  |\n",
      "|    n_updates          | 12484       |\n",
      "|    policyGradLoss     | -0.00409    |\n",
      "|    value_loss         | 1.66        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 787        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 197        |\n",
      "|    total_timesteps    | 25583616   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01266161 |\n",
      "|    entropy_loss       | -1.71      |\n",
      "|    explained_variance | 0.96       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.384      |\n",
      "|    mean_step_reward   | 0.39068013 |\n",
      "|    n_updates          | 12488      |\n",
      "|    policyGradLoss     | 0.000118   |\n",
      "|    value_loss         | 2.66       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 25591808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015642934 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.669       |\n",
      "|    mean_step_reward   | 0.3985252   |\n",
      "|    n_updates          | 12492       |\n",
      "|    policyGradLoss     | 0.000525    |\n",
      "|    value_loss         | 2.72        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 25600000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014430439 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.868       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 3.09        |\n",
      "|    mean_step_reward   | 0.34691525  |\n",
      "|    n_updates          | 12496       |\n",
      "|    policyGradLoss     | 0.0105      |\n",
      "|    value_loss         | 7.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 25608192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016055979 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.552       |\n",
      "|    mean_step_reward   | 0.38369426  |\n",
      "|    n_updates          | 12500       |\n",
      "|    policyGradLoss     | 0.000115    |\n",
      "|    value_loss         | 3.18        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 783          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 240          |\n",
      "|    total_timesteps    | 25616384     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0121682165 |\n",
      "|    entropy_loss       | -1.75        |\n",
      "|    explained_variance | 0.978        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.395        |\n",
      "|    mean_step_reward   | 0.34428594   |\n",
      "|    n_updates          | 12504        |\n",
      "|    policyGradLoss     | -0.00469     |\n",
      "|    value_loss         | 1.9          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 25624576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009816425 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.5         |\n",
      "|    mean_step_reward   | 0.35144123  |\n",
      "|    n_updates          | 12508       |\n",
      "|    policyGradLoss     | -0.00567    |\n",
      "|    value_loss         | 1.53        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 782        |\n",
      "|    iterations         | 25         |\n",
      "|    time_elapsed       | 261        |\n",
      "|    total_timesteps    | 25632768   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01029046 |\n",
      "|    entropy_loss       | -1.72      |\n",
      "|    explained_variance | 0.984      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.167      |\n",
      "|    mean_step_reward   | 0.3874448  |\n",
      "|    n_updates          | 12512      |\n",
      "|    policyGradLoss     | -0.00502   |\n",
      "|    value_loss         | 1.75       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 25640960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010811812 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.953       |\n",
      "|    mean_step_reward   | 0.3596401   |\n",
      "|    n_updates          | 12516       |\n",
      "|    policyGradLoss     | -0.00378    |\n",
      "|    value_loss         | 3.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 25649152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010896707 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.642       |\n",
      "|    mean_step_reward   | 0.28186873  |\n",
      "|    n_updates          | 12520       |\n",
      "|    policyGradLoss     | -0.00587    |\n",
      "|    value_loss         | 1.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 25657344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016563337 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.355       |\n",
      "|    mean_step_reward   | 0.36058712  |\n",
      "|    n_updates          | 12524       |\n",
      "|    policyGradLoss     | -0.00878    |\n",
      "|    value_loss         | 1.45        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 25665536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011210843 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.337       |\n",
      "|    mean_step_reward   | 0.39354485  |\n",
      "|    n_updates          | 12528       |\n",
      "|    policyGradLoss     | -0.00143    |\n",
      "|    value_loss         | 2.53        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 25673728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013106795 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.906       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.582       |\n",
      "|    mean_step_reward   | 0.39424753  |\n",
      "|    n_updates          | 12532       |\n",
      "|    policyGradLoss     | 0.005       |\n",
      "|    value_loss         | 5.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 25681920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010094163 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.896       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.41        |\n",
      "|    mean_step_reward   | 0.28672647  |\n",
      "|    n_updates          | 12536       |\n",
      "|    policyGradLoss     | -0.000925   |\n",
      "|    value_loss         | 3.72        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 25690112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010988953 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.742       |\n",
      "|    mean_step_reward   | 0.40301192  |\n",
      "|    n_updates          | 12540       |\n",
      "|    policyGradLoss     | 0.00566     |\n",
      "|    value_loss         | 4.98        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_97.zip\n",
      "[EVAL] Mean Return: 500.108, Best Return: 504.775\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_97_500.11.mp4\n",
      "\n",
      "=== Round 99 | Learn 262144 steps (Total trained: 25690112) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1129     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 25698304 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 920         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 25706496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013569259 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.694       |\n",
      "|    mean_step_reward   | 0.33060437  |\n",
      "|    n_updates          | 12548       |\n",
      "|    policyGradLoss     | -0.00183    |\n",
      "|    value_loss         | 3.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 865         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 25714688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013362553 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.899       |\n",
      "|    mean_step_reward   | 0.3494479   |\n",
      "|    n_updates          | 12552       |\n",
      "|    policyGradLoss     | 0.000623    |\n",
      "|    value_loss         | 2.52        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 840        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 38         |\n",
      "|    total_timesteps    | 25722880   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01067345 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.966      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.172      |\n",
      "|    mean_step_reward   | 0.34574544 |\n",
      "|    n_updates          | 12556      |\n",
      "|    policyGradLoss     | -0.00298   |\n",
      "|    value_loss         | 1.87       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 25731072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010512903 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.847       |\n",
      "|    mean_step_reward   | 0.37691882  |\n",
      "|    n_updates          | 12560       |\n",
      "|    policyGradLoss     | 2.47e-05    |\n",
      "|    value_loss         | 3.15        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 809        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 25739264   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01768189 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.89       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.364      |\n",
      "|    mean_step_reward   | 0.31269887 |\n",
      "|    n_updates          | 12564      |\n",
      "|    policyGradLoss     | 0.00525    |\n",
      "|    value_loss         | 2.7        |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 802          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 71           |\n",
      "|    total_timesteps    | 25747456     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0122169135 |\n",
      "|    entropy_loss       | -1.72        |\n",
      "|    explained_variance | 0.959        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.356        |\n",
      "|    mean_step_reward   | 0.33794677   |\n",
      "|    n_updates          | 12568        |\n",
      "|    policyGradLoss     | 0.00471      |\n",
      "|    value_loss         | 2.35         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 25755648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012360554 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.598       |\n",
      "|    mean_step_reward   | 0.4204255   |\n",
      "|    n_updates          | 12572       |\n",
      "|    policyGradLoss     | -0.000959   |\n",
      "|    value_loss         | 2.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 25763840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010042945 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.553       |\n",
      "|    mean_step_reward   | 0.33742717  |\n",
      "|    n_updates          | 12576       |\n",
      "|    policyGradLoss     | -0.00538    |\n",
      "|    value_loss         | 1.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 25772032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009183375 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.634       |\n",
      "|    mean_step_reward   | 0.33105564  |\n",
      "|    n_updates          | 12580       |\n",
      "|    policyGradLoss     | -0.00546    |\n",
      "|    value_loss         | 1.46        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 25780224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015704133 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.352       |\n",
      "|    mean_step_reward   | 0.37238878  |\n",
      "|    n_updates          | 12584       |\n",
      "|    policyGradLoss     | -0.00975    |\n",
      "|    value_loss         | 1.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 25788416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011224633 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.786       |\n",
      "|    mean_step_reward   | 0.4026013   |\n",
      "|    n_updates          | 12588       |\n",
      "|    policyGradLoss     | -0.00705    |\n",
      "|    value_loss         | 1.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 25796608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011359707 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.458       |\n",
      "|    mean_step_reward   | 0.35988018  |\n",
      "|    n_updates          | 12592       |\n",
      "|    policyGradLoss     | -0.00659    |\n",
      "|    value_loss         | 1.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 25804800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012532254 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.439       |\n",
      "|    mean_step_reward   | 0.35129648  |\n",
      "|    n_updates          | 12596       |\n",
      "|    policyGradLoss     | -0.00789    |\n",
      "|    value_loss         | 1.88        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 25812992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011771616 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.879       |\n",
      "|    mean_step_reward   | 0.37932855  |\n",
      "|    n_updates          | 12600       |\n",
      "|    policyGradLoss     | -0.000833   |\n",
      "|    value_loss         | 3.21        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 168        |\n",
      "|    total_timesteps    | 25821184   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00944025 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.984      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.507      |\n",
      "|    mean_step_reward   | 0.4049767  |\n",
      "|    n_updates          | 12604      |\n",
      "|    policyGradLoss     | -0.00384   |\n",
      "|    value_loss         | 1.65       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 25829376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011218168 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.68        |\n",
      "|    mean_step_reward   | 0.34710437  |\n",
      "|    n_updates          | 12608       |\n",
      "|    policyGradLoss     | -0.00383    |\n",
      "|    value_loss         | 1.84        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 25837568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008943584 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.743       |\n",
      "|    mean_step_reward   | 0.38687992  |\n",
      "|    n_updates          | 12612       |\n",
      "|    policyGradLoss     | -0.0037     |\n",
      "|    value_loss         | 2.49        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 778          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 199          |\n",
      "|    total_timesteps    | 25845760     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0133562805 |\n",
      "|    entropy_loss       | -1.66        |\n",
      "|    explained_variance | 0.988        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.36         |\n",
      "|    mean_step_reward   | 0.38840938   |\n",
      "|    n_updates          | 12616        |\n",
      "|    policyGradLoss     | -0.00767     |\n",
      "|    value_loss         | 1.15         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 25853952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011119414 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.03        |\n",
      "|    mean_step_reward   | 0.4351822   |\n",
      "|    n_updates          | 12620       |\n",
      "|    policyGradLoss     | -0.00696    |\n",
      "|    value_loss         | 1.83        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 25862144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010742954 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.412       |\n",
      "|    mean_step_reward   | 0.3878624   |\n",
      "|    n_updates          | 12624       |\n",
      "|    policyGradLoss     | -0.00511    |\n",
      "|    value_loss         | 1.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 25870336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011660177 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.636       |\n",
      "|    mean_step_reward   | 0.39452398  |\n",
      "|    n_updates          | 12628       |\n",
      "|    policyGradLoss     | -0.00174    |\n",
      "|    value_loss         | 3.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 25878528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009807322 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.867       |\n",
      "|    mean_step_reward   | 0.34035406  |\n",
      "|    n_updates          | 12632       |\n",
      "|    policyGradLoss     | -0.00365    |\n",
      "|    value_loss         | 2.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 25886720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013185687 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.289       |\n",
      "|    mean_step_reward   | 0.393233    |\n",
      "|    n_updates          | 12636       |\n",
      "|    policyGradLoss     | -0.00609    |\n",
      "|    value_loss         | 1.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 25894912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009221859 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.726       |\n",
      "|    mean_step_reward   | 0.35662216  |\n",
      "|    n_updates          | 12640       |\n",
      "|    policyGradLoss     | -0.00473    |\n",
      "|    value_loss         | 2.95        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 25903104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010042088 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.785       |\n",
      "|    mean_step_reward   | 0.39563733  |\n",
      "|    n_updates          | 12644       |\n",
      "|    policyGradLoss     | -0.00751    |\n",
      "|    value_loss         | 1.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 25911296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010813206 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.447       |\n",
      "|    mean_step_reward   | 0.36669707  |\n",
      "|    n_updates          | 12648       |\n",
      "|    policyGradLoss     | -0.00327    |\n",
      "|    value_loss         | 1.61        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 25919488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011063182 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.511       |\n",
      "|    mean_step_reward   | 0.3892095   |\n",
      "|    n_updates          | 12652       |\n",
      "|    policyGradLoss     | -0.00656    |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 25927680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013316122 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.338       |\n",
      "|    mean_step_reward   | 0.33683634  |\n",
      "|    n_updates          | 12656       |\n",
      "|    policyGradLoss     | -0.00713    |\n",
      "|    value_loss         | 1.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 25935872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012601221 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.18        |\n",
      "|    mean_step_reward   | 0.42072377  |\n",
      "|    n_updates          | 12660       |\n",
      "|    policyGradLoss     | -0.000145   |\n",
      "|    value_loss         | 5.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 25944064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010344711 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.302       |\n",
      "|    mean_step_reward   | 0.31260374  |\n",
      "|    n_updates          | 12664       |\n",
      "|    policyGradLoss     | -0.0067     |\n",
      "|    value_loss         | 1.9         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 25952256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011686841 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.204       |\n",
      "|    mean_step_reward   | 0.41288626  |\n",
      "|    n_updates          | 12668       |\n",
      "|    policyGradLoss     | -0.00464    |\n",
      "|    value_loss         | 1.51        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_98.zip\n",
      "[EVAL] Mean Return: 406.453, Best Return: 410.453\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_98_406.45.mp4\n",
      "\n",
      "=== Round 100 | Learn 262144 steps (Total trained: 25952256) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1158     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 25960448 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 925         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 25968640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013668383 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.403       |\n",
      "|    mean_step_reward   | 0.37299496  |\n",
      "|    n_updates          | 12676       |\n",
      "|    policyGradLoss     | -0.0046     |\n",
      "|    value_loss         | 1.41        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 873        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 25976832   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01584303 |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.986      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.215      |\n",
      "|    mean_step_reward   | 0.39544138 |\n",
      "|    n_updates          | 12680      |\n",
      "|    policyGradLoss     | -0.00531   |\n",
      "|    value_loss         | 1.65       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 850        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 38         |\n",
      "|    total_timesteps    | 25985024   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01274926 |\n",
      "|    entropy_loss       | -1.68      |\n",
      "|    explained_variance | 0.986      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.638      |\n",
      "|    mean_step_reward   | 0.40041393 |\n",
      "|    n_updates          | 12684      |\n",
      "|    policyGradLoss     | -0.00441   |\n",
      "|    value_loss         | 1.85       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 829         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 25993216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012700204 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.167       |\n",
      "|    mean_step_reward   | 0.35964507  |\n",
      "|    n_updates          | 12688       |\n",
      "|    policyGradLoss     | -0.00441    |\n",
      "|    value_loss         | 1.8         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 26001408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011832701 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.674       |\n",
      "|    mean_step_reward   | 0.42405003  |\n",
      "|    n_updates          | 12692       |\n",
      "|    policyGradLoss     | -0.00238    |\n",
      "|    value_loss         | 2.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 26009600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010444049 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.828       |\n",
      "|    mean_step_reward   | 0.33695826  |\n",
      "|    n_updates          | 12696       |\n",
      "|    policyGradLoss     | -0.00603    |\n",
      "|    value_loss         | 1.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 26017792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014199396 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.237       |\n",
      "|    mean_step_reward   | 0.4694326   |\n",
      "|    n_updates          | 12700       |\n",
      "|    policyGradLoss     | -0.00397    |\n",
      "|    value_loss         | 1.54        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 803          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 91           |\n",
      "|    total_timesteps    | 26025984     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0110120345 |\n",
      "|    entropy_loss       | -1.72        |\n",
      "|    explained_variance | 0.989        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.633        |\n",
      "|    mean_step_reward   | 0.36308742   |\n",
      "|    n_updates          | 12704        |\n",
      "|    policyGradLoss     | -0.00781     |\n",
      "|    value_loss         | 1.62         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 26034176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014804126 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.21        |\n",
      "|    mean_step_reward   | 0.36840388  |\n",
      "|    n_updates          | 12708       |\n",
      "|    policyGradLoss     | -0.00249    |\n",
      "|    value_loss         | 5.13        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 797        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 112        |\n",
      "|    total_timesteps    | 26042368   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01392736 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.977      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.23       |\n",
      "|    mean_step_reward   | 0.35189396 |\n",
      "|    n_updates          | 12712      |\n",
      "|    policyGradLoss     | -0.0017    |\n",
      "|    value_loss         | 1.78       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 26050560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014188858 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.405       |\n",
      "|    mean_step_reward   | 0.3712378   |\n",
      "|    n_updates          | 12716       |\n",
      "|    policyGradLoss     | -0.00664    |\n",
      "|    value_loss         | 1.43        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 26058752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015375183 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.961       |\n",
      "|    mean_step_reward   | 0.3629753   |\n",
      "|    n_updates          | 12720       |\n",
      "|    policyGradLoss     | -0.00476    |\n",
      "|    value_loss         | 1.94        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 26066944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015628828 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.5         |\n",
      "|    mean_step_reward   | 0.39002138  |\n",
      "|    n_updates          | 12724       |\n",
      "|    policyGradLoss     | -0.00541    |\n",
      "|    value_loss         | 1.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 26075136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014215232 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.774       |\n",
      "|    mean_step_reward   | 0.37401462  |\n",
      "|    n_updates          | 12728       |\n",
      "|    policyGradLoss     | -0.00761    |\n",
      "|    value_loss         | 1.45        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 26083328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011819522 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.872       |\n",
      "|    mean_step_reward   | 0.43478382  |\n",
      "|    n_updates          | 12732       |\n",
      "|    policyGradLoss     | -0.00315    |\n",
      "|    value_loss         | 1.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 26091520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011281926 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.325       |\n",
      "|    mean_step_reward   | 0.374638    |\n",
      "|    n_updates          | 12736       |\n",
      "|    policyGradLoss     | -0.00589    |\n",
      "|    value_loss         | 1.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 26099712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014042567 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.435       |\n",
      "|    mean_step_reward   | 0.34895203  |\n",
      "|    n_updates          | 12740       |\n",
      "|    policyGradLoss     | -0.00868    |\n",
      "|    value_loss         | 1.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 26107904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014536506 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.53        |\n",
      "|    mean_step_reward   | 0.41159436  |\n",
      "|    n_updates          | 12744       |\n",
      "|    policyGradLoss     | -0.00963    |\n",
      "|    value_loss         | 1.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 26116096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015957236 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.683       |\n",
      "|    mean_step_reward   | 0.40596515  |\n",
      "|    n_updates          | 12748       |\n",
      "|    policyGradLoss     | -0.00757    |\n",
      "|    value_loss         | 1.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 26124288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014939968 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.544       |\n",
      "|    mean_step_reward   | 0.37798607  |\n",
      "|    n_updates          | 12752       |\n",
      "|    policyGradLoss     | -0.0068     |\n",
      "|    value_loss         | 1.34        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 26132480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015370819 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.23        |\n",
      "|    mean_step_reward   | 0.35241956  |\n",
      "|    n_updates          | 12756       |\n",
      "|    policyGradLoss     | -0.00729    |\n",
      "|    value_loss         | 1.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 26140672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018257517 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.476       |\n",
      "|    mean_step_reward   | 0.39997464  |\n",
      "|    n_updates          | 12760       |\n",
      "|    policyGradLoss     | -0.00664    |\n",
      "|    value_loss         | 1.46        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 26148864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011015506 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.577       |\n",
      "|    mean_step_reward   | 0.34623784  |\n",
      "|    n_updates          | 12764       |\n",
      "|    policyGradLoss     | -0.00299    |\n",
      "|    value_loss         | 2.61        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 26157056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011810606 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.255       |\n",
      "|    mean_step_reward   | 0.37774056  |\n",
      "|    n_updates          | 12768       |\n",
      "|    policyGradLoss     | -0.00694    |\n",
      "|    value_loss         | 1.76        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 26165248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010852436 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.864       |\n",
      "|    mean_step_reward   | 0.37487155  |\n",
      "|    n_updates          | 12772       |\n",
      "|    policyGradLoss     | -0.00546    |\n",
      "|    value_loss         | 1.41        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 283        |\n",
      "|    total_timesteps    | 26173440   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01316018 |\n",
      "|    entropy_loss       | -1.66      |\n",
      "|    explained_variance | 0.99       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.938      |\n",
      "|    mean_step_reward   | 0.39949983 |\n",
      "|    n_updates          | 12776      |\n",
      "|    policyGradLoss     | -0.0085    |\n",
      "|    value_loss         | 1.26       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 294        |\n",
      "|    total_timesteps    | 26181632   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01135687 |\n",
      "|    entropy_loss       | -1.71      |\n",
      "|    explained_variance | 0.984      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.5        |\n",
      "|    mean_step_reward   | 0.3628245  |\n",
      "|    n_updates          | 12780      |\n",
      "|    policyGradLoss     | -0.00662   |\n",
      "|    value_loss         | 2.21       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 26189824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015364592 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.235       |\n",
      "|    mean_step_reward   | 0.4638961   |\n",
      "|    n_updates          | 12784       |\n",
      "|    policyGradLoss     | -0.00306    |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 26198016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012449468 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.463       |\n",
      "|    mean_step_reward   | 0.36076504  |\n",
      "|    n_updates          | 12788       |\n",
      "|    policyGradLoss     | -0.00671    |\n",
      "|    value_loss         | 1.88        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 778          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 326          |\n",
      "|    total_timesteps    | 26206208     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0117674265 |\n",
      "|    entropy_loss       | -1.63        |\n",
      "|    explained_variance | 0.987        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.594        |\n",
      "|    mean_step_reward   | 0.38573498   |\n",
      "|    n_updates          | 12792        |\n",
      "|    policyGradLoss     | -0.00653     |\n",
      "|    value_loss         | 1.54         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 26214400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015634352 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.26        |\n",
      "|    mean_step_reward   | 0.4541519   |\n",
      "|    n_updates          | 12796       |\n",
      "|    policyGradLoss     | -0.00743    |\n",
      "|    value_loss         | 1.18        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_99.zip\n",
      "[EVAL] Mean Return: 529.229, Best Return: 534.563\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_99_529.23.mp4\n",
      "\n",
      "=== Round 101 | Learn 262144 steps (Total trained: 26214400) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1136     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 26222592 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 935         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 26230784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017072462 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.118       |\n",
      "|    mean_step_reward   | 0.45945427  |\n",
      "|    n_updates          | 12804       |\n",
      "|    policyGradLoss     | -0.00683    |\n",
      "|    value_loss         | 0.756       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 869         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 26238976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012687149 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.612       |\n",
      "|    mean_step_reward   | 0.3258382   |\n",
      "|    n_updates          | 12808       |\n",
      "|    policyGradLoss     | -0.00606    |\n",
      "|    value_loss         | 2.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 841         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 26247168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012593987 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.167       |\n",
      "|    mean_step_reward   | 0.3743779   |\n",
      "|    n_updates          | 12812       |\n",
      "|    policyGradLoss     | -0.00752    |\n",
      "|    value_loss         | 1.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 829         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 26255360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011500704 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.322       |\n",
      "|    mean_step_reward   | 0.39585078  |\n",
      "|    n_updates          | 12816       |\n",
      "|    policyGradLoss     | -0.0082     |\n",
      "|    value_loss         | 1.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 26263552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009276785 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.602       |\n",
      "|    mean_step_reward   | 0.33843023  |\n",
      "|    n_updates          | 12820       |\n",
      "|    policyGradLoss     | -0.0053     |\n",
      "|    value_loss         | 2.45        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 26271744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009426905 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.341       |\n",
      "|    mean_step_reward   | 0.38736695  |\n",
      "|    n_updates          | 12824       |\n",
      "|    policyGradLoss     | -0.00608    |\n",
      "|    value_loss         | 1.61        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 26279936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012983117 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.337       |\n",
      "|    mean_step_reward   | 0.37345058  |\n",
      "|    n_updates          | 12828       |\n",
      "|    policyGradLoss     | -0.00557    |\n",
      "|    value_loss         | 1.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 26288128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011009002 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.478       |\n",
      "|    mean_step_reward   | 0.4040206   |\n",
      "|    n_updates          | 12832       |\n",
      "|    policyGradLoss     | -0.00529    |\n",
      "|    value_loss         | 1.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 26296320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017509138 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.335       |\n",
      "|    mean_step_reward   | 0.35061756  |\n",
      "|    n_updates          | 12836       |\n",
      "|    policyGradLoss     | -0.00306    |\n",
      "|    value_loss         | 1.99        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 112         |\n",
      "|    total_timesteps    | 26304512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013650475 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.101       |\n",
      "|    mean_step_reward   | 0.41882372  |\n",
      "|    n_updates          | 12840       |\n",
      "|    policyGradLoss     | -0.00917    |\n",
      "|    value_loss         | 0.781       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 794        |\n",
      "|    iterations         | 12         |\n",
      "|    time_elapsed       | 123        |\n",
      "|    total_timesteps    | 26312704   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00982745 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.77       |\n",
      "|    mean_step_reward   | 0.36568367 |\n",
      "|    n_updates          | 12844      |\n",
      "|    policyGradLoss     | -0.00688   |\n",
      "|    value_loss         | 1.44       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 793          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 134          |\n",
      "|    total_timesteps    | 26320896     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0102262795 |\n",
      "|    entropy_loss       | -1.69        |\n",
      "|    explained_variance | 0.962        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.378        |\n",
      "|    mean_step_reward   | 0.37362897   |\n",
      "|    n_updates          | 12848        |\n",
      "|    policyGradLoss     | 0.00113      |\n",
      "|    value_loss         | 3.18         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 26329088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010996453 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.944       |\n",
      "|    mean_step_reward   | 0.42683828  |\n",
      "|    n_updates          | 12852       |\n",
      "|    policyGradLoss     | -6.5e-06    |\n",
      "|    value_loss         | 2.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 26337280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008946817 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.19        |\n",
      "|    mean_step_reward   | 0.41401142  |\n",
      "|    n_updates          | 12856       |\n",
      "|    policyGradLoss     | -0.00713    |\n",
      "|    value_loss         | 1.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 26345472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010780659 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.408       |\n",
      "|    mean_step_reward   | 0.35121202  |\n",
      "|    n_updates          | 12860       |\n",
      "|    policyGradLoss     | -0.00176    |\n",
      "|    value_loss         | 2.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 26353664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012693685 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.512       |\n",
      "|    mean_step_reward   | 0.42520535  |\n",
      "|    n_updates          | 12864       |\n",
      "|    policyGradLoss     | -0.00145    |\n",
      "|    value_loss         | 1.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 186         |\n",
      "|    total_timesteps    | 26361856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012860768 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.924       |\n",
      "|    mean_step_reward   | 0.407516    |\n",
      "|    n_updates          | 12868       |\n",
      "|    policyGradLoss     | -0.00434    |\n",
      "|    value_loss         | 1.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 197         |\n",
      "|    total_timesteps    | 26370048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010945316 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.355       |\n",
      "|    mean_step_reward   | 0.38491228  |\n",
      "|    n_updates          | 12872       |\n",
      "|    policyGradLoss     | -0.00775    |\n",
      "|    value_loss         | 1.36        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 788        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 207        |\n",
      "|    total_timesteps    | 26378240   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01820175 |\n",
      "|    entropy_loss       | -1.72      |\n",
      "|    explained_variance | 0.977      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.901      |\n",
      "|    mean_step_reward   | 0.3474373  |\n",
      "|    n_updates          | 12876      |\n",
      "|    policyGradLoss     | -0.00416   |\n",
      "|    value_loss         | 2.24       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 787        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 218        |\n",
      "|    total_timesteps    | 26386432   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01253462 |\n",
      "|    entropy_loss       | -1.65      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.568      |\n",
      "|    mean_step_reward   | 0.41732764 |\n",
      "|    n_updates          | 12880      |\n",
      "|    policyGradLoss     | -0.00523   |\n",
      "|    value_loss         | 1.49       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 26394624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012929987 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.892       |\n",
      "|    mean_step_reward   | 0.34843966  |\n",
      "|    n_updates          | 12884       |\n",
      "|    policyGradLoss     | -0.000181   |\n",
      "|    value_loss         | 3.21        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 784          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 240          |\n",
      "|    total_timesteps    | 26402816     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0125942975 |\n",
      "|    entropy_loss       | -1.7         |\n",
      "|    explained_variance | 0.968        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.435        |\n",
      "|    mean_step_reward   | 0.35437942   |\n",
      "|    n_updates          | 12888        |\n",
      "|    policyGradLoss     | -0.0029      |\n",
      "|    value_loss         | 2.09         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 250         |\n",
      "|    total_timesteps    | 26411008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013854086 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.555       |\n",
      "|    mean_step_reward   | 0.3620449   |\n",
      "|    n_updates          | 12892       |\n",
      "|    policyGradLoss     | -0.00497    |\n",
      "|    value_loss         | 1.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 26419200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009488704 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.12        |\n",
      "|    mean_step_reward   | 0.38880047  |\n",
      "|    n_updates          | 12896       |\n",
      "|    policyGradLoss     | -0.00597    |\n",
      "|    value_loss         | 1.79        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 782        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 272        |\n",
      "|    total_timesteps    | 26427392   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01205363 |\n",
      "|    entropy_loss       | -1.74      |\n",
      "|    explained_variance | 0.986      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.585      |\n",
      "|    mean_step_reward   | 0.33334643 |\n",
      "|    n_updates          | 12900      |\n",
      "|    policyGradLoss     | -0.00955   |\n",
      "|    value_loss         | 1.42       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 26435584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012185866 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.358       |\n",
      "|    mean_step_reward   | 0.3060938   |\n",
      "|    n_updates          | 12904       |\n",
      "|    policyGradLoss     | -0.00901    |\n",
      "|    value_loss         | 1.51        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 782        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 293        |\n",
      "|    total_timesteps    | 26443776   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01417486 |\n",
      "|    entropy_loss       | -1.7       |\n",
      "|    explained_variance | 0.942      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.634      |\n",
      "|    mean_step_reward   | 0.34014198 |\n",
      "|    n_updates          | 12908      |\n",
      "|    policyGradLoss     | -0.00189   |\n",
      "|    value_loss         | 2.39       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 303         |\n",
      "|    total_timesteps    | 26451968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011414485 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.901       |\n",
      "|    mean_step_reward   | 0.39130878  |\n",
      "|    n_updates          | 12912       |\n",
      "|    policyGradLoss     | -0.00304    |\n",
      "|    value_loss         | 2.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 314         |\n",
      "|    total_timesteps    | 26460160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013233325 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.546       |\n",
      "|    mean_step_reward   | 0.34292912  |\n",
      "|    n_updates          | 12916       |\n",
      "|    policyGradLoss     | -0.0078     |\n",
      "|    value_loss         | 1.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 26468352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023978505 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.2         |\n",
      "|    mean_step_reward   | 0.3052863   |\n",
      "|    n_updates          | 12920       |\n",
      "|    policyGradLoss     | -0.00824    |\n",
      "|    value_loss         | 1.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 335         |\n",
      "|    total_timesteps    | 26476544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011696613 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.329       |\n",
      "|    mean_step_reward   | 0.34692734  |\n",
      "|    n_updates          | 12924       |\n",
      "|    policyGradLoss     | -0.00618    |\n",
      "|    value_loss         | 1.61        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_100.zip\n",
      "[EVAL] Mean Return: 407.943, Best Return: 413.276\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_100_407.94.mp4\n",
      "\n",
      "=== Round 102 | Learn 262144 steps (Total trained: 26476544) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1078     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 26484736 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 910         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 26492928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012932764 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.328       |\n",
      "|    mean_step_reward   | 0.3521961   |\n",
      "|    n_updates          | 12932       |\n",
      "|    policyGradLoss     | -0.00565    |\n",
      "|    value_loss         | 1.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 863         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 26501120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016207952 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.776       |\n",
      "|    mean_step_reward   | 0.4058941   |\n",
      "|    n_updates          | 12936       |\n",
      "|    policyGradLoss     | -0.000222   |\n",
      "|    value_loss         | 2.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 830         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 26509312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010050307 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.35        |\n",
      "|    mean_step_reward   | 0.38006926  |\n",
      "|    n_updates          | 12940       |\n",
      "|    policyGradLoss     | -0.0043     |\n",
      "|    value_loss         | 2.11        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 26517504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011907571 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.202       |\n",
      "|    mean_step_reward   | 0.37126583  |\n",
      "|    n_updates          | 12944       |\n",
      "|    policyGradLoss     | -0.00672    |\n",
      "|    value_loss         | 1.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 26525696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009629313 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.447       |\n",
      "|    mean_step_reward   | 0.36976862  |\n",
      "|    n_updates          | 12948       |\n",
      "|    policyGradLoss     | -0.00638    |\n",
      "|    value_loss         | 1.92        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 26533888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010541322 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.473       |\n",
      "|    mean_step_reward   | 0.39424145  |\n",
      "|    n_updates          | 12952       |\n",
      "|    policyGradLoss     | -0.00523    |\n",
      "|    value_loss         | 1.66        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 26542080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012510337 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.638       |\n",
      "|    mean_step_reward   | 0.36585855  |\n",
      "|    n_updates          | 12956       |\n",
      "|    policyGradLoss     | -0.00396    |\n",
      "|    value_loss         | 2.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 26550272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014400762 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.957       |\n",
      "|    mean_step_reward   | 0.36751133  |\n",
      "|    n_updates          | 12960       |\n",
      "|    policyGradLoss     | -0.00213    |\n",
      "|    value_loss         | 2.52        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 792        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 103        |\n",
      "|    total_timesteps    | 26558464   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00898785 |\n",
      "|    entropy_loss       | -1.7       |\n",
      "|    explained_variance | 0.985      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.396      |\n",
      "|    mean_step_reward   | 0.36877698 |\n",
      "|    n_updates          | 12964      |\n",
      "|    policyGradLoss     | -0.00627   |\n",
      "|    value_loss         | 1.74       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 26566656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012355591 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.147       |\n",
      "|    mean_step_reward   | 0.34530297  |\n",
      "|    n_updates          | 12968       |\n",
      "|    policyGradLoss     | -0.00627    |\n",
      "|    value_loss         | 1.94        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 26574848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015687997 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.318       |\n",
      "|    mean_step_reward   | 0.37186033  |\n",
      "|    n_updates          | 12972       |\n",
      "|    policyGradLoss     | -0.00672    |\n",
      "|    value_loss         | 2.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 26583040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012702294 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.44        |\n",
      "|    mean_step_reward   | 0.41191602  |\n",
      "|    n_updates          | 12976       |\n",
      "|    policyGradLoss     | -0.0029     |\n",
      "|    value_loss         | 1.61        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 26591232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013428778 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.232       |\n",
      "|    mean_step_reward   | 0.38872653  |\n",
      "|    n_updates          | 12980       |\n",
      "|    policyGradLoss     | -0.00481    |\n",
      "|    value_loss         | 1.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 26599424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011032347 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.563       |\n",
      "|    mean_step_reward   | 0.34154633  |\n",
      "|    n_updates          | 12984       |\n",
      "|    policyGradLoss     | -0.00378    |\n",
      "|    value_loss         | 2.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 26607616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018582825 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.294       |\n",
      "|    mean_step_reward   | 0.36985302  |\n",
      "|    n_updates          | 12988       |\n",
      "|    policyGradLoss     | 0.000699    |\n",
      "|    value_loss         | 1.66        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 782          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 178          |\n",
      "|    total_timesteps    | 26615808     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0127027575 |\n",
      "|    entropy_loss       | -1.72        |\n",
      "|    explained_variance | 0.979        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.632        |\n",
      "|    mean_step_reward   | 0.34976414   |\n",
      "|    n_updates          | 12992        |\n",
      "|    policyGradLoss     | -0.00148     |\n",
      "|    value_loss         | 2.21         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 26624000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014858697 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.688       |\n",
      "|    mean_step_reward   | 0.37480697  |\n",
      "|    n_updates          | 12996       |\n",
      "|    policyGradLoss     | -0.0018     |\n",
      "|    value_loss         | 2.74        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 26632192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012958007 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.869       |\n",
      "|    mean_step_reward   | 0.32627496  |\n",
      "|    n_updates          | 13000       |\n",
      "|    policyGradLoss     | -0.0047     |\n",
      "|    value_loss         | 1.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 26640384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011327548 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.803       |\n",
      "|    mean_step_reward   | 0.3521228   |\n",
      "|    n_updates          | 13004       |\n",
      "|    policyGradLoss     | -0.00508    |\n",
      "|    value_loss         | 1.65        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 26648576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009916877 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.265       |\n",
      "|    mean_step_reward   | 0.3701766   |\n",
      "|    n_updates          | 13008       |\n",
      "|    policyGradLoss     | -0.00472    |\n",
      "|    value_loss         | 1.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 26656768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012888523 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.793       |\n",
      "|    mean_step_reward   | 0.33207715  |\n",
      "|    n_updates          | 13012       |\n",
      "|    policyGradLoss     | -0.000314   |\n",
      "|    value_loss         | 1.88        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 26664960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014972947 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.811       |\n",
      "|    mean_step_reward   | 0.36458912  |\n",
      "|    n_updates          | 13016       |\n",
      "|    policyGradLoss     | -0.00507    |\n",
      "|    value_loss         | 1.43        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 26673152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015047259 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.637       |\n",
      "|    mean_step_reward   | 0.36502045  |\n",
      "|    n_updates          | 13020       |\n",
      "|    policyGradLoss     | -0.0015     |\n",
      "|    value_loss         | 2.9         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 26681344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011767758 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.488       |\n",
      "|    mean_step_reward   | 0.38834348  |\n",
      "|    n_updates          | 13024       |\n",
      "|    policyGradLoss     | -0.00092    |\n",
      "|    value_loss         | 2.45        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 26689536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013560217 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.366       |\n",
      "|    mean_step_reward   | 0.3895539   |\n",
      "|    n_updates          | 13028       |\n",
      "|    policyGradLoss     | -0.00208    |\n",
      "|    value_loss         | 2.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 26697728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009813198 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.192       |\n",
      "|    mean_step_reward   | 0.40668195  |\n",
      "|    n_updates          | 13032       |\n",
      "|    policyGradLoss     | -0.000922   |\n",
      "|    value_loss         | 1.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 26705920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012295391 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.689       |\n",
      "|    mean_step_reward   | 0.35275656  |\n",
      "|    n_updates          | 13036       |\n",
      "|    policyGradLoss     | -0.00176    |\n",
      "|    value_loss         | 2.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 26714112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013669654 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.1         |\n",
      "|    mean_step_reward   | 0.41431233  |\n",
      "|    n_updates          | 13040       |\n",
      "|    policyGradLoss     | -0.00118    |\n",
      "|    value_loss         | 2.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 26722304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010333741 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.682       |\n",
      "|    mean_step_reward   | 0.39432898  |\n",
      "|    n_updates          | 13044       |\n",
      "|    policyGradLoss     | -0.00413    |\n",
      "|    value_loss         | 2.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 26730496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010687169 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.737       |\n",
      "|    mean_step_reward   | 0.33442706  |\n",
      "|    n_updates          | 13048       |\n",
      "|    policyGradLoss     | -0.00895    |\n",
      "|    value_loss         | 1.44        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 32         |\n",
      "|    time_elapsed       | 336        |\n",
      "|    total_timesteps    | 26738688   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03514882 |\n",
      "|    entropy_loss       | -1.65      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0667     |\n",
      "|    mean_step_reward   | 0.41347158 |\n",
      "|    n_updates          | 13052      |\n",
      "|    policyGradLoss     | -0.00894   |\n",
      "|    value_loss         | 0.956      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_101.zip\n",
      "[EVAL] Mean Return: 526.771, Best Return: 531.438\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_101_526.77.mp4\n",
      "\n",
      "=== Round 103 | Learn 262144 steps (Total trained: 26738688) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1188     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 26746880 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 918         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 26755072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019605512 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.625       |\n",
      "|    mean_step_reward   | 0.45073903  |\n",
      "|    n_updates          | 13060       |\n",
      "|    policyGradLoss     | -0.00519    |\n",
      "|    value_loss         | 1.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 871         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 26763264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012608024 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.02        |\n",
      "|    mean_step_reward   | 0.33571646  |\n",
      "|    n_updates          | 13064       |\n",
      "|    policyGradLoss     | -0.00444    |\n",
      "|    value_loss         | 1.76        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 841        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 38         |\n",
      "|    total_timesteps    | 26771456   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01361662 |\n",
      "|    entropy_loss       | -1.7       |\n",
      "|    explained_variance | 0.947      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.602      |\n",
      "|    mean_step_reward   | 0.31832033 |\n",
      "|    n_updates          | 13068      |\n",
      "|    policyGradLoss     | -0.00177   |\n",
      "|    value_loss         | 3.22       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 26779648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012393337 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.525       |\n",
      "|    mean_step_reward   | 0.42875493  |\n",
      "|    n_updates          | 13072       |\n",
      "|    policyGradLoss     | 0.00174     |\n",
      "|    value_loss         | 2.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 26787840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011291065 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.302       |\n",
      "|    mean_step_reward   | 0.37140894  |\n",
      "|    n_updates          | 13076       |\n",
      "|    policyGradLoss     | -0.00654    |\n",
      "|    value_loss         | 1.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 26796032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014183807 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.479       |\n",
      "|    mean_step_reward   | 0.376392    |\n",
      "|    n_updates          | 13080       |\n",
      "|    policyGradLoss     | -0.00474    |\n",
      "|    value_loss         | 1.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 26804224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013197698 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.159       |\n",
      "|    mean_step_reward   | 0.42025775  |\n",
      "|    n_updates          | 13084       |\n",
      "|    policyGradLoss     | -0.00627    |\n",
      "|    value_loss         | 1.34        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 26812416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010471752 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.277       |\n",
      "|    mean_step_reward   | 0.34368926  |\n",
      "|    n_updates          | 13088       |\n",
      "|    policyGradLoss     | -0.00847    |\n",
      "|    value_loss         | 1.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 26820608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016191727 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.213       |\n",
      "|    mean_step_reward   | 0.45847768  |\n",
      "|    n_updates          | 13092       |\n",
      "|    policyGradLoss     | -0.00801    |\n",
      "|    value_loss         | 0.93        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 792          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 113          |\n",
      "|    total_timesteps    | 26828800     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0073991814 |\n",
      "|    entropy_loss       | -1.77        |\n",
      "|    explained_variance | 0.987        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.655        |\n",
      "|    mean_step_reward   | 0.32271647   |\n",
      "|    n_updates          | 13096        |\n",
      "|    policyGradLoss     | -0.00332     |\n",
      "|    value_loss         | 2.07         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 26836992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015011517 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.56        |\n",
      "|    mean_step_reward   | 0.40821332  |\n",
      "|    n_updates          | 13100       |\n",
      "|    policyGradLoss     | -0.00539    |\n",
      "|    value_loss         | 0.953       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 26845184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012683444 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.473       |\n",
      "|    mean_step_reward   | 0.39640743  |\n",
      "|    n_updates          | 13104       |\n",
      "|    policyGradLoss     | -0.00698    |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 26853376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010925574 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.455       |\n",
      "|    mean_step_reward   | 0.39201805  |\n",
      "|    n_updates          | 13108       |\n",
      "|    policyGradLoss     | -0.00467    |\n",
      "|    value_loss         | 1.96        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 26861568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019351896 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.455       |\n",
      "|    mean_step_reward   | 0.4692118   |\n",
      "|    n_updates          | 13112       |\n",
      "|    policyGradLoss     | -0.00476    |\n",
      "|    value_loss         | 1.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 26869760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007753391 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.66        |\n",
      "|    mean_step_reward   | 0.37164575  |\n",
      "|    n_updates          | 13116       |\n",
      "|    policyGradLoss     | -0.00301    |\n",
      "|    value_loss         | 2.65        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 26877952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014038367 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.341       |\n",
      "|    mean_step_reward   | 0.4316957   |\n",
      "|    n_updates          | 13120       |\n",
      "|    policyGradLoss     | -0.00611    |\n",
      "|    value_loss         | 0.716       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 26886144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016592508 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.367       |\n",
      "|    mean_step_reward   | 0.36834717  |\n",
      "|    n_updates          | 13124       |\n",
      "|    policyGradLoss     | -0.00327    |\n",
      "|    value_loss         | 1.92        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 26894336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014762533 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.804       |\n",
      "|    mean_step_reward   | 0.3790306   |\n",
      "|    n_updates          | 13128       |\n",
      "|    policyGradLoss     | -0.0069     |\n",
      "|    value_loss         | 1.71        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 26902528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014399489 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.481       |\n",
      "|    mean_step_reward   | 0.4073763   |\n",
      "|    n_updates          | 13132       |\n",
      "|    policyGradLoss     | -0.00726    |\n",
      "|    value_loss         | 1.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 26910720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012801934 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.551       |\n",
      "|    mean_step_reward   | 0.3725326   |\n",
      "|    n_updates          | 13136       |\n",
      "|    policyGradLoss     | -0.00382    |\n",
      "|    value_loss         | 1.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 26918912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013911954 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.246       |\n",
      "|    mean_step_reward   | 0.3827835   |\n",
      "|    n_updates          | 13140       |\n",
      "|    policyGradLoss     | -0.0093     |\n",
      "|    value_loss         | 1.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 26927104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012957444 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.342       |\n",
      "|    mean_step_reward   | 0.34554186  |\n",
      "|    n_updates          | 13144       |\n",
      "|    policyGradLoss     | -0.00739    |\n",
      "|    value_loss         | 1.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 26935296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016059767 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.223       |\n",
      "|    mean_step_reward   | 0.4181947   |\n",
      "|    n_updates          | 13148       |\n",
      "|    policyGradLoss     | -0.0058     |\n",
      "|    value_loss         | 1.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 26943488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013201117 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.122       |\n",
      "|    mean_step_reward   | 0.36483747  |\n",
      "|    n_updates          | 13152       |\n",
      "|    policyGradLoss     | -0.00236    |\n",
      "|    value_loss         | 1.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 26951680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020315338 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.32        |\n",
      "|    mean_step_reward   | 0.40102756  |\n",
      "|    n_updates          | 13156       |\n",
      "|    policyGradLoss     | -0.00537    |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 26959872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014383437 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.22        |\n",
      "|    mean_step_reward   | 0.38085264  |\n",
      "|    n_updates          | 13160       |\n",
      "|    policyGradLoss     | -0.0062     |\n",
      "|    value_loss         | 1.35        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 776        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 295        |\n",
      "|    total_timesteps    | 26968064   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01452694 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 2.01       |\n",
      "|    mean_step_reward   | 0.38263863 |\n",
      "|    n_updates          | 13164      |\n",
      "|    policyGradLoss     | -0.0064    |\n",
      "|    value_loss         | 1.92       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 26976256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014048561 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.197       |\n",
      "|    mean_step_reward   | 0.43097866  |\n",
      "|    n_updates          | 13168       |\n",
      "|    policyGradLoss     | -0.00631    |\n",
      "|    value_loss         | 1.61        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 26984448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011772443 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.788       |\n",
      "|    mean_step_reward   | 0.32143354  |\n",
      "|    n_updates          | 13172       |\n",
      "|    policyGradLoss     | -0.00525    |\n",
      "|    value_loss         | 1.75        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 26992640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019219713 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.657       |\n",
      "|    mean_step_reward   | 0.428202    |\n",
      "|    n_updates          | 13176       |\n",
      "|    policyGradLoss     | -0.00505    |\n",
      "|    value_loss         | 1.09        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 776        |\n",
      "|    iterations         | 32         |\n",
      "|    time_elapsed       | 337        |\n",
      "|    total_timesteps    | 27000832   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01219454 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.986      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.03       |\n",
      "|    mean_step_reward   | 0.38200137 |\n",
      "|    n_updates          | 13180      |\n",
      "|    policyGradLoss     | -0.00597   |\n",
      "|    value_loss         | 1.97       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_102.zip\n",
      "[EVAL] Mean Return: 528.878, Best Return: 536.211\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_102_528.88.mp4\n",
      "\n",
      "=== Round 104 | Learn 262144 steps (Total trained: 27000832) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1140     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 27009024 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 925         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 27017216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013358331 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.913       |\n",
      "|    mean_step_reward   | 0.39258736  |\n",
      "|    n_updates          | 13188       |\n",
      "|    policyGradLoss     | 0.0041      |\n",
      "|    value_loss         | 3.82        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 871         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 27025408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014768111 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.14        |\n",
      "|    mean_step_reward   | 0.32138732  |\n",
      "|    n_updates          | 13192       |\n",
      "|    policyGradLoss     | -0.00624    |\n",
      "|    value_loss         | 1.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 843         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 27033600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013292909 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.306       |\n",
      "|    mean_step_reward   | 0.4283064   |\n",
      "|    n_updates          | 13196       |\n",
      "|    policyGradLoss     | -0.00555    |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 829          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 49           |\n",
      "|    total_timesteps    | 27041792     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0149810165 |\n",
      "|    entropy_loss       | -1.67        |\n",
      "|    explained_variance | 0.991        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.396        |\n",
      "|    mean_step_reward   | 0.3705305    |\n",
      "|    n_updates          | 13200        |\n",
      "|    policyGradLoss     | -0.00793     |\n",
      "|    value_loss         | 1.2          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 27049984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014205596 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.437       |\n",
      "|    mean_step_reward   | 0.3773438   |\n",
      "|    n_updates          | 13204       |\n",
      "|    policyGradLoss     | -0.00513    |\n",
      "|    value_loss         | 1.64        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 27058176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016520398 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.708       |\n",
      "|    mean_step_reward   | 0.39404255  |\n",
      "|    n_updates          | 13208       |\n",
      "|    policyGradLoss     | -0.000448   |\n",
      "|    value_loss         | 3.25        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 800        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 81         |\n",
      "|    total_timesteps    | 27066368   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01140448 |\n",
      "|    entropy_loss       | -1.71      |\n",
      "|    explained_variance | 0.974      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.04       |\n",
      "|    mean_step_reward   | 0.2849555  |\n",
      "|    n_updates          | 13212      |\n",
      "|    policyGradLoss     | -0.00648   |\n",
      "|    value_loss         | 1.71       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 27074560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015286064 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.552       |\n",
      "|    mean_step_reward   | 0.41723698  |\n",
      "|    n_updates          | 13216       |\n",
      "|    policyGradLoss     | -0.00296    |\n",
      "|    value_loss         | 1.72        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 793        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 103        |\n",
      "|    total_timesteps    | 27082752   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01008866 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.985      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.565      |\n",
      "|    mean_step_reward   | 0.31505942 |\n",
      "|    n_updates          | 13220      |\n",
      "|    policyGradLoss     | -0.00558   |\n",
      "|    value_loss         | 1.78       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 27090944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012009766 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0924      |\n",
      "|    mean_step_reward   | 0.37942442  |\n",
      "|    n_updates          | 13224       |\n",
      "|    policyGradLoss     | -0.00385    |\n",
      "|    value_loss         | 0.999       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 27099136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013405374 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.29        |\n",
      "|    mean_step_reward   | 0.40000218  |\n",
      "|    n_updates          | 13228       |\n",
      "|    policyGradLoss     | -0.00303    |\n",
      "|    value_loss         | 3.19        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 790        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 134        |\n",
      "|    total_timesteps    | 27107328   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01091131 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.974      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.971      |\n",
      "|    mean_step_reward   | 0.34228554 |\n",
      "|    n_updates          | 13232      |\n",
      "|    policyGradLoss     | -0.00409   |\n",
      "|    value_loss         | 2.32       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 27115520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017201103 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.532       |\n",
      "|    mean_step_reward   | 0.39745727  |\n",
      "|    n_updates          | 13236       |\n",
      "|    policyGradLoss     | -0.00811    |\n",
      "|    value_loss         | 1.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 27123712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010536961 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.491       |\n",
      "|    mean_step_reward   | 0.41155958  |\n",
      "|    n_updates          | 13240       |\n",
      "|    policyGradLoss     | -0.00585    |\n",
      "|    value_loss         | 1.8         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 27131904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011005474 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.94        |\n",
      "|    mean_step_reward   | 0.31778982  |\n",
      "|    n_updates          | 13244       |\n",
      "|    policyGradLoss     | -0.00262    |\n",
      "|    value_loss         | 2.69        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 786          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 176          |\n",
      "|    total_timesteps    | 27140096     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0142413685 |\n",
      "|    entropy_loss       | -1.62        |\n",
      "|    explained_variance | 0.987        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.426        |\n",
      "|    mean_step_reward   | 0.4417435    |\n",
      "|    n_updates          | 13248        |\n",
      "|    policyGradLoss     | -0.00313     |\n",
      "|    value_loss         | 1.49         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 785        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 187        |\n",
      "|    total_timesteps    | 27148288   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01190275 |\n",
      "|    entropy_loss       | -1.72      |\n",
      "|    explained_variance | 0.988      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.19       |\n",
      "|    mean_step_reward   | 0.34651524 |\n",
      "|    n_updates          | 13252      |\n",
      "|    policyGradLoss     | -0.00685   |\n",
      "|    value_loss         | 1.9        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 27156480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012868517 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.613       |\n",
      "|    mean_step_reward   | 0.4268992   |\n",
      "|    n_updates          | 13256       |\n",
      "|    policyGradLoss     | -0.00519    |\n",
      "|    value_loss         | 1.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 27164672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016153842 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.637       |\n",
      "|    mean_step_reward   | 0.32288268  |\n",
      "|    n_updates          | 13260       |\n",
      "|    policyGradLoss     | -0.000227   |\n",
      "|    value_loss         | 3.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 27172864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016240142 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.428       |\n",
      "|    mean_step_reward   | 0.3686095   |\n",
      "|    n_updates          | 13264       |\n",
      "|    policyGradLoss     | -0.00557    |\n",
      "|    value_loss         | 1.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 27181056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014394758 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.718       |\n",
      "|    mean_step_reward   | 0.35816386  |\n",
      "|    n_updates          | 13268       |\n",
      "|    policyGradLoss     | -0.00736    |\n",
      "|    value_loss         | 1.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 27189248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012371759 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.291       |\n",
      "|    mean_step_reward   | 0.38122737  |\n",
      "|    n_updates          | 13272       |\n",
      "|    policyGradLoss     | -0.00303    |\n",
      "|    value_loss         | 2.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 27197440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009103328 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.938       |\n",
      "|    mean_step_reward   | 0.39546794  |\n",
      "|    n_updates          | 13276       |\n",
      "|    policyGradLoss     | -0.00498    |\n",
      "|    value_loss         | 1.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 27205632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012665015 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.23        |\n",
      "|    mean_step_reward   | 0.3777479   |\n",
      "|    n_updates          | 13280       |\n",
      "|    policyGradLoss     | -0.0068     |\n",
      "|    value_loss         | 1.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 27213824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018375691 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.452       |\n",
      "|    mean_step_reward   | 0.36929712  |\n",
      "|    n_updates          | 13284       |\n",
      "|    policyGradLoss     | -0.00512    |\n",
      "|    value_loss         | 1.66        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 27222016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019731065 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.646       |\n",
      "|    mean_step_reward   | 0.35512266  |\n",
      "|    n_updates          | 13288       |\n",
      "|    policyGradLoss     | -0.00273    |\n",
      "|    value_loss         | 1.98        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 27230208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015345014 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.584       |\n",
      "|    mean_step_reward   | 0.38170126  |\n",
      "|    n_updates          | 13292       |\n",
      "|    policyGradLoss     | -0.00402    |\n",
      "|    value_loss         | 2.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 27238400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009458314 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.925       |\n",
      "|    mean_step_reward   | 0.41025716  |\n",
      "|    n_updates          | 13296       |\n",
      "|    policyGradLoss     | -0.00358    |\n",
      "|    value_loss         | 2.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 27246592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012243681 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.893       |\n",
      "|    mean_step_reward   | 0.35894617  |\n",
      "|    n_updates          | 13300       |\n",
      "|    policyGradLoss     | -0.00426    |\n",
      "|    value_loss         | 2.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 27254784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014957208 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.629       |\n",
      "|    mean_step_reward   | 0.329162    |\n",
      "|    n_updates          | 13304       |\n",
      "|    policyGradLoss     | -0.00609    |\n",
      "|    value_loss         | 1.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 27262976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016149227 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.666       |\n",
      "|    mean_step_reward   | 0.34059727  |\n",
      "|    n_updates          | 13308       |\n",
      "|    policyGradLoss     | -0.00145    |\n",
      "|    value_loss         | 4.59        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_103.zip\n",
      "[EVAL] Mean Return: 406.766, Best Return: 411.433\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_103_406.77.mp4\n",
      "\n",
      "=== Round 105 | Learn 262144 steps (Total trained: 27262976) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1181     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 27271168 |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 920          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 27279360     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0101604825 |\n",
      "|    entropy_loss       | -1.68        |\n",
      "|    explained_variance | 0.981        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.457        |\n",
      "|    mean_step_reward   | 0.36529088   |\n",
      "|    n_updates          | 13316        |\n",
      "|    policyGradLoss     | -0.00479     |\n",
      "|    value_loss         | 1.66         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 861         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 27287552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010614575 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.08        |\n",
      "|    mean_step_reward   | 0.33258954  |\n",
      "|    n_updates          | 13320       |\n",
      "|    policyGradLoss     | -0.00377    |\n",
      "|    value_loss         | 2.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 834         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 27295744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016545147 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.42        |\n",
      "|    mean_step_reward   | 0.3988129   |\n",
      "|    n_updates          | 13324       |\n",
      "|    policyGradLoss     | 0.00342     |\n",
      "|    value_loss         | 3.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 27303936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010216449 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.844       |\n",
      "|    mean_step_reward   | 0.33843344  |\n",
      "|    n_updates          | 13328       |\n",
      "|    policyGradLoss     | -0.00115    |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 27312128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010522863 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.326       |\n",
      "|    mean_step_reward   | 0.36380967  |\n",
      "|    n_updates          | 13332       |\n",
      "|    policyGradLoss     | -0.00606    |\n",
      "|    value_loss         | 1.43        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 27320320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014683303 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.34        |\n",
      "|    mean_step_reward   | 0.36879873  |\n",
      "|    n_updates          | 13336       |\n",
      "|    policyGradLoss     | -0.00801    |\n",
      "|    value_loss         | 1.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 27328512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016604608 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.863       |\n",
      "|    mean_step_reward   | 0.37112087  |\n",
      "|    n_updates          | 13340       |\n",
      "|    policyGradLoss     | -0.00197    |\n",
      "|    value_loss         | 2.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 27336704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013415196 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.548       |\n",
      "|    mean_step_reward   | 0.38605934  |\n",
      "|    n_updates          | 13344       |\n",
      "|    policyGradLoss     | -0.00683    |\n",
      "|    value_loss         | 1.93        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 27344896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010649785 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.56        |\n",
      "|    mean_step_reward   | 0.34920022  |\n",
      "|    n_updates          | 13348       |\n",
      "|    policyGradLoss     | -0.00148    |\n",
      "|    value_loss         | 2.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 27353088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011442132 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.543       |\n",
      "|    mean_step_reward   | 0.37821805  |\n",
      "|    n_updates          | 13352       |\n",
      "|    policyGradLoss     | -0.00693    |\n",
      "|    value_loss         | 1           |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 27361280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013802428 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.533       |\n",
      "|    mean_step_reward   | 0.34504446  |\n",
      "|    n_updates          | 13356       |\n",
      "|    policyGradLoss     | -0.00685    |\n",
      "|    value_loss         | 1.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 27369472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014453484 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.756       |\n",
      "|    mean_step_reward   | 0.33737487  |\n",
      "|    n_updates          | 13360       |\n",
      "|    policyGradLoss     | -0.00545    |\n",
      "|    value_loss         | 1.91        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 781        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 146        |\n",
      "|    total_timesteps    | 27377664   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01187741 |\n",
      "|    entropy_loss       | -1.65      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.557      |\n",
      "|    mean_step_reward   | 0.4312145  |\n",
      "|    n_updates          | 13364      |\n",
      "|    policyGradLoss     | -0.0025    |\n",
      "|    value_loss         | 1.72       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 27385856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009111168 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.687       |\n",
      "|    mean_step_reward   | 0.39811146  |\n",
      "|    n_updates          | 13368       |\n",
      "|    policyGradLoss     | -0.00141    |\n",
      "|    value_loss         | 2.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 27394048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015035193 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.33        |\n",
      "|    mean_step_reward   | 0.3613158   |\n",
      "|    n_updates          | 13372       |\n",
      "|    policyGradLoss     | -0.0049     |\n",
      "|    value_loss         | 1.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 27402240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013078746 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.05        |\n",
      "|    mean_step_reward   | 0.3183586   |\n",
      "|    n_updates          | 13376       |\n",
      "|    policyGradLoss     | -0.00858    |\n",
      "|    value_loss         | 1.71        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 27410432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013721396 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.558       |\n",
      "|    mean_step_reward   | 0.4064943   |\n",
      "|    n_updates          | 13380       |\n",
      "|    policyGradLoss     | -0.00283    |\n",
      "|    value_loss         | 2.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 27418624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008865092 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.593       |\n",
      "|    mean_step_reward   | 0.41355115  |\n",
      "|    n_updates          | 13384       |\n",
      "|    policyGradLoss     | -0.00464    |\n",
      "|    value_loss         | 2.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 27426816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012674898 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.676       |\n",
      "|    mean_step_reward   | 0.40046     |\n",
      "|    n_updates          | 13388       |\n",
      "|    policyGradLoss     | -0.00785    |\n",
      "|    value_loss         | 1.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 27435008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011263223 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0967      |\n",
      "|    mean_step_reward   | 0.36344847  |\n",
      "|    n_updates          | 13392       |\n",
      "|    policyGradLoss     | -0.00813    |\n",
      "|    value_loss         | 1.39        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 776          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 232          |\n",
      "|    total_timesteps    | 27443200     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0128324935 |\n",
      "|    entropy_loss       | -1.63        |\n",
      "|    explained_variance | 0.961        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.07         |\n",
      "|    mean_step_reward   | 0.37260973   |\n",
      "|    n_updates          | 13396        |\n",
      "|    policyGradLoss     | -0.00374     |\n",
      "|    value_loss         | 2.32         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 776        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 242        |\n",
      "|    total_timesteps    | 27451392   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01552785 |\n",
      "|    entropy_loss       | -1.65      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.874      |\n",
      "|    mean_step_reward   | 0.3870061  |\n",
      "|    n_updates          | 13400      |\n",
      "|    policyGradLoss     | -0.00682   |\n",
      "|    value_loss         | 1.64       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 27459584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013106894 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.04        |\n",
      "|    mean_step_reward   | 0.36069435  |\n",
      "|    n_updates          | 13404       |\n",
      "|    policyGradLoss     | -0.00299    |\n",
      "|    value_loss         | 2.94        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 775        |\n",
      "|    iterations         | 25         |\n",
      "|    time_elapsed       | 264        |\n",
      "|    total_timesteps    | 27467776   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01512625 |\n",
      "|    entropy_loss       | -1.63      |\n",
      "|    explained_variance | 0.979      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.519      |\n",
      "|    mean_step_reward   | 0.43946427 |\n",
      "|    n_updates          | 13408      |\n",
      "|    policyGradLoss     | -0.00159   |\n",
      "|    value_loss         | 2.09       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 27475968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012323466 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.87        |\n",
      "|    mean_step_reward   | 0.38834792  |\n",
      "|    n_updates          | 13412       |\n",
      "|    policyGradLoss     | -0.00805    |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 27484160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013747674 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.671       |\n",
      "|    mean_step_reward   | 0.39391264  |\n",
      "|    n_updates          | 13416       |\n",
      "|    policyGradLoss     | -0.00755    |\n",
      "|    value_loss         | 1.71        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 27492352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014937994 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.22        |\n",
      "|    mean_step_reward   | 0.4004476   |\n",
      "|    n_updates          | 13420       |\n",
      "|    policyGradLoss     | -0.00408    |\n",
      "|    value_loss         | 1.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 27500544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010899607 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.723       |\n",
      "|    mean_step_reward   | 0.40339887  |\n",
      "|    n_updates          | 13424       |\n",
      "|    policyGradLoss     | -0.00464    |\n",
      "|    value_loss         | 1.89        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 27508736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013684535 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.33        |\n",
      "|    mean_step_reward   | 0.41502905  |\n",
      "|    n_updates          | 13428       |\n",
      "|    policyGradLoss     | -0.00698    |\n",
      "|    value_loss         | 1.11        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 27516928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013508298 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.598       |\n",
      "|    mean_step_reward   | 0.32832104  |\n",
      "|    n_updates          | 13432       |\n",
      "|    policyGradLoss     | -0.00552    |\n",
      "|    value_loss         | 1.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 27525120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022043414 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.557       |\n",
      "|    mean_step_reward   | 0.43920153  |\n",
      "|    n_updates          | 13436       |\n",
      "|    policyGradLoss     | -0.00431    |\n",
      "|    value_loss         | 1.11        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_104.zip\n",
      "[EVAL] Mean Return: 411.574, Best Return: 416.907\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_104_411.57.mp4\n",
      "\n",
      "=== Round 106 | Learn 262144 steps (Total trained: 27525120) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1151     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 27533312 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 932         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 27541504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009609401 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.322       |\n",
      "|    mean_step_reward   | 0.38419405  |\n",
      "|    n_updates          | 13444       |\n",
      "|    policyGradLoss     | -0.0058     |\n",
      "|    value_loss         | 1.86        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 869        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 27549696   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0137372  |\n",
      "|    entropy_loss       | -1.65      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.801      |\n",
      "|    mean_step_reward   | 0.43949166 |\n",
      "|    n_updates          | 13448      |\n",
      "|    policyGradLoss     | -0.00496   |\n",
      "|    value_loss         | 1.75       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 847         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 27557888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010681588 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.928       |\n",
      "|    mean_step_reward   | 0.35331866  |\n",
      "|    n_updates          | 13452       |\n",
      "|    policyGradLoss     | -0.00617    |\n",
      "|    value_loss         | 2.43        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 831         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 27566080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013532709 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.88        |\n",
      "|    mean_step_reward   | 0.3902412   |\n",
      "|    n_updates          | 13456       |\n",
      "|    policyGradLoss     | 0.00516     |\n",
      "|    value_loss         | 3.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 27574272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010050403 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.791       |\n",
      "|    mean_step_reward   | 0.41883188  |\n",
      "|    n_updates          | 13460       |\n",
      "|    policyGradLoss     | -0.00591    |\n",
      "|    value_loss         | 2.82        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 812          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 70           |\n",
      "|    total_timesteps    | 27582464     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0126210805 |\n",
      "|    entropy_loss       | -1.64        |\n",
      "|    explained_variance | 0.986        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.657        |\n",
      "|    mean_step_reward   | 0.38953128   |\n",
      "|    n_updates          | 13464        |\n",
      "|    policyGradLoss     | -0.00502     |\n",
      "|    value_loss         | 1.19         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 805        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 81         |\n",
      "|    total_timesteps    | 27590656   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01308501 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.993      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.499      |\n",
      "|    mean_step_reward   | 0.40424955 |\n",
      "|    n_updates          | 13468      |\n",
      "|    policyGradLoss     | -0.00935   |\n",
      "|    value_loss         | 1.18       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 800          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 92           |\n",
      "|    total_timesteps    | 27598848     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0119459415 |\n",
      "|    entropy_loss       | -1.7         |\n",
      "|    explained_variance | 0.986        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.642        |\n",
      "|    mean_step_reward   | 0.3559205    |\n",
      "|    n_updates          | 13472        |\n",
      "|    policyGradLoss     | -0.00618     |\n",
      "|    value_loss         | 1.59         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 797        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 102        |\n",
      "|    total_timesteps    | 27607040   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01709605 |\n",
      "|    entropy_loss       | -1.65      |\n",
      "|    explained_variance | 0.986      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.494      |\n",
      "|    mean_step_reward   | 0.42126554 |\n",
      "|    n_updates          | 13476      |\n",
      "|    policyGradLoss     | -0.00702   |\n",
      "|    value_loss         | 1.44       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 27615232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012568003 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.17        |\n",
      "|    mean_step_reward   | 0.36132723  |\n",
      "|    n_updates          | 13480       |\n",
      "|    policyGradLoss     | -0.00503    |\n",
      "|    value_loss         | 1.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 27623424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012825342 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.326       |\n",
      "|    mean_step_reward   | 0.42280146  |\n",
      "|    n_updates          | 13484       |\n",
      "|    policyGradLoss     | -0.0049     |\n",
      "|    value_loss         | 1.86        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 27631616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015894419 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.082       |\n",
      "|    mean_step_reward   | 0.3547985   |\n",
      "|    n_updates          | 13488       |\n",
      "|    policyGradLoss     | -0.00882    |\n",
      "|    value_loss         | 1.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 27639808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011805844 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.511       |\n",
      "|    mean_step_reward   | 0.40168628  |\n",
      "|    n_updates          | 13492       |\n",
      "|    policyGradLoss     | -0.00611    |\n",
      "|    value_loss         | 1.76        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 787        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 155        |\n",
      "|    total_timesteps    | 27648000   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01008023 |\n",
      "|    entropy_loss       | -1.66      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.379      |\n",
      "|    mean_step_reward   | 0.40471113 |\n",
      "|    n_updates          | 13496      |\n",
      "|    policyGradLoss     | -0.00797   |\n",
      "|    value_loss         | 1.29       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 27656192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010881404 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.408       |\n",
      "|    mean_step_reward   | 0.43997598  |\n",
      "|    n_updates          | 13500       |\n",
      "|    policyGradLoss     | -0.00345    |\n",
      "|    value_loss         | 2.52        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 27664384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015974235 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.4         |\n",
      "|    mean_step_reward   | 0.38589245  |\n",
      "|    n_updates          | 13504       |\n",
      "|    policyGradLoss     | -0.00569    |\n",
      "|    value_loss         | 1.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 27672576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015344579 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.326       |\n",
      "|    mean_step_reward   | 0.40072188  |\n",
      "|    n_updates          | 13508       |\n",
      "|    policyGradLoss     | -0.00669    |\n",
      "|    value_loss         | 1.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 27680768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011157133 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.28        |\n",
      "|    mean_step_reward   | 0.43014193  |\n",
      "|    n_updates          | 13512       |\n",
      "|    policyGradLoss     | -0.00567    |\n",
      "|    value_loss         | 1.8         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 27688960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016623128 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.235       |\n",
      "|    mean_step_reward   | 0.38012677  |\n",
      "|    n_updates          | 13516       |\n",
      "|    policyGradLoss     | -0.00526    |\n",
      "|    value_loss         | 1.49        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 782        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 219        |\n",
      "|    total_timesteps    | 27697152   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0132394  |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.99       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.286      |\n",
      "|    mean_step_reward   | 0.41008767 |\n",
      "|    n_updates          | 13520      |\n",
      "|    policyGradLoss     | -0.00678   |\n",
      "|    value_loss         | 1.12       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 27705344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008797181 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.684       |\n",
      "|    mean_step_reward   | 0.3940813   |\n",
      "|    n_updates          | 13524       |\n",
      "|    policyGradLoss     | -0.0056     |\n",
      "|    value_loss         | 1.76        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 27713536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020542525 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.824       |\n",
      "|    mean_step_reward   | 0.36195248  |\n",
      "|    n_updates          | 13528       |\n",
      "|    policyGradLoss     | -0.00175    |\n",
      "|    value_loss         | 4.93        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 27721728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012811392 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.925       |\n",
      "|    mean_step_reward   | 0.38993052  |\n",
      "|    n_updates          | 13532       |\n",
      "|    policyGradLoss     | -0.00153    |\n",
      "|    value_loss         | 2.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 27729920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014075896 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.297       |\n",
      "|    mean_step_reward   | 0.39548695  |\n",
      "|    n_updates          | 13536       |\n",
      "|    policyGradLoss     | -0.00772    |\n",
      "|    value_loss         | 1.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 27738112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015608168 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.311       |\n",
      "|    mean_step_reward   | 0.37561327  |\n",
      "|    n_updates          | 13540       |\n",
      "|    policyGradLoss     | -0.00522    |\n",
      "|    value_loss         | 2.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 27746304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012744947 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.408       |\n",
      "|    mean_step_reward   | 0.32958305  |\n",
      "|    n_updates          | 13544       |\n",
      "|    policyGradLoss     | -0.00811    |\n",
      "|    value_loss         | 1.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 27754496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017624145 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.299       |\n",
      "|    mean_step_reward   | 0.3605209   |\n",
      "|    n_updates          | 13548       |\n",
      "|    policyGradLoss     | -0.00831    |\n",
      "|    value_loss         | 1.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 27762688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013167379 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.21        |\n",
      "|    mean_step_reward   | 0.3245566   |\n",
      "|    n_updates          | 13552       |\n",
      "|    policyGradLoss     | -0.00414    |\n",
      "|    value_loss         | 2.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 27770880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014773909 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.442       |\n",
      "|    mean_step_reward   | 0.35657448  |\n",
      "|    n_updates          | 13556       |\n",
      "|    policyGradLoss     | -0.00836    |\n",
      "|    value_loss         | 1.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 27779072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014274424 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.315       |\n",
      "|    mean_step_reward   | 0.3328655   |\n",
      "|    n_updates          | 13560       |\n",
      "|    policyGradLoss     | -0.00829    |\n",
      "|    value_loss         | 1.56        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 776          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 337          |\n",
      "|    total_timesteps    | 27787264     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0133122895 |\n",
      "|    entropy_loss       | -1.66        |\n",
      "|    explained_variance | 0.985        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.28         |\n",
      "|    mean_step_reward   | 0.37817043   |\n",
      "|    n_updates          | 13564        |\n",
      "|    policyGradLoss     | -0.00461     |\n",
      "|    value_loss         | 1.82         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_105.zip\n",
      "[EVAL] Mean Return: 528.445, Best Return: 536.445\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_105_528.45.mp4\n",
      "\n",
      "=== Round 107 | Learn 262144 steps (Total trained: 27787264) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1145     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 27795456 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 927         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 27803648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016413474 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.959       |\n",
      "|    mean_step_reward   | 0.42656383  |\n",
      "|    n_updates          | 13572       |\n",
      "|    policyGradLoss     | -0.0014     |\n",
      "|    value_loss         | 4.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 865         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 27811840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015125103 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.597       |\n",
      "|    mean_step_reward   | 0.37381288  |\n",
      "|    n_updates          | 13576       |\n",
      "|    policyGradLoss     | -0.0056     |\n",
      "|    value_loss         | 1.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 27820032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012628856 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.942       |\n",
      "|    mean_step_reward   | 0.36997986  |\n",
      "|    n_updates          | 13580       |\n",
      "|    policyGradLoss     | -0.00113    |\n",
      "|    value_loss         | 3.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 827         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 27828224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013760567 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.558       |\n",
      "|    mean_step_reward   | 0.36766478  |\n",
      "|    n_updates          | 13584       |\n",
      "|    policyGradLoss     | -0.00412    |\n",
      "|    value_loss         | 1.84        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 27836416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019300902 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.92        |\n",
      "|    mean_step_reward   | 0.37886205  |\n",
      "|    n_updates          | 13588       |\n",
      "|    policyGradLoss     | -0.00192    |\n",
      "|    value_loss         | 2.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 27844608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010669071 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.834       |\n",
      "|    mean_step_reward   | 0.39277643  |\n",
      "|    n_updates          | 13592       |\n",
      "|    policyGradLoss     | -0.00465    |\n",
      "|    value_loss         | 2.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 27852800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013689997 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.426       |\n",
      "|    mean_step_reward   | 0.40600985  |\n",
      "|    n_updates          | 13596       |\n",
      "|    policyGradLoss     | -0.00624    |\n",
      "|    value_loss         | 1.53        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 27860992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013083669 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.829       |\n",
      "|    mean_step_reward   | 0.39377308  |\n",
      "|    n_updates          | 13600       |\n",
      "|    policyGradLoss     | 0.000459    |\n",
      "|    value_loss         | 2.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 27869184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014477359 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.42        |\n",
      "|    mean_step_reward   | 0.38678142  |\n",
      "|    n_updates          | 13604       |\n",
      "|    policyGradLoss     | -0.00231    |\n",
      "|    value_loss         | 1.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 27877376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014275072 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.56        |\n",
      "|    mean_step_reward   | 0.44272983  |\n",
      "|    n_updates          | 13608       |\n",
      "|    policyGradLoss     | -0.00861    |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 27885568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013691789 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.454       |\n",
      "|    mean_step_reward   | 0.3620538   |\n",
      "|    n_updates          | 13612       |\n",
      "|    policyGradLoss     | -0.00223    |\n",
      "|    value_loss         | 2.12        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 789        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 134        |\n",
      "|    total_timesteps    | 27893760   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0181057  |\n",
      "|    entropy_loss       | -1.6       |\n",
      "|    explained_variance | 0.99       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.156      |\n",
      "|    mean_step_reward   | 0.41875958 |\n",
      "|    n_updates          | 13616      |\n",
      "|    policyGradLoss     | -0.0069    |\n",
      "|    value_loss         | 1.11       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 787        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 145        |\n",
      "|    total_timesteps    | 27901952   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01314307 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.975      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.718      |\n",
      "|    mean_step_reward   | 0.40877232 |\n",
      "|    n_updates          | 13620      |\n",
      "|    policyGradLoss     | -0.00173   |\n",
      "|    value_loss         | 2.93       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 27910144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013787741 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.587       |\n",
      "|    mean_step_reward   | 0.31539857  |\n",
      "|    n_updates          | 13624       |\n",
      "|    policyGradLoss     | -0.00412    |\n",
      "|    value_loss         | 1.75        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 27918336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017433578 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.178       |\n",
      "|    mean_step_reward   | 0.4034478   |\n",
      "|    n_updates          | 13628       |\n",
      "|    policyGradLoss     | -0.00778    |\n",
      "|    value_loss         | 1.04        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 27926528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016044887 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.846       |\n",
      "|    mean_step_reward   | 0.37186897  |\n",
      "|    n_updates          | 13632       |\n",
      "|    policyGradLoss     | -0.00659    |\n",
      "|    value_loss         | 1.98        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 27934720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012130115 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.696       |\n",
      "|    mean_step_reward   | 0.43656948  |\n",
      "|    n_updates          | 13636       |\n",
      "|    policyGradLoss     | -0.00262    |\n",
      "|    value_loss         | 2.5         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 783          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 198          |\n",
      "|    total_timesteps    | 27942912     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0073507465 |\n",
      "|    entropy_loss       | -1.68        |\n",
      "|    explained_variance | 0.988        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.61         |\n",
      "|    mean_step_reward   | 0.37745616   |\n",
      "|    n_updates          | 13640        |\n",
      "|    policyGradLoss     | -0.00449     |\n",
      "|    value_loss         | 1.81         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 27951104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017862879 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.101       |\n",
      "|    mean_step_reward   | 0.43930402  |\n",
      "|    n_updates          | 13644       |\n",
      "|    policyGradLoss     | -0.00799    |\n",
      "|    value_loss         | 1.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 27959296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009175441 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.336       |\n",
      "|    mean_step_reward   | 0.36128995  |\n",
      "|    n_updates          | 13648       |\n",
      "|    policyGradLoss     | -0.0037     |\n",
      "|    value_loss         | 2.45        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 27967488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014546341 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.942       |\n",
      "|    mean_step_reward   | 0.42062354  |\n",
      "|    n_updates          | 13652       |\n",
      "|    policyGradLoss     | -0.00488    |\n",
      "|    value_loss         | 1.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 27975680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010868388 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.363       |\n",
      "|    mean_step_reward   | 0.39950567  |\n",
      "|    n_updates          | 13656       |\n",
      "|    policyGradLoss     | 0.00221     |\n",
      "|    value_loss         | 3.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 27983872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013413751 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.436       |\n",
      "|    mean_step_reward   | 0.40293032  |\n",
      "|    n_updates          | 13660       |\n",
      "|    policyGradLoss     | -0.00728    |\n",
      "|    value_loss         | 1.82        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 27992064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011556618 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.194       |\n",
      "|    mean_step_reward   | 0.41841552  |\n",
      "|    n_updates          | 13664       |\n",
      "|    policyGradLoss     | -0.00913    |\n",
      "|    value_loss         | 1.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 28000256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009040889 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.799       |\n",
      "|    mean_step_reward   | 0.36645037  |\n",
      "|    n_updates          | 13668       |\n",
      "|    policyGradLoss     | -0.00589    |\n",
      "|    value_loss         | 1.5         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 28008448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015777778 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.392       |\n",
      "|    mean_step_reward   | 0.3748227   |\n",
      "|    n_updates          | 13672       |\n",
      "|    policyGradLoss     | -0.0073     |\n",
      "|    value_loss         | 1.64        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 777          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 295          |\n",
      "|    total_timesteps    | 28016640     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0108586745 |\n",
      "|    entropy_loss       | -1.65        |\n",
      "|    explained_variance | 0.961        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.953        |\n",
      "|    mean_step_reward   | 0.43865046   |\n",
      "|    n_updates          | 13676        |\n",
      "|    policyGradLoss     | -0.000866    |\n",
      "|    value_loss         | 2.74         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 28024832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018662775 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.353       |\n",
      "|    mean_step_reward   | 0.3754543   |\n",
      "|    n_updates          | 13680       |\n",
      "|    policyGradLoss     | 0.00357     |\n",
      "|    value_loss         | 2.43        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 28033024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012860539 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.149       |\n",
      "|    mean_step_reward   | 0.4288379   |\n",
      "|    n_updates          | 13684       |\n",
      "|    policyGradLoss     | -0.00614    |\n",
      "|    value_loss         | 1.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 28041216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013426978 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.818       |\n",
      "|    mean_step_reward   | 0.34651193  |\n",
      "|    n_updates          | 13688       |\n",
      "|    policyGradLoss     | -0.00121    |\n",
      "|    value_loss         | 2           |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 28049408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011098653 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.953       |\n",
      "|    mean_step_reward   | 0.35596177  |\n",
      "|    n_updates          | 13692       |\n",
      "|    policyGradLoss     | 4.83e-05    |\n",
      "|    value_loss         | 2.73        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_106.zip\n",
      "[EVAL] Mean Return: 530.047, Best Return: 537.380\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_106_530.05.mp4\n",
      "\n",
      "=== Round 108 | Learn 262144 steps (Total trained: 28049408) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1130     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 28057600 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 911         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 28065792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014688649 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.06        |\n",
      "|    mean_step_reward   | 0.39163053  |\n",
      "|    n_updates          | 13700       |\n",
      "|    policyGradLoss     | -0.00449    |\n",
      "|    value_loss         | 1.82        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 864         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 28073984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013335188 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.477       |\n",
      "|    mean_step_reward   | 0.4225276   |\n",
      "|    n_updates          | 13704       |\n",
      "|    policyGradLoss     | -0.00448    |\n",
      "|    value_loss         | 1.96        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 843        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 38         |\n",
      "|    total_timesteps    | 28082176   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01603856 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.257      |\n",
      "|    mean_step_reward   | 0.31553724 |\n",
      "|    n_updates          | 13708      |\n",
      "|    policyGradLoss     | -0.00539   |\n",
      "|    value_loss         | 1.41       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 827         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 28090368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014780079 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.689       |\n",
      "|    mean_step_reward   | 0.39438313  |\n",
      "|    n_updates          | 13712       |\n",
      "|    policyGradLoss     | -0.000417   |\n",
      "|    value_loss         | 2.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 28098560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011308443 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.898       |\n",
      "|    mean_step_reward   | 0.41848433  |\n",
      "|    n_updates          | 13716       |\n",
      "|    policyGradLoss     | -0.0073     |\n",
      "|    value_loss         | 1.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 28106752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015353812 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.446       |\n",
      "|    mean_step_reward   | 0.29868072  |\n",
      "|    n_updates          | 13720       |\n",
      "|    policyGradLoss     | -0.00865    |\n",
      "|    value_loss         | 0.846       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 809        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 80         |\n",
      "|    total_timesteps    | 28114944   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01349823 |\n",
      "|    entropy_loss       | -1.63      |\n",
      "|    explained_variance | 0.988      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.547      |\n",
      "|    mean_step_reward   | 0.4559238  |\n",
      "|    n_updates          | 13724      |\n",
      "|    policyGradLoss     | -0.0032    |\n",
      "|    value_loss         | 1.41       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 28123136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011227252 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.24        |\n",
      "|    mean_step_reward   | 0.384189    |\n",
      "|    n_updates          | 13728       |\n",
      "|    policyGradLoss     | -0.00616    |\n",
      "|    value_loss         | 1.95        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 28131328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011411697 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.866       |\n",
      "|    mean_step_reward   | 0.40828788  |\n",
      "|    n_updates          | 13732       |\n",
      "|    policyGradLoss     | -0.00508    |\n",
      "|    value_loss         | 1.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 112         |\n",
      "|    total_timesteps    | 28139520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010777614 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.185       |\n",
      "|    mean_step_reward   | 0.38946527  |\n",
      "|    n_updates          | 13736       |\n",
      "|    policyGradLoss     | -0.00755    |\n",
      "|    value_loss         | 1.89        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 28147712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015431276 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.538       |\n",
      "|    mean_step_reward   | 0.38056654  |\n",
      "|    n_updates          | 13740       |\n",
      "|    policyGradLoss     | -0.00619    |\n",
      "|    value_loss         | 1.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 133         |\n",
      "|    total_timesteps    | 28155904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013588551 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.813       |\n",
      "|    mean_step_reward   | 0.40406832  |\n",
      "|    n_updates          | 13744       |\n",
      "|    policyGradLoss     | 0.00126     |\n",
      "|    value_loss         | 1.87        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 795          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 144          |\n",
      "|    total_timesteps    | 28164096     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0071162335 |\n",
      "|    entropy_loss       | -1.65        |\n",
      "|    explained_variance | 0.989        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.12         |\n",
      "|    mean_step_reward   | 0.41997695   |\n",
      "|    n_updates          | 13748        |\n",
      "|    policyGradLoss     | -0.0038      |\n",
      "|    value_loss         | 1.77         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 796        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 154        |\n",
      "|    total_timesteps    | 28172288   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01084423 |\n",
      "|    entropy_loss       | -1.63      |\n",
      "|    explained_variance | 0.992      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.718      |\n",
      "|    mean_step_reward   | 0.42977694 |\n",
      "|    n_updates          | 13752      |\n",
      "|    policyGradLoss     | -0.00474   |\n",
      "|    value_loss         | 1.34       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 28180480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011099096 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.405       |\n",
      "|    mean_step_reward   | 0.3942548   |\n",
      "|    n_updates          | 13756       |\n",
      "|    policyGradLoss     | -0.00502    |\n",
      "|    value_loss         | 1.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 175         |\n",
      "|    total_timesteps    | 28188672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010402765 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.562       |\n",
      "|    mean_step_reward   | 0.39693147  |\n",
      "|    n_updates          | 13760       |\n",
      "|    policyGradLoss     | -0.00462    |\n",
      "|    value_loss         | 1.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 186         |\n",
      "|    total_timesteps    | 28196864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010223882 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.14        |\n",
      "|    mean_step_reward   | 0.46619707  |\n",
      "|    n_updates          | 13764       |\n",
      "|    policyGradLoss     | -0.00476    |\n",
      "|    value_loss         | 1.25        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 789          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 197          |\n",
      "|    total_timesteps    | 28205056     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0088669835 |\n",
      "|    entropy_loss       | -1.67        |\n",
      "|    explained_variance | 0.984        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.53         |\n",
      "|    mean_step_reward   | 0.39792597   |\n",
      "|    n_updates          | 13768        |\n",
      "|    policyGradLoss     | -0.00161     |\n",
      "|    value_loss         | 2.58         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 789          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 207          |\n",
      "|    total_timesteps    | 28213248     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0109454505 |\n",
      "|    entropy_loss       | -1.65        |\n",
      "|    explained_variance | 0.991        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.346        |\n",
      "|    mean_step_reward   | 0.39205867   |\n",
      "|    n_updates          | 13772        |\n",
      "|    policyGradLoss     | -0.00707     |\n",
      "|    value_loss         | 1.28         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 218         |\n",
      "|    total_timesteps    | 28221440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012007856 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.285       |\n",
      "|    mean_step_reward   | 0.41924733  |\n",
      "|    n_updates          | 13776       |\n",
      "|    policyGradLoss     | -0.00846    |\n",
      "|    value_loss         | 1.16        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 786          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 229          |\n",
      "|    total_timesteps    | 28229632     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0125400005 |\n",
      "|    entropy_loss       | -1.71        |\n",
      "|    explained_variance | 0.94         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.897        |\n",
      "|    mean_step_reward   | 0.34055388   |\n",
      "|    n_updates          | 13780        |\n",
      "|    policyGradLoss     | -0.00222     |\n",
      "|    value_loss         | 4.17         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 239         |\n",
      "|    total_timesteps    | 28237824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014877801 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.405       |\n",
      "|    mean_step_reward   | 0.44900817  |\n",
      "|    n_updates          | 13784       |\n",
      "|    policyGradLoss     | 0.00357     |\n",
      "|    value_loss         | 1.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 250         |\n",
      "|    total_timesteps    | 28246016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010532421 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.926       |\n",
      "|    mean_step_reward   | 0.38200608  |\n",
      "|    n_updates          | 13788       |\n",
      "|    policyGradLoss     | -0.00371    |\n",
      "|    value_loss         | 2.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 28254208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015851334 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.485       |\n",
      "|    mean_step_reward   | 0.3374141   |\n",
      "|    n_updates          | 13792       |\n",
      "|    policyGradLoss     | -0.00173    |\n",
      "|    value_loss         | 1.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 28262400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011538276 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.295       |\n",
      "|    mean_step_reward   | 0.44903117  |\n",
      "|    n_updates          | 13796       |\n",
      "|    policyGradLoss     | -0.000671   |\n",
      "|    value_loss         | 2.81        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 28270592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009851565 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.92        |\n",
      "|    mean_step_reward   | 0.30712575  |\n",
      "|    n_updates          | 13800       |\n",
      "|    policyGradLoss     | -0.00207    |\n",
      "|    value_loss         | 2.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 28278784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015257176 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.55        |\n",
      "|    mean_step_reward   | 0.42495567  |\n",
      "|    n_updates          | 13804       |\n",
      "|    policyGradLoss     | 0.00388     |\n",
      "|    value_loss         | 2.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 28286976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010446785 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.28        |\n",
      "|    mean_step_reward   | 0.31113085  |\n",
      "|    n_updates          | 13808       |\n",
      "|    policyGradLoss     | 0.000124    |\n",
      "|    value_loss         | 2.99        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 28295168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019693788 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.654       |\n",
      "|    mean_step_reward   | 0.376633    |\n",
      "|    n_updates          | 13812       |\n",
      "|    policyGradLoss     | -0.00535    |\n",
      "|    value_loss         | 1.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 28303360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013339369 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.192       |\n",
      "|    mean_step_reward   | 0.38586736  |\n",
      "|    n_updates          | 13816       |\n",
      "|    policyGradLoss     | -0.00838    |\n",
      "|    value_loss         | 0.991       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 28311552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011604678 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.855       |\n",
      "|    mean_step_reward   | 0.3613153   |\n",
      "|    n_updates          | 13820       |\n",
      "|    policyGradLoss     | -0.00409    |\n",
      "|    value_loss         | 1.89        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_107.zip\n",
      "[EVAL] Mean Return: 529.899, Best Return: 536.565\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_107_529.90.mp4\n",
      "\n",
      "=== Round 109 | Learn 262144 steps (Total trained: 28311552) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1128     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 28319744 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 923         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 28327936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011783546 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.495       |\n",
      "|    mean_step_reward   | 0.31036466  |\n",
      "|    n_updates          | 13828       |\n",
      "|    policyGradLoss     | -0.00808    |\n",
      "|    value_loss         | 1.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 873         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 28336128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011312143 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 4.11        |\n",
      "|    mean_step_reward   | 0.47794852  |\n",
      "|    n_updates          | 13832       |\n",
      "|    policyGradLoss     | 0.00112     |\n",
      "|    value_loss         | 6.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 833         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 28344320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009966908 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.02        |\n",
      "|    mean_step_reward   | 0.3793072   |\n",
      "|    n_updates          | 13836       |\n",
      "|    policyGradLoss     | -0.00128    |\n",
      "|    value_loss         | 2.9         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 28352512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013108578 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.481       |\n",
      "|    mean_step_reward   | 0.33995432  |\n",
      "|    n_updates          | 13840       |\n",
      "|    policyGradLoss     | -0.00732    |\n",
      "|    value_loss         | 1.68        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 811          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 60           |\n",
      "|    total_timesteps    | 28360704     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0103953425 |\n",
      "|    entropy_loss       | -1.67        |\n",
      "|    explained_variance | 0.989        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.335        |\n",
      "|    mean_step_reward   | 0.4007813    |\n",
      "|    n_updates          | 13844        |\n",
      "|    policyGradLoss     | -0.00714     |\n",
      "|    value_loss         | 0.945        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 28368896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015414266 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.32        |\n",
      "|    mean_step_reward   | 0.36783594  |\n",
      "|    n_updates          | 13848       |\n",
      "|    policyGradLoss     | -0.00554    |\n",
      "|    value_loss         | 2.39        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 801        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 81         |\n",
      "|    total_timesteps    | 28377088   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01434138 |\n",
      "|    entropy_loss       | -1.65      |\n",
      "|    explained_variance | 0.959      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.59       |\n",
      "|    mean_step_reward   | 0.39414912 |\n",
      "|    n_updates          | 13852      |\n",
      "|    policyGradLoss     | -0.00289   |\n",
      "|    value_loss         | 4.69       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 28385280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015541768 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.281       |\n",
      "|    mean_step_reward   | 0.4205484   |\n",
      "|    n_updates          | 13856       |\n",
      "|    policyGradLoss     | -0.00556    |\n",
      "|    value_loss         | 1.76        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 28393472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010712439 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.497       |\n",
      "|    mean_step_reward   | 0.38275605  |\n",
      "|    n_updates          | 13860       |\n",
      "|    policyGradLoss     | -0.00465    |\n",
      "|    value_loss         | 1.59        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 797        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 113        |\n",
      "|    total_timesteps    | 28401664   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01141878 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.988      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.459      |\n",
      "|    mean_step_reward   | 0.37742984 |\n",
      "|    n_updates          | 13864      |\n",
      "|    policyGradLoss     | -0.00649   |\n",
      "|    value_loss         | 1.58       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 28409856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011234899 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.47        |\n",
      "|    mean_step_reward   | 0.40742642  |\n",
      "|    n_updates          | 13868       |\n",
      "|    policyGradLoss     | -0.00693    |\n",
      "|    value_loss         | 1.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 28418048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011873486 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.743       |\n",
      "|    mean_step_reward   | 0.41298383  |\n",
      "|    n_updates          | 13872       |\n",
      "|    policyGradLoss     | -0.00529    |\n",
      "|    value_loss         | 1.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 28426240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009466452 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.343       |\n",
      "|    mean_step_reward   | 0.37308472  |\n",
      "|    n_updates          | 13876       |\n",
      "|    policyGradLoss     | -0.00529    |\n",
      "|    value_loss         | 1.86        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 28434432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011247563 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.467       |\n",
      "|    mean_step_reward   | 0.395028    |\n",
      "|    n_updates          | 13880       |\n",
      "|    policyGradLoss     | -0.00446    |\n",
      "|    value_loss         | 1.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 28442624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010554581 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.387       |\n",
      "|    mean_step_reward   | 0.37950522  |\n",
      "|    n_updates          | 13884       |\n",
      "|    policyGradLoss     | -0.00716    |\n",
      "|    value_loss         | 1.4         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 784        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 177        |\n",
      "|    total_timesteps    | 28450816   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00938837 |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.99       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.332      |\n",
      "|    mean_step_reward   | 0.44190234 |\n",
      "|    n_updates          | 13888      |\n",
      "|    policyGradLoss     | -0.00659   |\n",
      "|    value_loss         | 1.72       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 28459008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013511293 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.02        |\n",
      "|    mean_step_reward   | 0.35392326  |\n",
      "|    n_updates          | 13892       |\n",
      "|    policyGradLoss     | -0.0025     |\n",
      "|    value_loss         | 4.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 28467200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010901365 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.313       |\n",
      "|    mean_step_reward   | 0.42518046  |\n",
      "|    n_updates          | 13896       |\n",
      "|    policyGradLoss     | -0.00305    |\n",
      "|    value_loss         | 1.34        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 28475392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013648773 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.599       |\n",
      "|    mean_step_reward   | 0.40899438  |\n",
      "|    n_updates          | 13900       |\n",
      "|    policyGradLoss     | -0.0068     |\n",
      "|    value_loss         | 1.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 28483584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016146425 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.572       |\n",
      "|    mean_step_reward   | 0.3815031   |\n",
      "|    n_updates          | 13904       |\n",
      "|    policyGradLoss     | -0.00633    |\n",
      "|    value_loss         | 1.65        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 783        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 230        |\n",
      "|    total_timesteps    | 28491776   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01594487 |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.416      |\n",
      "|    mean_step_reward   | 0.3962029  |\n",
      "|    n_updates          | 13908      |\n",
      "|    policyGradLoss     | -0.00725   |\n",
      "|    value_loss         | 1.07       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 28499968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011476679 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.759       |\n",
      "|    mean_step_reward   | 0.35924375  |\n",
      "|    n_updates          | 13912       |\n",
      "|    policyGradLoss     | -0.00501    |\n",
      "|    value_loss         | 2.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 28508160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014882145 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.33        |\n",
      "|    mean_step_reward   | 0.36597627  |\n",
      "|    n_updates          | 13916       |\n",
      "|    policyGradLoss     | -0.00598    |\n",
      "|    value_loss         | 1.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 28516352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017238216 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.359       |\n",
      "|    mean_step_reward   | 0.3787224   |\n",
      "|    n_updates          | 13920       |\n",
      "|    policyGradLoss     | -0.00633    |\n",
      "|    value_loss         | 1.72        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 28524544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016801089 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.817       |\n",
      "|    mean_step_reward   | 0.37142313  |\n",
      "|    n_updates          | 13924       |\n",
      "|    policyGradLoss     | -0.0064     |\n",
      "|    value_loss         | 2.6         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 283        |\n",
      "|    total_timesteps    | 28532736   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0146576  |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.99       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.375      |\n",
      "|    mean_step_reward   | 0.39628303 |\n",
      "|    n_updates          | 13928      |\n",
      "|    policyGradLoss     | -0.00814   |\n",
      "|    value_loss         | 1.19       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 778          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 294          |\n",
      "|    total_timesteps    | 28540928     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0093859155 |\n",
      "|    entropy_loss       | -1.66        |\n",
      "|    explained_variance | 0.977        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.23         |\n",
      "|    mean_step_reward   | 0.3980491    |\n",
      "|    n_updates          | 13932        |\n",
      "|    policyGradLoss     | -0.00208     |\n",
      "|    value_loss         | 2.71         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 304        |\n",
      "|    total_timesteps    | 28549120   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01608704 |\n",
      "|    entropy_loss       | -1.6       |\n",
      "|    explained_variance | 0.976      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.481      |\n",
      "|    mean_step_reward   | 0.44976178 |\n",
      "|    n_updates          | 13936      |\n",
      "|    policyGradLoss     | -0.00201   |\n",
      "|    value_loss         | 2.33       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 28557312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009641734 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.64        |\n",
      "|    mean_step_reward   | 0.39153996  |\n",
      "|    n_updates          | 13940       |\n",
      "|    policyGradLoss     | -0.00458    |\n",
      "|    value_loss         | 1.94        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 28565504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014202148 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.314       |\n",
      "|    mean_step_reward   | 0.4178373   |\n",
      "|    n_updates          | 13944       |\n",
      "|    policyGradLoss     | -0.00357    |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 28573696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011552352 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.285       |\n",
      "|    mean_step_reward   | 0.4205007   |\n",
      "|    n_updates          | 13948       |\n",
      "|    policyGradLoss     | -0.0083     |\n",
      "|    value_loss         | 1.03        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_108.zip\n",
      "[EVAL] Mean Return: 530.938, Best Return: 535.605\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_108_530.94.mp4\n",
      "\n",
      "=== Round 110 | Learn 262144 steps (Total trained: 28573696) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1124     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 28581888 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 910         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 28590080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017042223 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.298       |\n",
      "|    mean_step_reward   | 0.42622697  |\n",
      "|    n_updates          | 13956       |\n",
      "|    policyGradLoss     | -0.00782    |\n",
      "|    value_loss         | 1.21        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 866          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 28598272     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0141472295 |\n",
      "|    entropy_loss       | -1.71        |\n",
      "|    explained_variance | 0.985        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.271        |\n",
      "|    mean_step_reward   | 0.32324046   |\n",
      "|    n_updates          | 13960        |\n",
      "|    policyGradLoss     | -0.00485     |\n",
      "|    value_loss         | 1.58         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 28606464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013814354 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.4         |\n",
      "|    mean_step_reward   | 0.4138585   |\n",
      "|    n_updates          | 13964       |\n",
      "|    policyGradLoss     | -0.00105    |\n",
      "|    value_loss         | 3.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 28614656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012698014 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.496       |\n",
      "|    mean_step_reward   | 0.37615097  |\n",
      "|    n_updates          | 13968       |\n",
      "|    policyGradLoss     | -0.0076     |\n",
      "|    value_loss         | 1.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 28622848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012996499 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.396       |\n",
      "|    mean_step_reward   | 0.39309222  |\n",
      "|    n_updates          | 13972       |\n",
      "|    policyGradLoss     | -0.00619    |\n",
      "|    value_loss         | 1.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 28631040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010926267 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.583       |\n",
      "|    mean_step_reward   | 0.47623143  |\n",
      "|    n_updates          | 13976       |\n",
      "|    policyGradLoss     | -0.00204    |\n",
      "|    value_loss         | 5.04        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 28639232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010656353 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.537       |\n",
      "|    mean_step_reward   | 0.3373844   |\n",
      "|    n_updates          | 13980       |\n",
      "|    policyGradLoss     | -0.00698    |\n",
      "|    value_loss         | 1.52        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 28647424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011785079 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.527       |\n",
      "|    mean_step_reward   | 0.4086696   |\n",
      "|    n_updates          | 13984       |\n",
      "|    policyGradLoss     | -0.004      |\n",
      "|    value_loss         | 1.49        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 792        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 103        |\n",
      "|    total_timesteps    | 28655616   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0159253  |\n",
      "|    entropy_loss       | -1.66      |\n",
      "|    explained_variance | 0.992      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.828      |\n",
      "|    mean_step_reward   | 0.42741916 |\n",
      "|    n_updates          | 13988      |\n",
      "|    policyGradLoss     | -0.00591   |\n",
      "|    value_loss         | 1.43       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 28663808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016244179 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.3         |\n",
      "|    mean_step_reward   | 0.33515018  |\n",
      "|    n_updates          | 13992       |\n",
      "|    policyGradLoss     | -0.00875    |\n",
      "|    value_loss         | 1.34        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 28672000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013265436 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0988      |\n",
      "|    mean_step_reward   | 0.4232357   |\n",
      "|    n_updates          | 13996       |\n",
      "|    policyGradLoss     | -0.011      |\n",
      "|    value_loss         | 0.769       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 28680192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010597168 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.669       |\n",
      "|    mean_step_reward   | 0.36021936  |\n",
      "|    n_updates          | 14000       |\n",
      "|    policyGradLoss     | -0.00165    |\n",
      "|    value_loss         | 2.98        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 28688384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011104301 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.487       |\n",
      "|    mean_step_reward   | 0.44214222  |\n",
      "|    n_updates          | 14004       |\n",
      "|    policyGradLoss     | -0.00179    |\n",
      "|    value_loss         | 2.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 28696576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013674254 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.415       |\n",
      "|    mean_step_reward   | 0.3652693   |\n",
      "|    n_updates          | 14008       |\n",
      "|    policyGradLoss     | -0.00341    |\n",
      "|    value_loss         | 1.84        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 28704768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012242472 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.442       |\n",
      "|    mean_step_reward   | 0.38002914  |\n",
      "|    n_updates          | 14012       |\n",
      "|    policyGradLoss     | -0.00461    |\n",
      "|    value_loss         | 1.97        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 28712960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012162535 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.946       |\n",
      "|    mean_step_reward   | 0.40188253  |\n",
      "|    n_updates          | 14016       |\n",
      "|    policyGradLoss     | -0.0056     |\n",
      "|    value_loss         | 1.88        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 28721152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010451635 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.11        |\n",
      "|    mean_step_reward   | 0.41518274  |\n",
      "|    n_updates          | 14020       |\n",
      "|    policyGradLoss     | -0.00159    |\n",
      "|    value_loss         | 1.97        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 28729344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011486249 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.46        |\n",
      "|    mean_step_reward   | 0.40519285  |\n",
      "|    n_updates          | 14024       |\n",
      "|    policyGradLoss     | -0.00377    |\n",
      "|    value_loss         | 1.82        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 28737536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014233545 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.706       |\n",
      "|    mean_step_reward   | 0.39072686  |\n",
      "|    n_updates          | 14028       |\n",
      "|    policyGradLoss     | -0.00213    |\n",
      "|    value_loss         | 1.72        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 28745728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011873482 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.442       |\n",
      "|    mean_step_reward   | 0.4116886   |\n",
      "|    n_updates          | 14032       |\n",
      "|    policyGradLoss     | -0.00473    |\n",
      "|    value_loss         | 1.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 28753920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015365236 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.175       |\n",
      "|    mean_step_reward   | 0.420109    |\n",
      "|    n_updates          | 14036       |\n",
      "|    policyGradLoss     | -0.00602    |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 28762112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010474147 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.473       |\n",
      "|    mean_step_reward   | 0.4166581   |\n",
      "|    n_updates          | 14040       |\n",
      "|    policyGradLoss     | -0.00485    |\n",
      "|    value_loss         | 1.52        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 28770304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012409382 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.443       |\n",
      "|    mean_step_reward   | 0.34939507  |\n",
      "|    n_updates          | 14044       |\n",
      "|    policyGradLoss     | -0.00536    |\n",
      "|    value_loss         | 1.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 28778496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015960831 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0369      |\n",
      "|    mean_step_reward   | 0.4488781   |\n",
      "|    n_updates          | 14048       |\n",
      "|    policyGradLoss     | -0.00538    |\n",
      "|    value_loss         | 0.961       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 28786688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015378236 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.37        |\n",
      "|    mean_step_reward   | 0.37351173  |\n",
      "|    n_updates          | 14052       |\n",
      "|    policyGradLoss     | 0.00188     |\n",
      "|    value_loss         | 4.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 28794880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021232734 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.215       |\n",
      "|    mean_step_reward   | 0.41968194  |\n",
      "|    n_updates          | 14056       |\n",
      "|    policyGradLoss     | -0.0026     |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 777          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 294          |\n",
      "|    total_timesteps    | 28803072     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0105820475 |\n",
      "|    entropy_loss       | -1.68        |\n",
      "|    explained_variance | 0.971        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.467        |\n",
      "|    mean_step_reward   | 0.34509176   |\n",
      "|    n_updates          | 14060        |\n",
      "|    policyGradLoss     | -0.00196     |\n",
      "|    value_loss         | 1.89         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 28811264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014073764 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.373       |\n",
      "|    mean_step_reward   | 0.36790034  |\n",
      "|    n_updates          | 14064       |\n",
      "|    policyGradLoss     | -0.00103    |\n",
      "|    value_loss         | 1.29        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 776        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 316        |\n",
      "|    total_timesteps    | 28819456   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01717731 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.954      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.489      |\n",
      "|    mean_step_reward   | 0.37136886 |\n",
      "|    n_updates          | 14068      |\n",
      "|    policyGradLoss     | -0.00104   |\n",
      "|    value_loss         | 4.49       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 28827648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014744924 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.563       |\n",
      "|    mean_step_reward   | 0.30793577  |\n",
      "|    n_updates          | 14072       |\n",
      "|    policyGradLoss     | -0.00674    |\n",
      "|    value_loss         | 1.72        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 28835840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017342698 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.871       |\n",
      "|    mean_step_reward   | 0.33269     |\n",
      "|    n_updates          | 14076       |\n",
      "|    policyGradLoss     | -0.00516    |\n",
      "|    value_loss         | 2.32        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_109.zip\n",
      "[EVAL] Mean Return: 534.036, Best Return: 540.703\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_109_534.04.mp4\n",
      "\n",
      "=== Round 111 | Learn 262144 steps (Total trained: 28835840) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1080     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 28844032 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 906         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 28852224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014124439 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.402       |\n",
      "|    mean_step_reward   | 0.38799384  |\n",
      "|    n_updates          | 14084       |\n",
      "|    policyGradLoss     | -0.00103    |\n",
      "|    value_loss         | 3.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 856         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 28860416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011192469 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.642       |\n",
      "|    mean_step_reward   | 0.3853342   |\n",
      "|    n_updates          | 14088       |\n",
      "|    policyGradLoss     | -0.0024     |\n",
      "|    value_loss         | 2.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 832         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 28868608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012078617 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.422       |\n",
      "|    mean_step_reward   | 0.3300222   |\n",
      "|    n_updates          | 14092       |\n",
      "|    policyGradLoss     | -0.0043     |\n",
      "|    value_loss         | 2.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 28876800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013306856 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.45        |\n",
      "|    mean_step_reward   | 0.41007057  |\n",
      "|    n_updates          | 14096       |\n",
      "|    policyGradLoss     | -0.00211    |\n",
      "|    value_loss         | 1.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 28884992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015924275 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.848       |\n",
      "|    mean_step_reward   | 0.3383195   |\n",
      "|    n_updates          | 14100       |\n",
      "|    policyGradLoss     | -0.00897    |\n",
      "|    value_loss         | 1.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 28893184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016577888 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.389       |\n",
      "|    mean_step_reward   | 0.39341888  |\n",
      "|    n_updates          | 14104       |\n",
      "|    policyGradLoss     | 0.00276     |\n",
      "|    value_loss         | 2.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 28901376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011269574 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.49        |\n",
      "|    mean_step_reward   | 0.2919579   |\n",
      "|    n_updates          | 14108       |\n",
      "|    policyGradLoss     | 0.00226     |\n",
      "|    value_loss         | 3.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 28909568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014308622 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.394       |\n",
      "|    mean_step_reward   | 0.35621116  |\n",
      "|    n_updates          | 14112       |\n",
      "|    policyGradLoss     | -0.00409    |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 28917760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015210745 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.158       |\n",
      "|    mean_step_reward   | 0.3522458   |\n",
      "|    n_updates          | 14116       |\n",
      "|    policyGradLoss     | -0.00602    |\n",
      "|    value_loss         | 0.935       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 28925952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010514995 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.43        |\n",
      "|    mean_step_reward   | 0.35556996  |\n",
      "|    n_updates          | 14120       |\n",
      "|    policyGradLoss     | -0.00137    |\n",
      "|    value_loss         | 2.31        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 789        |\n",
      "|    iterations         | 12         |\n",
      "|    time_elapsed       | 124        |\n",
      "|    total_timesteps    | 28934144   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01485012 |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.461      |\n",
      "|    mean_step_reward   | 0.41508996 |\n",
      "|    n_updates          | 14124      |\n",
      "|    policyGradLoss     | -0.0059    |\n",
      "|    value_loss         | 1.24       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 28942336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010367308 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.408       |\n",
      "|    mean_step_reward   | 0.38969868  |\n",
      "|    n_updates          | 14128       |\n",
      "|    policyGradLoss     | -0.00267    |\n",
      "|    value_loss         | 2.9         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 787          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 145          |\n",
      "|    total_timesteps    | 28950528     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0145817585 |\n",
      "|    entropy_loss       | -1.68        |\n",
      "|    explained_variance | 0.957        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.464        |\n",
      "|    mean_step_reward   | 0.37097186   |\n",
      "|    n_updates          | 14132        |\n",
      "|    policyGradLoss     | 0.00473      |\n",
      "|    value_loss         | 2.82         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 28958720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014065991 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.628       |\n",
      "|    mean_step_reward   | 0.35924044  |\n",
      "|    n_updates          | 14136       |\n",
      "|    policyGradLoss     | -0.00423    |\n",
      "|    value_loss         | 2.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 28966912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015023867 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.925       |\n",
      "|    mean_step_reward   | 0.35045946  |\n",
      "|    n_updates          | 14140       |\n",
      "|    policyGradLoss     | 0.00235     |\n",
      "|    value_loss         | 3.5         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 28975104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012424758 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.998       |\n",
      "|    mean_step_reward   | 0.38501805  |\n",
      "|    n_updates          | 14144       |\n",
      "|    policyGradLoss     | -0.00127    |\n",
      "|    value_loss         | 2.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 28983296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010983381 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.363       |\n",
      "|    mean_step_reward   | 0.286214    |\n",
      "|    n_updates          | 14148       |\n",
      "|    policyGradLoss     | -0.00504    |\n",
      "|    value_loss         | 2.09        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 28991488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010216334 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.289       |\n",
      "|    mean_step_reward   | 0.35635716  |\n",
      "|    n_updates          | 14152       |\n",
      "|    policyGradLoss     | -0.00774    |\n",
      "|    value_loss         | 1.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 28999680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012102151 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.12        |\n",
      "|    mean_step_reward   | 0.35932663  |\n",
      "|    n_updates          | 14156       |\n",
      "|    policyGradLoss     | 0.000643    |\n",
      "|    value_loss         | 5.94        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 29007872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012835447 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.553       |\n",
      "|    mean_step_reward   | 0.42650113  |\n",
      "|    n_updates          | 14160       |\n",
      "|    policyGradLoss     | 0.0021      |\n",
      "|    value_loss         | 2.33        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 781          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 230          |\n",
      "|    total_timesteps    | 29016064     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0119120255 |\n",
      "|    entropy_loss       | -1.72        |\n",
      "|    explained_variance | 0.983        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.255        |\n",
      "|    mean_step_reward   | 0.41785663   |\n",
      "|    n_updates          | 14164        |\n",
      "|    policyGradLoss     | -0.00504     |\n",
      "|    value_loss         | 2.09         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 29024256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012896274 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.898       |\n",
      "|    mean_step_reward   | 0.39168048  |\n",
      "|    n_updates          | 14168       |\n",
      "|    policyGradLoss     | -0.00564    |\n",
      "|    value_loss         | 2.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 29032448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010299896 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.648       |\n",
      "|    mean_step_reward   | 0.350439    |\n",
      "|    n_updates          | 14172       |\n",
      "|    policyGradLoss     | 0.00058     |\n",
      "|    value_loss         | 2.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 29040640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011774577 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.489       |\n",
      "|    mean_step_reward   | 0.37396717  |\n",
      "|    n_updates          | 14176       |\n",
      "|    policyGradLoss     | -0.00751    |\n",
      "|    value_loss         | 1.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 29048832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012283058 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.795       |\n",
      "|    mean_step_reward   | 0.41400343  |\n",
      "|    n_updates          | 14180       |\n",
      "|    policyGradLoss     | -0.00534    |\n",
      "|    value_loss         | 1.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 29057024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010546123 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.13        |\n",
      "|    mean_step_reward   | 0.42349014  |\n",
      "|    n_updates          | 14184       |\n",
      "|    policyGradLoss     | -0.00444    |\n",
      "|    value_loss         | 2.43        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 29065216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009988874 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.727       |\n",
      "|    mean_step_reward   | 0.38165402  |\n",
      "|    n_updates          | 14188       |\n",
      "|    policyGradLoss     | -0.000333   |\n",
      "|    value_loss         | 4.07        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 29073408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013847811 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.622       |\n",
      "|    mean_step_reward   | 0.38446006  |\n",
      "|    n_updates          | 14192       |\n",
      "|    policyGradLoss     | -0.00557    |\n",
      "|    value_loss         | 1.97        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 29081600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012718266 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.03        |\n",
      "|    mean_step_reward   | 0.36381215  |\n",
      "|    n_updates          | 14196       |\n",
      "|    policyGradLoss     | -0.00272    |\n",
      "|    value_loss         | 2.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 29089792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009721797 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.49        |\n",
      "|    mean_step_reward   | 0.3969205   |\n",
      "|    n_updates          | 14200       |\n",
      "|    policyGradLoss     | -0.00193    |\n",
      "|    value_loss         | 2.45        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 29097984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019533902 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.613       |\n",
      "|    mean_step_reward   | 0.3569662   |\n",
      "|    n_updates          | 14204       |\n",
      "|    policyGradLoss     | -0.00473    |\n",
      "|    value_loss         | 1.8         |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_110.zip\n",
      "[EVAL] Mean Return: 407.349, Best Return: 413.349\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_110_407.35.mp4\n",
      "\n",
      "=== Round 112 | Learn 262144 steps (Total trained: 29097984) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1111     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 29106176 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 921         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 29114368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013392907 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.19        |\n",
      "|    mean_step_reward   | 0.40577537  |\n",
      "|    n_updates          | 14212       |\n",
      "|    policyGradLoss     | -0.00844    |\n",
      "|    value_loss         | 1.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 863         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 29122560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007283003 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.43        |\n",
      "|    mean_step_reward   | 0.4133923   |\n",
      "|    n_updates          | 14216       |\n",
      "|    policyGradLoss     | -0.00104    |\n",
      "|    value_loss         | 2.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 833         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 29130752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011460108 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.24        |\n",
      "|    mean_step_reward   | 0.43863416  |\n",
      "|    n_updates          | 14220       |\n",
      "|    policyGradLoss     | -0.00334    |\n",
      "|    value_loss         | 1.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 29138944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008896621 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.907       |\n",
      "|    mean_step_reward   | 0.38282102  |\n",
      "|    n_updates          | 14224       |\n",
      "|    policyGradLoss     | -0.00187    |\n",
      "|    value_loss         | 2.64        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 29147136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011291517 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.351       |\n",
      "|    mean_step_reward   | 0.33297354  |\n",
      "|    n_updates          | 14228       |\n",
      "|    policyGradLoss     | -0.000563   |\n",
      "|    value_loss         | 2.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 29155328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012813613 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.442       |\n",
      "|    mean_step_reward   | 0.36440834  |\n",
      "|    n_updates          | 14232       |\n",
      "|    policyGradLoss     | -0.000972   |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 29163520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015942786 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.764       |\n",
      "|    mean_step_reward   | 0.34824252  |\n",
      "|    n_updates          | 14236       |\n",
      "|    policyGradLoss     | 0.00386     |\n",
      "|    value_loss         | 5.61        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 793        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 92         |\n",
      "|    total_timesteps    | 29171712   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0166793  |\n",
      "|    entropy_loss       | -1.66      |\n",
      "|    explained_variance | 0.945      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.01       |\n",
      "|    mean_step_reward   | 0.44122064 |\n",
      "|    n_updates          | 14240      |\n",
      "|    policyGradLoss     | 0.00248    |\n",
      "|    value_loss         | 4.44       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 29179904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009295654 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.84        |\n",
      "|    mean_step_reward   | 0.37769407  |\n",
      "|    n_updates          | 14244       |\n",
      "|    policyGradLoss     | -0.000211   |\n",
      "|    value_loss         | 3.33        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 788        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 114        |\n",
      "|    total_timesteps    | 29188096   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01045349 |\n",
      "|    entropy_loss       | -1.65      |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.248      |\n",
      "|    mean_step_reward   | 0.3590399  |\n",
      "|    n_updates          | 14248      |\n",
      "|    policyGradLoss     | -0.00364   |\n",
      "|    value_loss         | 1.5        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 29196288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016283749 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.395       |\n",
      "|    mean_step_reward   | 0.4336879   |\n",
      "|    n_updates          | 14252       |\n",
      "|    policyGradLoss     | -0.00304    |\n",
      "|    value_loss         | 1.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 29204480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015351134 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.01        |\n",
      "|    mean_step_reward   | 0.43220553  |\n",
      "|    n_updates          | 14256       |\n",
      "|    policyGradLoss     | 0.000706    |\n",
      "|    value_loss         | 2.46        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 29212672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011850495 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.367       |\n",
      "|    mean_step_reward   | 0.4246599   |\n",
      "|    n_updates          | 14260       |\n",
      "|    policyGradLoss     | -0.01       |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 29220864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009343527 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.45        |\n",
      "|    mean_step_reward   | 0.35854766  |\n",
      "|    n_updates          | 14264       |\n",
      "|    policyGradLoss     | -0.00442    |\n",
      "|    value_loss         | 2.07        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 29229056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011894874 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.139       |\n",
      "|    mean_step_reward   | 0.40048593  |\n",
      "|    n_updates          | 14268       |\n",
      "|    policyGradLoss     | -0.00537    |\n",
      "|    value_loss         | 1.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 29237248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009496776 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.193       |\n",
      "|    mean_step_reward   | 0.3989907   |\n",
      "|    n_updates          | 14272       |\n",
      "|    policyGradLoss     | -0.00557    |\n",
      "|    value_loss         | 1.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 29245440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010005939 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.752       |\n",
      "|    mean_step_reward   | 0.3883581   |\n",
      "|    n_updates          | 14276       |\n",
      "|    policyGradLoss     | 0.00162     |\n",
      "|    value_loss         | 2.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 29253632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013368219 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.312       |\n",
      "|    mean_step_reward   | 0.4131819   |\n",
      "|    n_updates          | 14280       |\n",
      "|    policyGradLoss     | -0.00217    |\n",
      "|    value_loss         | 2.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 29261824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010428304 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.369       |\n",
      "|    mean_step_reward   | 0.38866097  |\n",
      "|    n_updates          | 14284       |\n",
      "|    policyGradLoss     | -0.00346    |\n",
      "|    value_loss         | 2.04        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 29270016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014841345 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.311       |\n",
      "|    mean_step_reward   | 0.40718094  |\n",
      "|    n_updates          | 14288       |\n",
      "|    policyGradLoss     | -0.00525    |\n",
      "|    value_loss         | 1.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 29278208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009559475 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.512       |\n",
      "|    mean_step_reward   | 0.391568    |\n",
      "|    n_updates          | 14292       |\n",
      "|    policyGradLoss     | -0.00863    |\n",
      "|    value_loss         | 1.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 29286400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009107184 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.838       |\n",
      "|    mean_step_reward   | 0.34903777  |\n",
      "|    n_updates          | 14296       |\n",
      "|    policyGradLoss     | -0.00603    |\n",
      "|    value_loss         | 1.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 29294592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013904565 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.514       |\n",
      "|    mean_step_reward   | 0.36870885  |\n",
      "|    n_updates          | 14300       |\n",
      "|    policyGradLoss     | -0.000874   |\n",
      "|    value_loss         | 3.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 29302784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010875926 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.535       |\n",
      "|    mean_step_reward   | 0.38963655  |\n",
      "|    n_updates          | 14304       |\n",
      "|    policyGradLoss     | -0.00232    |\n",
      "|    value_loss         | 2.7         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 780          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 272          |\n",
      "|    total_timesteps    | 29310976     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0123835895 |\n",
      "|    entropy_loss       | -1.69        |\n",
      "|    explained_variance | 0.961        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.601        |\n",
      "|    mean_step_reward   | 0.35885304   |\n",
      "|    n_updates          | 14308        |\n",
      "|    policyGradLoss     | -1.5e-05     |\n",
      "|    value_loss         | 2.82         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 29319168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009656324 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.764       |\n",
      "|    mean_step_reward   | 0.42927325  |\n",
      "|    n_updates          | 14312       |\n",
      "|    policyGradLoss     | -0.000513   |\n",
      "|    value_loss         | 3.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 29327360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010002855 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.497       |\n",
      "|    mean_step_reward   | 0.41079295  |\n",
      "|    n_updates          | 14316       |\n",
      "|    policyGradLoss     | -0.00228    |\n",
      "|    value_loss         | 2.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 29335552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012708419 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.597       |\n",
      "|    mean_step_reward   | 0.42339224  |\n",
      "|    n_updates          | 14320       |\n",
      "|    policyGradLoss     | -0.00552    |\n",
      "|    value_loss         | 1.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 314         |\n",
      "|    total_timesteps    | 29343744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013824148 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.525       |\n",
      "|    mean_step_reward   | 0.4024353   |\n",
      "|    n_updates          | 14324       |\n",
      "|    policyGradLoss     | -0.00668    |\n",
      "|    value_loss         | 1.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 29351936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010936398 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.46        |\n",
      "|    mean_step_reward   | 0.40825737  |\n",
      "|    n_updates          | 14328       |\n",
      "|    policyGradLoss     | -0.00509    |\n",
      "|    value_loss         | 2.05        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 780          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 335          |\n",
      "|    total_timesteps    | 29360128     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0141085945 |\n",
      "|    entropy_loss       | -1.65        |\n",
      "|    explained_variance | 0.975        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.473        |\n",
      "|    mean_step_reward   | 0.43502355   |\n",
      "|    n_updates          | 14332        |\n",
      "|    policyGradLoss     | -0.00249     |\n",
      "|    value_loss         | 2.01         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_111.zip\n",
      "[EVAL] Mean Return: 408.082, Best Return: 413.415\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_111_408.08.mp4\n",
      "\n",
      "=== Round 113 | Learn 262144 steps (Total trained: 29360128) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1153     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 29368320 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 922         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 29376512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019176546 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.949       |\n",
      "|    mean_step_reward   | 0.4106997   |\n",
      "|    n_updates          | 14340       |\n",
      "|    policyGradLoss     | -0.005      |\n",
      "|    value_loss         | 1.66        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 853         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 29384704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014891226 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.439       |\n",
      "|    mean_step_reward   | 0.4683303   |\n",
      "|    n_updates          | 14344       |\n",
      "|    policyGradLoss     | -0.00715    |\n",
      "|    value_loss         | 1.75        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 834        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 39         |\n",
      "|    total_timesteps    | 29392896   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01416906 |\n",
      "|    entropy_loss       | -1.7       |\n",
      "|    explained_variance | 0.983      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.815      |\n",
      "|    mean_step_reward   | 0.33557218 |\n",
      "|    n_updates          | 14348      |\n",
      "|    policyGradLoss     | -0.00499   |\n",
      "|    value_loss         | 1.82       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 29401088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013571705 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.453       |\n",
      "|    mean_step_reward   | 0.47626454  |\n",
      "|    n_updates          | 14352       |\n",
      "|    policyGradLoss     | -0.00556    |\n",
      "|    value_loss         | 1.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 29409280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014014812 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.533       |\n",
      "|    mean_step_reward   | 0.33472034  |\n",
      "|    n_updates          | 14356       |\n",
      "|    policyGradLoss     | -0.00598    |\n",
      "|    value_loss         | 1.76        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 29417472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017021745 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0215      |\n",
      "|    mean_step_reward   | 0.43750244  |\n",
      "|    n_updates          | 14360       |\n",
      "|    policyGradLoss     | -0.00591    |\n",
      "|    value_loss         | 0.704       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 29425664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014264354 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.787       |\n",
      "|    mean_step_reward   | 0.3731367   |\n",
      "|    n_updates          | 14364       |\n",
      "|    policyGradLoss     | 0.000462    |\n",
      "|    value_loss         | 4.26        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 796        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 92         |\n",
      "|    total_timesteps    | 29433856   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01360713 |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.961      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.492      |\n",
      "|    mean_step_reward   | 0.42018273 |\n",
      "|    n_updates          | 14368      |\n",
      "|    policyGradLoss     | -0.000797  |\n",
      "|    value_loss         | 3.26       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 29442048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013818299 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.161       |\n",
      "|    mean_step_reward   | 0.4242775   |\n",
      "|    n_updates          | 14372       |\n",
      "|    policyGradLoss     | -0.00707    |\n",
      "|    value_loss         | 0.998       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 29450240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013290042 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.366       |\n",
      "|    mean_step_reward   | 0.3565798   |\n",
      "|    n_updates          | 14376       |\n",
      "|    policyGradLoss     | -0.00343    |\n",
      "|    value_loss         | 2.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 29458432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013821381 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.06        |\n",
      "|    mean_step_reward   | 0.33661348  |\n",
      "|    n_updates          | 14380       |\n",
      "|    policyGradLoss     | -0.00339    |\n",
      "|    value_loss         | 2.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 29466624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013861068 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.529       |\n",
      "|    mean_step_reward   | 0.39189857  |\n",
      "|    n_updates          | 14384       |\n",
      "|    policyGradLoss     | -0.00432    |\n",
      "|    value_loss         | 1.94        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 786        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 145        |\n",
      "|    total_timesteps    | 29474816   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01721391 |\n",
      "|    entropy_loss       | -1.62      |\n",
      "|    explained_variance | 0.949      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.609      |\n",
      "|    mean_step_reward   | 0.3963285  |\n",
      "|    n_updates          | 14388      |\n",
      "|    policyGradLoss     | -0.00134   |\n",
      "|    value_loss         | 3.89       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 29483008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013697336 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.185       |\n",
      "|    mean_step_reward   | 0.44200695  |\n",
      "|    n_updates          | 14392       |\n",
      "|    policyGradLoss     | -0.00295    |\n",
      "|    value_loss         | 1.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 29491200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011207629 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.433       |\n",
      "|    mean_step_reward   | 0.38394088  |\n",
      "|    n_updates          | 14396       |\n",
      "|    policyGradLoss     | -0.00433    |\n",
      "|    value_loss         | 1.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 29499392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015581744 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.234       |\n",
      "|    mean_step_reward   | 0.44761992  |\n",
      "|    n_updates          | 14400       |\n",
      "|    policyGradLoss     | -0.0051     |\n",
      "|    value_loss         | 1.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 29507584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011425612 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.4         |\n",
      "|    mean_step_reward   | 0.35763985  |\n",
      "|    n_updates          | 14404       |\n",
      "|    policyGradLoss     | -0.00151    |\n",
      "|    value_loss         | 2.57        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 199        |\n",
      "|    total_timesteps    | 29515776   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01835734 |\n",
      "|    entropy_loss       | -1.63      |\n",
      "|    explained_variance | 0.932      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.41       |\n",
      "|    mean_step_reward   | 0.44386286 |\n",
      "|    n_updates          | 14408      |\n",
      "|    policyGradLoss     | 0.00542    |\n",
      "|    value_loss         | 4.91       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 29523968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016201837 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.596       |\n",
      "|    mean_step_reward   | 0.35815817  |\n",
      "|    n_updates          | 14412       |\n",
      "|    policyGradLoss     | -0.00617    |\n",
      "|    value_loss         | 1.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 29532160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012409955 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.938       |\n",
      "|    mean_step_reward   | 0.4156847   |\n",
      "|    n_updates          | 14416       |\n",
      "|    policyGradLoss     | 0.00154     |\n",
      "|    value_loss         | 3.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 29540352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012753632 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.47        |\n",
      "|    mean_step_reward   | 0.3583458   |\n",
      "|    n_updates          | 14420       |\n",
      "|    policyGradLoss     | 0.00737     |\n",
      "|    value_loss         | 2.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 29548544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012089685 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.251       |\n",
      "|    mean_step_reward   | 0.35485205  |\n",
      "|    n_updates          | 14424       |\n",
      "|    policyGradLoss     | -0.0053     |\n",
      "|    value_loss         | 1.94        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 29556736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013193998 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.656       |\n",
      "|    mean_step_reward   | 0.3585685   |\n",
      "|    n_updates          | 14428       |\n",
      "|    policyGradLoss     | 0.00234     |\n",
      "|    value_loss         | 3.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 29564928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012047496 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.636       |\n",
      "|    mean_step_reward   | 0.32564214  |\n",
      "|    n_updates          | 14432       |\n",
      "|    policyGradLoss     | -0.00809    |\n",
      "|    value_loss         | 1.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 29573120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011679333 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.872       |\n",
      "|    mean_step_reward   | 0.35525858  |\n",
      "|    n_updates          | 14436       |\n",
      "|    policyGradLoss     | -0.00634    |\n",
      "|    value_loss         | 1.72        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 774        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 285        |\n",
      "|    total_timesteps    | 29581312   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01400559 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.937      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.904      |\n",
      "|    mean_step_reward   | 0.412298   |\n",
      "|    n_updates          | 14440      |\n",
      "|    policyGradLoss     | 0.00403    |\n",
      "|    value_loss         | 4          |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 29589504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010751473 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.634       |\n",
      "|    mean_step_reward   | 0.4096099   |\n",
      "|    n_updates          | 14444       |\n",
      "|    policyGradLoss     | 0.00214     |\n",
      "|    value_loss         | 2.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 29597696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009446567 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.751       |\n",
      "|    mean_step_reward   | 0.3365158   |\n",
      "|    n_updates          | 14448       |\n",
      "|    policyGradLoss     | -0.00391    |\n",
      "|    value_loss         | 2.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 29605888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010041701 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.515       |\n",
      "|    mean_step_reward   | 0.31313762  |\n",
      "|    n_updates          | 14452       |\n",
      "|    policyGradLoss     | -0.00475    |\n",
      "|    value_loss         | 1.52        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 774          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 328          |\n",
      "|    total_timesteps    | 29614080     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0122401295 |\n",
      "|    entropy_loss       | -1.69        |\n",
      "|    explained_variance | 0.973        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.189        |\n",
      "|    mean_step_reward   | 0.3396093    |\n",
      "|    n_updates          | 14456        |\n",
      "|    policyGradLoss     | -0.00176     |\n",
      "|    value_loss         | 1.3          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 29622272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013411088 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.97        |\n",
      "|    mean_step_reward   | 0.3407523   |\n",
      "|    n_updates          | 14460       |\n",
      "|    policyGradLoss     | -0.000921   |\n",
      "|    value_loss         | 4.09        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_112.zip\n",
      "[EVAL] Mean Return: 532.450, Best Return: 539.117\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_112_532.45.mp4\n",
      "\n",
      "=== Round 114 | Learn 262144 steps (Total trained: 29622272) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1143     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 29630464 |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 920          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 29638656     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0100500975 |\n",
      "|    entropy_loss       | -1.71        |\n",
      "|    explained_variance | 0.987        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.622        |\n",
      "|    mean_step_reward   | 0.36729798   |\n",
      "|    n_updates          | 14468        |\n",
      "|    policyGradLoss     | -0.00405     |\n",
      "|    value_loss         | 1.58         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 859         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 29646848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010133799 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.444       |\n",
      "|    mean_step_reward   | 0.36902583  |\n",
      "|    n_updates          | 14472       |\n",
      "|    policyGradLoss     | -0.00527    |\n",
      "|    value_loss         | 1.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 29655040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009873328 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.511       |\n",
      "|    mean_step_reward   | 0.41490707  |\n",
      "|    n_updates          | 14476       |\n",
      "|    policyGradLoss     | -0.00107    |\n",
      "|    value_loss         | 2.76        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 29663232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009955614 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.398       |\n",
      "|    mean_step_reward   | 0.41322404  |\n",
      "|    n_updates          | 14480       |\n",
      "|    policyGradLoss     | -0.00744    |\n",
      "|    value_loss         | 1.92        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 808        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 29671424   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00950615 |\n",
      "|    entropy_loss       | -1.66      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.673      |\n",
      "|    mean_step_reward   | 0.4481293  |\n",
      "|    n_updates          | 14484      |\n",
      "|    policyGradLoss     | -0.00652   |\n",
      "|    value_loss         | 1.51       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 29679616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012296524 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.777       |\n",
      "|    mean_step_reward   | 0.369326    |\n",
      "|    n_updates          | 14488       |\n",
      "|    policyGradLoss     | -0.00387    |\n",
      "|    value_loss         | 1.72        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 29687808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014942222 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.53        |\n",
      "|    mean_step_reward   | 0.4135837   |\n",
      "|    n_updates          | 14492       |\n",
      "|    policyGradLoss     | -0.00393    |\n",
      "|    value_loss         | 1.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 29696000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012317074 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.394       |\n",
      "|    mean_step_reward   | 0.41270533  |\n",
      "|    n_updates          | 14496       |\n",
      "|    policyGradLoss     | -0.000174   |\n",
      "|    value_loss         | 2.8         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 794          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 103          |\n",
      "|    total_timesteps    | 29704192     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0104884105 |\n",
      "|    entropy_loss       | -1.72        |\n",
      "|    explained_variance | 0.984        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.972        |\n",
      "|    mean_step_reward   | 0.3942094    |\n",
      "|    n_updates          | 14500        |\n",
      "|    policyGradLoss     | -0.00483     |\n",
      "|    value_loss         | 2.37         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 29712384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014344923 |\n",
      "|    entropy_loss       | -1.57       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.376       |\n",
      "|    mean_step_reward   | 0.4779125   |\n",
      "|    n_updates          | 14504       |\n",
      "|    policyGradLoss     | -0.00522    |\n",
      "|    value_loss         | 1.01        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 789        |\n",
      "|    iterations         | 12         |\n",
      "|    time_elapsed       | 124        |\n",
      "|    total_timesteps    | 29720576   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01284331 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.925      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.25       |\n",
      "|    mean_step_reward   | 0.3578419  |\n",
      "|    n_updates          | 14508      |\n",
      "|    policyGradLoss     | 0.000996   |\n",
      "|    value_loss         | 5.98       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 29728768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011816816 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.695       |\n",
      "|    mean_step_reward   | 0.3859159   |\n",
      "|    n_updates          | 14512       |\n",
      "|    policyGradLoss     | -0.00146    |\n",
      "|    value_loss         | 1.92        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 29736960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013844483 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.509       |\n",
      "|    mean_step_reward   | 0.38203904  |\n",
      "|    n_updates          | 14516       |\n",
      "|    policyGradLoss     | 0.00288     |\n",
      "|    value_loss         | 3.34        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 29745152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011147179 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.12        |\n",
      "|    mean_step_reward   | 0.4152118   |\n",
      "|    n_updates          | 14520       |\n",
      "|    policyGradLoss     | -0.00156    |\n",
      "|    value_loss         | 2.52        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 784        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 167        |\n",
      "|    total_timesteps    | 29753344   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02061671 |\n",
      "|    entropy_loss       | -1.63      |\n",
      "|    explained_variance | 0.983      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.51       |\n",
      "|    mean_step_reward   | 0.4117827  |\n",
      "|    n_updates          | 14524      |\n",
      "|    policyGradLoss     | -0.00283   |\n",
      "|    value_loss         | 1.81       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 783          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 177          |\n",
      "|    total_timesteps    | 29761536     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0146346055 |\n",
      "|    entropy_loss       | -1.69        |\n",
      "|    explained_variance | 0.983        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.15         |\n",
      "|    mean_step_reward   | 0.3267359    |\n",
      "|    n_updates          | 14528        |\n",
      "|    policyGradLoss     | -0.00341     |\n",
      "|    value_loss         | 1.5          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 29769728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009691987 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.531       |\n",
      "|    mean_step_reward   | 0.40151128  |\n",
      "|    n_updates          | 14532       |\n",
      "|    policyGradLoss     | 0.00254     |\n",
      "|    value_loss         | 2.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 29777920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009499583 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.59        |\n",
      "|    mean_step_reward   | 0.4179064   |\n",
      "|    n_updates          | 14536       |\n",
      "|    policyGradLoss     | -0.00503    |\n",
      "|    value_loss         | 1.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 29786112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012885644 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.41        |\n",
      "|    mean_step_reward   | 0.31468803  |\n",
      "|    n_updates          | 14540       |\n",
      "|    policyGradLoss     | -0.00412    |\n",
      "|    value_loss         | 1.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 29794304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012163699 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.71        |\n",
      "|    mean_step_reward   | 0.4671958   |\n",
      "|    n_updates          | 14544       |\n",
      "|    policyGradLoss     | -0.00454    |\n",
      "|    value_loss         | 1.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 29802496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010311049 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.81        |\n",
      "|    mean_step_reward   | 0.36526203  |\n",
      "|    n_updates          | 14548       |\n",
      "|    policyGradLoss     | -0.00543    |\n",
      "|    value_loss         | 2.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 29810688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011564281 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.422       |\n",
      "|    mean_step_reward   | 0.41758436  |\n",
      "|    n_updates          | 14552       |\n",
      "|    policyGradLoss     | -0.00605    |\n",
      "|    value_loss         | 1.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 29818880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009850133 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.458       |\n",
      "|    mean_step_reward   | 0.37892702  |\n",
      "|    n_updates          | 14556       |\n",
      "|    policyGradLoss     | -0.00555    |\n",
      "|    value_loss         | 1.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 29827072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011160165 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.15        |\n",
      "|    mean_step_reward   | 0.42669052  |\n",
      "|    n_updates          | 14560       |\n",
      "|    policyGradLoss     | -0.00484    |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 29835264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019142482 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.217       |\n",
      "|    mean_step_reward   | 0.41979766  |\n",
      "|    n_updates          | 14564       |\n",
      "|    policyGradLoss     | -0.00864    |\n",
      "|    value_loss         | 1.06        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 284        |\n",
      "|    total_timesteps    | 29843456   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01162996 |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.435      |\n",
      "|    mean_step_reward   | 0.38037008 |\n",
      "|    n_updates          | 14568      |\n",
      "|    policyGradLoss     | -0.00651   |\n",
      "|    value_loss         | 1.21       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 29851648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010870466 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.667       |\n",
      "|    mean_step_reward   | 0.41956082  |\n",
      "|    n_updates          | 14572       |\n",
      "|    policyGradLoss     | -0.00543    |\n",
      "|    value_loss         | 1.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 29859840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010339493 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.13        |\n",
      "|    mean_step_reward   | 0.39309883  |\n",
      "|    n_updates          | 14576       |\n",
      "|    policyGradLoss     | -0.00726    |\n",
      "|    value_loss         | 1.64        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 29868032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014246347 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.416       |\n",
      "|    mean_step_reward   | 0.45576578  |\n",
      "|    n_updates          | 14580       |\n",
      "|    policyGradLoss     | -0.00786    |\n",
      "|    value_loss         | 1.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 29876224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010074014 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.492       |\n",
      "|    mean_step_reward   | 0.3765237   |\n",
      "|    n_updates          | 14584       |\n",
      "|    policyGradLoss     | -0.00519    |\n",
      "|    value_loss         | 1.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 29884416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012813099 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.08        |\n",
      "|    mean_step_reward   | 0.4000759   |\n",
      "|    n_updates          | 14588       |\n",
      "|    policyGradLoss     | -0.000759   |\n",
      "|    value_loss         | 2.7         |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_113.zip\n",
      "[EVAL] Mean Return: 520.137, Best Return: 526.803\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_113_520.14.mp4\n",
      "\n",
      "=== Round 115 | Learn 262144 steps (Total trained: 29884416) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1159     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 29892608 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 916         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 29900800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010862414 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.451       |\n",
      "|    mean_step_reward   | 0.3990388   |\n",
      "|    n_updates          | 14596       |\n",
      "|    policyGradLoss     | -0.00285    |\n",
      "|    value_loss         | 2.71        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 866         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 29908992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013804137 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.367       |\n",
      "|    mean_step_reward   | 0.4121182   |\n",
      "|    n_updates          | 14600       |\n",
      "|    policyGradLoss     | -0.00742    |\n",
      "|    value_loss         | 1.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 834         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 29917184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010292184 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.503       |\n",
      "|    mean_step_reward   | 0.3918863   |\n",
      "|    n_updates          | 14604       |\n",
      "|    policyGradLoss     | -0.0074     |\n",
      "|    value_loss         | 1.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 823         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 29925376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008811476 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.337       |\n",
      "|    mean_step_reward   | 0.41061565  |\n",
      "|    n_updates          | 14608       |\n",
      "|    policyGradLoss     | -0.0034     |\n",
      "|    value_loss         | 1.96        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 29933568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009502337 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.407       |\n",
      "|    mean_step_reward   | 0.41489267  |\n",
      "|    n_updates          | 14612       |\n",
      "|    policyGradLoss     | -0.00672    |\n",
      "|    value_loss         | 1.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 29941760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011056615 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.95        |\n",
      "|    mean_step_reward   | 0.38720068  |\n",
      "|    n_updates          | 14616       |\n",
      "|    policyGradLoss     | -0.00545    |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 29949952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011914628 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.61        |\n",
      "|    mean_step_reward   | 0.44712424  |\n",
      "|    n_updates          | 14620       |\n",
      "|    policyGradLoss     | -0.00769    |\n",
      "|    value_loss         | 1.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 29958144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013037935 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.684       |\n",
      "|    mean_step_reward   | 0.41744137  |\n",
      "|    n_updates          | 14624       |\n",
      "|    policyGradLoss     | -0.0035     |\n",
      "|    value_loss         | 1.95        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 29966336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008469847 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.799       |\n",
      "|    mean_step_reward   | 0.35257342  |\n",
      "|    n_updates          | 14628       |\n",
      "|    policyGradLoss     | -0.00925    |\n",
      "|    value_loss         | 1.43        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 29974528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012508309 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.402       |\n",
      "|    mean_step_reward   | 0.45265597  |\n",
      "|    n_updates          | 14632       |\n",
      "|    policyGradLoss     | -0.00221    |\n",
      "|    value_loss         | 2.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 29982720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012784254 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.77        |\n",
      "|    mean_step_reward   | 0.39573467  |\n",
      "|    n_updates          | 14636       |\n",
      "|    policyGradLoss     | 0.00458     |\n",
      "|    value_loss         | 5.71        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 29990912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012009323 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.58        |\n",
      "|    mean_step_reward   | 0.4300977   |\n",
      "|    n_updates          | 14640       |\n",
      "|    policyGradLoss     | -0.000444   |\n",
      "|    value_loss         | 2.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 29999104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014935994 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.718       |\n",
      "|    mean_step_reward   | 0.3916009   |\n",
      "|    n_updates          | 14644       |\n",
      "|    policyGradLoss     | 0.00352     |\n",
      "|    value_loss         | 3.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 30007296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011373751 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.289       |\n",
      "|    mean_step_reward   | 0.37250048  |\n",
      "|    n_updates          | 14648       |\n",
      "|    policyGradLoss     | -0.00487    |\n",
      "|    value_loss         | 1.99        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 30015488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014445968 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.516       |\n",
      "|    mean_step_reward   | 0.44898385  |\n",
      "|    n_updates          | 14652       |\n",
      "|    policyGradLoss     | 0.00177     |\n",
      "|    value_loss         | 3.14        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 782        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 177        |\n",
      "|    total_timesteps    | 30023680   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01211964 |\n",
      "|    entropy_loss       | -1.76      |\n",
      "|    explained_variance | 0.967      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.55       |\n",
      "|    mean_step_reward   | 0.32658276 |\n",
      "|    n_updates          | 14656      |\n",
      "|    policyGradLoss     | 3.22e-05   |\n",
      "|    value_loss         | 3.09       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 30031872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015916444 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.497       |\n",
      "|    mean_step_reward   | 0.4547445   |\n",
      "|    n_updates          | 14660       |\n",
      "|    policyGradLoss     | -0.000101   |\n",
      "|    value_loss         | 0.919       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 30040064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011501053 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.942       |\n",
      "|    mean_step_reward   | 0.25907087  |\n",
      "|    n_updates          | 14664       |\n",
      "|    policyGradLoss     | -0.00579    |\n",
      "|    value_loss         | 1.91        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 210        |\n",
      "|    total_timesteps    | 30048256   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01580025 |\n",
      "|    entropy_loss       | -1.7       |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.283      |\n",
      "|    mean_step_reward   | 0.30861235 |\n",
      "|    n_updates          | 14668      |\n",
      "|    policyGradLoss     | -0.00414   |\n",
      "|    value_loss         | 0.931      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 778          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 221          |\n",
      "|    total_timesteps    | 30056448     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0093875965 |\n",
      "|    entropy_loss       | -1.7         |\n",
      "|    explained_variance | 0.983        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.637        |\n",
      "|    mean_step_reward   | 0.38385952   |\n",
      "|    n_updates          | 14672        |\n",
      "|    policyGradLoss     | -0.0061      |\n",
      "|    value_loss         | 1.61         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 30064640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011005525 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.374       |\n",
      "|    mean_step_reward   | 0.3710304   |\n",
      "|    n_updates          | 14676       |\n",
      "|    policyGradLoss     | -0.00406    |\n",
      "|    value_loss         | 2.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 30072832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014627106 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.431       |\n",
      "|    mean_step_reward   | 0.44951117  |\n",
      "|    n_updates          | 14680       |\n",
      "|    policyGradLoss     | -0.00673    |\n",
      "|    value_loss         | 0.846       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 30081024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009429434 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.3         |\n",
      "|    mean_step_reward   | 0.34370613  |\n",
      "|    n_updates          | 14684       |\n",
      "|    policyGradLoss     | -0.00535    |\n",
      "|    value_loss         | 1.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 30089216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012190033 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.302       |\n",
      "|    mean_step_reward   | 0.425796    |\n",
      "|    n_updates          | 14688       |\n",
      "|    policyGradLoss     | -0.00474    |\n",
      "|    value_loss         | 1.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 30097408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013386995 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.508       |\n",
      "|    mean_step_reward   | 0.3531043   |\n",
      "|    n_updates          | 14692       |\n",
      "|    policyGradLoss     | -0.00168    |\n",
      "|    value_loss         | 3.35        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 774        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 285        |\n",
      "|    total_timesteps    | 30105600   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01558837 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.927      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.471      |\n",
      "|    mean_step_reward   | 0.33390236 |\n",
      "|    n_updates          | 14696      |\n",
      "|    policyGradLoss     | -0.00134   |\n",
      "|    value_loss         | 3.58       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 30113792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011951973 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.93        |\n",
      "|    mean_step_reward   | 0.40879697  |\n",
      "|    n_updates          | 14700       |\n",
      "|    policyGradLoss     | 0.00049     |\n",
      "|    value_loss         | 6.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 30121984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017143741 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.545       |\n",
      "|    mean_step_reward   | 0.36023337  |\n",
      "|    n_updates          | 14704       |\n",
      "|    policyGradLoss     | -0.00134    |\n",
      "|    value_loss         | 1.55        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 30130176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017346907 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.252       |\n",
      "|    mean_step_reward   | 0.4001677   |\n",
      "|    n_updates          | 14708       |\n",
      "|    policyGradLoss     | -0.008      |\n",
      "|    value_loss         | 1.26        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 773        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 328        |\n",
      "|    total_timesteps    | 30138368   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01124988 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.984      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.397      |\n",
      "|    mean_step_reward   | 0.37720662 |\n",
      "|    n_updates          | 14712      |\n",
      "|    policyGradLoss     | -0.00369   |\n",
      "|    value_loss         | 1.8        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 773        |\n",
      "|    iterations         | 32         |\n",
      "|    time_elapsed       | 338        |\n",
      "|    total_timesteps    | 30146560   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01464753 |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.99       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.997      |\n",
      "|    mean_step_reward   | 0.38142583 |\n",
      "|    n_updates          | 14716      |\n",
      "|    policyGradLoss     | -0.00795   |\n",
      "|    value_loss         | 1.44       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_114.zip\n",
      "[EVAL] Mean Return: 37.227, Best Return: 37.894\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_114_37.23.mp4\n",
      "\n",
      "=== Round 116 | Learn 262144 steps (Total trained: 30146560) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1129     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 30154752 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 918         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 30162944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016997477 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.985       |\n",
      "|    mean_step_reward   | 0.41541135  |\n",
      "|    n_updates          | 14724       |\n",
      "|    policyGradLoss     | -0.00743    |\n",
      "|    value_loss         | 1.61        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 869         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 30171136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014222171 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.373       |\n",
      "|    mean_step_reward   | 0.34518972  |\n",
      "|    n_updates          | 14728       |\n",
      "|    policyGradLoss     | -0.00563    |\n",
      "|    value_loss         | 1.95        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 843         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 30179328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016587824 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.479       |\n",
      "|    mean_step_reward   | 0.40234232  |\n",
      "|    n_updates          | 14732       |\n",
      "|    policyGradLoss     | -0.00294    |\n",
      "|    value_loss         | 1.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 828         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 30187520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013096282 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.375       |\n",
      "|    mean_step_reward   | 0.41758528  |\n",
      "|    n_updates          | 14736       |\n",
      "|    policyGradLoss     | -0.00418    |\n",
      "|    value_loss         | 1.09        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 30195712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011340663 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.709       |\n",
      "|    mean_step_reward   | 0.43047065  |\n",
      "|    n_updates          | 14740       |\n",
      "|    policyGradLoss     | -0.00524    |\n",
      "|    value_loss         | 1.82        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 814        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 70         |\n",
      "|    total_timesteps    | 30203904   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01321573 |\n",
      "|    entropy_loss       | -1.58      |\n",
      "|    explained_variance | 0.993      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.588      |\n",
      "|    mean_step_reward   | 0.4202837  |\n",
      "|    n_updates          | 14744      |\n",
      "|    policyGradLoss     | -0.00795   |\n",
      "|    value_loss         | 0.936      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 30212096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014732644 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.532       |\n",
      "|    mean_step_reward   | 0.40811074  |\n",
      "|    n_updates          | 14748       |\n",
      "|    policyGradLoss     | -0.00588    |\n",
      "|    value_loss         | 1.65        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 30220288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013148458 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.456       |\n",
      "|    mean_step_reward   | 0.47483516  |\n",
      "|    n_updates          | 14752       |\n",
      "|    policyGradLoss     | -0.00683    |\n",
      "|    value_loss         | 1.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 30228480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015831366 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.121       |\n",
      "|    mean_step_reward   | 0.37514764  |\n",
      "|    n_updates          | 14756       |\n",
      "|    policyGradLoss     | -0.00274    |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 30236672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012334362 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.623       |\n",
      "|    mean_step_reward   | 0.42498174  |\n",
      "|    n_updates          | 14760       |\n",
      "|    policyGradLoss     | -0.00404    |\n",
      "|    value_loss         | 1.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 30244864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014277304 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.591       |\n",
      "|    mean_step_reward   | 0.40943375  |\n",
      "|    n_updates          | 14764       |\n",
      "|    policyGradLoss     | -0.00389    |\n",
      "|    value_loss         | 1.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 30253056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014385112 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.949       |\n",
      "|    mean_step_reward   | 0.38306072  |\n",
      "|    n_updates          | 14768       |\n",
      "|    policyGradLoss     | -0.00514    |\n",
      "|    value_loss         | 1.53        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 30261248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010925669 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.464       |\n",
      "|    mean_step_reward   | 0.40623212  |\n",
      "|    n_updates          | 14772       |\n",
      "|    policyGradLoss     | -0.00485    |\n",
      "|    value_loss         | 1.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 30269440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011911324 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.256       |\n",
      "|    mean_step_reward   | 0.3824103   |\n",
      "|    n_updates          | 14776       |\n",
      "|    policyGradLoss     | -0.00756    |\n",
      "|    value_loss         | 1.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 30277632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009257114 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.73        |\n",
      "|    mean_step_reward   | 0.37107876  |\n",
      "|    n_updates          | 14780       |\n",
      "|    policyGradLoss     | -0.00595    |\n",
      "|    value_loss         | 1.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 30285824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011091825 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.486       |\n",
      "|    mean_step_reward   | 0.42787647  |\n",
      "|    n_updates          | 14784       |\n",
      "|    policyGradLoss     | -0.00256    |\n",
      "|    value_loss         | 1.94        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 30294016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010289552 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.863       |\n",
      "|    mean_step_reward   | 0.4371109   |\n",
      "|    n_updates          | 14788       |\n",
      "|    policyGradLoss     | -0.00506    |\n",
      "|    value_loss         | 2.99        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 30302208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007990397 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.261       |\n",
      "|    mean_step_reward   | 0.376768    |\n",
      "|    n_updates          | 14792       |\n",
      "|    policyGradLoss     | -0.00414    |\n",
      "|    value_loss         | 1.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 30310400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010030521 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.77        |\n",
      "|    mean_step_reward   | 0.43974662  |\n",
      "|    n_updates          | 14796       |\n",
      "|    policyGradLoss     | -0.00286    |\n",
      "|    value_loss         | 1.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 30318592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014844274 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.797       |\n",
      "|    mean_step_reward   | 0.36488616  |\n",
      "|    n_updates          | 14800       |\n",
      "|    policyGradLoss     | -0.00406    |\n",
      "|    value_loss         | 1.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 30326784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013926318 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.446       |\n",
      "|    mean_step_reward   | 0.42413878  |\n",
      "|    n_updates          | 14804       |\n",
      "|    policyGradLoss     | 0.000378    |\n",
      "|    value_loss         | 2.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 30334976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009476848 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.94        |\n",
      "|    mean_step_reward   | 0.42691514  |\n",
      "|    n_updates          | 14808       |\n",
      "|    policyGradLoss     | -0.00409    |\n",
      "|    value_loss         | 2.92        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 30343168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012565194 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.783       |\n",
      "|    mean_step_reward   | 0.39409196  |\n",
      "|    n_updates          | 14812       |\n",
      "|    policyGradLoss     | 0.00364     |\n",
      "|    value_loss         | 4.52        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 30351360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010298281 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.42        |\n",
      "|    mean_step_reward   | 0.37118334  |\n",
      "|    n_updates          | 14816       |\n",
      "|    policyGradLoss     | -0.00321    |\n",
      "|    value_loss         | 2.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 30359552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010109263 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.413       |\n",
      "|    mean_step_reward   | 0.3800848   |\n",
      "|    n_updates          | 14820       |\n",
      "|    policyGradLoss     | -0.00163    |\n",
      "|    value_loss         | 1.95        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 30367744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010168519 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.203       |\n",
      "|    mean_step_reward   | 0.44791502  |\n",
      "|    n_updates          | 14824       |\n",
      "|    policyGradLoss     | -0.00595    |\n",
      "|    value_loss         | 1.56        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 778       |\n",
      "|    iterations         | 28        |\n",
      "|    time_elapsed       | 294       |\n",
      "|    total_timesteps    | 30375936  |\n",
      "| train/                |           |\n",
      "|    approx_kl          | 0.010255  |\n",
      "|    entropy_loss       | -1.68     |\n",
      "|    explained_variance | 0.988     |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    loss               | 0.77      |\n",
      "|    mean_step_reward   | 0.4223053 |\n",
      "|    n_updates          | 14828     |\n",
      "|    policyGradLoss     | -0.0045   |\n",
      "|    value_loss         | 2.08      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 30384128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011183286 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.858       |\n",
      "|    mean_step_reward   | 0.41035905  |\n",
      "|    n_updates          | 14832       |\n",
      "|    policyGradLoss     | -0.00389    |\n",
      "|    value_loss         | 2.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 30392320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015863586 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.401       |\n",
      "|    mean_step_reward   | 0.4083857   |\n",
      "|    n_updates          | 14836       |\n",
      "|    policyGradLoss     | -0.00199    |\n",
      "|    value_loss         | 2.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 30400512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011853208 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.22        |\n",
      "|    mean_step_reward   | 0.3858577   |\n",
      "|    n_updates          | 14840       |\n",
      "|    policyGradLoss     | -0.00371    |\n",
      "|    value_loss         | 2.17        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 777          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 337          |\n",
      "|    total_timesteps    | 30408704     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0138449725 |\n",
      "|    entropy_loss       | -1.63        |\n",
      "|    explained_variance | 0.984        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.734        |\n",
      "|    mean_step_reward   | 0.38487792   |\n",
      "|    n_updates          | 14844        |\n",
      "|    policyGradLoss     | -0.00526     |\n",
      "|    value_loss         | 1.58         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_115.zip\n",
      "[EVAL] Mean Return: 531.392, Best Return: 538.059\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_115_531.39.mp4\n",
      "\n",
      "=== Round 117 | Learn 262144 steps (Total trained: 30408704) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1107     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 30416896 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 905         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 30425088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010849426 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.643       |\n",
      "|    mean_step_reward   | 0.4161818   |\n",
      "|    n_updates          | 14852       |\n",
      "|    policyGradLoss     | -0.00602    |\n",
      "|    value_loss         | 1.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 853         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 30433280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008829853 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.753       |\n",
      "|    mean_step_reward   | 0.43667585  |\n",
      "|    n_updates          | 14856       |\n",
      "|    policyGradLoss     | -0.00662    |\n",
      "|    value_loss         | 1.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 836         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 30441472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011618382 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.4         |\n",
      "|    mean_step_reward   | 0.35963297  |\n",
      "|    n_updates          | 14860       |\n",
      "|    policyGradLoss     | -0.005      |\n",
      "|    value_loss         | 1.79        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 821        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 49         |\n",
      "|    total_timesteps    | 30449664   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01481599 |\n",
      "|    entropy_loss       | -1.62      |\n",
      "|    explained_variance | 0.97       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.441      |\n",
      "|    mean_step_reward   | 0.4252002  |\n",
      "|    n_updates          | 14864      |\n",
      "|    policyGradLoss     | -0.00242   |\n",
      "|    value_loss         | 2.44       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 811        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 30457856   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00875911 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.975      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.47       |\n",
      "|    mean_step_reward   | 0.3679443  |\n",
      "|    n_updates          | 14868      |\n",
      "|    policyGradLoss     | 0.00202    |\n",
      "|    value_loss         | 1.76       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 30466048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011671141 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.806       |\n",
      "|    mean_step_reward   | 0.42684868  |\n",
      "|    n_updates          | 14872       |\n",
      "|    policyGradLoss     | -0.00428    |\n",
      "|    value_loss         | 2.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 30474240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010559235 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.581       |\n",
      "|    mean_step_reward   | 0.4233391   |\n",
      "|    n_updates          | 14876       |\n",
      "|    policyGradLoss     | -0.00572    |\n",
      "|    value_loss         | 1.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 30482432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011269253 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.938       |\n",
      "|    mean_step_reward   | 0.41643652  |\n",
      "|    n_updates          | 14880       |\n",
      "|    policyGradLoss     | -0.00364    |\n",
      "|    value_loss         | 2.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 30490624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018306756 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.845       |\n",
      "|    mean_step_reward   | 0.41952556  |\n",
      "|    n_updates          | 14884       |\n",
      "|    policyGradLoss     | -0.00651    |\n",
      "|    value_loss         | 1.2         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 796        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 113        |\n",
      "|    total_timesteps    | 30498816   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01175168 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.952      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.01       |\n",
      "|    mean_step_reward   | 0.3904825  |\n",
      "|    n_updates          | 14888      |\n",
      "|    policyGradLoss     | -0.00159   |\n",
      "|    value_loss         | 3.71       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 30507008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010945124 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.239       |\n",
      "|    mean_step_reward   | 0.42625394  |\n",
      "|    n_updates          | 14892       |\n",
      "|    policyGradLoss     | -0.00549    |\n",
      "|    value_loss         | 1.22        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 790        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 134        |\n",
      "|    total_timesteps    | 30515200   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01087321 |\n",
      "|    entropy_loss       | -1.66      |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.636      |\n",
      "|    mean_step_reward   | 0.39279288 |\n",
      "|    n_updates          | 14896      |\n",
      "|    policyGradLoss     | -0.00548   |\n",
      "|    value_loss         | 1.78       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 30523392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017495545 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.119       |\n",
      "|    mean_step_reward   | 0.41171634  |\n",
      "|    n_updates          | 14900       |\n",
      "|    policyGradLoss     | -0.00828    |\n",
      "|    value_loss         | 1.43        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 30531584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010548634 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.789       |\n",
      "|    mean_step_reward   | 0.4295178   |\n",
      "|    n_updates          | 14904       |\n",
      "|    policyGradLoss     | -0.00662    |\n",
      "|    value_loss         | 1.64        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 30539776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010203166 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.936       |\n",
      "|    mean_step_reward   | 0.40173793  |\n",
      "|    n_updates          | 14908       |\n",
      "|    policyGradLoss     | -0.00194    |\n",
      "|    value_loss         | 3.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 30547968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017168524 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.807       |\n",
      "|    mean_step_reward   | 0.3848368   |\n",
      "|    n_updates          | 14912       |\n",
      "|    policyGradLoss     | 0.00229     |\n",
      "|    value_loss         | 5.33        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 788          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 186          |\n",
      "|    total_timesteps    | 30556160     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0140515845 |\n",
      "|    entropy_loss       | -1.69        |\n",
      "|    explained_variance | 0.952        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.599        |\n",
      "|    mean_step_reward   | 0.39966816   |\n",
      "|    n_updates          | 14916        |\n",
      "|    policyGradLoss     | 0.00467      |\n",
      "|    value_loss         | 3.16         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 197         |\n",
      "|    total_timesteps    | 30564352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011881641 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.786       |\n",
      "|    mean_step_reward   | 0.41683426  |\n",
      "|    n_updates          | 14920       |\n",
      "|    policyGradLoss     | -0.00444    |\n",
      "|    value_loss         | 1.96        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 30572544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012879799 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.215       |\n",
      "|    mean_step_reward   | 0.41695783  |\n",
      "|    n_updates          | 14924       |\n",
      "|    policyGradLoss     | -0.00578    |\n",
      "|    value_loss         | 1.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 218         |\n",
      "|    total_timesteps    | 30580736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014830416 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.695       |\n",
      "|    mean_step_reward   | 0.3985452   |\n",
      "|    n_updates          | 14928       |\n",
      "|    policyGradLoss     | -0.00549    |\n",
      "|    value_loss         | 1.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 30588928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012789028 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.804       |\n",
      "|    mean_step_reward   | 0.375208    |\n",
      "|    n_updates          | 14932       |\n",
      "|    policyGradLoss     | -0.00901    |\n",
      "|    value_loss         | 1.31        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 784        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 240        |\n",
      "|    total_timesteps    | 30597120   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01467083 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.379      |\n",
      "|    mean_step_reward   | 0.41924584 |\n",
      "|    n_updates          | 14936      |\n",
      "|    policyGradLoss     | -0.00722   |\n",
      "|    value_loss         | 1.87       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 250         |\n",
      "|    total_timesteps    | 30605312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010169403 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.723       |\n",
      "|    mean_step_reward   | 0.35775188  |\n",
      "|    n_updates          | 14940       |\n",
      "|    policyGradLoss     | -0.00541    |\n",
      "|    value_loss         | 1.82        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 30613504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017063264 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.616       |\n",
      "|    mean_step_reward   | 0.4348237   |\n",
      "|    n_updates          | 14944       |\n",
      "|    policyGradLoss     | -0.00781    |\n",
      "|    value_loss         | 0.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 30621696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010098654 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.01        |\n",
      "|    mean_step_reward   | 0.35898077  |\n",
      "|    n_updates          | 14948       |\n",
      "|    policyGradLoss     | -0.00365    |\n",
      "|    value_loss         | 1.75        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 30629888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013680242 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.438       |\n",
      "|    mean_step_reward   | 0.33819512  |\n",
      "|    n_updates          | 14952       |\n",
      "|    policyGradLoss     | -0.00473    |\n",
      "|    value_loss         | 1.43        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 30638080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011060158 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.36        |\n",
      "|    mean_step_reward   | 0.44354987  |\n",
      "|    n_updates          | 14956       |\n",
      "|    policyGradLoss     | -0.00678    |\n",
      "|    value_loss         | 0.953       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 303         |\n",
      "|    total_timesteps    | 30646272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011382882 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.723       |\n",
      "|    mean_step_reward   | 0.37358564  |\n",
      "|    n_updates          | 14960       |\n",
      "|    policyGradLoss     | -0.00367    |\n",
      "|    value_loss         | 2.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 314         |\n",
      "|    total_timesteps    | 30654464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013565934 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.535       |\n",
      "|    mean_step_reward   | 0.40607607  |\n",
      "|    n_updates          | 14964       |\n",
      "|    policyGradLoss     | 0.00116     |\n",
      "|    value_loss         | 3.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 30662656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012804678 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.6         |\n",
      "|    mean_step_reward   | 0.43788236  |\n",
      "|    n_updates          | 14968       |\n",
      "|    policyGradLoss     | -0.0059     |\n",
      "|    value_loss         | 1.46        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 30670848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011728037 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.612       |\n",
      "|    mean_step_reward   | 0.35618323  |\n",
      "|    n_updates          | 14972       |\n",
      "|    policyGradLoss     | -0.00488    |\n",
      "|    value_loss         | 2.37        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_116.zip\n",
      "[EVAL] Mean Return: 531.408, Best Return: 538.075\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_116_531.41.mp4\n",
      "\n",
      "=== Round 118 | Learn 262144 steps (Total trained: 30670848) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1171     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 30679040 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 916         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 30687232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012998598 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.777       |\n",
      "|    mean_step_reward   | 0.35487825  |\n",
      "|    n_updates          | 14980       |\n",
      "|    policyGradLoss     | -0.00451    |\n",
      "|    value_loss         | 2           |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 863         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 30695424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016465334 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.835       |\n",
      "|    mean_step_reward   | 0.43168917  |\n",
      "|    n_updates          | 14984       |\n",
      "|    policyGradLoss     | -0.00399    |\n",
      "|    value_loss         | 1.53        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 841        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 38         |\n",
      "|    total_timesteps    | 30703616   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01277122 |\n",
      "|    entropy_loss       | -1.66      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.299      |\n",
      "|    mean_step_reward   | 0.3985154  |\n",
      "|    n_updates          | 14988      |\n",
      "|    policyGradLoss     | -0.0058    |\n",
      "|    value_loss         | 1.35       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 828         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 30711808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011127524 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.918       |\n",
      "|    mean_step_reward   | 0.3630348   |\n",
      "|    n_updates          | 14992       |\n",
      "|    policyGradLoss     | -0.00292    |\n",
      "|    value_loss         | 2.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 30720000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013037117 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.315       |\n",
      "|    mean_step_reward   | 0.44691733  |\n",
      "|    n_updates          | 14996       |\n",
      "|    policyGradLoss     | 0.00779     |\n",
      "|    value_loss         | 2.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 30728192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010625752 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.5         |\n",
      "|    mean_step_reward   | 0.38117185  |\n",
      "|    n_updates          | 15000       |\n",
      "|    policyGradLoss     | -0.00201    |\n",
      "|    value_loss         | 2.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 80          |\n",
      "|    total_timesteps    | 30736384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016282707 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.291       |\n",
      "|    mean_step_reward   | 0.40291935  |\n",
      "|    n_updates          | 15004       |\n",
      "|    policyGradLoss     | -0.00731    |\n",
      "|    value_loss         | 1.45        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 30744576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015230654 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.518       |\n",
      "|    mean_step_reward   | 0.41351205  |\n",
      "|    n_updates          | 15008       |\n",
      "|    policyGradLoss     | -0.00489    |\n",
      "|    value_loss         | 1.86        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 30752768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010003844 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.675       |\n",
      "|    mean_step_reward   | 0.42498714  |\n",
      "|    n_updates          | 15012       |\n",
      "|    policyGradLoss     | -0.00779    |\n",
      "|    value_loss         | 1.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 112         |\n",
      "|    total_timesteps    | 30760960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012378769 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.416       |\n",
      "|    mean_step_reward   | 0.44375548  |\n",
      "|    n_updates          | 15016       |\n",
      "|    policyGradLoss     | -0.00343    |\n",
      "|    value_loss         | 1.76        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 30769152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010708888 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.3         |\n",
      "|    mean_step_reward   | 0.39274082  |\n",
      "|    n_updates          | 15020       |\n",
      "|    policyGradLoss     | -0.00437    |\n",
      "|    value_loss         | 2.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 30777344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018769806 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.543       |\n",
      "|    mean_step_reward   | 0.39737114  |\n",
      "|    n_updates          | 15024       |\n",
      "|    policyGradLoss     | -0.00558    |\n",
      "|    value_loss         | 1.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 30785536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014298366 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.4         |\n",
      "|    mean_step_reward   | 0.38062108  |\n",
      "|    n_updates          | 15028       |\n",
      "|    policyGradLoss     | -0.000921   |\n",
      "|    value_loss         | 2.8         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 30793728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011163264 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.503       |\n",
      "|    mean_step_reward   | 0.43405926  |\n",
      "|    n_updates          | 15032       |\n",
      "|    policyGradLoss     | -0.000838   |\n",
      "|    value_loss         | 1.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 30801920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012154885 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.05        |\n",
      "|    mean_step_reward   | 0.37803632  |\n",
      "|    n_updates          | 15036       |\n",
      "|    policyGradLoss     | -0.00624    |\n",
      "|    value_loss         | 1.64        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 787        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 176        |\n",
      "|    total_timesteps    | 30810112   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01303681 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.966      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.82       |\n",
      "|    mean_step_reward   | 0.3684144  |\n",
      "|    n_updates          | 15040      |\n",
      "|    policyGradLoss     | -0.0017    |\n",
      "|    value_loss         | 2.08       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 30818304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008566099 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.356       |\n",
      "|    mean_step_reward   | 0.40489373  |\n",
      "|    n_updates          | 15044       |\n",
      "|    policyGradLoss     | -0.00197    |\n",
      "|    value_loss         | 2.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 30826496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012623977 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.213       |\n",
      "|    mean_step_reward   | 0.3740788   |\n",
      "|    n_updates          | 15048       |\n",
      "|    policyGradLoss     | 0.000931    |\n",
      "|    value_loss         | 2.76        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 30834688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013810835 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.498       |\n",
      "|    mean_step_reward   | 0.4708862   |\n",
      "|    n_updates          | 15052       |\n",
      "|    policyGradLoss     | -0.0025     |\n",
      "|    value_loss         | 2.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 30842880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012220863 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.2         |\n",
      "|    mean_step_reward   | 0.39969718  |\n",
      "|    n_updates          | 15056       |\n",
      "|    policyGradLoss     | -0.00369    |\n",
      "|    value_loss         | 1.99        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 30851072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012909435 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.677       |\n",
      "|    mean_step_reward   | 0.35109326  |\n",
      "|    n_updates          | 15060       |\n",
      "|    policyGradLoss     | -0.00282    |\n",
      "|    value_loss         | 2.28        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 782       |\n",
      "|    iterations         | 23        |\n",
      "|    time_elapsed       | 240       |\n",
      "|    total_timesteps    | 30859264  |\n",
      "| train/                |           |\n",
      "|    approx_kl          | 0.0158864 |\n",
      "|    entropy_loss       | -1.68     |\n",
      "|    explained_variance | 0.94      |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    loss               | 0.543     |\n",
      "|    mean_step_reward   | 0.3590936 |\n",
      "|    n_updates          | 15064     |\n",
      "|    policyGradLoss     | 0.00292   |\n",
      "|    value_loss         | 3.73      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 30867456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010363586 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.58        |\n",
      "|    mean_step_reward   | 0.3091069   |\n",
      "|    n_updates          | 15068       |\n",
      "|    policyGradLoss     | -0.00183    |\n",
      "|    value_loss         | 2.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 30875648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012071185 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.31        |\n",
      "|    mean_step_reward   | 0.41681412  |\n",
      "|    n_updates          | 15072       |\n",
      "|    policyGradLoss     | -0.00267    |\n",
      "|    value_loss         | 1.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 30883840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008328438 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.616       |\n",
      "|    mean_step_reward   | 0.4141767   |\n",
      "|    n_updates          | 15076       |\n",
      "|    policyGradLoss     | -0.00394    |\n",
      "|    value_loss         | 2.2         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 782          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 282          |\n",
      "|    total_timesteps    | 30892032     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0113250725 |\n",
      "|    entropy_loss       | -1.67        |\n",
      "|    explained_variance | 0.982        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.544        |\n",
      "|    mean_step_reward   | 0.38714302   |\n",
      "|    n_updates          | 15080        |\n",
      "|    policyGradLoss     | -0.00573     |\n",
      "|    value_loss         | 1.92         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 30900224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014440266 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.489       |\n",
      "|    mean_step_reward   | 0.397499    |\n",
      "|    n_updates          | 15084       |\n",
      "|    policyGradLoss     | -0.00848    |\n",
      "|    value_loss         | 1.55        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 303         |\n",
      "|    total_timesteps    | 30908416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015987247 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.143       |\n",
      "|    mean_step_reward   | 0.3540405   |\n",
      "|    n_updates          | 15088       |\n",
      "|    policyGradLoss     | -0.00839    |\n",
      "|    value_loss         | 0.711       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 314         |\n",
      "|    total_timesteps    | 30916608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014077324 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.292       |\n",
      "|    mean_step_reward   | 0.4228298   |\n",
      "|    n_updates          | 15092       |\n",
      "|    policyGradLoss     | -0.00636    |\n",
      "|    value_loss         | 1.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 324         |\n",
      "|    total_timesteps    | 30924800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008384997 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.13        |\n",
      "|    mean_step_reward   | 0.3710761   |\n",
      "|    n_updates          | 15096       |\n",
      "|    policyGradLoss     | -0.00484    |\n",
      "|    value_loss         | 2.34        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 334         |\n",
      "|    total_timesteps    | 30932992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016599733 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0328      |\n",
      "|    mean_step_reward   | 0.42565125  |\n",
      "|    n_updates          | 15100       |\n",
      "|    policyGradLoss     | -0.00879    |\n",
      "|    value_loss         | 0.861       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_117.zip\n",
      "[EVAL] Mean Return: 495.911, Best Return: 502.578\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_117_495.91.mp4\n",
      "\n",
      "=== Round 119 | Learn 262144 steps (Total trained: 30932992) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1091     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 30941184 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 900         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 30949376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020827344 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.92        |\n",
      "|    mean_step_reward   | 0.38480437  |\n",
      "|    n_updates          | 15108       |\n",
      "|    policyGradLoss     | -0.000785   |\n",
      "|    value_loss         | 4.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 845         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 30957568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017270954 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.485       |\n",
      "|    mean_step_reward   | 0.38279444  |\n",
      "|    n_updates          | 15112       |\n",
      "|    policyGradLoss     | -0.00374    |\n",
      "|    value_loss         | 1.52        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 30965760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012098535 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.371       |\n",
      "|    mean_step_reward   | 0.35603693  |\n",
      "|    n_updates          | 15116       |\n",
      "|    policyGradLoss     | -0.00612    |\n",
      "|    value_loss         | 2.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 30973952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015488178 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.59        |\n",
      "|    mean_step_reward   | 0.38285857  |\n",
      "|    n_updates          | 15120       |\n",
      "|    policyGradLoss     | -0.00327    |\n",
      "|    value_loss         | 1.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 30982144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015558519 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.65        |\n",
      "|    mean_step_reward   | 0.4557953   |\n",
      "|    n_updates          | 15124       |\n",
      "|    policyGradLoss     | -0.000471   |\n",
      "|    value_loss         | 3.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 30990336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020645794 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.93        |\n",
      "|    mean_step_reward   | 0.3809057   |\n",
      "|    n_updates          | 15128       |\n",
      "|    policyGradLoss     | -0.000315   |\n",
      "|    value_loss         | 2.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 30998528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012838284 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.419       |\n",
      "|    mean_step_reward   | 0.40148163  |\n",
      "|    n_updates          | 15132       |\n",
      "|    policyGradLoss     | -0.000774   |\n",
      "|    value_loss         | 3.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 31006720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011225481 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.568       |\n",
      "|    mean_step_reward   | 0.3549896   |\n",
      "|    n_updates          | 15136       |\n",
      "|    policyGradLoss     | 0.00271     |\n",
      "|    value_loss         | 2.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 31014912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012209544 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.292       |\n",
      "|    mean_step_reward   | 0.39630103  |\n",
      "|    n_updates          | 15140       |\n",
      "|    policyGradLoss     | -0.00541    |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 31023104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009746643 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.11        |\n",
      "|    mean_step_reward   | 0.42315015  |\n",
      "|    n_updates          | 15144       |\n",
      "|    policyGradLoss     | 0.000604    |\n",
      "|    value_loss         | 2.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 31031296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014116066 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.95        |\n",
      "|    mean_step_reward   | 0.36387247  |\n",
      "|    n_updates          | 15148       |\n",
      "|    policyGradLoss     | 0.00787     |\n",
      "|    value_loss         | 5.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 31039488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015656695 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.383       |\n",
      "|    mean_step_reward   | 0.3310859   |\n",
      "|    n_updates          | 15152       |\n",
      "|    policyGradLoss     | -0.00171    |\n",
      "|    value_loss         | 1.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 31047680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012415716 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.795       |\n",
      "|    mean_step_reward   | 0.40648815  |\n",
      "|    n_updates          | 15156       |\n",
      "|    policyGradLoss     | 0.000511    |\n",
      "|    value_loss         | 3.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 31055872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013551769 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.03        |\n",
      "|    mean_step_reward   | 0.33279985  |\n",
      "|    n_updates          | 15160       |\n",
      "|    policyGradLoss     | -0.00725    |\n",
      "|    value_loss         | 1.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 31064064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016166227 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.204       |\n",
      "|    mean_step_reward   | 0.44326746  |\n",
      "|    n_updates          | 15164       |\n",
      "|    policyGradLoss     | -0.00663    |\n",
      "|    value_loss         | 0.853       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 31072256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013978967 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.635       |\n",
      "|    mean_step_reward   | 0.3908132   |\n",
      "|    n_updates          | 15168       |\n",
      "|    policyGradLoss     | -0.00664    |\n",
      "|    value_loss         | 1.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 31080448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009583058 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.14        |\n",
      "|    mean_step_reward   | 0.4248464   |\n",
      "|    n_updates          | 15172       |\n",
      "|    policyGradLoss     | -0.000878   |\n",
      "|    value_loss         | 3.94        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 31088640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015082325 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.07        |\n",
      "|    mean_step_reward   | 0.37016803  |\n",
      "|    n_updates          | 15176       |\n",
      "|    policyGradLoss     | -0.00675    |\n",
      "|    value_loss         | 1.11        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 782        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 209        |\n",
      "|    total_timesteps    | 31096832   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01148067 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.977      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.241      |\n",
      "|    mean_step_reward   | 0.36947948 |\n",
      "|    n_updates          | 15180      |\n",
      "|    policyGradLoss     | -0.00338   |\n",
      "|    value_loss         | 1.84       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 31105024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015633127 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.575       |\n",
      "|    mean_step_reward   | 0.42653796  |\n",
      "|    n_updates          | 15184       |\n",
      "|    policyGradLoss     | -0.00457    |\n",
      "|    value_loss         | 2.3         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 780        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 231        |\n",
      "|    total_timesteps    | 31113216   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01184005 |\n",
      "|    entropy_loss       | -1.66      |\n",
      "|    explained_variance | 0.956      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.316      |\n",
      "|    mean_step_reward   | 0.39276773 |\n",
      "|    n_updates          | 15188      |\n",
      "|    policyGradLoss     | -0.00341   |\n",
      "|    value_loss         | 2.16       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 31121408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011770073 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.591       |\n",
      "|    mean_step_reward   | 0.35705566  |\n",
      "|    n_updates          | 15192       |\n",
      "|    policyGradLoss     | -0.00837    |\n",
      "|    value_loss         | 1.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 31129600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014168572 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.701       |\n",
      "|    mean_step_reward   | 0.35875013  |\n",
      "|    n_updates          | 15196       |\n",
      "|    policyGradLoss     | 0.00223     |\n",
      "|    value_loss         | 4.8         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 31137792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009996679 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.298       |\n",
      "|    mean_step_reward   | 0.39845502  |\n",
      "|    n_updates          | 15200       |\n",
      "|    policyGradLoss     | -0.00645    |\n",
      "|    value_loss         | 1.29        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 273        |\n",
      "|    total_timesteps    | 31145984   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01129329 |\n",
      "|    entropy_loss       | -1.7       |\n",
      "|    explained_variance | 0.986      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.573      |\n",
      "|    mean_step_reward   | 0.3800641  |\n",
      "|    n_updates          | 15204      |\n",
      "|    policyGradLoss     | -0.00645   |\n",
      "|    value_loss         | 1.76       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 31154176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013293697 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.552       |\n",
      "|    mean_step_reward   | 0.43211123  |\n",
      "|    n_updates          | 15208       |\n",
      "|    policyGradLoss     | -0.00803    |\n",
      "|    value_loss         | 1.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 31162368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013818912 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.526       |\n",
      "|    mean_step_reward   | 0.42090973  |\n",
      "|    n_updates          | 15212       |\n",
      "|    policyGradLoss     | -0.00578    |\n",
      "|    value_loss         | 1.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 31170560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016163811 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.895       |\n",
      "|    mean_step_reward   | 0.34257683  |\n",
      "|    n_updates          | 15216       |\n",
      "|    policyGradLoss     | -0.00213    |\n",
      "|    value_loss         | 1.82        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 776          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 316          |\n",
      "|    total_timesteps    | 31178752     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0128533505 |\n",
      "|    entropy_loss       | -1.66        |\n",
      "|    explained_variance | 0.99         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.557        |\n",
      "|    mean_step_reward   | 0.38707802   |\n",
      "|    n_updates          | 15220        |\n",
      "|    policyGradLoss     | -0.00931     |\n",
      "|    value_loss         | 0.975        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 31186944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008919819 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.543       |\n",
      "|    mean_step_reward   | 0.36705816  |\n",
      "|    n_updates          | 15224       |\n",
      "|    policyGradLoss     | -0.00369    |\n",
      "|    value_loss         | 2.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 31195136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011534363 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.713       |\n",
      "|    mean_step_reward   | 0.39557344  |\n",
      "|    n_updates          | 15228       |\n",
      "|    policyGradLoss     | -0.00495    |\n",
      "|    value_loss         | 2.6         |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_118.zip\n",
      "[EVAL] Mean Return: 531.084, Best Return: 537.750\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_118_531.08.mp4\n",
      "\n",
      "=== Round 120 | Learn 262144 steps (Total trained: 31195136) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1070     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 31203328 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 890         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 31211520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013148207 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.648       |\n",
      "|    mean_step_reward   | 0.33594948  |\n",
      "|    n_updates          | 15236       |\n",
      "|    policyGradLoss     | -0.00767    |\n",
      "|    value_loss         | 1.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 848         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 31219712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015782118 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.831       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.21        |\n",
      "|    mean_step_reward   | 0.32805195  |\n",
      "|    n_updates          | 15240       |\n",
      "|    policyGradLoss     | 0.00394     |\n",
      "|    value_loss         | 7.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 31227904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010104284 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.479       |\n",
      "|    mean_step_reward   | 0.41853878  |\n",
      "|    n_updates          | 15244       |\n",
      "|    policyGradLoss     | 0.000265    |\n",
      "|    value_loss         | 3.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 31236096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015667472 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.518       |\n",
      "|    mean_step_reward   | 0.31695402  |\n",
      "|    n_updates          | 15248       |\n",
      "|    policyGradLoss     | -0.00613    |\n",
      "|    value_loss         | 1.96        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 31244288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016339406 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.102       |\n",
      "|    mean_step_reward   | 0.4375366   |\n",
      "|    n_updates          | 15252       |\n",
      "|    policyGradLoss     | -0.00679    |\n",
      "|    value_loss         | 0.774       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 31252480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012823682 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.558       |\n",
      "|    mean_step_reward   | 0.37134266  |\n",
      "|    n_updates          | 15256       |\n",
      "|    policyGradLoss     | -0.00689    |\n",
      "|    value_loss         | 1.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 31260672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010639036 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.47        |\n",
      "|    mean_step_reward   | 0.3998861   |\n",
      "|    n_updates          | 15260       |\n",
      "|    policyGradLoss     | -0.00517    |\n",
      "|    value_loss         | 1.81        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 31268864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015131524 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.356       |\n",
      "|    mean_step_reward   | 0.3214897   |\n",
      "|    n_updates          | 15264       |\n",
      "|    policyGradLoss     | -0.00828    |\n",
      "|    value_loss         | 1.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 31277056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014631706 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.475       |\n",
      "|    mean_step_reward   | 0.37365028  |\n",
      "|    n_updates          | 15268       |\n",
      "|    policyGradLoss     | -0.00603    |\n",
      "|    value_loss         | 1.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 31285248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016232988 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.408       |\n",
      "|    mean_step_reward   | 0.4125393   |\n",
      "|    n_updates          | 15272       |\n",
      "|    policyGradLoss     | -0.0047     |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 790        |\n",
      "|    iterations         | 12         |\n",
      "|    time_elapsed       | 124        |\n",
      "|    total_timesteps    | 31293440   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01387843 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.38       |\n",
      "|    mean_step_reward   | 0.34436494 |\n",
      "|    n_updates          | 15276      |\n",
      "|    policyGradLoss     | -0.00697   |\n",
      "|    value_loss         | 1.26       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 31301632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009377716 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.942       |\n",
      "|    mean_step_reward   | 0.37551787  |\n",
      "|    n_updates          | 15280       |\n",
      "|    policyGradLoss     | -0.0039     |\n",
      "|    value_loss         | 1.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 31309824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011044145 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.665       |\n",
      "|    mean_step_reward   | 0.41801816  |\n",
      "|    n_updates          | 15284       |\n",
      "|    policyGradLoss     | -0.00699    |\n",
      "|    value_loss         | 1.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 31318016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010655614 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.591       |\n",
      "|    mean_step_reward   | 0.4399686   |\n",
      "|    n_updates          | 15288       |\n",
      "|    policyGradLoss     | -0.00451    |\n",
      "|    value_loss         | 1.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 31326208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011414137 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.613       |\n",
      "|    mean_step_reward   | 0.4396108   |\n",
      "|    n_updates          | 15292       |\n",
      "|    policyGradLoss     | -0.00551    |\n",
      "|    value_loss         | 1.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 31334400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009492046 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.67        |\n",
      "|    mean_step_reward   | 0.38507032  |\n",
      "|    n_updates          | 15296       |\n",
      "|    policyGradLoss     | -0.00611    |\n",
      "|    value_loss         | 1.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 31342592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010859866 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.556       |\n",
      "|    mean_step_reward   | 0.39230072  |\n",
      "|    n_updates          | 15300       |\n",
      "|    policyGradLoss     | -0.00363    |\n",
      "|    value_loss         | 2.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 31350784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011414043 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.494       |\n",
      "|    mean_step_reward   | 0.44999295  |\n",
      "|    n_updates          | 15304       |\n",
      "|    policyGradLoss     | -0.00456    |\n",
      "|    value_loss         | 1.45        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 31358976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008190222 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.56        |\n",
      "|    mean_step_reward   | 0.4080071   |\n",
      "|    n_updates          | 15308       |\n",
      "|    policyGradLoss     | -0.00354    |\n",
      "|    value_loss         | 2.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 31367168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017094113 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.566       |\n",
      "|    mean_step_reward   | 0.38610286  |\n",
      "|    n_updates          | 15312       |\n",
      "|    policyGradLoss     | -0.00913    |\n",
      "|    value_loss         | 1.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 31375360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009644639 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.175       |\n",
      "|    mean_step_reward   | 0.43219423  |\n",
      "|    n_updates          | 15316       |\n",
      "|    policyGradLoss     | -0.00166    |\n",
      "|    value_loss         | 2.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 31383552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014252242 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.03        |\n",
      "|    mean_step_reward   | 0.35962164  |\n",
      "|    n_updates          | 15320       |\n",
      "|    policyGradLoss     | -0.0037     |\n",
      "|    value_loss         | 2.55        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 31391744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017769188 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.287       |\n",
      "|    mean_step_reward   | 0.4437027   |\n",
      "|    n_updates          | 15324       |\n",
      "|    policyGradLoss     | 0.00106     |\n",
      "|    value_loss         | 3.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 31399936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008091612 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.13        |\n",
      "|    mean_step_reward   | 0.41537297  |\n",
      "|    n_updates          | 15328       |\n",
      "|    policyGradLoss     | -0.00414    |\n",
      "|    value_loss         | 1.96        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 31408128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019231115 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.597       |\n",
      "|    mean_step_reward   | 0.35606694  |\n",
      "|    n_updates          | 15332       |\n",
      "|    policyGradLoss     | -0.00781    |\n",
      "|    value_loss         | 1.71        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 31416320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012005132 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.349       |\n",
      "|    mean_step_reward   | 0.46506548  |\n",
      "|    n_updates          | 15336       |\n",
      "|    policyGradLoss     | -0.00783    |\n",
      "|    value_loss         | 1.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 31424512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010122903 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.25        |\n",
      "|    mean_step_reward   | 0.35478845  |\n",
      "|    n_updates          | 15340       |\n",
      "|    policyGradLoss     | -0.00405    |\n",
      "|    value_loss         | 2.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 31432704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013490533 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.146       |\n",
      "|    mean_step_reward   | 0.43929046  |\n",
      "|    n_updates          | 15344       |\n",
      "|    policyGradLoss     | -0.00404    |\n",
      "|    value_loss         | 0.87        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 779          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 315          |\n",
      "|    total_timesteps    | 31440896     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0084041115 |\n",
      "|    entropy_loss       | -1.75        |\n",
      "|    explained_variance | 0.988        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.289        |\n",
      "|    mean_step_reward   | 0.36989456   |\n",
      "|    n_updates          | 15348        |\n",
      "|    policyGradLoss     | -0.00416     |\n",
      "|    value_loss         | 2.04         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 325        |\n",
      "|    total_timesteps    | 31449088   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00858552 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.98       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.365      |\n",
      "|    mean_step_reward   | 0.37176272 |\n",
      "|    n_updates          | 15352      |\n",
      "|    policyGradLoss     | -0.00443   |\n",
      "|    value_loss         | 1.91       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 31457280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016111314 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 2.14        |\n",
      "|    mean_step_reward   | 0.42836624  |\n",
      "|    n_updates          | 15356       |\n",
      "|    policyGradLoss     | 0.00141     |\n",
      "|    value_loss         | 5.09        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_119.zip\n",
      "[EVAL] Mean Return: 531.731, Best Return: 538.398\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_119_531.73.mp4\n",
      "\n",
      "=== Round 121 | Learn 262144 steps (Total trained: 31457280) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1124     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 31465472 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 911         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 31473664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020699717 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.607       |\n",
      "|    mean_step_reward   | 0.48547164  |\n",
      "|    n_updates          | 15364       |\n",
      "|    policyGradLoss     | 0.0116      |\n",
      "|    value_loss         | 2.74        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 854         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 31481856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012805844 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.03        |\n",
      "|    mean_step_reward   | 0.35908526  |\n",
      "|    n_updates          | 15368       |\n",
      "|    policyGradLoss     | -0.00502    |\n",
      "|    value_loss         | 1.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 831         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 31490048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017450847 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.974       |\n",
      "|    mean_step_reward   | 0.33947933  |\n",
      "|    n_updates          | 15372       |\n",
      "|    policyGradLoss     | -0.00796    |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 31498240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013960679 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.492       |\n",
      "|    mean_step_reward   | 0.45474374  |\n",
      "|    n_updates          | 15376       |\n",
      "|    policyGradLoss     | -0.00714    |\n",
      "|    value_loss         | 1.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 31506432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008019979 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.78        |\n",
      "|    mean_step_reward   | 0.33741775  |\n",
      "|    n_updates          | 15380       |\n",
      "|    policyGradLoss     | -0.00512    |\n",
      "|    value_loss         | 2.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 31514624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016643614 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.413       |\n",
      "|    mean_step_reward   | 0.44130993  |\n",
      "|    n_updates          | 15384       |\n",
      "|    policyGradLoss     | -0.00739    |\n",
      "|    value_loss         | 1.07        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 31522816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013301636 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.525       |\n",
      "|    mean_step_reward   | 0.34814036  |\n",
      "|    n_updates          | 15388       |\n",
      "|    policyGradLoss     | -0.00677    |\n",
      "|    value_loss         | 1.63        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 795        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 92         |\n",
      "|    total_timesteps    | 31531008   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01741413 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.985      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.682      |\n",
      "|    mean_step_reward   | 0.3425508  |\n",
      "|    n_updates          | 15392      |\n",
      "|    policyGradLoss     | -0.00568   |\n",
      "|    value_loss         | 1.63       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 792          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 103          |\n",
      "|    total_timesteps    | 31539200     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0151853375 |\n",
      "|    entropy_loss       | -1.6         |\n",
      "|    explained_variance | 0.992        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0554       |\n",
      "|    mean_step_reward   | 0.43146923   |\n",
      "|    n_updates          | 15396        |\n",
      "|    policyGradLoss     | -0.00806     |\n",
      "|    value_loss         | 0.904        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 31547392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011816688 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.339       |\n",
      "|    mean_step_reward   | 0.37504613  |\n",
      "|    n_updates          | 15400       |\n",
      "|    policyGradLoss     | -0.00494    |\n",
      "|    value_loss         | 1.8         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 31555584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014369668 |\n",
      "|    entropy_loss       | -1.56       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.365       |\n",
      "|    mean_step_reward   | 0.4589346   |\n",
      "|    n_updates          | 15404       |\n",
      "|    policyGradLoss     | -0.00631    |\n",
      "|    value_loss         | 0.843       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 31563776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012752823 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.313       |\n",
      "|    mean_step_reward   | 0.3961993   |\n",
      "|    n_updates          | 15408       |\n",
      "|    policyGradLoss     | -0.00662    |\n",
      "|    value_loss         | 1.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 31571968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013486788 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.85        |\n",
      "|    mean_step_reward   | 0.3534001   |\n",
      "|    n_updates          | 15412       |\n",
      "|    policyGradLoss     | -0.00471    |\n",
      "|    value_loss         | 2.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 31580160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024329575 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.203       |\n",
      "|    mean_step_reward   | 0.40810984  |\n",
      "|    n_updates          | 15416       |\n",
      "|    policyGradLoss     | -0.00723    |\n",
      "|    value_loss         | 0.732       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 783        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 167        |\n",
      "|    total_timesteps    | 31588352   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01749974 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.966      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.531      |\n",
      "|    mean_step_reward   | 0.37589544 |\n",
      "|    n_updates          | 15420      |\n",
      "|    policyGradLoss     | -0.00206   |\n",
      "|    value_loss         | 3.83       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 31596544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011644151 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.463       |\n",
      "|    mean_step_reward   | 0.43893307  |\n",
      "|    n_updates          | 15424       |\n",
      "|    policyGradLoss     | -0.00454    |\n",
      "|    value_loss         | 0.994       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 31604736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014098375 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.558       |\n",
      "|    mean_step_reward   | 0.4270516   |\n",
      "|    n_updates          | 15428       |\n",
      "|    policyGradLoss     | -0.00501    |\n",
      "|    value_loss         | 1.9         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 781          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 199          |\n",
      "|    total_timesteps    | 31612928     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0120868245 |\n",
      "|    entropy_loss       | -1.67        |\n",
      "|    explained_variance | 0.96         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.39         |\n",
      "|    mean_step_reward   | 0.3858769    |\n",
      "|    n_updates          | 15432        |\n",
      "|    policyGradLoss     | -0.00223     |\n",
      "|    value_loss         | 5.28         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 31621120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013208974 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.16        |\n",
      "|    mean_step_reward   | 0.42837515  |\n",
      "|    n_updates          | 15436       |\n",
      "|    policyGradLoss     | -0.000509   |\n",
      "|    value_loss         | 3.83        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 31629312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014546138 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.789       |\n",
      "|    mean_step_reward   | 0.37725437  |\n",
      "|    n_updates          | 15440       |\n",
      "|    policyGradLoss     | -0.00324    |\n",
      "|    value_loss         | 2.83        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 31637504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011260399 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.667       |\n",
      "|    mean_step_reward   | 0.4606962   |\n",
      "|    n_updates          | 15444       |\n",
      "|    policyGradLoss     | -0.00207    |\n",
      "|    value_loss         | 2.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 31645696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018655352 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.473       |\n",
      "|    mean_step_reward   | 0.3798866   |\n",
      "|    n_updates          | 15448       |\n",
      "|    policyGradLoss     | -0.004      |\n",
      "|    value_loss         | 1.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 31653888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012706669 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.451       |\n",
      "|    mean_step_reward   | 0.420622    |\n",
      "|    n_updates          | 15452       |\n",
      "|    policyGradLoss     | -0.00579    |\n",
      "|    value_loss         | 1.07        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 31662080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010374672 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.847       |\n",
      "|    mean_step_reward   | 0.38802624  |\n",
      "|    n_updates          | 15456       |\n",
      "|    policyGradLoss     | -0.00257    |\n",
      "|    value_loss         | 2.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 31670272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012917662 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.987       |\n",
      "|    mean_step_reward   | 0.41347393  |\n",
      "|    n_updates          | 15460       |\n",
      "|    policyGradLoss     | -0.00156    |\n",
      "|    value_loss         | 2.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 31678464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012775287 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.578       |\n",
      "|    mean_step_reward   | 0.45185065  |\n",
      "|    n_updates          | 15464       |\n",
      "|    policyGradLoss     | 0.000341    |\n",
      "|    value_loss         | 3.33        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 780          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 294          |\n",
      "|    total_timesteps    | 31686656     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0121179335 |\n",
      "|    entropy_loss       | -1.72        |\n",
      "|    explained_variance | 0.973        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.843        |\n",
      "|    mean_step_reward   | 0.3586456    |\n",
      "|    n_updates          | 15468        |\n",
      "|    policyGradLoss     | 0.00231      |\n",
      "|    value_loss         | 3.06         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 31694848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011117928 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.16        |\n",
      "|    mean_step_reward   | 0.42027012  |\n",
      "|    n_updates          | 15472       |\n",
      "|    policyGradLoss     | 0.0017      |\n",
      "|    value_loss         | 4.82        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 315        |\n",
      "|    total_timesteps    | 31703040   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01114288 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.971      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.699      |\n",
      "|    mean_step_reward   | 0.34397498 |\n",
      "|    n_updates          | 15476      |\n",
      "|    policyGradLoss     | 0.000221   |\n",
      "|    value_loss         | 2.93       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 31711232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012512985 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.932       |\n",
      "|    mean_step_reward   | 0.37358797  |\n",
      "|    n_updates          | 15480       |\n",
      "|    policyGradLoss     | -0.00436    |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 31719424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010269304 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.14        |\n",
      "|    mean_step_reward   | 0.44135085  |\n",
      "|    n_updates          | 15484       |\n",
      "|    policyGradLoss     | -0.00629    |\n",
      "|    value_loss         | 1.75        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_120.zip\n",
      "[EVAL] Mean Return: 532.978, Best Return: 539.645\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_120_532.98.mp4\n",
      "\n",
      "=== Round 122 | Learn 262144 steps (Total trained: 31719424) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1126     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 31727616 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 919         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 31735808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015658688 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.387       |\n",
      "|    mean_step_reward   | 0.42703512  |\n",
      "|    n_updates          | 15492       |\n",
      "|    policyGradLoss     | -0.00388    |\n",
      "|    value_loss         | 1.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 860         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 31744000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013322771 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.729       |\n",
      "|    mean_step_reward   | 0.3553208   |\n",
      "|    n_updates          | 15496       |\n",
      "|    policyGradLoss     | -0.00628    |\n",
      "|    value_loss         | 2.11        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 833         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 31752192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008978522 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.474       |\n",
      "|    mean_step_reward   | 0.3583075   |\n",
      "|    n_updates          | 15500       |\n",
      "|    policyGradLoss     | -0.00372    |\n",
      "|    value_loss         | 1.94        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 31760384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023045996 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.268       |\n",
      "|    mean_step_reward   | 0.42158967  |\n",
      "|    n_updates          | 15504       |\n",
      "|    policyGradLoss     | -0.0096     |\n",
      "|    value_loss         | 0.906       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 31768576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011069524 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.753       |\n",
      "|    mean_step_reward   | 0.42255387  |\n",
      "|    n_updates          | 15508       |\n",
      "|    policyGradLoss     | -0.00411    |\n",
      "|    value_loss         | 1.89        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 31776768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013128633 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.698       |\n",
      "|    mean_step_reward   | 0.42105752  |\n",
      "|    n_updates          | 15512       |\n",
      "|    policyGradLoss     | 0.0018      |\n",
      "|    value_loss         | 4.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 31784960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018442199 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.375       |\n",
      "|    mean_step_reward   | 0.33578694  |\n",
      "|    n_updates          | 15516       |\n",
      "|    policyGradLoss     | -0.00516    |\n",
      "|    value_loss         | 1.17        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 795          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 92           |\n",
      "|    total_timesteps    | 31793152     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0132482555 |\n",
      "|    entropy_loss       | -1.67        |\n",
      "|    explained_variance | 0.988        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.678        |\n",
      "|    mean_step_reward   | 0.37056836   |\n",
      "|    n_updates          | 15520        |\n",
      "|    policyGradLoss     | -0.00583     |\n",
      "|    value_loss         | 1.53         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 31801344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010152742 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.931       |\n",
      "|    mean_step_reward   | 0.42079318  |\n",
      "|    n_updates          | 15524       |\n",
      "|    policyGradLoss     | -0.00398    |\n",
      "|    value_loss         | 2.93        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 31809536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011032101 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.64        |\n",
      "|    mean_step_reward   | 0.41256964  |\n",
      "|    n_updates          | 15528       |\n",
      "|    policyGradLoss     | -0.00702    |\n",
      "|    value_loss         | 1.75        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 31817728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009424768 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.34        |\n",
      "|    mean_step_reward   | 0.35211653  |\n",
      "|    n_updates          | 15532       |\n",
      "|    policyGradLoss     | -0.0014     |\n",
      "|    value_loss         | 1.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 31825920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013720083 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.236       |\n",
      "|    mean_step_reward   | 0.3833344   |\n",
      "|    n_updates          | 15536       |\n",
      "|    policyGradLoss     | -0.00719    |\n",
      "|    value_loss         | 1.45        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 31834112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013846526 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.53        |\n",
      "|    mean_step_reward   | 0.40628394  |\n",
      "|    n_updates          | 15540       |\n",
      "|    policyGradLoss     | -0.0061     |\n",
      "|    value_loss         | 1.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 31842304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018696997 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.768       |\n",
      "|    mean_step_reward   | 0.3666623   |\n",
      "|    n_updates          | 15544       |\n",
      "|    policyGradLoss     | -0.00396    |\n",
      "|    value_loss         | 2.07        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 31850496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015569379 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.269       |\n",
      "|    mean_step_reward   | 0.3656671   |\n",
      "|    n_updates          | 15548       |\n",
      "|    policyGradLoss     | -0.0092     |\n",
      "|    value_loss         | 0.746       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 31858688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012819015 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.509       |\n",
      "|    mean_step_reward   | 0.41840923  |\n",
      "|    n_updates          | 15552       |\n",
      "|    policyGradLoss     | -0.00758    |\n",
      "|    value_loss         | 1.48        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 778          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 189          |\n",
      "|    total_timesteps    | 31866880     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0091013145 |\n",
      "|    entropy_loss       | -1.63        |\n",
      "|    explained_variance | 0.952        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.815        |\n",
      "|    mean_step_reward   | 0.44908783   |\n",
      "|    n_updates          | 15556        |\n",
      "|    policyGradLoss     | 0.0011       |\n",
      "|    value_loss         | 4.59         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 31875072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005518082 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 2.16        |\n",
      "|    mean_step_reward   | 0.37676775  |\n",
      "|    n_updates          | 15560       |\n",
      "|    policyGradLoss     | -0.0017     |\n",
      "|    value_loss         | 2.5         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 31883264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012140483 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.194       |\n",
      "|    mean_step_reward   | 0.33711034  |\n",
      "|    n_updates          | 15564       |\n",
      "|    policyGradLoss     | -0.00268    |\n",
      "|    value_loss         | 2.07        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 31891456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008368225 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.611       |\n",
      "|    mean_step_reward   | 0.40914577  |\n",
      "|    n_updates          | 15568       |\n",
      "|    policyGradLoss     | -0.0039     |\n",
      "|    value_loss         | 1.93        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 31899648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010844022 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.943       |\n",
      "|    mean_step_reward   | 0.3664806   |\n",
      "|    n_updates          | 15572       |\n",
      "|    policyGradLoss     | 0.00584     |\n",
      "|    value_loss         | 2.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 31907840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012216312 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.765       |\n",
      "|    mean_step_reward   | 0.409212    |\n",
      "|    n_updates          | 15576       |\n",
      "|    policyGradLoss     | -0.00385    |\n",
      "|    value_loss         | 1.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 31916032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008696245 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.681       |\n",
      "|    mean_step_reward   | 0.32760447  |\n",
      "|    n_updates          | 15580       |\n",
      "|    policyGradLoss     | -0.00495    |\n",
      "|    value_loss         | 2.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 31924224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010714849 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.185       |\n",
      "|    mean_step_reward   | 0.42882213  |\n",
      "|    n_updates          | 15584       |\n",
      "|    policyGradLoss     | -0.00651    |\n",
      "|    value_loss         | 0.932       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 31932416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010604655 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.469       |\n",
      "|    mean_step_reward   | 0.3053131   |\n",
      "|    n_updates          | 15588       |\n",
      "|    policyGradLoss     | -0.00321    |\n",
      "|    value_loss         | 2.26        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 775          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 285          |\n",
      "|    total_timesteps    | 31940608     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0121013895 |\n",
      "|    entropy_loss       | -1.64        |\n",
      "|    explained_variance | 0.99         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.405        |\n",
      "|    mean_step_reward   | 0.41977063   |\n",
      "|    n_updates          | 15592        |\n",
      "|    policyGradLoss     | -0.00826     |\n",
      "|    value_loss         | 1.16         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 31948800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012027179 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.259       |\n",
      "|    mean_step_reward   | 0.35853356  |\n",
      "|    n_updates          | 15596       |\n",
      "|    policyGradLoss     | -0.0082     |\n",
      "|    value_loss         | 1.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 31956992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012813594 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.396       |\n",
      "|    mean_step_reward   | 0.37541455  |\n",
      "|    n_updates          | 15600       |\n",
      "|    policyGradLoss     | -0.00597    |\n",
      "|    value_loss         | 1.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 31965184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017136645 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.336       |\n",
      "|    mean_step_reward   | 0.45647204  |\n",
      "|    n_updates          | 15604       |\n",
      "|    policyGradLoss     | -0.00395    |\n",
      "|    value_loss         | 1.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 31973376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009738472 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.575       |\n",
      "|    mean_step_reward   | 0.36816582  |\n",
      "|    n_updates          | 15608       |\n",
      "|    policyGradLoss     | -0.00334    |\n",
      "|    value_loss         | 2.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 31981568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.036348622 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.1         |\n",
      "|    mean_step_reward   | 0.37206244  |\n",
      "|    n_updates          | 15612       |\n",
      "|    policyGradLoss     | 6.93e-05    |\n",
      "|    value_loss         | 4.88        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_121.zip\n",
      "[EVAL] Mean Return: 531.892, Best Return: 538.559\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_121_531.89.mp4\n",
      "\n",
      "=== Round 123 | Learn 262144 steps (Total trained: 31981568) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1143     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 31989760 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 940         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 31997952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013148665 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.293       |\n",
      "|    mean_step_reward   | 0.35937017  |\n",
      "|    n_updates          | 15620       |\n",
      "|    policyGradLoss     | -0.00209    |\n",
      "|    value_loss         | 1.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 875         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 32006144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012840636 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.356       |\n",
      "|    mean_step_reward   | 0.439148    |\n",
      "|    n_updates          | 15624       |\n",
      "|    policyGradLoss     | -0.00382    |\n",
      "|    value_loss         | 2.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 842         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 32014336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010797931 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.01        |\n",
      "|    mean_step_reward   | 0.37830907  |\n",
      "|    n_updates          | 15628       |\n",
      "|    policyGradLoss     | -0.00539    |\n",
      "|    value_loss         | 1.92        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 32022528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014088424 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.715       |\n",
      "|    mean_step_reward   | 0.4141152   |\n",
      "|    n_updates          | 15632       |\n",
      "|    policyGradLoss     | -0.00687    |\n",
      "|    value_loss         | 1.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 32030720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009087408 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.491       |\n",
      "|    mean_step_reward   | 0.3893159   |\n",
      "|    n_updates          | 15636       |\n",
      "|    policyGradLoss     | -0.005      |\n",
      "|    value_loss         | 2.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 32038912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011785302 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.542       |\n",
      "|    mean_step_reward   | 0.44509056  |\n",
      "|    n_updates          | 15640       |\n",
      "|    policyGradLoss     | -0.00726    |\n",
      "|    value_loss         | 1.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 32047104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010027204 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.38        |\n",
      "|    mean_step_reward   | 0.4147792   |\n",
      "|    n_updates          | 15644       |\n",
      "|    policyGradLoss     | -0.00144    |\n",
      "|    value_loss         | 2.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 32055296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009054985 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.557       |\n",
      "|    mean_step_reward   | 0.3891691   |\n",
      "|    n_updates          | 15648       |\n",
      "|    policyGradLoss     | -0.000361   |\n",
      "|    value_loss         | 2.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 32063488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010293443 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.39        |\n",
      "|    mean_step_reward   | 0.43929416  |\n",
      "|    n_updates          | 15652       |\n",
      "|    policyGradLoss     | -0.00445    |\n",
      "|    value_loss         | 2.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 32071680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012846904 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.972       |\n",
      "|    mean_step_reward   | 0.37224162  |\n",
      "|    n_updates          | 15656       |\n",
      "|    policyGradLoss     | -0.00438    |\n",
      "|    value_loss         | 1.9         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 32079872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014626824 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.426       |\n",
      "|    mean_step_reward   | 0.38367403  |\n",
      "|    n_updates          | 15660       |\n",
      "|    policyGradLoss     | -0.00381    |\n",
      "|    value_loss         | 1.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 32088064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013327785 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.727       |\n",
      "|    mean_step_reward   | 0.33700114  |\n",
      "|    n_updates          | 15664       |\n",
      "|    policyGradLoss     | -0.00213    |\n",
      "|    value_loss         | 2.65        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 32096256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012281789 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.63        |\n",
      "|    mean_step_reward   | 0.3263415   |\n",
      "|    n_updates          | 15668       |\n",
      "|    policyGradLoss     | -0.00696    |\n",
      "|    value_loss         | 1.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 32104448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014592117 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.66        |\n",
      "|    mean_step_reward   | 0.3905843   |\n",
      "|    n_updates          | 15672       |\n",
      "|    policyGradLoss     | -0.00817    |\n",
      "|    value_loss         | 1.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 32112640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012253329 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.714       |\n",
      "|    mean_step_reward   | 0.32512844  |\n",
      "|    n_updates          | 15676       |\n",
      "|    policyGradLoss     | 0.00285     |\n",
      "|    value_loss         | 3.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 32120832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013503252 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.491       |\n",
      "|    mean_step_reward   | 0.3743692   |\n",
      "|    n_updates          | 15680       |\n",
      "|    policyGradLoss     | -0.0098     |\n",
      "|    value_loss         | 1.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 32129024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015039191 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.653       |\n",
      "|    mean_step_reward   | 0.3520982   |\n",
      "|    n_updates          | 15684       |\n",
      "|    policyGradLoss     | -0.00598    |\n",
      "|    value_loss         | 1.62        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 779          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 199          |\n",
      "|    total_timesteps    | 32137216     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0076889647 |\n",
      "|    entropy_loss       | -1.67        |\n",
      "|    explained_variance | 0.983        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.74         |\n",
      "|    mean_step_reward   | 0.40176302   |\n",
      "|    n_updates          | 15688        |\n",
      "|    policyGradLoss     | -0.00391     |\n",
      "|    value_loss         | 2.01         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 210        |\n",
      "|    total_timesteps    | 32145408   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01293498 |\n",
      "|    entropy_loss       | -1.63      |\n",
      "|    explained_variance | 0.988      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.181      |\n",
      "|    mean_step_reward   | 0.3623069  |\n",
      "|    n_updates          | 15692      |\n",
      "|    policyGradLoss     | -0.00724   |\n",
      "|    value_loss         | 1.02       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 32153600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014265188 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.312       |\n",
      "|    mean_step_reward   | 0.34744668  |\n",
      "|    n_updates          | 15696       |\n",
      "|    policyGradLoss     | -0.00898    |\n",
      "|    value_loss         | 1.52        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 32161792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009930953 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.05        |\n",
      "|    mean_step_reward   | 0.35181892  |\n",
      "|    n_updates          | 15700       |\n",
      "|    policyGradLoss     | -0.00351    |\n",
      "|    value_loss         | 2.38        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 242        |\n",
      "|    total_timesteps    | 32169984   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01034259 |\n",
      "|    entropy_loss       | -1.68      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.628      |\n",
      "|    mean_step_reward   | 0.39757198 |\n",
      "|    n_updates          | 15704      |\n",
      "|    policyGradLoss     | -0.00451   |\n",
      "|    value_loss         | 1.52       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 32178176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012904136 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.757       |\n",
      "|    mean_step_reward   | 0.3743084   |\n",
      "|    n_updates          | 15708       |\n",
      "|    policyGradLoss     | -0.00405    |\n",
      "|    value_loss         | 2.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 32186368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010893336 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.15        |\n",
      "|    mean_step_reward   | 0.40349507  |\n",
      "|    n_updates          | 15712       |\n",
      "|    policyGradLoss     | -0.00636    |\n",
      "|    value_loss         | 1.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 32194560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009615913 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.747       |\n",
      "|    mean_step_reward   | 0.37514836  |\n",
      "|    n_updates          | 15716       |\n",
      "|    policyGradLoss     | -0.00517    |\n",
      "|    value_loss         | 1.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 32202752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010805506 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.28        |\n",
      "|    mean_step_reward   | 0.4192375   |\n",
      "|    n_updates          | 15720       |\n",
      "|    policyGradLoss     | -0.00437    |\n",
      "|    value_loss         | 2.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 32210944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009012345 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.603       |\n",
      "|    mean_step_reward   | 0.4537059   |\n",
      "|    n_updates          | 15724       |\n",
      "|    policyGradLoss     | -0.00257    |\n",
      "|    value_loss         | 1.85        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 775        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 306        |\n",
      "|    total_timesteps    | 32219136   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00677923 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.99       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.703      |\n",
      "|    mean_step_reward   | 0.40653574 |\n",
      "|    n_updates          | 15728      |\n",
      "|    policyGradLoss     | -0.00502   |\n",
      "|    value_loss         | 1.82       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 32227328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015519131 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.355       |\n",
      "|    mean_step_reward   | 0.40189838  |\n",
      "|    n_updates          | 15732       |\n",
      "|    policyGradLoss     | -0.00471    |\n",
      "|    value_loss         | 1.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 32235520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015396742 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.856       |\n",
      "|    mean_step_reward   | 0.41842422  |\n",
      "|    n_updates          | 15736       |\n",
      "|    policyGradLoss     | -0.00371    |\n",
      "|    value_loss         | 2.97        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 32243712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011711817 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.989       |\n",
      "|    mean_step_reward   | 0.42868197  |\n",
      "|    n_updates          | 15740       |\n",
      "|    policyGradLoss     | -0.00344    |\n",
      "|    value_loss         | 2.9         |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_122.zip\n",
      "[EVAL] Mean Return: 531.487, Best Return: 538.487\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_122_531.49.mp4\n",
      "\n",
      "=== Round 124 | Learn 262144 steps (Total trained: 32243712) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1177     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 32251904 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 933         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 32260096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012008362 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.793       |\n",
      "|    mean_step_reward   | 0.39363414  |\n",
      "|    n_updates          | 15748       |\n",
      "|    policyGradLoss     | -0.00164    |\n",
      "|    value_loss         | 2.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 873         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 32268288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010431823 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.43        |\n",
      "|    mean_step_reward   | 0.37853146  |\n",
      "|    n_updates          | 15752       |\n",
      "|    policyGradLoss     | -0.00528    |\n",
      "|    value_loss         | 1.98        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 841         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 32276480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011699042 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.643       |\n",
      "|    mean_step_reward   | 0.43995935  |\n",
      "|    n_updates          | 15756       |\n",
      "|    policyGradLoss     | -0.00616    |\n",
      "|    value_loss         | 1.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 828         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 32284672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017503373 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.51        |\n",
      "|    mean_step_reward   | 0.4189536   |\n",
      "|    n_updates          | 15760       |\n",
      "|    policyGradLoss     | -0.00473    |\n",
      "|    value_loss         | 1.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 32292864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016206963 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.345       |\n",
      "|    mean_step_reward   | 0.42761952  |\n",
      "|    n_updates          | 15764       |\n",
      "|    policyGradLoss     | -0.00617    |\n",
      "|    value_loss         | 1.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 32301056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012682961 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.727       |\n",
      "|    mean_step_reward   | 0.3939213   |\n",
      "|    n_updates          | 15768       |\n",
      "|    policyGradLoss     | -0.0058     |\n",
      "|    value_loss         | 1.95        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 32309248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013464874 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.657       |\n",
      "|    mean_step_reward   | 0.4087151   |\n",
      "|    n_updates          | 15772       |\n",
      "|    policyGradLoss     | -0.00462    |\n",
      "|    value_loss         | 1.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 32317440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016963521 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.377       |\n",
      "|    mean_step_reward   | 0.41791427  |\n",
      "|    n_updates          | 15776       |\n",
      "|    policyGradLoss     | -0.00612    |\n",
      "|    value_loss         | 1.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 32325632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012455012 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.26        |\n",
      "|    mean_step_reward   | 0.35925227  |\n",
      "|    n_updates          | 15780       |\n",
      "|    policyGradLoss     | -0.00509    |\n",
      "|    value_loss         | 1.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 32333824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017218176 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.29        |\n",
      "|    mean_step_reward   | 0.47986895  |\n",
      "|    n_updates          | 15784       |\n",
      "|    policyGradLoss     | -0.00362    |\n",
      "|    value_loss         | 1.35        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 790        |\n",
      "|    iterations         | 12         |\n",
      "|    time_elapsed       | 124        |\n",
      "|    total_timesteps    | 32342016   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01213234 |\n",
      "|    entropy_loss       | -1.74      |\n",
      "|    explained_variance | 0.986      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.564      |\n",
      "|    mean_step_reward   | 0.38361734 |\n",
      "|    n_updates          | 15788      |\n",
      "|    policyGradLoss     | -0.00376   |\n",
      "|    value_loss         | 2.15       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 32350208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016847122 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.311       |\n",
      "|    mean_step_reward   | 0.4237979   |\n",
      "|    n_updates          | 15792       |\n",
      "|    policyGradLoss     | -0.00631    |\n",
      "|    value_loss         | 1.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 32358400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015730003 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.723       |\n",
      "|    mean_step_reward   | 0.38611183  |\n",
      "|    n_updates          | 15796       |\n",
      "|    policyGradLoss     | -0.00767    |\n",
      "|    value_loss         | 1.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 32366592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015584863 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.54        |\n",
      "|    mean_step_reward   | 0.3847014   |\n",
      "|    n_updates          | 15800       |\n",
      "|    policyGradLoss     | -0.00827    |\n",
      "|    value_loss         | 0.853       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 32374784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020848766 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.996       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.28        |\n",
      "|    mean_step_reward   | 0.44926208  |\n",
      "|    n_updates          | 15804       |\n",
      "|    policyGradLoss     | -0.00967    |\n",
      "|    value_loss         | 0.762       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 780          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 178          |\n",
      "|    total_timesteps    | 32382976     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0115374895 |\n",
      "|    entropy_loss       | -1.67        |\n",
      "|    explained_variance | 0.987        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.49         |\n",
      "|    mean_step_reward   | 0.41309714   |\n",
      "|    n_updates          | 15808        |\n",
      "|    policyGradLoss     | -0.00461     |\n",
      "|    value_loss         | 1.94         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 32391168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012322567 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.11        |\n",
      "|    mean_step_reward   | 0.46591306  |\n",
      "|    n_updates          | 15812       |\n",
      "|    policyGradLoss     | -0.00333    |\n",
      "|    value_loss         | 3.11        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 199        |\n",
      "|    total_timesteps    | 32399360   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01150484 |\n",
      "|    entropy_loss       | -1.7       |\n",
      "|    explained_variance | 0.961      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.31       |\n",
      "|    mean_step_reward   | 0.33637953 |\n",
      "|    n_updates          | 15816      |\n",
      "|    policyGradLoss     | -0.00214   |\n",
      "|    value_loss         | 2.68       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 32407552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013175873 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.451       |\n",
      "|    mean_step_reward   | 0.45865273  |\n",
      "|    n_updates          | 15820       |\n",
      "|    policyGradLoss     | -0.0034     |\n",
      "|    value_loss         | 1.75        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 32415744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010031942 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.528       |\n",
      "|    mean_step_reward   | 0.38008043  |\n",
      "|    n_updates          | 15824       |\n",
      "|    policyGradLoss     | -0.00338    |\n",
      "|    value_loss         | 2.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 32423936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011507906 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.673       |\n",
      "|    mean_step_reward   | 0.37580585  |\n",
      "|    n_updates          | 15828       |\n",
      "|    policyGradLoss     | -0.00421    |\n",
      "|    value_loss         | 2.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 32432128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014978356 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.369       |\n",
      "|    mean_step_reward   | 0.4097045   |\n",
      "|    n_updates          | 15832       |\n",
      "|    policyGradLoss     | -0.00665    |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 32440320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013721498 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.361       |\n",
      "|    mean_step_reward   | 0.43007314  |\n",
      "|    n_updates          | 15836       |\n",
      "|    policyGradLoss     | -0.00555    |\n",
      "|    value_loss         | 1.18        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 776        |\n",
      "|    iterations         | 25         |\n",
      "|    time_elapsed       | 263        |\n",
      "|    total_timesteps    | 32448512   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01550475 |\n",
      "|    entropy_loss       | -1.66      |\n",
      "|    explained_variance | 0.978      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.812      |\n",
      "|    mean_step_reward   | 0.4368046  |\n",
      "|    n_updates          | 15840      |\n",
      "|    policyGradLoss     | 0.00291    |\n",
      "|    value_loss         | 2.38       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 32456704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012325963 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.21        |\n",
      "|    mean_step_reward   | 0.38311958  |\n",
      "|    n_updates          | 15844       |\n",
      "|    policyGradLoss     | -0.00277    |\n",
      "|    value_loss         | 3.94        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 32464896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014883287 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.607       |\n",
      "|    mean_step_reward   | 0.42896107  |\n",
      "|    n_updates          | 15848       |\n",
      "|    policyGradLoss     | -0.00351    |\n",
      "|    value_loss         | 1.97        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 774        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 296        |\n",
      "|    total_timesteps    | 32473088   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01160668 |\n",
      "|    entropy_loss       | -1.7       |\n",
      "|    explained_variance | 0.986      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.86       |\n",
      "|    mean_step_reward   | 0.38380396 |\n",
      "|    n_updates          | 15852      |\n",
      "|    policyGradLoss     | -0.0039    |\n",
      "|    value_loss         | 2          |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 774        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 306        |\n",
      "|    total_timesteps    | 32481280   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01692969 |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.22       |\n",
      "|    mean_step_reward   | 0.43963003 |\n",
      "|    n_updates          | 15856      |\n",
      "|    policyGradLoss     | -0.00431   |\n",
      "|    value_loss         | 1.68       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 32489472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013647672 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.812       |\n",
      "|    mean_step_reward   | 0.40505552  |\n",
      "|    n_updates          | 15860       |\n",
      "|    policyGradLoss     | -0.00819    |\n",
      "|    value_loss         | 1.55        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 32497664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012289865 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.37        |\n",
      "|    mean_step_reward   | 0.35227585  |\n",
      "|    n_updates          | 15864       |\n",
      "|    policyGradLoss     | -0.00279    |\n",
      "|    value_loss         | 3.71        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 32505856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020872332 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.219       |\n",
      "|    mean_step_reward   | 0.35368177  |\n",
      "|    n_updates          | 15868       |\n",
      "|    policyGradLoss     | -0.00195    |\n",
      "|    value_loss         | 2.64        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_123.zip\n",
      "[EVAL] Mean Return: 526.721, Best Return: 533.387\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_123_526.72.mp4\n",
      "\n",
      "=== Round 125 | Learn 262144 steps (Total trained: 32505856) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1134     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 32514048 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 920         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 32522240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011923203 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.539       |\n",
      "|    mean_step_reward   | 0.3616957   |\n",
      "|    n_updates          | 15876       |\n",
      "|    policyGradLoss     | -0.00436    |\n",
      "|    value_loss         | 2.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 866         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 32530432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011356084 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.608       |\n",
      "|    mean_step_reward   | 0.4630152   |\n",
      "|    n_updates          | 15880       |\n",
      "|    policyGradLoss     | -0.00749    |\n",
      "|    value_loss         | 1.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 843         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 32538624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010799339 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.977       |\n",
      "|    mean_step_reward   | 0.3125968   |\n",
      "|    n_updates          | 15884       |\n",
      "|    policyGradLoss     | -0.00276    |\n",
      "|    value_loss         | 2.81        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 821        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 49         |\n",
      "|    total_timesteps    | 32546816   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01016465 |\n",
      "|    entropy_loss       | -1.61      |\n",
      "|    explained_variance | 0.966      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.521      |\n",
      "|    mean_step_reward   | 0.46871752 |\n",
      "|    n_updates          | 15888      |\n",
      "|    policyGradLoss     | -0.0018    |\n",
      "|    value_loss         | 2.54       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 32555008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013670889 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.32        |\n",
      "|    mean_step_reward   | 0.3484633   |\n",
      "|    n_updates          | 15892       |\n",
      "|    policyGradLoss     | 0.00176     |\n",
      "|    value_loss         | 2.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 32563200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009490964 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.252       |\n",
      "|    mean_step_reward   | 0.41452745  |\n",
      "|    n_updates          | 15896       |\n",
      "|    policyGradLoss     | -0.00357    |\n",
      "|    value_loss         | 1.5         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 32571392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012231622 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.486       |\n",
      "|    mean_step_reward   | 0.41415697  |\n",
      "|    n_updates          | 15900       |\n",
      "|    policyGradLoss     | -0.00499    |\n",
      "|    value_loss         | 1.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 32579584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010218388 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.912       |\n",
      "|    mean_step_reward   | 0.4278152   |\n",
      "|    n_updates          | 15904       |\n",
      "|    policyGradLoss     | -0.00336    |\n",
      "|    value_loss         | 2.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 32587776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009631202 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.312       |\n",
      "|    mean_step_reward   | 0.41187042  |\n",
      "|    n_updates          | 15908       |\n",
      "|    policyGradLoss     | -0.00625    |\n",
      "|    value_loss         | 1.31        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 789        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 114        |\n",
      "|    total_timesteps    | 32595968   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00917382 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 2.7        |\n",
      "|    mean_step_reward   | 0.39892915 |\n",
      "|    n_updates          | 15912      |\n",
      "|    policyGradLoss     | -0.00266   |\n",
      "|    value_loss         | 2.1        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 32604160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011180863 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.856       |\n",
      "|    mean_step_reward   | 0.4827519   |\n",
      "|    n_updates          | 15916       |\n",
      "|    policyGradLoss     | -0.00224    |\n",
      "|    value_loss         | 1.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 32612352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014783946 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.669       |\n",
      "|    mean_step_reward   | 0.38956368  |\n",
      "|    n_updates          | 15920       |\n",
      "|    policyGradLoss     | -0.00513    |\n",
      "|    value_loss         | 1.98        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 32620544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016478114 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.354       |\n",
      "|    mean_step_reward   | 0.41365016  |\n",
      "|    n_updates          | 15924       |\n",
      "|    policyGradLoss     | -0.00728    |\n",
      "|    value_loss         | 1.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 32628736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012611715 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.707       |\n",
      "|    mean_step_reward   | 0.39037758  |\n",
      "|    n_updates          | 15928       |\n",
      "|    policyGradLoss     | -0.00546    |\n",
      "|    value_loss         | 2.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 32636928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015015545 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.604       |\n",
      "|    mean_step_reward   | 0.4376555   |\n",
      "|    n_updates          | 15932       |\n",
      "|    policyGradLoss     | -0.00338    |\n",
      "|    value_loss         | 2.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 32645120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015123066 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.766       |\n",
      "|    mean_step_reward   | 0.44477236  |\n",
      "|    n_updates          | 15936       |\n",
      "|    policyGradLoss     | -0.00812    |\n",
      "|    value_loss         | 1.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 32653312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019015513 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.593       |\n",
      "|    mean_step_reward   | 0.34428865  |\n",
      "|    n_updates          | 15940       |\n",
      "|    policyGradLoss     | -0.00474    |\n",
      "|    value_loss         | 1.76        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 32661504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019017179 |\n",
      "|    entropy_loss       | -1.57       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.19        |\n",
      "|    mean_step_reward   | 0.49863076  |\n",
      "|    n_updates          | 15944       |\n",
      "|    policyGradLoss     | -0.00441    |\n",
      "|    value_loss         | 0.74        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 32669696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014669422 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.06        |\n",
      "|    mean_step_reward   | 0.37298328  |\n",
      "|    n_updates          | 15948       |\n",
      "|    policyGradLoss     | -0.0032     |\n",
      "|    value_loss         | 2.39        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 781        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 220        |\n",
      "|    total_timesteps    | 32677888   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01922247 |\n",
      "|    entropy_loss       | -1.58      |\n",
      "|    explained_variance | 0.994      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.338      |\n",
      "|    mean_step_reward   | 0.46611017 |\n",
      "|    n_updates          | 15952      |\n",
      "|    policyGradLoss     | -0.00404   |\n",
      "|    value_loss         | 0.871      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 32686080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013240032 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.349       |\n",
      "|    mean_step_reward   | 0.37675834  |\n",
      "|    n_updates          | 15956       |\n",
      "|    policyGradLoss     | -0.00564    |\n",
      "|    value_loss         | 1.96        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 32694272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017740287 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.699       |\n",
      "|    mean_step_reward   | 0.4005835   |\n",
      "|    n_updates          | 15960       |\n",
      "|    policyGradLoss     | -0.00253    |\n",
      "|    value_loss         | 1.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 32702464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015551465 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.595       |\n",
      "|    mean_step_reward   | 0.43227088  |\n",
      "|    n_updates          | 15964       |\n",
      "|    policyGradLoss     | -0.00623    |\n",
      "|    value_loss         | 1.21        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 25         |\n",
      "|    time_elapsed       | 263        |\n",
      "|    total_timesteps    | 32710656   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01400547 |\n",
      "|    entropy_loss       | -1.68      |\n",
      "|    explained_variance | 0.984      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.98       |\n",
      "|    mean_step_reward   | 0.34237385 |\n",
      "|    n_updates          | 15968      |\n",
      "|    policyGradLoss     | -0.00377   |\n",
      "|    value_loss         | 1.94       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 32718848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014986026 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.02        |\n",
      "|    mean_step_reward   | 0.40930086  |\n",
      "|    n_updates          | 15972       |\n",
      "|    policyGradLoss     | -0.00233    |\n",
      "|    value_loss         | 2.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 32727040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014390932 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.186       |\n",
      "|    mean_step_reward   | 0.35278922  |\n",
      "|    n_updates          | 15976       |\n",
      "|    policyGradLoss     | -0.00638    |\n",
      "|    value_loss         | 1.96        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 32735232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017052859 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.381       |\n",
      "|    mean_step_reward   | 0.42609847  |\n",
      "|    n_updates          | 15980       |\n",
      "|    policyGradLoss     | -0.00674    |\n",
      "|    value_loss         | 0.982       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 32743424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010068974 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.453       |\n",
      "|    mean_step_reward   | 0.37637913  |\n",
      "|    n_updates          | 15984       |\n",
      "|    policyGradLoss     | -0.00505    |\n",
      "|    value_loss         | 1.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 32751616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012530573 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.71        |\n",
      "|    mean_step_reward   | 0.34872484  |\n",
      "|    n_updates          | 15988       |\n",
      "|    policyGradLoss     | -0.00354    |\n",
      "|    value_loss         | 1.84        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 32759808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015904227 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.452       |\n",
      "|    mean_step_reward   | 0.40645093  |\n",
      "|    n_updates          | 15992       |\n",
      "|    policyGradLoss     | -0.00266    |\n",
      "|    value_loss         | 3.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 32768000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011600283 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.835       |\n",
      "|    mean_step_reward   | 0.3670045   |\n",
      "|    n_updates          | 15996       |\n",
      "|    policyGradLoss     | -0.00395    |\n",
      "|    value_loss         | 1.92        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_124.zip\n",
      "[EVAL] Mean Return: 544.593, Best Return: 545.927\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_124_544.59.mp4\n",
      "\n",
      "=== Round 126 | Learn 262144 steps (Total trained: 32768000) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1123     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 32776192 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 912         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 32784384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012412662 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.63        |\n",
      "|    mean_step_reward   | 0.40353984  |\n",
      "|    n_updates          | 16004       |\n",
      "|    policyGradLoss     | -0.00171    |\n",
      "|    value_loss         | 2.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 859         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 32792576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016132882 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.498       |\n",
      "|    mean_step_reward   | 0.4442526   |\n",
      "|    n_updates          | 16008       |\n",
      "|    policyGradLoss     | -0.00303    |\n",
      "|    value_loss         | 1.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 833         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 32800768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010103126 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.469       |\n",
      "|    mean_step_reward   | 0.42071015  |\n",
      "|    n_updates          | 16012       |\n",
      "|    policyGradLoss     | -0.00339    |\n",
      "|    value_loss         | 2.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 32808960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014154043 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.09        |\n",
      "|    mean_step_reward   | 0.41565222  |\n",
      "|    n_updates          | 16016       |\n",
      "|    policyGradLoss     | -0.00551    |\n",
      "|    value_loss         | 1.54        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 808        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 32817152   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01634488 |\n",
      "|    entropy_loss       | -1.61      |\n",
      "|    explained_variance | 0.992      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.595      |\n",
      "|    mean_step_reward   | 0.44736072 |\n",
      "|    n_updates          | 16020      |\n",
      "|    policyGradLoss     | -0.00648   |\n",
      "|    value_loss         | 1.36       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 800          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 71           |\n",
      "|    total_timesteps    | 32825344     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0120041855 |\n",
      "|    entropy_loss       | -1.64        |\n",
      "|    explained_variance | 0.993        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.533        |\n",
      "|    mean_step_reward   | 0.4220056    |\n",
      "|    n_updates          | 16024        |\n",
      "|    policyGradLoss     | -0.00781     |\n",
      "|    value_loss         | 1.2          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 32833536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011947915 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.554       |\n",
      "|    mean_step_reward   | 0.41285962  |\n",
      "|    n_updates          | 16028       |\n",
      "|    policyGradLoss     | -0.0058     |\n",
      "|    value_loss         | 1.74        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 32841728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017074618 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.34        |\n",
      "|    mean_step_reward   | 0.3941285   |\n",
      "|    n_updates          | 16032       |\n",
      "|    policyGradLoss     | -0.00637    |\n",
      "|    value_loss         | 1.75        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 32849920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017065855 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.753       |\n",
      "|    mean_step_reward   | 0.38174236  |\n",
      "|    n_updates          | 16036       |\n",
      "|    policyGradLoss     | -0.00638    |\n",
      "|    value_loss         | 1.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 32858112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016369857 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.808       |\n",
      "|    mean_step_reward   | 0.37426293  |\n",
      "|    n_updates          | 16040       |\n",
      "|    policyGradLoss     | -0.00304    |\n",
      "|    value_loss         | 1.93        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 32866304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019917514 |\n",
      "|    entropy_loss       | -1.55       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.486       |\n",
      "|    mean_step_reward   | 0.4728858   |\n",
      "|    n_updates          | 16044       |\n",
      "|    policyGradLoss     | -0.00135    |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 32874496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013215972 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.397       |\n",
      "|    mean_step_reward   | 0.3776448   |\n",
      "|    n_updates          | 16048       |\n",
      "|    policyGradLoss     | -0.00392    |\n",
      "|    value_loss         | 1.99        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 32882688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014691459 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.45        |\n",
      "|    mean_step_reward   | 0.45668352  |\n",
      "|    n_updates          | 16052       |\n",
      "|    policyGradLoss     | -0.00481    |\n",
      "|    value_loss         | 1.55        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 32890880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014721689 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.468       |\n",
      "|    mean_step_reward   | 0.40151107  |\n",
      "|    n_updates          | 16056       |\n",
      "|    policyGradLoss     | -0.00734    |\n",
      "|    value_loss         | 0.9         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 32899072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010986858 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.432       |\n",
      "|    mean_step_reward   | 0.41455078  |\n",
      "|    n_updates          | 16060       |\n",
      "|    policyGradLoss     | -0.00604    |\n",
      "|    value_loss         | 1.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 32907264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012502782 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.492       |\n",
      "|    mean_step_reward   | 0.41759774  |\n",
      "|    n_updates          | 16064       |\n",
      "|    policyGradLoss     | -0.00385    |\n",
      "|    value_loss         | 1.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 32915456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010804255 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.761       |\n",
      "|    mean_step_reward   | 0.4199581   |\n",
      "|    n_updates          | 16068       |\n",
      "|    policyGradLoss     | -0.00367    |\n",
      "|    value_loss         | 2.92        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 32923648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012712532 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.436       |\n",
      "|    mean_step_reward   | 0.45738232  |\n",
      "|    n_updates          | 16072       |\n",
      "|    policyGradLoss     | -0.00591    |\n",
      "|    value_loss         | 1.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 32931840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008096169 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.755       |\n",
      "|    mean_step_reward   | 0.3948534   |\n",
      "|    n_updates          | 16076       |\n",
      "|    policyGradLoss     | -0.00218    |\n",
      "|    value_loss         | 2.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 32940032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015308902 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.224       |\n",
      "|    mean_step_reward   | 0.44351715  |\n",
      "|    n_updates          | 16080       |\n",
      "|    policyGradLoss     | -0.00724    |\n",
      "|    value_loss         | 0.832       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 777          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 231          |\n",
      "|    total_timesteps    | 32948224     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0122917015 |\n",
      "|    entropy_loss       | -1.7         |\n",
      "|    explained_variance | 0.987        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.827        |\n",
      "|    mean_step_reward   | 0.36312854   |\n",
      "|    n_updates          | 16084        |\n",
      "|    policyGradLoss     | -0.00785     |\n",
      "|    value_loss         | 1.9          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 32956416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011566752 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.274       |\n",
      "|    mean_step_reward   | 0.46922642  |\n",
      "|    n_updates          | 16088       |\n",
      "|    policyGradLoss     | 0.00641     |\n",
      "|    value_loss         | 2.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 32964608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011586353 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.34        |\n",
      "|    mean_step_reward   | 0.41497412  |\n",
      "|    n_updates          | 16092       |\n",
      "|    policyGradLoss     | -0.00544    |\n",
      "|    value_loss         | 1.88        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 32972800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010784451 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.29        |\n",
      "|    mean_step_reward   | 0.37239662  |\n",
      "|    n_updates          | 16096       |\n",
      "|    policyGradLoss     | -0.00639    |\n",
      "|    value_loss         | 2.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 32980992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010615518 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.289       |\n",
      "|    mean_step_reward   | 0.41176766  |\n",
      "|    n_updates          | 16100       |\n",
      "|    policyGradLoss     | -0.00721    |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 32989184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011543178 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.583       |\n",
      "|    mean_step_reward   | 0.4136296   |\n",
      "|    n_updates          | 16104       |\n",
      "|    policyGradLoss     | -0.00423    |\n",
      "|    value_loss         | 1.75        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 776          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 295          |\n",
      "|    total_timesteps    | 32997376     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0116132945 |\n",
      "|    entropy_loss       | -1.65        |\n",
      "|    explained_variance | 0.973        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.282        |\n",
      "|    mean_step_reward   | 0.40816933   |\n",
      "|    n_updates          | 16108        |\n",
      "|    policyGradLoss     | -0.00384     |\n",
      "|    value_loss         | 2.84         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 776        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 306        |\n",
      "|    total_timesteps    | 33005568   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01511992 |\n",
      "|    entropy_loss       | -1.66      |\n",
      "|    explained_variance | 0.949      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.633      |\n",
      "|    mean_step_reward   | 0.3654688  |\n",
      "|    n_updates          | 16112      |\n",
      "|    policyGradLoss     | 0.000439   |\n",
      "|    value_loss         | 3.33       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 33013760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014121316 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.34        |\n",
      "|    mean_step_reward   | 0.43102354  |\n",
      "|    n_updates          | 16116       |\n",
      "|    policyGradLoss     | -0.00638    |\n",
      "|    value_loss         | 1.43        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 33021952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007445792 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.506       |\n",
      "|    mean_step_reward   | 0.39533612  |\n",
      "|    n_updates          | 16120       |\n",
      "|    policyGradLoss     | -0.00694    |\n",
      "|    value_loss         | 2.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 33030144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013136556 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.796       |\n",
      "|    mean_step_reward   | 0.41036084  |\n",
      "|    n_updates          | 16124       |\n",
      "|    policyGradLoss     | -0.0064     |\n",
      "|    value_loss         | 1.51        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_125.zip\n",
      "[EVAL] Mean Return: 519.875, Best Return: 525.875\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_125_519.87.mp4\n",
      "\n",
      "=== Round 127 | Learn 262144 steps (Total trained: 33030144) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1116     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 33038336 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 914         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 33046528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012970606 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.86        |\n",
      "|    mean_step_reward   | 0.38319206  |\n",
      "|    n_updates          | 16132       |\n",
      "|    policyGradLoss     | -0.00694    |\n",
      "|    value_loss         | 1.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 853         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 33054720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018449944 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.107       |\n",
      "|    mean_step_reward   | 0.41907674  |\n",
      "|    n_updates          | 16136       |\n",
      "|    policyGradLoss     | -0.00507    |\n",
      "|    value_loss         | 1.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 835         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 33062912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012149615 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.298       |\n",
      "|    mean_step_reward   | 0.3382051   |\n",
      "|    n_updates          | 16140       |\n",
      "|    policyGradLoss     | -0.00355    |\n",
      "|    value_loss         | 1.55        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 33071104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013997171 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.744       |\n",
      "|    mean_step_reward   | 0.42468625  |\n",
      "|    n_updates          | 16144       |\n",
      "|    policyGradLoss     | -0.00535    |\n",
      "|    value_loss         | 1.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 33079296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009902652 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.61        |\n",
      "|    mean_step_reward   | 0.38994473  |\n",
      "|    n_updates          | 16148       |\n",
      "|    policyGradLoss     | -0.00648    |\n",
      "|    value_loss         | 2.14        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 804          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 71           |\n",
      "|    total_timesteps    | 33087488     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0104649365 |\n",
      "|    entropy_loss       | -1.63        |\n",
      "|    explained_variance | 0.988        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.18         |\n",
      "|    mean_step_reward   | 0.39478815   |\n",
      "|    n_updates          | 16152        |\n",
      "|    policyGradLoss     | -0.00403     |\n",
      "|    value_loss         | 1.42         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 33095680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013559099 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.958       |\n",
      "|    mean_step_reward   | 0.34875977  |\n",
      "|    n_updates          | 16156       |\n",
      "|    policyGradLoss     | -0.00661    |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 33103872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010163385 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.03        |\n",
      "|    mean_step_reward   | 0.3634231   |\n",
      "|    n_updates          | 16160       |\n",
      "|    policyGradLoss     | -0.00348    |\n",
      "|    value_loss         | 1.42        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 793        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 103        |\n",
      "|    total_timesteps    | 33112064   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01461503 |\n",
      "|    entropy_loss       | -1.68      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.04       |\n",
      "|    mean_step_reward   | 0.39964136 |\n",
      "|    n_updates          | 16164      |\n",
      "|    policyGradLoss     | -0.00491   |\n",
      "|    value_loss         | 1.61       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 33120256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011931375 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.572       |\n",
      "|    mean_step_reward   | 0.34532678  |\n",
      "|    n_updates          | 16168       |\n",
      "|    policyGradLoss     | -0.00722    |\n",
      "|    value_loss         | 1.59        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 33128448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016671255 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.76        |\n",
      "|    mean_step_reward   | 0.4077606   |\n",
      "|    n_updates          | 16172       |\n",
      "|    policyGradLoss     | -0.00178    |\n",
      "|    value_loss         | 4.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 33136640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012129532 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.68        |\n",
      "|    mean_step_reward   | 0.38911796  |\n",
      "|    n_updates          | 16176       |\n",
      "|    policyGradLoss     | -0.000229   |\n",
      "|    value_loss         | 2.3         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 785          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 145          |\n",
      "|    total_timesteps    | 33144832     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0097039975 |\n",
      "|    entropy_loss       | -1.69        |\n",
      "|    explained_variance | 0.99         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.431        |\n",
      "|    mean_step_reward   | 0.41879255   |\n",
      "|    n_updates          | 16180        |\n",
      "|    policyGradLoss     | -0.00343     |\n",
      "|    value_loss         | 1.51         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 33153024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015924256 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.43        |\n",
      "|    mean_step_reward   | 0.397268    |\n",
      "|    n_updates          | 16184       |\n",
      "|    policyGradLoss     | -0.00243    |\n",
      "|    value_loss         | 2.97        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 33161216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010642222 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.76        |\n",
      "|    mean_step_reward   | 0.3793597   |\n",
      "|    n_updates          | 16188       |\n",
      "|    policyGradLoss     | -0.00467    |\n",
      "|    value_loss         | 2.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 33169408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016435556 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.329       |\n",
      "|    mean_step_reward   | 0.4558623   |\n",
      "|    n_updates          | 16192       |\n",
      "|    policyGradLoss     | -0.00802    |\n",
      "|    value_loss         | 0.901       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 33177600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010108007 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.547       |\n",
      "|    mean_step_reward   | 0.3636005   |\n",
      "|    n_updates          | 16196       |\n",
      "|    policyGradLoss     | -0.00296    |\n",
      "|    value_loss         | 2.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 33185792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013326629 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.539       |\n",
      "|    mean_step_reward   | 0.41918862  |\n",
      "|    n_updates          | 16200       |\n",
      "|    policyGradLoss     | 0.000452    |\n",
      "|    value_loss         | 3.02        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 780        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 209        |\n",
      "|    total_timesteps    | 33193984   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01943999 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.203      |\n",
      "|    mean_step_reward   | 0.37628174 |\n",
      "|    n_updates          | 16204      |\n",
      "|    policyGradLoss     | -0.00423   |\n",
      "|    value_loss         | 1.25       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 33202176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011277214 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.934       |\n",
      "|    mean_step_reward   | 0.41425097  |\n",
      "|    n_updates          | 16208       |\n",
      "|    policyGradLoss     | -0.00307    |\n",
      "|    value_loss         | 2.09        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 33210368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011634251 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.653       |\n",
      "|    mean_step_reward   | 0.37070704  |\n",
      "|    n_updates          | 16212       |\n",
      "|    policyGradLoss     | -0.00957    |\n",
      "|    value_loss         | 1.46        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 33218560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008689749 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.853       |\n",
      "|    mean_step_reward   | 0.32378882  |\n",
      "|    n_updates          | 16216       |\n",
      "|    policyGradLoss     | -0.00358    |\n",
      "|    value_loss         | 3.24        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 779          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 252          |\n",
      "|    total_timesteps    | 33226752     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0089087095 |\n",
      "|    entropy_loss       | -1.7         |\n",
      "|    explained_variance | 0.97         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.532        |\n",
      "|    mean_step_reward   | 0.34593284   |\n",
      "|    n_updates          | 16220        |\n",
      "|    policyGradLoss     | -0.0022      |\n",
      "|    value_loss         | 2.19         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 33234944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009621048 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.583       |\n",
      "|    mean_step_reward   | 0.3953216   |\n",
      "|    n_updates          | 16224       |\n",
      "|    policyGradLoss     | -0.00245    |\n",
      "|    value_loss         | 2.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 33243136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009109775 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.167       |\n",
      "|    mean_step_reward   | 0.39663935  |\n",
      "|    n_updates          | 16228       |\n",
      "|    policyGradLoss     | -0.00682    |\n",
      "|    value_loss         | 1.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 33251328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010522132 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.566       |\n",
      "|    mean_step_reward   | 0.40547806  |\n",
      "|    n_updates          | 16232       |\n",
      "|    policyGradLoss     | -0.00536    |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 33259520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013247652 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.61        |\n",
      "|    mean_step_reward   | 0.43131495  |\n",
      "|    n_updates          | 16236       |\n",
      "|    policyGradLoss     | -0.00463    |\n",
      "|    value_loss         | 1.71        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 33267712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017974596 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.356       |\n",
      "|    mean_step_reward   | 0.38669297  |\n",
      "|    n_updates          | 16240       |\n",
      "|    policyGradLoss     | -0.00837    |\n",
      "|    value_loss         | 1.22        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 315        |\n",
      "|    total_timesteps    | 33275904   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0164306  |\n",
      "|    entropy_loss       | -1.66      |\n",
      "|    explained_variance | 0.99       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.968      |\n",
      "|    mean_step_reward   | 0.40840426 |\n",
      "|    n_updates          | 16244      |\n",
      "|    policyGradLoss     | -0.00794   |\n",
      "|    value_loss         | 1.43       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 33284096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010603232 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.801       |\n",
      "|    mean_step_reward   | 0.3607814   |\n",
      "|    n_updates          | 16248       |\n",
      "|    policyGradLoss     | -0.00905    |\n",
      "|    value_loss         | 1.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 33292288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011093278 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.34        |\n",
      "|    mean_step_reward   | 0.43843114  |\n",
      "|    n_updates          | 16252       |\n",
      "|    policyGradLoss     | -0.000436   |\n",
      "|    value_loss         | 2.96        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_126.zip\n",
      "[EVAL] Mean Return: 531.538, Best Return: 537.538\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_126_531.54.mp4\n",
      "\n",
      "=== Round 128 | Learn 262144 steps (Total trained: 33292288) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1119     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 33300480 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 908         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 33308672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013227928 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.29        |\n",
      "|    mean_step_reward   | 0.41033798  |\n",
      "|    n_updates          | 16260       |\n",
      "|    policyGradLoss     | -0.00621    |\n",
      "|    value_loss         | 1.46        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 858         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 33316864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012685363 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.574       |\n",
      "|    mean_step_reward   | 0.39376023  |\n",
      "|    n_updates          | 16264       |\n",
      "|    policyGradLoss     | -0.00638    |\n",
      "|    value_loss         | 1.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 831         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 33325056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010023867 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.912       |\n",
      "|    mean_step_reward   | 0.40454608  |\n",
      "|    n_updates          | 16268       |\n",
      "|    policyGradLoss     | -0.00342    |\n",
      "|    value_loss         | 2.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 33333248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009741117 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.136       |\n",
      "|    mean_step_reward   | 0.47502774  |\n",
      "|    n_updates          | 16272       |\n",
      "|    policyGradLoss     | -0.00679    |\n",
      "|    value_loss         | 1.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 33341440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011600271 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.06        |\n",
      "|    mean_step_reward   | 0.40985465  |\n",
      "|    n_updates          | 16276       |\n",
      "|    policyGradLoss     | -0.00439    |\n",
      "|    value_loss         | 2.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 33349632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013316641 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.18        |\n",
      "|    mean_step_reward   | 0.35468554  |\n",
      "|    n_updates          | 16280       |\n",
      "|    policyGradLoss     | -0.0098     |\n",
      "|    value_loss         | 1.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 33357824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016989782 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.203       |\n",
      "|    mean_step_reward   | 0.41042346  |\n",
      "|    n_updates          | 16284       |\n",
      "|    policyGradLoss     | -0.00559    |\n",
      "|    value_loss         | 1.97        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 33366016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014974665 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.24        |\n",
      "|    mean_step_reward   | 0.39567572  |\n",
      "|    n_updates          | 16288       |\n",
      "|    policyGradLoss     | -0.00884    |\n",
      "|    value_loss         | 1.54        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 795          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 102          |\n",
      "|    total_timesteps    | 33374208     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0087666735 |\n",
      "|    entropy_loss       | -1.66        |\n",
      "|    explained_variance | 0.99         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.521        |\n",
      "|    mean_step_reward   | 0.45439693   |\n",
      "|    n_updates          | 16292        |\n",
      "|    policyGradLoss     | -0.00632     |\n",
      "|    value_loss         | 1.71         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 33382400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011954043 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.925       |\n",
      "|    mean_step_reward   | 0.37166813  |\n",
      "|    n_updates          | 16296       |\n",
      "|    policyGradLoss     | -0.00306    |\n",
      "|    value_loss         | 3.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 33390592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010903414 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.375       |\n",
      "|    mean_step_reward   | 0.3701315   |\n",
      "|    n_updates          | 16300       |\n",
      "|    policyGradLoss     | -0.00269    |\n",
      "|    value_loss         | 3.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 33398784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012180865 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.77        |\n",
      "|    mean_step_reward   | 0.36686707  |\n",
      "|    n_updates          | 16304       |\n",
      "|    policyGradLoss     | -0.00126    |\n",
      "|    value_loss         | 3.89        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 33406976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012212187 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.551       |\n",
      "|    mean_step_reward   | 0.42560756  |\n",
      "|    n_updates          | 16308       |\n",
      "|    policyGradLoss     | -0.0034     |\n",
      "|    value_loss         | 2.5         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 33415168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008004591 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.502       |\n",
      "|    mean_step_reward   | 0.41178834  |\n",
      "|    n_updates          | 16312       |\n",
      "|    policyGradLoss     | -0.00505    |\n",
      "|    value_loss         | 2.13        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 788        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 166        |\n",
      "|    total_timesteps    | 33423360   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01197347 |\n",
      "|    entropy_loss       | -1.7       |\n",
      "|    explained_variance | 0.964      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.538      |\n",
      "|    mean_step_reward   | 0.34025058 |\n",
      "|    n_updates          | 16316      |\n",
      "|    policyGradLoss     | -0.00191   |\n",
      "|    value_loss         | 2.51       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 33431552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012595436 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.277       |\n",
      "|    mean_step_reward   | 0.4264983   |\n",
      "|    n_updates          | 16320       |\n",
      "|    policyGradLoss     | -0.00618    |\n",
      "|    value_loss         | 0.918       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 33439744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010587226 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.606       |\n",
      "|    mean_step_reward   | 0.3093918   |\n",
      "|    n_updates          | 16324       |\n",
      "|    policyGradLoss     | -0.00243    |\n",
      "|    value_loss         | 2.82        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 33447936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015279528 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.307       |\n",
      "|    mean_step_reward   | 0.36295718  |\n",
      "|    n_updates          | 16328       |\n",
      "|    policyGradLoss     | -0.00689    |\n",
      "|    value_loss         | 1.29        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 783          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 209          |\n",
      "|    total_timesteps    | 33456128     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0144511135 |\n",
      "|    entropy_loss       | -1.69        |\n",
      "|    explained_variance | 0.975        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.94         |\n",
      "|    mean_step_reward   | 0.40258393   |\n",
      "|    n_updates          | 16332        |\n",
      "|    policyGradLoss     | -0.00318     |\n",
      "|    value_loss         | 3.28         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 33464320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013197476 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.649       |\n",
      "|    mean_step_reward   | 0.39763296  |\n",
      "|    n_updates          | 16336       |\n",
      "|    policyGradLoss     | -3.3e-05    |\n",
      "|    value_loss         | 1.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 33472512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015357675 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.692       |\n",
      "|    mean_step_reward   | 0.39246574  |\n",
      "|    n_updates          | 16340       |\n",
      "|    policyGradLoss     | -0.00666    |\n",
      "|    value_loss         | 1.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 33480704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009135901 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.598       |\n",
      "|    mean_step_reward   | 0.432746    |\n",
      "|    n_updates          | 16344       |\n",
      "|    policyGradLoss     | -0.00401    |\n",
      "|    value_loss         | 1.69        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 781        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 251        |\n",
      "|    total_timesteps    | 33488896   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01402976 |\n",
      "|    entropy_loss       | -1.62      |\n",
      "|    explained_variance | 0.988      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.802      |\n",
      "|    mean_step_reward   | 0.36002815 |\n",
      "|    n_updates          | 16348      |\n",
      "|    policyGradLoss     | -0.00564   |\n",
      "|    value_loss         | 1.39       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 33497088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013178481 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.318       |\n",
      "|    mean_step_reward   | 0.4264973   |\n",
      "|    n_updates          | 16352       |\n",
      "|    policyGradLoss     | -0.00326    |\n",
      "|    value_loss         | 1.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 33505280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011038039 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.913       |\n",
      "|    mean_step_reward   | 0.43028328  |\n",
      "|    n_updates          | 16356       |\n",
      "|    policyGradLoss     | 0.00249     |\n",
      "|    value_loss         | 3.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 33513472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013363622 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.909       |\n",
      "|    mean_step_reward   | 0.38208514  |\n",
      "|    n_updates          | 16360       |\n",
      "|    policyGradLoss     | -0.00363    |\n",
      "|    value_loss         | 1.96        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 33521664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011636924 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.71        |\n",
      "|    mean_step_reward   | 0.412674    |\n",
      "|    n_updates          | 16364       |\n",
      "|    policyGradLoss     | -0.00865    |\n",
      "|    value_loss         | 1.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 33529856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012216674 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.986       |\n",
      "|    mean_step_reward   | 0.40755808  |\n",
      "|    n_updates          | 16368       |\n",
      "|    policyGradLoss     | -0.00582    |\n",
      "|    value_loss         | 1.86        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 314         |\n",
      "|    total_timesteps    | 33538048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014182356 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.2         |\n",
      "|    mean_step_reward   | 0.4153246   |\n",
      "|    n_updates          | 16372       |\n",
      "|    policyGradLoss     | 7.14e-05    |\n",
      "|    value_loss         | 3.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 33546240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018454269 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.251       |\n",
      "|    mean_step_reward   | 0.4408923   |\n",
      "|    n_updates          | 16376       |\n",
      "|    policyGradLoss     | -0.00558    |\n",
      "|    value_loss         | 1.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 33554432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012555212 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.665       |\n",
      "|    mean_step_reward   | 0.3418411   |\n",
      "|    n_updates          | 16380       |\n",
      "|    policyGradLoss     | -0.00596    |\n",
      "|    value_loss         | 1.82        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_127.zip\n",
      "[EVAL] Mean Return: 533.514, Best Return: 541.514\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_127_533.51.mp4\n",
      "\n",
      "=== Round 129 | Learn 262144 steps (Total trained: 33554432) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1170     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 33562624 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 938         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 33570816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013507951 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.314       |\n",
      "|    mean_step_reward   | 0.38993755  |\n",
      "|    n_updates          | 16388       |\n",
      "|    policyGradLoss     | -0.00105    |\n",
      "|    value_loss         | 3.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 874         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 33579008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011768471 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.52        |\n",
      "|    mean_step_reward   | 0.33908984  |\n",
      "|    n_updates          | 16392       |\n",
      "|    policyGradLoss     | -0.00658    |\n",
      "|    value_loss         | 1.72        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 842         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 33587200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020741018 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0957      |\n",
      "|    mean_step_reward   | 0.3979576   |\n",
      "|    n_updates          | 16396       |\n",
      "|    policyGradLoss     | -0.00572    |\n",
      "|    value_loss         | 0.834       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 835         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 33595392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012950579 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.371       |\n",
      "|    mean_step_reward   | 0.3958121   |\n",
      "|    n_updates          | 16400       |\n",
      "|    policyGradLoss     | -0.00637    |\n",
      "|    value_loss         | 1.69        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 822        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 59         |\n",
      "|    total_timesteps    | 33603584   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01191359 |\n",
      "|    entropy_loss       | -1.66      |\n",
      "|    explained_variance | 0.992      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.738      |\n",
      "|    mean_step_reward   | 0.430424   |\n",
      "|    n_updates          | 16404      |\n",
      "|    policyGradLoss     | -0.00648   |\n",
      "|    value_loss         | 1.37       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 33611776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009408241 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.501       |\n",
      "|    mean_step_reward   | 0.4021662   |\n",
      "|    n_updates          | 16408       |\n",
      "|    policyGradLoss     | -0.00351    |\n",
      "|    value_loss         | 1.89        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 807        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 81         |\n",
      "|    total_timesteps    | 33619968   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01472594 |\n",
      "|    entropy_loss       | -1.66      |\n",
      "|    explained_variance | 0.986      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.893      |\n",
      "|    mean_step_reward   | 0.3865109  |\n",
      "|    n_updates          | 16412      |\n",
      "|    policyGradLoss     | -0.00612   |\n",
      "|    value_loss         | 1.77       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 33628160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015948975 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.255       |\n",
      "|    mean_step_reward   | 0.43318662  |\n",
      "|    n_updates          | 16416       |\n",
      "|    policyGradLoss     | -0.00579    |\n",
      "|    value_loss         | 1.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 33636352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012207052 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.707       |\n",
      "|    mean_step_reward   | 0.36275625  |\n",
      "|    n_updates          | 16420       |\n",
      "|    policyGradLoss     | -0.0071     |\n",
      "|    value_loss         | 1.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 33644544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014932837 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.46        |\n",
      "|    mean_step_reward   | 0.40667832  |\n",
      "|    n_updates          | 16424       |\n",
      "|    policyGradLoss     | -0.00713    |\n",
      "|    value_loss         | 1.12        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 793        |\n",
      "|    iterations         | 12         |\n",
      "|    time_elapsed       | 123        |\n",
      "|    total_timesteps    | 33652736   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01037164 |\n",
      "|    entropy_loss       | -1.7       |\n",
      "|    explained_variance | 0.985      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.795      |\n",
      "|    mean_step_reward   | 0.3799659  |\n",
      "|    n_updates          | 16428      |\n",
      "|    policyGradLoss     | -0.00471   |\n",
      "|    value_loss         | 2.24       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 33660928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010597282 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.332       |\n",
      "|    mean_step_reward   | 0.43560907  |\n",
      "|    n_updates          | 16432       |\n",
      "|    policyGradLoss     | -0.00477    |\n",
      "|    value_loss         | 1.53        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 33669120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008293549 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.27        |\n",
      "|    mean_step_reward   | 0.3959393   |\n",
      "|    n_updates          | 16436       |\n",
      "|    policyGradLoss     | -0.00581    |\n",
      "|    value_loss         | 2.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 33677312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013179617 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.1         |\n",
      "|    mean_step_reward   | 0.37231606  |\n",
      "|    n_updates          | 16440       |\n",
      "|    policyGradLoss     | -0.00659    |\n",
      "|    value_loss         | 1.93        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 33685504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013620219 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.265       |\n",
      "|    mean_step_reward   | 0.42898768  |\n",
      "|    n_updates          | 16444       |\n",
      "|    policyGradLoss     | -0.00708    |\n",
      "|    value_loss         | 1.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 33693696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009592569 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.8         |\n",
      "|    mean_step_reward   | 0.38653523  |\n",
      "|    n_updates          | 16448       |\n",
      "|    policyGradLoss     | -0.00522    |\n",
      "|    value_loss         | 3.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 33701888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018912958 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.251       |\n",
      "|    mean_step_reward   | 0.4549969   |\n",
      "|    n_updates          | 16452       |\n",
      "|    policyGradLoss     | 0.00302     |\n",
      "|    value_loss         | 1.46        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 33710080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007744911 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.53        |\n",
      "|    mean_step_reward   | 0.3845506   |\n",
      "|    n_updates          | 16456       |\n",
      "|    policyGradLoss     | -0.00343    |\n",
      "|    value_loss         | 2.27        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 785        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 208        |\n",
      "|    total_timesteps    | 33718272   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01549533 |\n",
      "|    entropy_loss       | -1.6       |\n",
      "|    explained_variance | 0.992      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.573      |\n",
      "|    mean_step_reward   | 0.4580262  |\n",
      "|    n_updates          | 16460      |\n",
      "|    policyGradLoss     | -0.00664   |\n",
      "|    value_loss         | 1.26       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 783          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 219          |\n",
      "|    total_timesteps    | 33726464     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0107093165 |\n",
      "|    entropy_loss       | -1.66        |\n",
      "|    explained_variance | 0.948        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.23         |\n",
      "|    mean_step_reward   | 0.41101733   |\n",
      "|    n_updates          | 16464        |\n",
      "|    policyGradLoss     | 0.00171      |\n",
      "|    value_loss         | 4.16         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 33734656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013696562 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.422       |\n",
      "|    mean_step_reward   | 0.36191258  |\n",
      "|    n_updates          | 16468       |\n",
      "|    policyGradLoss     | -0.00648    |\n",
      "|    value_loss         | 1.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 33742848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011796465 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.62        |\n",
      "|    mean_step_reward   | 0.46801865  |\n",
      "|    n_updates          | 16472       |\n",
      "|    policyGradLoss     | -0.00392    |\n",
      "|    value_loss         | 1.65        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 33751040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008152139 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.27        |\n",
      "|    mean_step_reward   | 0.36781067  |\n",
      "|    n_updates          | 16476       |\n",
      "|    policyGradLoss     | -0.00458    |\n",
      "|    value_loss         | 1.95        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 33759232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010409869 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.564       |\n",
      "|    mean_step_reward   | 0.43725872  |\n",
      "|    n_updates          | 16480       |\n",
      "|    policyGradLoss     | -0.00396    |\n",
      "|    value_loss         | 1.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 33767424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015307095 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.207       |\n",
      "|    mean_step_reward   | 0.41281277  |\n",
      "|    n_updates          | 16484       |\n",
      "|    policyGradLoss     | -0.00773    |\n",
      "|    value_loss         | 0.94        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 779          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 283          |\n",
      "|    total_timesteps    | 33775616     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0132398615 |\n",
      "|    entropy_loss       | -1.66        |\n",
      "|    explained_variance | 0.949        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.877        |\n",
      "|    mean_step_reward   | 0.39653695   |\n",
      "|    n_updates          | 16488        |\n",
      "|    policyGradLoss     | 0.00305      |\n",
      "|    value_loss         | 4.17         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 33783808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016006127 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.438       |\n",
      "|    mean_step_reward   | 0.45668405  |\n",
      "|    n_updates          | 16492       |\n",
      "|    policyGradLoss     | -0.0037     |\n",
      "|    value_loss         | 1.79        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 304        |\n",
      "|    total_timesteps    | 33792000   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01316404 |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.628      |\n",
      "|    mean_step_reward   | 0.39542234 |\n",
      "|    n_updates          | 16496      |\n",
      "|    policyGradLoss     | -0.00506   |\n",
      "|    value_loss         | 1.46       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 33800192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014160431 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.336       |\n",
      "|    mean_step_reward   | 0.39822704  |\n",
      "|    n_updates          | 16500       |\n",
      "|    policyGradLoss     | -0.00665    |\n",
      "|    value_loss         | 1.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 33808384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014688573 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.823       |\n",
      "|    mean_step_reward   | 0.4715482   |\n",
      "|    n_updates          | 16504       |\n",
      "|    policyGradLoss     | -0.00611    |\n",
      "|    value_loss         | 1.61        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 33816576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015607631 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.425       |\n",
      "|    mean_step_reward   | 0.40600163  |\n",
      "|    n_updates          | 16508       |\n",
      "|    policyGradLoss     | -0.009      |\n",
      "|    value_loss         | 1.31        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_128.zip\n",
      "[EVAL] Mean Return: 534.911, Best Return: 541.578\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_128_534.91.mp4\n",
      "\n",
      "=== Round 130 | Learn 262144 steps (Total trained: 33816576) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1172     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 33824768 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 916         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 33832960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016688399 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.78        |\n",
      "|    mean_step_reward   | 0.39464802  |\n",
      "|    n_updates          | 16516       |\n",
      "|    policyGradLoss     | -0.00726    |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 862         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 33841152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016196925 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.266       |\n",
      "|    mean_step_reward   | 0.38772106  |\n",
      "|    n_updates          | 16520       |\n",
      "|    policyGradLoss     | -0.0069     |\n",
      "|    value_loss         | 1.21        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 839        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 39         |\n",
      "|    total_timesteps    | 33849344   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01277112 |\n",
      "|    entropy_loss       | -1.62      |\n",
      "|    explained_variance | 0.992      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.423      |\n",
      "|    mean_step_reward   | 0.42629707 |\n",
      "|    n_updates          | 16524      |\n",
      "|    policyGradLoss     | -0.0065    |\n",
      "|    value_loss         | 1.47       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 825          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 49           |\n",
      "|    total_timesteps    | 33857536     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0102741495 |\n",
      "|    entropy_loss       | -1.65        |\n",
      "|    explained_variance | 0.989        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.745        |\n",
      "|    mean_step_reward   | 0.38419282   |\n",
      "|    n_updates          | 16528        |\n",
      "|    policyGradLoss     | -0.00652     |\n",
      "|    value_loss         | 1.62         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 33865728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012987694 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.668       |\n",
      "|    mean_step_reward   | 0.38798955  |\n",
      "|    n_updates          | 16532       |\n",
      "|    policyGradLoss     | -0.00437    |\n",
      "|    value_loss         | 1.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 33873920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012987945 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.766       |\n",
      "|    mean_step_reward   | 0.40851814  |\n",
      "|    n_updates          | 16536       |\n",
      "|    policyGradLoss     | -0.00685    |\n",
      "|    value_loss         | 1.45        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 33882112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013509566 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.557       |\n",
      "|    mean_step_reward   | 0.4225838   |\n",
      "|    n_updates          | 16540       |\n",
      "|    policyGradLoss     | -0.00523    |\n",
      "|    value_loss         | 1.66        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 33890304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009813402 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.258       |\n",
      "|    mean_step_reward   | 0.44456887  |\n",
      "|    n_updates          | 16544       |\n",
      "|    policyGradLoss     | -0.00662    |\n",
      "|    value_loss         | 1.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 33898496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009402087 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.922       |\n",
      "|    mean_step_reward   | 0.43625447  |\n",
      "|    n_updates          | 16548       |\n",
      "|    policyGradLoss     | -0.00449    |\n",
      "|    value_loss         | 1.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 33906688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008912975 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.835       |\n",
      "|    mean_step_reward   | 0.42468604  |\n",
      "|    n_updates          | 16552       |\n",
      "|    policyGradLoss     | -0.00622    |\n",
      "|    value_loss         | 1.81        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 33914880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011152806 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.157       |\n",
      "|    mean_step_reward   | 0.41447473  |\n",
      "|    n_updates          | 16556       |\n",
      "|    policyGradLoss     | -0.00493    |\n",
      "|    value_loss         | 1.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 33923072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012428649 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.06        |\n",
      "|    mean_step_reward   | 0.4057346   |\n",
      "|    n_updates          | 16560       |\n",
      "|    policyGradLoss     | -0.00617    |\n",
      "|    value_loss         | 1.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 33931264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011226795 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.712       |\n",
      "|    mean_step_reward   | 0.4258504   |\n",
      "|    n_updates          | 16564       |\n",
      "|    policyGradLoss     | -0.00335    |\n",
      "|    value_loss         | 2.07        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 33939456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015002946 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.728       |\n",
      "|    mean_step_reward   | 0.398901    |\n",
      "|    n_updates          | 16568       |\n",
      "|    policyGradLoss     | -0.00549    |\n",
      "|    value_loss         | 2.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 33947648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014553649 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.723       |\n",
      "|    mean_step_reward   | 0.34222707  |\n",
      "|    n_updates          | 16572       |\n",
      "|    policyGradLoss     | -0.0042     |\n",
      "|    value_loss         | 2.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 33955840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011685843 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.155       |\n",
      "|    mean_step_reward   | 0.43526828  |\n",
      "|    n_updates          | 16576       |\n",
      "|    policyGradLoss     | -0.00547    |\n",
      "|    value_loss         | 1.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 33964032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010627786 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.623       |\n",
      "|    mean_step_reward   | 0.35224295  |\n",
      "|    n_updates          | 16580       |\n",
      "|    policyGradLoss     | -0.00109    |\n",
      "|    value_loss         | 2.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 33972224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013753276 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.95        |\n",
      "|    mean_step_reward   | 0.46160847  |\n",
      "|    n_updates          | 16584       |\n",
      "|    policyGradLoss     | -0.00643    |\n",
      "|    value_loss         | 1.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 33980416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010041881 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.506       |\n",
      "|    mean_step_reward   | 0.34617215  |\n",
      "|    n_updates          | 16588       |\n",
      "|    policyGradLoss     | -0.00523    |\n",
      "|    value_loss         | 1.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 33988608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011518454 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.453       |\n",
      "|    mean_step_reward   | 0.4053386   |\n",
      "|    n_updates          | 16592       |\n",
      "|    policyGradLoss     | -0.00257    |\n",
      "|    value_loss         | 1.71        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 33996800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010011288 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.979       |\n",
      "|    mean_step_reward   | 0.40091205  |\n",
      "|    n_updates          | 16596       |\n",
      "|    policyGradLoss     | -0.00471    |\n",
      "|    value_loss         | 1.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 34004992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010889445 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.777       |\n",
      "|    mean_step_reward   | 0.37055063  |\n",
      "|    n_updates          | 16600       |\n",
      "|    policyGradLoss     | -0.00423    |\n",
      "|    value_loss         | 1.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 34013184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011640774 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0745      |\n",
      "|    mean_step_reward   | 0.40722713  |\n",
      "|    n_updates          | 16604       |\n",
      "|    policyGradLoss     | -0.00687    |\n",
      "|    value_loss         | 1.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 34021376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009743347 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.865       |\n",
      "|    mean_step_reward   | 0.38814592  |\n",
      "|    n_updates          | 16608       |\n",
      "|    policyGradLoss     | -0.00558    |\n",
      "|    value_loss         | 2.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 34029568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013789343 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.306       |\n",
      "|    mean_step_reward   | 0.3992424   |\n",
      "|    n_updates          | 16612       |\n",
      "|    policyGradLoss     | -0.0081     |\n",
      "|    value_loss         | 0.774       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 34037760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013237077 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.49        |\n",
      "|    mean_step_reward   | 0.36615205  |\n",
      "|    n_updates          | 16616       |\n",
      "|    policyGradLoss     | -0.00251    |\n",
      "|    value_loss         | 2.82        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 34045952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015122471 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.717       |\n",
      "|    mean_step_reward   | 0.40169102  |\n",
      "|    n_updates          | 16620       |\n",
      "|    policyGradLoss     | -0.00398    |\n",
      "|    value_loss         | 1.98        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 34054144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013403958 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.235       |\n",
      "|    mean_step_reward   | 0.41386685  |\n",
      "|    n_updates          | 16624       |\n",
      "|    policyGradLoss     | -0.00326    |\n",
      "|    value_loss         | 3.03        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 316        |\n",
      "|    total_timesteps    | 34062336   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01313949 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.983      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.462      |\n",
      "|    mean_step_reward   | 0.33370432 |\n",
      "|    n_updates          | 16628      |\n",
      "|    policyGradLoss     | -0.00538   |\n",
      "|    value_loss         | 1.97       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 34070528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013635132 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.853       |\n",
      "|    mean_step_reward   | 0.42536554  |\n",
      "|    n_updates          | 16632       |\n",
      "|    policyGradLoss     | 0.000453    |\n",
      "|    value_loss         | 3.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 34078720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014962165 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.796       |\n",
      "|    mean_step_reward   | 0.3472216   |\n",
      "|    n_updates          | 16636       |\n",
      "|    policyGradLoss     | -0.00766    |\n",
      "|    value_loss         | 1.4         |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_129.zip\n",
      "[EVAL] Mean Return: 538.433, Best Return: 545.100\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_129_538.43.mp4\n",
      "\n",
      "=== Round 131 | Learn 262144 steps (Total trained: 34078720) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1154     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 34086912 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 919         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 34095104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011008648 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.425       |\n",
      "|    mean_step_reward   | 0.3677625   |\n",
      "|    n_updates          | 16644       |\n",
      "|    policyGradLoss     | -0.00523    |\n",
      "|    value_loss         | 1.92        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 870        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 34103296   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00784397 |\n",
      "|    entropy_loss       | -1.63      |\n",
      "|    explained_variance | 0.986      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.332      |\n",
      "|    mean_step_reward   | 0.40210396 |\n",
      "|    n_updates          | 16648      |\n",
      "|    policyGradLoss     | -0.00368   |\n",
      "|    value_loss         | 1.53       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 842         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 34111488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009434896 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.65        |\n",
      "|    mean_step_reward   | 0.40480092  |\n",
      "|    n_updates          | 16652       |\n",
      "|    policyGradLoss     | -0.00655    |\n",
      "|    value_loss         | 1.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 827         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 34119680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010973411 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.699       |\n",
      "|    mean_step_reward   | 0.36718625  |\n",
      "|    n_updates          | 16656       |\n",
      "|    policyGradLoss     | -0.00491    |\n",
      "|    value_loss         | 1.72        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 34127872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014027704 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.26        |\n",
      "|    mean_step_reward   | 0.42655128  |\n",
      "|    n_updates          | 16660       |\n",
      "|    policyGradLoss     | -0.0092     |\n",
      "|    value_loss         | 0.888       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 34136064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009629508 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.708       |\n",
      "|    mean_step_reward   | 0.41277558  |\n",
      "|    n_updates          | 16664       |\n",
      "|    policyGradLoss     | -0.000541   |\n",
      "|    value_loss         | 2.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 34144256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014781918 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.534       |\n",
      "|    mean_step_reward   | 0.451394    |\n",
      "|    n_updates          | 16668       |\n",
      "|    policyGradLoss     | -0.00575    |\n",
      "|    value_loss         | 1.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 34152448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013473557 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.27        |\n",
      "|    mean_step_reward   | 0.3561489   |\n",
      "|    n_updates          | 16672       |\n",
      "|    policyGradLoss     | -0.00415    |\n",
      "|    value_loss         | 2.31        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 795        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 102        |\n",
      "|    total_timesteps    | 34160640   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01748121 |\n",
      "|    entropy_loss       | -1.59      |\n",
      "|    explained_variance | 0.986      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.494      |\n",
      "|    mean_step_reward   | 0.40446633 |\n",
      "|    n_updates          | 16676      |\n",
      "|    policyGradLoss     | -0.0062    |\n",
      "|    value_loss         | 1.51       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 34168832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012006393 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.326       |\n",
      "|    mean_step_reward   | 0.44624504  |\n",
      "|    n_updates          | 16680       |\n",
      "|    policyGradLoss     | -0.00689    |\n",
      "|    value_loss         | 1.64        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 793        |\n",
      "|    iterations         | 12         |\n",
      "|    time_elapsed       | 123        |\n",
      "|    total_timesteps    | 34177024   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01656619 |\n",
      "|    entropy_loss       | -1.66      |\n",
      "|    explained_variance | 0.988      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.689      |\n",
      "|    mean_step_reward   | 0.40752137 |\n",
      "|    n_updates          | 16684      |\n",
      "|    policyGradLoss     | -0.00549   |\n",
      "|    value_loss         | 1.96       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 34185216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014150485 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.468       |\n",
      "|    mean_step_reward   | 0.45637986  |\n",
      "|    n_updates          | 16688       |\n",
      "|    policyGradLoss     | -0.000338   |\n",
      "|    value_loss         | 3.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 34193408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013227073 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.883       |\n",
      "|    mean_step_reward   | 0.39866394  |\n",
      "|    n_updates          | 16692       |\n",
      "|    policyGradLoss     | -0.00532    |\n",
      "|    value_loss         | 2.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 34201600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014523177 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.309       |\n",
      "|    mean_step_reward   | 0.3894214   |\n",
      "|    n_updates          | 16696       |\n",
      "|    policyGradLoss     | -0.00541    |\n",
      "|    value_loss         | 1.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 34209792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017305579 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.682       |\n",
      "|    mean_step_reward   | 0.40919012  |\n",
      "|    n_updates          | 16700       |\n",
      "|    policyGradLoss     | -0.00637    |\n",
      "|    value_loss         | 1.65        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 34217984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013452269 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.547       |\n",
      "|    mean_step_reward   | 0.44067508  |\n",
      "|    n_updates          | 16704       |\n",
      "|    policyGradLoss     | -0.00527    |\n",
      "|    value_loss         | 1.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 34226176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011422632 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.867       |\n",
      "|    mean_step_reward   | 0.39583763  |\n",
      "|    n_updates          | 16708       |\n",
      "|    policyGradLoss     | -0.00388    |\n",
      "|    value_loss         | 2.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 34234368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010491796 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.913       |\n",
      "|    mean_step_reward   | 0.34147057  |\n",
      "|    n_updates          | 16712       |\n",
      "|    policyGradLoss     | -0.00252    |\n",
      "|    value_loss         | 2.03        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 781        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 209        |\n",
      "|    total_timesteps    | 34242560   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01380678 |\n",
      "|    entropy_loss       | -1.62      |\n",
      "|    explained_variance | 0.99       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.121      |\n",
      "|    mean_step_reward   | 0.42922232 |\n",
      "|    n_updates          | 16716      |\n",
      "|    policyGradLoss     | -0.00607   |\n",
      "|    value_loss         | 1.01       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 34250752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010841769 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.468       |\n",
      "|    mean_step_reward   | 0.39323187  |\n",
      "|    n_updates          | 16720       |\n",
      "|    policyGradLoss     | -0.00571    |\n",
      "|    value_loss         | 2.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 34258944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008593499 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.899       |\n",
      "|    mean_step_reward   | 0.451135    |\n",
      "|    n_updates          | 16724       |\n",
      "|    policyGradLoss     | -0.00226    |\n",
      "|    value_loss         | 1.66        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 34267136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018162994 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.921       |\n",
      "|    mean_step_reward   | 0.40593976  |\n",
      "|    n_updates          | 16728       |\n",
      "|    policyGradLoss     | -0.00931    |\n",
      "|    value_loss         | 1.46        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 34275328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009007789 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.295       |\n",
      "|    mean_step_reward   | 0.41143256  |\n",
      "|    n_updates          | 16732       |\n",
      "|    policyGradLoss     | -0.00775    |\n",
      "|    value_loss         | 1.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 34283520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015577206 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.251       |\n",
      "|    mean_step_reward   | 0.37045044  |\n",
      "|    n_updates          | 16736       |\n",
      "|    policyGradLoss     | -0.00941    |\n",
      "|    value_loss         | 1.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 34291712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012933507 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.626       |\n",
      "|    mean_step_reward   | 0.42233902  |\n",
      "|    n_updates          | 16740       |\n",
      "|    policyGradLoss     | -0.00815    |\n",
      "|    value_loss         | 1.64        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 284        |\n",
      "|    total_timesteps    | 34299904   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01413166 |\n",
      "|    entropy_loss       | -1.66      |\n",
      "|    explained_variance | 0.958      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.628      |\n",
      "|    mean_step_reward   | 0.40601575 |\n",
      "|    n_updates          | 16744      |\n",
      "|    policyGradLoss     | -0.000995  |\n",
      "|    value_loss         | 3          |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 34308096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015040321 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.419       |\n",
      "|    mean_step_reward   | 0.4142262   |\n",
      "|    n_updates          | 16748       |\n",
      "|    policyGradLoss     | -0.00622    |\n",
      "|    value_loss         | 1.86        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 34316288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026054356 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.858       |\n",
      "|    mean_step_reward   | 0.38923746  |\n",
      "|    n_updates          | 16752       |\n",
      "|    policyGradLoss     | -0.00771    |\n",
      "|    value_loss         | 1.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 34324480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013024648 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.479       |\n",
      "|    mean_step_reward   | 0.3795469   |\n",
      "|    n_updates          | 16756       |\n",
      "|    policyGradLoss     | -0.00674    |\n",
      "|    value_loss         | 1.52        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 34332672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020577498 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.452       |\n",
      "|    mean_step_reward   | 0.40946758  |\n",
      "|    n_updates          | 16760       |\n",
      "|    policyGradLoss     | -0.00262    |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 34340864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015476455 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.559       |\n",
      "|    mean_step_reward   | 0.39401704  |\n",
      "|    n_updates          | 16764       |\n",
      "|    policyGradLoss     | -0.0018     |\n",
      "|    value_loss         | 2.71        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_130.zip\n",
      "[EVAL] Mean Return: 531.754, Best Return: 537.754\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_130_531.75.mp4\n",
      "\n",
      "=== Round 132 | Learn 262144 steps (Total trained: 34340864) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1135     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 34349056 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 933        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 34357248   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01857768 |\n",
      "|    entropy_loss       | -1.63      |\n",
      "|    explained_variance | 0.944      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.01       |\n",
      "|    mean_step_reward   | 0.40671855 |\n",
      "|    n_updates          | 16772      |\n",
      "|    policyGradLoss     | 0.00483    |\n",
      "|    value_loss         | 4.04       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 872         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 34365440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009540692 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.915       |\n",
      "|    mean_step_reward   | 0.3818715   |\n",
      "|    n_updates          | 16776       |\n",
      "|    policyGradLoss     | -0.00231    |\n",
      "|    value_loss         | 3.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 840         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 34373632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016276669 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.719       |\n",
      "|    mean_step_reward   | 0.4116939   |\n",
      "|    n_updates          | 16780       |\n",
      "|    policyGradLoss     | -0.00342    |\n",
      "|    value_loss         | 2.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 34381824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013349039 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.449       |\n",
      "|    mean_step_reward   | 0.4275717   |\n",
      "|    n_updates          | 16784       |\n",
      "|    policyGradLoss     | -0.00225    |\n",
      "|    value_loss         | 3.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 34390016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011308674 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.6         |\n",
      "|    mean_step_reward   | 0.446279    |\n",
      "|    n_updates          | 16788       |\n",
      "|    policyGradLoss     | 0.00133     |\n",
      "|    value_loss         | 3.66        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 34398208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014145913 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.35        |\n",
      "|    mean_step_reward   | 0.43971187  |\n",
      "|    n_updates          | 16792       |\n",
      "|    policyGradLoss     | 0.00113     |\n",
      "|    value_loss         | 2.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 34406400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014800436 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.302       |\n",
      "|    mean_step_reward   | 0.3811061   |\n",
      "|    n_updates          | 16796       |\n",
      "|    policyGradLoss     | -0.00527    |\n",
      "|    value_loss         | 1.8         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 34414592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013225402 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.911       |\n",
      "|    mean_step_reward   | 0.3777186   |\n",
      "|    n_updates          | 16800       |\n",
      "|    policyGradLoss     | -0.00224    |\n",
      "|    value_loss         | 3.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 34422784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016702669 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.402       |\n",
      "|    mean_step_reward   | 0.33692336  |\n",
      "|    n_updates          | 16804       |\n",
      "|    policyGradLoss     | -0.00531    |\n",
      "|    value_loss         | 1.75        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 34430976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015883956 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.328       |\n",
      "|    mean_step_reward   | 0.44340467  |\n",
      "|    n_updates          | 16808       |\n",
      "|    policyGradLoss     | -0.00615    |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 34439168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013375852 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.24        |\n",
      "|    mean_step_reward   | 0.3603692   |\n",
      "|    n_updates          | 16812       |\n",
      "|    policyGradLoss     | -0.00445    |\n",
      "|    value_loss         | 1.89        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 34447360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012718262 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.29        |\n",
      "|    mean_step_reward   | 0.40421593  |\n",
      "|    n_updates          | 16816       |\n",
      "|    policyGradLoss     | -0.00731    |\n",
      "|    value_loss         | 1.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 34455552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017938301 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.155       |\n",
      "|    mean_step_reward   | 0.40006888  |\n",
      "|    n_updates          | 16820       |\n",
      "|    policyGradLoss     | -0.0084     |\n",
      "|    value_loss         | 1.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 34463744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017418569 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.611       |\n",
      "|    mean_step_reward   | 0.3935343   |\n",
      "|    n_updates          | 16824       |\n",
      "|    policyGradLoss     | -0.00534    |\n",
      "|    value_loss         | 1.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 34471936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016073437 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.366       |\n",
      "|    mean_step_reward   | 0.4347586   |\n",
      "|    n_updates          | 16828       |\n",
      "|    policyGradLoss     | -0.00561    |\n",
      "|    value_loss         | 1.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 34480128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014319618 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.901       |\n",
      "|    mean_step_reward   | 0.45674974  |\n",
      "|    n_updates          | 16832       |\n",
      "|    policyGradLoss     | -0.00612    |\n",
      "|    value_loss         | 1.5         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 34488320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012916999 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.01        |\n",
      "|    mean_step_reward   | 0.3740806   |\n",
      "|    n_updates          | 16836       |\n",
      "|    policyGradLoss     | -0.00858    |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 34496512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013961301 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.321       |\n",
      "|    mean_step_reward   | 0.40324217  |\n",
      "|    n_updates          | 16840       |\n",
      "|    policyGradLoss     | -0.00287    |\n",
      "|    value_loss         | 1.96        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 34504704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011825316 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.757       |\n",
      "|    mean_step_reward   | 0.40499747  |\n",
      "|    n_updates          | 16844       |\n",
      "|    policyGradLoss     | -0.00438    |\n",
      "|    value_loss         | 2.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 34512896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016334228 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.426       |\n",
      "|    mean_step_reward   | 0.40650374  |\n",
      "|    n_updates          | 16848       |\n",
      "|    policyGradLoss     | -0.00757    |\n",
      "|    value_loss         | 1.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 34521088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010419096 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.02        |\n",
      "|    mean_step_reward   | 0.35431617  |\n",
      "|    n_updates          | 16852       |\n",
      "|    policyGradLoss     | -0.00219    |\n",
      "|    value_loss         | 3.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 34529280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008101644 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.669       |\n",
      "|    mean_step_reward   | 0.39695868  |\n",
      "|    n_updates          | 16856       |\n",
      "|    policyGradLoss     | -0.00183    |\n",
      "|    value_loss         | 2.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 34537472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010566807 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.565       |\n",
      "|    mean_step_reward   | 0.41912967  |\n",
      "|    n_updates          | 16860       |\n",
      "|    policyGradLoss     | -0.00535    |\n",
      "|    value_loss         | 1.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 34545664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012743295 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.545       |\n",
      "|    mean_step_reward   | 0.44647717  |\n",
      "|    n_updates          | 16864       |\n",
      "|    policyGradLoss     | -0.00453    |\n",
      "|    value_loss         | 2.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 34553856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016249165 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.1         |\n",
      "|    mean_step_reward   | 0.37638026  |\n",
      "|    n_updates          | 16868       |\n",
      "|    policyGradLoss     | -0.00762    |\n",
      "|    value_loss         | 1.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 34562048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014751162 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.625       |\n",
      "|    mean_step_reward   | 0.37698704  |\n",
      "|    n_updates          | 16872       |\n",
      "|    policyGradLoss     | -0.00831    |\n",
      "|    value_loss         | 1.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 34570240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019411806 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.351       |\n",
      "|    mean_step_reward   | 0.4676321   |\n",
      "|    n_updates          | 16876       |\n",
      "|    policyGradLoss     | -0.00919    |\n",
      "|    value_loss         | 0.965       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 34578432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013746713 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.638       |\n",
      "|    mean_step_reward   | 0.38803154  |\n",
      "|    n_updates          | 16880       |\n",
      "|    policyGradLoss     | -0.00665    |\n",
      "|    value_loss         | 1.88        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 34586624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009897108 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.677       |\n",
      "|    mean_step_reward   | 0.4114123   |\n",
      "|    n_updates          | 16884       |\n",
      "|    policyGradLoss     | -0.00776    |\n",
      "|    value_loss         | 1.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 34594816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008860882 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.44        |\n",
      "|    mean_step_reward   | 0.40420318  |\n",
      "|    n_updates          | 16888       |\n",
      "|    policyGradLoss     | -0.00192    |\n",
      "|    value_loss         | 2.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 34603008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016166626 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.73        |\n",
      "|    mean_step_reward   | 0.37317494  |\n",
      "|    n_updates          | 16892       |\n",
      "|    policyGradLoss     | -0.00807    |\n",
      "|    value_loss         | 1.17        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_131.zip\n",
      "[EVAL] Mean Return: 538.642, Best Return: 545.642\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_131_538.64.mp4\n",
      "\n",
      "=== Round 133 | Learn 262144 steps (Total trained: 34603008) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1115     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 34611200 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 911         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 34619392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012087338 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.951       |\n",
      "|    mean_step_reward   | 0.40268946  |\n",
      "|    n_updates          | 16900       |\n",
      "|    policyGradLoss     | -0.00539    |\n",
      "|    value_loss         | 1.74        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 856         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 34627584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010219401 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.864       |\n",
      "|    mean_step_reward   | 0.43187982  |\n",
      "|    n_updates          | 16904       |\n",
      "|    policyGradLoss     | -0.00279    |\n",
      "|    value_loss         | 2.53        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 827        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 39         |\n",
      "|    total_timesteps    | 34635776   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01138474 |\n",
      "|    entropy_loss       | -1.66      |\n",
      "|    explained_variance | 0.959      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.593      |\n",
      "|    mean_step_reward   | 0.37380204 |\n",
      "|    n_updates          | 16908      |\n",
      "|    policyGradLoss     | -0.00215   |\n",
      "|    value_loss         | 2.74       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 812        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 50         |\n",
      "|    total_timesteps    | 34643968   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02316725 |\n",
      "|    entropy_loss       | -1.62      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.687      |\n",
      "|    mean_step_reward   | 0.40596402 |\n",
      "|    n_updates          | 16912      |\n",
      "|    policyGradLoss     | -0.00704   |\n",
      "|    value_loss         | 1.54       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 34652160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011687487 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.3         |\n",
      "|    mean_step_reward   | 0.44145894  |\n",
      "|    n_updates          | 16916       |\n",
      "|    policyGradLoss     | -0.00387    |\n",
      "|    value_loss         | 2.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 34660352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014825663 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.04        |\n",
      "|    mean_step_reward   | 0.3935906   |\n",
      "|    n_updates          | 16920       |\n",
      "|    policyGradLoss     | -0.00787    |\n",
      "|    value_loss         | 1.86        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 34668544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021602552 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.127       |\n",
      "|    mean_step_reward   | 0.4634942   |\n",
      "|    n_updates          | 16924       |\n",
      "|    policyGradLoss     | -0.00455    |\n",
      "|    value_loss         | 0.944       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 34676736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010786526 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.76        |\n",
      "|    mean_step_reward   | 0.3816308   |\n",
      "|    n_updates          | 16928       |\n",
      "|    policyGradLoss     | 0.000305    |\n",
      "|    value_loss         | 4.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 34684928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013002804 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.346       |\n",
      "|    mean_step_reward   | 0.44969684  |\n",
      "|    n_updates          | 16932       |\n",
      "|    policyGradLoss     | -0.00304    |\n",
      "|    value_loss         | 1.81        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 34693120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013310319 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.702       |\n",
      "|    mean_step_reward   | 0.38974467  |\n",
      "|    n_updates          | 16936       |\n",
      "|    policyGradLoss     | -0.00223    |\n",
      "|    value_loss         | 2.41        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 793        |\n",
      "|    iterations         | 12         |\n",
      "|    time_elapsed       | 123        |\n",
      "|    total_timesteps    | 34701312   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01340892 |\n",
      "|    entropy_loss       | -1.61      |\n",
      "|    explained_variance | 0.984      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.305      |\n",
      "|    mean_step_reward   | 0.43176705 |\n",
      "|    n_updates          | 16940      |\n",
      "|    policyGradLoss     | -0.00613   |\n",
      "|    value_loss         | 1.52       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 34709504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011923587 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.447       |\n",
      "|    mean_step_reward   | 0.3761537   |\n",
      "|    n_updates          | 16944       |\n",
      "|    policyGradLoss     | -0.00625    |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 34717696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013253204 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.13        |\n",
      "|    mean_step_reward   | 0.42924893  |\n",
      "|    n_updates          | 16948       |\n",
      "|    policyGradLoss     | 0.00147     |\n",
      "|    value_loss         | 5.99        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 34725888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013126934 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.612       |\n",
      "|    mean_step_reward   | 0.39623654  |\n",
      "|    n_updates          | 16952       |\n",
      "|    policyGradLoss     | -0.00247    |\n",
      "|    value_loss         | 2.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 34734080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017772334 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.988       |\n",
      "|    mean_step_reward   | 0.3585712   |\n",
      "|    n_updates          | 16956       |\n",
      "|    policyGradLoss     | -0.0043     |\n",
      "|    value_loss         | 1.95        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 34742272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010186437 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.558       |\n",
      "|    mean_step_reward   | 0.46161288  |\n",
      "|    n_updates          | 16960       |\n",
      "|    policyGradLoss     | -0.00256    |\n",
      "|    value_loss         | 2.07        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 186         |\n",
      "|    total_timesteps    | 34750464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011979704 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.595       |\n",
      "|    mean_step_reward   | 0.4057058   |\n",
      "|    n_updates          | 16964       |\n",
      "|    policyGradLoss     | -0.00722    |\n",
      "|    value_loss         | 1.99        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 197         |\n",
      "|    total_timesteps    | 34758656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013045002 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.523       |\n",
      "|    mean_step_reward   | 0.4274932   |\n",
      "|    n_updates          | 16968       |\n",
      "|    policyGradLoss     | -0.0023     |\n",
      "|    value_loss         | 2.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 207         |\n",
      "|    total_timesteps    | 34766848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012173568 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.05        |\n",
      "|    mean_step_reward   | 0.38898847  |\n",
      "|    n_updates          | 16972       |\n",
      "|    policyGradLoss     | -0.00756    |\n",
      "|    value_loss         | 1.98        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 787        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 218        |\n",
      "|    total_timesteps    | 34775040   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01278648 |\n",
      "|    entropy_loss       | -1.63      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.279      |\n",
      "|    mean_step_reward   | 0.43991297 |\n",
      "|    n_updates          | 16976      |\n",
      "|    policyGradLoss     | -0.00612   |\n",
      "|    value_loss         | 1.59       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 785        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 229        |\n",
      "|    total_timesteps    | 34783232   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01421617 |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.69       |\n",
      "|    mean_step_reward   | 0.41989303 |\n",
      "|    n_updates          | 16980      |\n",
      "|    policyGradLoss     | -0.00648   |\n",
      "|    value_loss         | 1.63       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 239         |\n",
      "|    total_timesteps    | 34791424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012510253 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.341       |\n",
      "|    mean_step_reward   | 0.38861418  |\n",
      "|    n_updates          | 16984       |\n",
      "|    policyGradLoss     | -0.00852    |\n",
      "|    value_loss         | 1.45        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 785        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 250        |\n",
      "|    total_timesteps    | 34799616   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01668588 |\n",
      "|    entropy_loss       | -1.58      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.194      |\n",
      "|    mean_step_reward   | 0.44859493 |\n",
      "|    n_updates          | 16988      |\n",
      "|    policyGradLoss     | -0.00713   |\n",
      "|    value_loss         | 1.16       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 260         |\n",
      "|    total_timesteps    | 34807808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013073259 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.755       |\n",
      "|    mean_step_reward   | 0.3378245   |\n",
      "|    n_updates          | 16992       |\n",
      "|    policyGradLoss     | -0.00643    |\n",
      "|    value_loss         | 1.75        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 34816000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013163637 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.265       |\n",
      "|    mean_step_reward   | 0.41061908  |\n",
      "|    n_updates          | 16996       |\n",
      "|    policyGradLoss     | -0.00468    |\n",
      "|    value_loss         | 1.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 34824192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011525979 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.965       |\n",
      "|    mean_step_reward   | 0.4465178   |\n",
      "|    n_updates          | 17000       |\n",
      "|    policyGradLoss     | -0.00761    |\n",
      "|    value_loss         | 1.63        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 784          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 292          |\n",
      "|    total_timesteps    | 34832384     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0127441455 |\n",
      "|    entropy_loss       | -1.66        |\n",
      "|    explained_variance | 0.986        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.752        |\n",
      "|    mean_step_reward   | 0.3881036    |\n",
      "|    n_updates          | 17004        |\n",
      "|    policyGradLoss     | -0.00583     |\n",
      "|    value_loss         | 1.84         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 303         |\n",
      "|    total_timesteps    | 34840576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016893597 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.596       |\n",
      "|    mean_step_reward   | 0.39750117  |\n",
      "|    n_updates          | 17008       |\n",
      "|    policyGradLoss     | -0.00681    |\n",
      "|    value_loss         | 1.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 313         |\n",
      "|    total_timesteps    | 34848768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015676098 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.288       |\n",
      "|    mean_step_reward   | 0.41017646  |\n",
      "|    n_updates          | 17012       |\n",
      "|    policyGradLoss     | -0.00943    |\n",
      "|    value_loss         | 1.4         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 783          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 324          |\n",
      "|    total_timesteps    | 34856960     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0128883775 |\n",
      "|    entropy_loss       | -1.66        |\n",
      "|    explained_variance | 0.992        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.643        |\n",
      "|    mean_step_reward   | 0.3967412    |\n",
      "|    n_updates          | 17016        |\n",
      "|    policyGradLoss     | -0.00807     |\n",
      "|    value_loss         | 1.25         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 334         |\n",
      "|    total_timesteps    | 34865152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012181083 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.323       |\n",
      "|    mean_step_reward   | 0.4023211   |\n",
      "|    n_updates          | 17020       |\n",
      "|    policyGradLoss     | -0.00714    |\n",
      "|    value_loss         | 1.09        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_132.zip\n",
      "[EVAL] Mean Return: 542.525, Best Return: 549.192\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_132_542.52.mp4\n",
      "\n",
      "=== Round 134 | Learn 262144 steps (Total trained: 34865152) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1157     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 34873344 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 936         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 34881536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016476639 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.54        |\n",
      "|    mean_step_reward   | 0.40492743  |\n",
      "|    n_updates          | 17028       |\n",
      "|    policyGradLoss     | -0.00645    |\n",
      "|    value_loss         | 2.07        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 879         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 34889728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010244907 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.963       |\n",
      "|    mean_step_reward   | 0.42293245  |\n",
      "|    n_updates          | 17032       |\n",
      "|    policyGradLoss     | -0.00596    |\n",
      "|    value_loss         | 1.92        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 848         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 34897920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011330458 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.791       |\n",
      "|    mean_step_reward   | 0.37895817  |\n",
      "|    n_updates          | 17036       |\n",
      "|    policyGradLoss     | -0.00633    |\n",
      "|    value_loss         | 2.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 829         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 34906112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019812085 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.779       |\n",
      "|    mean_step_reward   | 0.35381952  |\n",
      "|    n_updates          | 17040       |\n",
      "|    policyGradLoss     | -0.00392    |\n",
      "|    value_loss         | 2.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 34914304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013172596 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.95        |\n",
      "|    mean_step_reward   | 0.39514136  |\n",
      "|    n_updates          | 17044       |\n",
      "|    policyGradLoss     | -0.00291    |\n",
      "|    value_loss         | 1.72        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 34922496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012257504 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.137       |\n",
      "|    mean_step_reward   | 0.3911046   |\n",
      "|    n_updates          | 17048       |\n",
      "|    policyGradLoss     | -0.00347    |\n",
      "|    value_loss         | 1.73        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 805        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 81         |\n",
      "|    total_timesteps    | 34930688   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01232237 |\n",
      "|    entropy_loss       | -1.66      |\n",
      "|    explained_variance | 0.984      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.22       |\n",
      "|    mean_step_reward   | 0.37063196 |\n",
      "|    n_updates          | 17052      |\n",
      "|    policyGradLoss     | -0.00254   |\n",
      "|    value_loss         | 2.08       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 34938880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014795201 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.668       |\n",
      "|    mean_step_reward   | 0.49510336  |\n",
      "|    n_updates          | 17056       |\n",
      "|    policyGradLoss     | -0.00656    |\n",
      "|    value_loss         | 1.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 34947072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010889113 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.547       |\n",
      "|    mean_step_reward   | 0.38672012  |\n",
      "|    n_updates          | 17060       |\n",
      "|    policyGradLoss     | -0.00579    |\n",
      "|    value_loss         | 2.11        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 34955264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016533481 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.263       |\n",
      "|    mean_step_reward   | 0.4097417   |\n",
      "|    n_updates          | 17064       |\n",
      "|    policyGradLoss     | -0.00268    |\n",
      "|    value_loss         | 2.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 34963456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011855468 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.56        |\n",
      "|    mean_step_reward   | 0.44043213  |\n",
      "|    n_updates          | 17068       |\n",
      "|    policyGradLoss     | 0.00257     |\n",
      "|    value_loss         | 2.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 34971648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013826303 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.09        |\n",
      "|    mean_step_reward   | 0.41869527  |\n",
      "|    n_updates          | 17072       |\n",
      "|    policyGradLoss     | -0.00619    |\n",
      "|    value_loss         | 1.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 34979840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012373815 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.252       |\n",
      "|    mean_step_reward   | 0.39771187  |\n",
      "|    n_updates          | 17076       |\n",
      "|    policyGradLoss     | -0.00511    |\n",
      "|    value_loss         | 1.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 34988032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011108333 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.663       |\n",
      "|    mean_step_reward   | 0.42927995  |\n",
      "|    n_updates          | 17080       |\n",
      "|    policyGradLoss     | -0.00682    |\n",
      "|    value_loss         | 1.91        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 784       |\n",
      "|    iterations         | 16        |\n",
      "|    time_elapsed       | 167       |\n",
      "|    total_timesteps    | 34996224  |\n",
      "| train/                |           |\n",
      "|    approx_kl          | 0.012238  |\n",
      "|    entropy_loss       | -1.66     |\n",
      "|    explained_variance | 0.982     |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    loss               | 1.15      |\n",
      "|    mean_step_reward   | 0.4249602 |\n",
      "|    n_updates          | 17084     |\n",
      "|    policyGradLoss     | -0.00196  |\n",
      "|    value_loss         | 2.12      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 35004416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011144208 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.501       |\n",
      "|    mean_step_reward   | 0.3821476   |\n",
      "|    n_updates          | 17088       |\n",
      "|    policyGradLoss     | -0.00569    |\n",
      "|    value_loss         | 2.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 35012608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016714333 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.23        |\n",
      "|    mean_step_reward   | 0.43165034  |\n",
      "|    n_updates          | 17092       |\n",
      "|    policyGradLoss     | -0.00743    |\n",
      "|    value_loss         | 1.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 35020800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013421459 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.4         |\n",
      "|    mean_step_reward   | 0.34604988  |\n",
      "|    n_updates          | 17096       |\n",
      "|    policyGradLoss     | -0.00198    |\n",
      "|    value_loss         | 3.25        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 782        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 209        |\n",
      "|    total_timesteps    | 35028992   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02117069 |\n",
      "|    entropy_loss       | -1.65      |\n",
      "|    explained_variance | 0.979      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.644      |\n",
      "|    mean_step_reward   | 0.4099791  |\n",
      "|    n_updates          | 17100      |\n",
      "|    policyGradLoss     | -0.00462   |\n",
      "|    value_loss         | 1.92       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 35037184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014159447 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.259       |\n",
      "|    mean_step_reward   | 0.41536522  |\n",
      "|    n_updates          | 17104       |\n",
      "|    policyGradLoss     | -0.00891    |\n",
      "|    value_loss         | 1.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 35045376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017887034 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.19        |\n",
      "|    mean_step_reward   | 0.4119509   |\n",
      "|    n_updates          | 17108       |\n",
      "|    policyGradLoss     | -0.00822    |\n",
      "|    value_loss         | 1.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 35053568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018138885 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.554       |\n",
      "|    mean_step_reward   | 0.36815295  |\n",
      "|    n_updates          | 17112       |\n",
      "|    policyGradLoss     | -0.00602    |\n",
      "|    value_loss         | 1.98        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 35061760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017205875 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.257       |\n",
      "|    mean_step_reward   | 0.37584645  |\n",
      "|    n_updates          | 17116       |\n",
      "|    policyGradLoss     | -0.00422    |\n",
      "|    value_loss         | 1.44        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 778          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 262          |\n",
      "|    total_timesteps    | 35069952     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0145593025 |\n",
      "|    entropy_loss       | -1.7         |\n",
      "|    explained_variance | 0.987        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.305        |\n",
      "|    mean_step_reward   | 0.34773764   |\n",
      "|    n_updates          | 17120        |\n",
      "|    policyGradLoss     | -0.00267     |\n",
      "|    value_loss         | 1.47         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 35078144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018292354 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.529       |\n",
      "|    mean_step_reward   | 0.31173366  |\n",
      "|    n_updates          | 17124       |\n",
      "|    policyGradLoss     | -0.00469    |\n",
      "|    value_loss         | 1.81        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 35086336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012182854 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.27        |\n",
      "|    mean_step_reward   | 0.40508187  |\n",
      "|    n_updates          | 17128       |\n",
      "|    policyGradLoss     | -0.00404    |\n",
      "|    value_loss         | 1.75        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 35094528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012462627 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.757       |\n",
      "|    mean_step_reward   | 0.3684842   |\n",
      "|    n_updates          | 17132       |\n",
      "|    policyGradLoss     | -0.006      |\n",
      "|    value_loss         | 1.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 35102720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013661364 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.209       |\n",
      "|    mean_step_reward   | 0.37199342  |\n",
      "|    n_updates          | 17136       |\n",
      "|    policyGradLoss     | -0.00764    |\n",
      "|    value_loss         | 1.11        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 35110912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015903706 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.34        |\n",
      "|    mean_step_reward   | 0.41149008  |\n",
      "|    n_updates          | 17140       |\n",
      "|    policyGradLoss     | -0.00676    |\n",
      "|    value_loss         | 1.66        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 326        |\n",
      "|    total_timesteps    | 35119104   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01460586 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.993      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.173      |\n",
      "|    mean_step_reward   | 0.4161886  |\n",
      "|    n_updates          | 17144      |\n",
      "|    policyGradLoss     | -0.0069    |\n",
      "|    value_loss         | 1.18       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 35127296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018633718 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.513       |\n",
      "|    mean_step_reward   | 0.42654264  |\n",
      "|    n_updates          | 17148       |\n",
      "|    policyGradLoss     | -0.00659    |\n",
      "|    value_loss         | 1.86        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_133.zip\n",
      "[EVAL] Mean Return: 534.582, Best Return: 541.249\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_133_534.58.mp4\n",
      "\n",
      "=== Round 135 | Learn 262144 steps (Total trained: 35127296) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1115     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 35135488 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 904         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 35143680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014355024 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.53        |\n",
      "|    mean_step_reward   | 0.4307865   |\n",
      "|    n_updates          | 17156       |\n",
      "|    policyGradLoss     | -0.00548    |\n",
      "|    value_loss         | 2.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 848         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 35151872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014324741 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.836       |\n",
      "|    mean_step_reward   | 0.37293077  |\n",
      "|    n_updates          | 17160       |\n",
      "|    policyGradLoss     | -0.00419    |\n",
      "|    value_loss         | 2.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 836         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 35160064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011676034 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.296       |\n",
      "|    mean_step_reward   | 0.35477242  |\n",
      "|    n_updates          | 17164       |\n",
      "|    policyGradLoss     | -0.00659    |\n",
      "|    value_loss         | 1.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 823         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 35168256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013603974 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.572       |\n",
      "|    mean_step_reward   | 0.363602    |\n",
      "|    n_updates          | 17168       |\n",
      "|    policyGradLoss     | -0.00329    |\n",
      "|    value_loss         | 2.11        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 814          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 60           |\n",
      "|    total_timesteps    | 35176448     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0128397895 |\n",
      "|    entropy_loss       | -1.64        |\n",
      "|    explained_variance | 0.964        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.495        |\n",
      "|    mean_step_reward   | 0.39379978   |\n",
      "|    n_updates          | 17172        |\n",
      "|    policyGradLoss     | -0.00193     |\n",
      "|    value_loss         | 2.31         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 35184640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013109745 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.878       |\n",
      "|    mean_step_reward   | 0.42107943  |\n",
      "|    n_updates          | 17176       |\n",
      "|    policyGradLoss     | -0.00535    |\n",
      "|    value_loss         | 2.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 35192832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011246017 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.55        |\n",
      "|    mean_step_reward   | 0.3773709   |\n",
      "|    n_updates          | 17180       |\n",
      "|    policyGradLoss     | -0.00123    |\n",
      "|    value_loss         | 3.61        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 35201024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013368423 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.55        |\n",
      "|    mean_step_reward   | 0.4241889   |\n",
      "|    n_updates          | 17184       |\n",
      "|    policyGradLoss     | -0.00233    |\n",
      "|    value_loss         | 4.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 35209216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010382248 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.12        |\n",
      "|    mean_step_reward   | 0.38232863  |\n",
      "|    n_updates          | 17188       |\n",
      "|    policyGradLoss     | -0.000823   |\n",
      "|    value_loss         | 3.74        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 35217408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019201782 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.153       |\n",
      "|    mean_step_reward   | 0.46082968  |\n",
      "|    n_updates          | 17192       |\n",
      "|    policyGradLoss     | -0.000827   |\n",
      "|    value_loss         | 1.75        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 787        |\n",
      "|    iterations         | 12         |\n",
      "|    time_elapsed       | 124        |\n",
      "|    total_timesteps    | 35225600   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01973075 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.483      |\n",
      "|    mean_step_reward   | 0.3991686  |\n",
      "|    n_updates          | 17196      |\n",
      "|    policyGradLoss     | -0.00627   |\n",
      "|    value_loss         | 2.29       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 35233792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012277888 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.517       |\n",
      "|    mean_step_reward   | 0.4429525   |\n",
      "|    n_updates          | 17200       |\n",
      "|    policyGradLoss     | -0.00185    |\n",
      "|    value_loss         | 3.09        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 787        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 145        |\n",
      "|    total_timesteps    | 35241984   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01345943 |\n",
      "|    entropy_loss       | -1.66      |\n",
      "|    explained_variance | 0.974      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.463      |\n",
      "|    mean_step_reward   | 0.38718677 |\n",
      "|    n_updates          | 17204      |\n",
      "|    policyGradLoss     | 0.00277    |\n",
      "|    value_loss         | 2.13       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 35250176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017781297 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.441       |\n",
      "|    mean_step_reward   | 0.39766142  |\n",
      "|    n_updates          | 17208       |\n",
      "|    policyGradLoss     | -0.00583    |\n",
      "|    value_loss         | 1.5         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 35258368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015796984 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.599       |\n",
      "|    mean_step_reward   | 0.39358902  |\n",
      "|    n_updates          | 17212       |\n",
      "|    policyGradLoss     | -0.00431    |\n",
      "|    value_loss         | 1.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 35266560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012469223 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.317       |\n",
      "|    mean_step_reward   | 0.35523468  |\n",
      "|    n_updates          | 17216       |\n",
      "|    policyGradLoss     | -0.00932    |\n",
      "|    value_loss         | 1.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 35274752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012760997 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.717       |\n",
      "|    mean_step_reward   | 0.36130226  |\n",
      "|    n_updates          | 17220       |\n",
      "|    policyGradLoss     | -0.00855    |\n",
      "|    value_loss         | 1.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 35282944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012625193 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.356       |\n",
      "|    mean_step_reward   | 0.35915804  |\n",
      "|    n_updates          | 17224       |\n",
      "|    policyGradLoss     | -0.00721    |\n",
      "|    value_loss         | 1.99        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 783        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 209        |\n",
      "|    total_timesteps    | 35291136   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01110571 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.974      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.889      |\n",
      "|    mean_step_reward   | 0.39117324 |\n",
      "|    n_updates          | 17228      |\n",
      "|    policyGradLoss     | -0.00297   |\n",
      "|    value_loss         | 2.71       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 35299328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011505059 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.843       |\n",
      "|    mean_step_reward   | 0.39911884  |\n",
      "|    n_updates          | 17232       |\n",
      "|    policyGradLoss     | -0.00786    |\n",
      "|    value_loss         | 1.65        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 35307520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016139079 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.765       |\n",
      "|    mean_step_reward   | 0.37194204  |\n",
      "|    n_updates          | 17236       |\n",
      "|    policyGradLoss     | -0.00766    |\n",
      "|    value_loss         | 1.66        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 35315712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014231391 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.306       |\n",
      "|    mean_step_reward   | 0.37724853  |\n",
      "|    n_updates          | 17240       |\n",
      "|    policyGradLoss     | -0.00712    |\n",
      "|    value_loss         | 1.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 35323904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013147172 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.209       |\n",
      "|    mean_step_reward   | 0.3988845   |\n",
      "|    n_updates          | 17244       |\n",
      "|    policyGradLoss     | -0.00716    |\n",
      "|    value_loss         | 1.36        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 780          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 262          |\n",
      "|    total_timesteps    | 35332096     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0143086575 |\n",
      "|    entropy_loss       | -1.71        |\n",
      "|    explained_variance | 0.985        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.05         |\n",
      "|    mean_step_reward   | 0.3392839    |\n",
      "|    n_updates          | 17248        |\n",
      "|    policyGradLoss     | -0.00715     |\n",
      "|    value_loss         | 1.82         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 35340288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013075465 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.06        |\n",
      "|    mean_step_reward   | 0.38443428  |\n",
      "|    n_updates          | 17252       |\n",
      "|    policyGradLoss     | -0.00797    |\n",
      "|    value_loss         | 1.53        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 35348480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016763778 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.33        |\n",
      "|    mean_step_reward   | 0.4064741   |\n",
      "|    n_updates          | 17256       |\n",
      "|    policyGradLoss     | -0.00736    |\n",
      "|    value_loss         | 1.48        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 780        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 293        |\n",
      "|    total_timesteps    | 35356672   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00969611 |\n",
      "|    entropy_loss       | -1.68      |\n",
      "|    explained_variance | 0.986      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.567      |\n",
      "|    mean_step_reward   | 0.38586566 |\n",
      "|    n_updates          | 17260      |\n",
      "|    policyGradLoss     | -0.00606   |\n",
      "|    value_loss         | 1.65       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 35364864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009176021 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.41        |\n",
      "|    mean_step_reward   | 0.38966465  |\n",
      "|    n_updates          | 17264       |\n",
      "|    policyGradLoss     | -0.00847    |\n",
      "|    value_loss         | 1.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 35373056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011562707 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.662       |\n",
      "|    mean_step_reward   | 0.3768491   |\n",
      "|    n_updates          | 17268       |\n",
      "|    policyGradLoss     | -0.00434    |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 325        |\n",
      "|    total_timesteps    | 35381248   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01788085 |\n",
      "|    entropy_loss       | -1.63      |\n",
      "|    explained_variance | 0.957      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.56       |\n",
      "|    mean_step_reward   | 0.3963465  |\n",
      "|    n_updates          | 17272      |\n",
      "|    policyGradLoss     | -0.00114   |\n",
      "|    value_loss         | 4.59       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 35389440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010862775 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.676       |\n",
      "|    mean_step_reward   | 0.3949579   |\n",
      "|    n_updates          | 17276       |\n",
      "|    policyGradLoss     | -0.00309    |\n",
      "|    value_loss         | 2.59        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_134.zip\n",
      "[EVAL] Mean Return: 537.730, Best Return: 544.396\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_134_537.73.mp4\n",
      "\n",
      "=== Round 136 | Learn 262144 steps (Total trained: 35389440) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1100     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 35397632 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 906         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 35405824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015085512 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.248       |\n",
      "|    mean_step_reward   | 0.3696121   |\n",
      "|    n_updates          | 17284       |\n",
      "|    policyGradLoss     | -0.00686    |\n",
      "|    value_loss         | 1.45        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 840         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 35414016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011586754 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.292       |\n",
      "|    mean_step_reward   | 0.35427547  |\n",
      "|    n_updates          | 17288       |\n",
      "|    policyGradLoss     | -0.00685    |\n",
      "|    value_loss         | 1.47        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 816        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 40         |\n",
      "|    total_timesteps    | 35422208   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01733993 |\n",
      "|    entropy_loss       | -1.72      |\n",
      "|    explained_variance | 0.949      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.599      |\n",
      "|    mean_step_reward   | 0.32608745 |\n",
      "|    n_updates          | 17292      |\n",
      "|    policyGradLoss     | -0.00265   |\n",
      "|    value_loss         | 4.99       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 35430400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012607815 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.163       |\n",
      "|    mean_step_reward   | 0.31893963  |\n",
      "|    n_updates          | 17296       |\n",
      "|    policyGradLoss     | -0.00461    |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 35438592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013433113 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.395       |\n",
      "|    mean_step_reward   | 0.32471344  |\n",
      "|    n_updates          | 17300       |\n",
      "|    policyGradLoss     | -0.00647    |\n",
      "|    value_loss         | 1.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 35446784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013595028 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.467       |\n",
      "|    mean_step_reward   | 0.3345634   |\n",
      "|    n_updates          | 17304       |\n",
      "|    policyGradLoss     | -0.00623    |\n",
      "|    value_loss         | 1.64        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 35454976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011736974 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.921       |\n",
      "|    mean_step_reward   | 0.40908635  |\n",
      "|    n_updates          | 17308       |\n",
      "|    policyGradLoss     | -0.00576    |\n",
      "|    value_loss         | 1.81        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 789        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 93         |\n",
      "|    total_timesteps    | 35463168   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01611223 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.992      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.41       |\n",
      "|    mean_step_reward   | 0.39836136 |\n",
      "|    n_updates          | 17312      |\n",
      "|    policyGradLoss     | -0.00706   |\n",
      "|    value_loss         | 1.44       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 35471360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011667479 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.291       |\n",
      "|    mean_step_reward   | 0.36410162  |\n",
      "|    n_updates          | 17316       |\n",
      "|    policyGradLoss     | -0.00884    |\n",
      "|    value_loss         | 1.64        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 35479552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011624061 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.395       |\n",
      "|    mean_step_reward   | 0.39081007  |\n",
      "|    n_updates          | 17320       |\n",
      "|    policyGradLoss     | -0.00345    |\n",
      "|    value_loss         | 2.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 35487744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012305036 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.997       |\n",
      "|    mean_step_reward   | 0.39118242  |\n",
      "|    n_updates          | 17324       |\n",
      "|    policyGradLoss     | -0.00826    |\n",
      "|    value_loss         | 1.65        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 35495936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009869469 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.57        |\n",
      "|    mean_step_reward   | 0.42085716  |\n",
      "|    n_updates          | 17328       |\n",
      "|    policyGradLoss     | 0.000737    |\n",
      "|    value_loss         | 4.12        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 783          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 146          |\n",
      "|    total_timesteps    | 35504128     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0093966015 |\n",
      "|    entropy_loss       | -1.64        |\n",
      "|    explained_variance | 0.987        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.851        |\n",
      "|    mean_step_reward   | 0.40801212   |\n",
      "|    n_updates          | 17332        |\n",
      "|    policyGradLoss     | -0.00613     |\n",
      "|    value_loss         | 1.67         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 35512320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011114028 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.964       |\n",
      "|    mean_step_reward   | 0.40180135  |\n",
      "|    n_updates          | 17336       |\n",
      "|    policyGradLoss     | -0.00272    |\n",
      "|    value_loss         | 4           |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 35520512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008898569 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.797       |\n",
      "|    mean_step_reward   | 0.42321745  |\n",
      "|    n_updates          | 17340       |\n",
      "|    policyGradLoss     | -0.00499    |\n",
      "|    value_loss         | 1.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 35528704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018743731 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.247       |\n",
      "|    mean_step_reward   | 0.38525516  |\n",
      "|    n_updates          | 17344       |\n",
      "|    policyGradLoss     | -0.00832    |\n",
      "|    value_loss         | 1.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 35536896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018210571 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.548       |\n",
      "|    mean_step_reward   | 0.3594196   |\n",
      "|    n_updates          | 17348       |\n",
      "|    policyGradLoss     | -0.00934    |\n",
      "|    value_loss         | 1.36        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 200        |\n",
      "|    total_timesteps    | 35545088   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01832242 |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.985      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.563      |\n",
      "|    mean_step_reward   | 0.41559488 |\n",
      "|    n_updates          | 17352      |\n",
      "|    policyGradLoss     | 0.00127    |\n",
      "|    value_loss         | 1.94       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 35553280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017035725 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.17        |\n",
      "|    mean_step_reward   | 0.39594185  |\n",
      "|    n_updates          | 17356       |\n",
      "|    policyGradLoss     | -0.00591    |\n",
      "|    value_loss         | 1.76        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 35561472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015002115 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.961       |\n",
      "|    mean_step_reward   | 0.38887587  |\n",
      "|    n_updates          | 17360       |\n",
      "|    policyGradLoss     | -0.00691    |\n",
      "|    value_loss         | 1.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 35569664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015567493 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.456       |\n",
      "|    mean_step_reward   | 0.36166674  |\n",
      "|    n_updates          | 17364       |\n",
      "|    policyGradLoss     | -0.00189    |\n",
      "|    value_loss         | 2.46        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 775        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 242        |\n",
      "|    total_timesteps    | 35577856   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01267416 |\n",
      "|    entropy_loss       | -1.61      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.581      |\n",
      "|    mean_step_reward   | 0.3665492  |\n",
      "|    n_updates          | 17368      |\n",
      "|    policyGradLoss     | -0.0078    |\n",
      "|    value_loss         | 1.31       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 35586048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012331899 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.596       |\n",
      "|    mean_step_reward   | 0.44971937  |\n",
      "|    n_updates          | 17372       |\n",
      "|    policyGradLoss     | -0.00222    |\n",
      "|    value_loss         | 3.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 35594240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011917597 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.25        |\n",
      "|    mean_step_reward   | 0.3568408   |\n",
      "|    n_updates          | 17376       |\n",
      "|    policyGradLoss     | -0.00127    |\n",
      "|    value_loss         | 2.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 275         |\n",
      "|    total_timesteps    | 35602432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018928675 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.05        |\n",
      "|    mean_step_reward   | 0.41696554  |\n",
      "|    n_updates          | 17380       |\n",
      "|    policyGradLoss     | -0.00883    |\n",
      "|    value_loss         | 0.961       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 286         |\n",
      "|    total_timesteps    | 35610624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013135461 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.679       |\n",
      "|    mean_step_reward   | 0.35325977  |\n",
      "|    n_updates          | 17384       |\n",
      "|    policyGradLoss     | -0.00767    |\n",
      "|    value_loss         | 1.86        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 35618816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011333411 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.05        |\n",
      "|    mean_step_reward   | 0.3716364   |\n",
      "|    n_updates          | 17388       |\n",
      "|    policyGradLoss     | -0.00563    |\n",
      "|    value_loss         | 1.61        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 307         |\n",
      "|    total_timesteps    | 35627008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025143612 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.82        |\n",
      "|    mean_step_reward   | 0.4214308   |\n",
      "|    n_updates          | 17392       |\n",
      "|    policyGradLoss     | 0.0055      |\n",
      "|    value_loss         | 4.61        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 35635200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017519522 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.12        |\n",
      "|    mean_step_reward   | 0.40568662  |\n",
      "|    n_updates          | 17396       |\n",
      "|    policyGradLoss     | 0.00168     |\n",
      "|    value_loss         | 5.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 35643392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013909835 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.31        |\n",
      "|    mean_step_reward   | 0.4449145   |\n",
      "|    n_updates          | 17400       |\n",
      "|    policyGradLoss     | -0.00336    |\n",
      "|    value_loss         | 2.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 35651584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015757546 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.501       |\n",
      "|    mean_step_reward   | 0.36111176  |\n",
      "|    n_updates          | 17404       |\n",
      "|    policyGradLoss     | 0.00118     |\n",
      "|    value_loss         | 2.91        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_135.zip\n",
      "[EVAL] Mean Return: 536.655, Best Return: 543.988\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_135_536.65.mp4\n",
      "\n",
      "=== Round 137 | Learn 262144 steps (Total trained: 35651584) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1073     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 35659776 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 897         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 35667968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012173103 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.34        |\n",
      "|    mean_step_reward   | 0.32415307  |\n",
      "|    n_updates          | 17412       |\n",
      "|    policyGradLoss     | -0.00661    |\n",
      "|    value_loss         | 2.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 849         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 35676160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012962978 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.07        |\n",
      "|    mean_step_reward   | 0.39788228  |\n",
      "|    n_updates          | 17416       |\n",
      "|    policyGradLoss     | -0.00616    |\n",
      "|    value_loss         | 2.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 35684352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012297485 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.04        |\n",
      "|    mean_step_reward   | 0.37166172  |\n",
      "|    n_updates          | 17420       |\n",
      "|    policyGradLoss     | -0.0034     |\n",
      "|    value_loss         | 2.59        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 35692544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011448206 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.375       |\n",
      "|    mean_step_reward   | 0.45192114  |\n",
      "|    n_updates          | 17424       |\n",
      "|    policyGradLoss     | -0.00309    |\n",
      "|    value_loss         | 1.34        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 35700736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011383537 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.765       |\n",
      "|    mean_step_reward   | 0.40543553  |\n",
      "|    n_updates          | 17428       |\n",
      "|    policyGradLoss     | -0.00677    |\n",
      "|    value_loss         | 1.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 35708928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012325264 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.577       |\n",
      "|    mean_step_reward   | 0.4120841   |\n",
      "|    n_updates          | 17432       |\n",
      "|    policyGradLoss     | -0.00289    |\n",
      "|    value_loss         | 2           |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 35717120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013370061 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.526       |\n",
      "|    mean_step_reward   | 0.42309028  |\n",
      "|    n_updates          | 17436       |\n",
      "|    policyGradLoss     | -0.00554    |\n",
      "|    value_loss         | 1.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 35725312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011565816 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.552       |\n",
      "|    mean_step_reward   | 0.41925994  |\n",
      "|    n_updates          | 17440       |\n",
      "|    policyGradLoss     | -0.00522    |\n",
      "|    value_loss         | 1.81        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 35733504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012119574 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.399       |\n",
      "|    mean_step_reward   | 0.4255464   |\n",
      "|    n_updates          | 17444       |\n",
      "|    policyGradLoss     | -0.00858    |\n",
      "|    value_loss         | 1.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 35741696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010534693 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.762       |\n",
      "|    mean_step_reward   | 0.41596776  |\n",
      "|    n_updates          | 17448       |\n",
      "|    policyGradLoss     | -0.00532    |\n",
      "|    value_loss         | 1.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 35749888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015803998 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.12        |\n",
      "|    mean_step_reward   | 0.45788318  |\n",
      "|    n_updates          | 17452       |\n",
      "|    policyGradLoss     | -0.00686    |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 35758080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010870483 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.75        |\n",
      "|    mean_step_reward   | 0.4109351   |\n",
      "|    n_updates          | 17456       |\n",
      "|    policyGradLoss     | -0.00448    |\n",
      "|    value_loss         | 2.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 35766272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013079382 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.3         |\n",
      "|    mean_step_reward   | 0.41668886  |\n",
      "|    n_updates          | 17460       |\n",
      "|    policyGradLoss     | -0.00645    |\n",
      "|    value_loss         | 1.36        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 157        |\n",
      "|    total_timesteps    | 35774464   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01566419 |\n",
      "|    entropy_loss       | -1.63      |\n",
      "|    explained_variance | 0.97       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 2.99       |\n",
      "|    mean_step_reward   | 0.39513433 |\n",
      "|    n_updates          | 17464      |\n",
      "|    policyGradLoss     | -0.00558   |\n",
      "|    value_loss         | 3.96       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 35782656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014418175 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.31        |\n",
      "|    mean_step_reward   | 0.3781409   |\n",
      "|    n_updates          | 17468       |\n",
      "|    policyGradLoss     | -0.00678    |\n",
      "|    value_loss         | 1.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 35790848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016697157 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.657       |\n",
      "|    mean_step_reward   | 0.426538    |\n",
      "|    n_updates          | 17472       |\n",
      "|    policyGradLoss     | -0.00785    |\n",
      "|    value_loss         | 1.44        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 189        |\n",
      "|    total_timesteps    | 35799040   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03171268 |\n",
      "|    entropy_loss       | -1.63      |\n",
      "|    explained_variance | 0.99       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.529      |\n",
      "|    mean_step_reward   | 0.41845283 |\n",
      "|    n_updates          | 17476      |\n",
      "|    policyGradLoss     | -0.00679   |\n",
      "|    value_loss         | 1.3        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 35807232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014249507 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.461       |\n",
      "|    mean_step_reward   | 0.37671652  |\n",
      "|    n_updates          | 17480       |\n",
      "|    policyGradLoss     | -0.00441    |\n",
      "|    value_loss         | 1.97        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 35815424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024048587 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.334       |\n",
      "|    mean_step_reward   | 0.39571792  |\n",
      "|    n_updates          | 17484       |\n",
      "|    policyGradLoss     | -0.00231    |\n",
      "|    value_loss         | 1.52        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 35823616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015252298 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.508       |\n",
      "|    mean_step_reward   | 0.41635892  |\n",
      "|    n_updates          | 17488       |\n",
      "|    policyGradLoss     | -0.00345    |\n",
      "|    value_loss         | 1.96        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 35831808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016225055 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.825       |\n",
      "|    mean_step_reward   | 0.45266882  |\n",
      "|    n_updates          | 17492       |\n",
      "|    policyGradLoss     | -0.00489    |\n",
      "|    value_loss         | 1.97        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 35840000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014496317 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.676       |\n",
      "|    mean_step_reward   | 0.46053874  |\n",
      "|    n_updates          | 17496       |\n",
      "|    policyGradLoss     | -0.000542   |\n",
      "|    value_loss         | 2.9         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 35848192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011989444 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.19        |\n",
      "|    mean_step_reward   | 0.39422148  |\n",
      "|    n_updates          | 17500       |\n",
      "|    policyGradLoss     | 0.000498    |\n",
      "|    value_loss         | 4.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 35856384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012248063 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.996       |\n",
      "|    mean_step_reward   | 0.38880134  |\n",
      "|    n_updates          | 17504       |\n",
      "|    policyGradLoss     | 0.000945    |\n",
      "|    value_loss         | 3.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 275         |\n",
      "|    total_timesteps    | 35864576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010682962 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.877       |\n",
      "|    mean_step_reward   | 0.41848084  |\n",
      "|    n_updates          | 17508       |\n",
      "|    policyGradLoss     | 0.00209     |\n",
      "|    value_loss         | 2.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 35872768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008707933 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.668       |\n",
      "|    mean_step_reward   | 0.38206685  |\n",
      "|    n_updates          | 17512       |\n",
      "|    policyGradLoss     | -0.0025     |\n",
      "|    value_loss         | 2.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 35880960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014846176 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.842       |\n",
      "|    mean_step_reward   | 0.46033555  |\n",
      "|    n_updates          | 17516       |\n",
      "|    policyGradLoss     | -0.00396    |\n",
      "|    value_loss         | 1.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 307         |\n",
      "|    total_timesteps    | 35889152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010713854 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.734       |\n",
      "|    mean_step_reward   | 0.36505824  |\n",
      "|    n_updates          | 17520       |\n",
      "|    policyGradLoss     | -0.00498    |\n",
      "|    value_loss         | 1.97        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 35897344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014100777 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.305       |\n",
      "|    mean_step_reward   | 0.39083713  |\n",
      "|    n_updates          | 17524       |\n",
      "|    policyGradLoss     | -0.00557    |\n",
      "|    value_loss         | 1.93        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 35905536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014366155 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.369       |\n",
      "|    mean_step_reward   | 0.41294253  |\n",
      "|    n_updates          | 17528       |\n",
      "|    policyGradLoss     | -0.00667    |\n",
      "|    value_loss         | 1.72        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 35913728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012682821 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.82        |\n",
      "|    mean_step_reward   | 0.36252576  |\n",
      "|    n_updates          | 17532       |\n",
      "|    policyGradLoss     | -0.0073     |\n",
      "|    value_loss         | 1.68        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_136.zip\n",
      "[EVAL] Mean Return: 540.510, Best Return: 547.177\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_136_540.51.mp4\n",
      "\n",
      "=== Round 138 | Learn 262144 steps (Total trained: 35913728) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1158     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 35921920 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 928         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 35930112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013451444 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.41        |\n",
      "|    mean_step_reward   | 0.44335002  |\n",
      "|    n_updates          | 17540       |\n",
      "|    policyGradLoss     | -0.00268    |\n",
      "|    value_loss         | 6.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 868         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 35938304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015175877 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.445       |\n",
      "|    mean_step_reward   | 0.4550979   |\n",
      "|    n_updates          | 17544       |\n",
      "|    policyGradLoss     | -0.000293   |\n",
      "|    value_loss         | 3.93        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 847         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 35946496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012313618 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 6.93        |\n",
      "|    mean_step_reward   | 0.39057413  |\n",
      "|    n_updates          | 17548       |\n",
      "|    policyGradLoss     | -9.48e-05   |\n",
      "|    value_loss         | 5.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 832         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 35954688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014458387 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.58        |\n",
      "|    mean_step_reward   | 0.42244083  |\n",
      "|    n_updates          | 17552       |\n",
      "|    policyGradLoss     | -0.00474    |\n",
      "|    value_loss         | 1.78        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 821        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 59         |\n",
      "|    total_timesteps    | 35962880   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01713809 |\n",
      "|    entropy_loss       | -1.62      |\n",
      "|    explained_variance | 0.928      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.77       |\n",
      "|    mean_step_reward   | 0.46043137 |\n",
      "|    n_updates          | 17556      |\n",
      "|    policyGradLoss     | 0.0054     |\n",
      "|    value_loss         | 5.73       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 35971072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010744133 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.59        |\n",
      "|    mean_step_reward   | 0.37524688  |\n",
      "|    n_updates          | 17560       |\n",
      "|    policyGradLoss     | 0.00047     |\n",
      "|    value_loss         | 3.89        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 80          |\n",
      "|    total_timesteps    | 35979264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013403622 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0486      |\n",
      "|    mean_step_reward   | 0.4357983   |\n",
      "|    n_updates          | 17564       |\n",
      "|    policyGradLoss     | -0.0057     |\n",
      "|    value_loss         | 1.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 35987456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011265213 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.06        |\n",
      "|    mean_step_reward   | 0.40058693  |\n",
      "|    n_updates          | 17568       |\n",
      "|    policyGradLoss     | -0.00418    |\n",
      "|    value_loss         | 2.66        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 35995648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011132272 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.454       |\n",
      "|    mean_step_reward   | 0.42831445  |\n",
      "|    n_updates          | 17572       |\n",
      "|    policyGradLoss     | -0.00458    |\n",
      "|    value_loss         | 1.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 112         |\n",
      "|    total_timesteps    | 36003840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015361395 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.612       |\n",
      "|    mean_step_reward   | 0.42803192  |\n",
      "|    n_updates          | 17576       |\n",
      "|    policyGradLoss     | -0.00119    |\n",
      "|    value_loss         | 4.65        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 36012032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011039036 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.3         |\n",
      "|    mean_step_reward   | 0.36180156  |\n",
      "|    n_updates          | 17580       |\n",
      "|    policyGradLoss     | -0.00584    |\n",
      "|    value_loss         | 2.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 36020224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010506384 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.196       |\n",
      "|    mean_step_reward   | 0.3634715   |\n",
      "|    n_updates          | 17584       |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 1           |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 36028416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014655866 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.562       |\n",
      "|    mean_step_reward   | 0.4129649   |\n",
      "|    n_updates          | 17588       |\n",
      "|    policyGradLoss     | -0.00548    |\n",
      "|    value_loss         | 2.07        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 36036608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016046807 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0714      |\n",
      "|    mean_step_reward   | 0.37489963  |\n",
      "|    n_updates          | 17592       |\n",
      "|    policyGradLoss     | -0.00994    |\n",
      "|    value_loss         | 0.943       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 36044800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016858153 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.45        |\n",
      "|    mean_step_reward   | 0.42081317  |\n",
      "|    n_updates          | 17596       |\n",
      "|    policyGradLoss     | -0.00593    |\n",
      "|    value_loss         | 1.5         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 36052992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020087836 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.794       |\n",
      "|    mean_step_reward   | 0.3888796   |\n",
      "|    n_updates          | 17600       |\n",
      "|    policyGradLoss     | -0.00504    |\n",
      "|    value_loss         | 1.94        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 36061184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014501804 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.189       |\n",
      "|    mean_step_reward   | 0.46332127  |\n",
      "|    n_updates          | 17604       |\n",
      "|    policyGradLoss     | 0.00125     |\n",
      "|    value_loss         | 2.8         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 36069376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012766264 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.513       |\n",
      "|    mean_step_reward   | 0.39745033  |\n",
      "|    n_updates          | 17608       |\n",
      "|    policyGradLoss     | -0.00343    |\n",
      "|    value_loss         | 2.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 36077568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017109249 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.2         |\n",
      "|    mean_step_reward   | 0.39247322  |\n",
      "|    n_updates          | 17612       |\n",
      "|    policyGradLoss     | -0.0053     |\n",
      "|    value_loss         | 1.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 36085760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014781047 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.897       |\n",
      "|    mean_step_reward   | 0.45918     |\n",
      "|    n_updates          | 17616       |\n",
      "|    policyGradLoss     | -0.00178    |\n",
      "|    value_loss         | 1.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 36093952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012883754 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.75        |\n",
      "|    mean_step_reward   | 0.41304764  |\n",
      "|    n_updates          | 17620       |\n",
      "|    policyGradLoss     | -0.00602    |\n",
      "|    value_loss         | 1.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 36102144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014573619 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.739       |\n",
      "|    mean_step_reward   | 0.40570906  |\n",
      "|    n_updates          | 17624       |\n",
      "|    policyGradLoss     | -0.00229    |\n",
      "|    value_loss         | 4.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 250         |\n",
      "|    total_timesteps    | 36110336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010298748 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.15        |\n",
      "|    mean_step_reward   | 0.42047644  |\n",
      "|    n_updates          | 17628       |\n",
      "|    policyGradLoss     | -0.00444    |\n",
      "|    value_loss         | 2.04        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 36118528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012257539 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.484       |\n",
      "|    mean_step_reward   | 0.33496928  |\n",
      "|    n_updates          | 17632       |\n",
      "|    policyGradLoss     | -0.00636    |\n",
      "|    value_loss         | 1.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 36126720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010549542 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.586       |\n",
      "|    mean_step_reward   | 0.41379806  |\n",
      "|    n_updates          | 17636       |\n",
      "|    policyGradLoss     | -0.0065     |\n",
      "|    value_loss         | 1.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 36134912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010337265 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.897       |\n",
      "|    mean_step_reward   | 0.3898239   |\n",
      "|    n_updates          | 17640       |\n",
      "|    policyGradLoss     | -0.0063     |\n",
      "|    value_loss         | 1.81        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 36143104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017228309 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.082       |\n",
      "|    mean_step_reward   | 0.39808768  |\n",
      "|    n_updates          | 17644       |\n",
      "|    policyGradLoss     | -0.00929    |\n",
      "|    value_loss         | 1.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 36151296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010456383 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.755       |\n",
      "|    mean_step_reward   | 0.41631037  |\n",
      "|    n_updates          | 17648       |\n",
      "|    policyGradLoss     | -0.0067     |\n",
      "|    value_loss         | 1.65        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 36159488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014398392 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.604       |\n",
      "|    mean_step_reward   | 0.39748192  |\n",
      "|    n_updates          | 17652       |\n",
      "|    policyGradLoss     | -0.00941    |\n",
      "|    value_loss         | 1.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 36167680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011576555 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.742       |\n",
      "|    mean_step_reward   | 0.45212054  |\n",
      "|    n_updates          | 17656       |\n",
      "|    policyGradLoss     | -0.00458    |\n",
      "|    value_loss         | 2.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 36175872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012516845 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.322       |\n",
      "|    mean_step_reward   | 0.38235062  |\n",
      "|    n_updates          | 17660       |\n",
      "|    policyGradLoss     | -0.00515    |\n",
      "|    value_loss         | 1.69        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_137.zip\n",
      "[EVAL] Mean Return: 544.316, Best Return: 550.982\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_137_544.32.mp4\n",
      "\n",
      "=== Round 139 | Learn 262144 steps (Total trained: 36175872) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1126     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 36184064 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 920         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 36192256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015157958 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.25        |\n",
      "|    mean_step_reward   | 0.39532334  |\n",
      "|    n_updates          | 17668       |\n",
      "|    policyGradLoss     | -0.000803   |\n",
      "|    value_loss         | 5.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 866         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 36200448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014517776 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.551       |\n",
      "|    mean_step_reward   | 0.4118785   |\n",
      "|    n_updates          | 17672       |\n",
      "|    policyGradLoss     | -0.00539    |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 839         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 36208640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015486043 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.821       |\n",
      "|    mean_step_reward   | 0.4488145   |\n",
      "|    n_updates          | 17676       |\n",
      "|    policyGradLoss     | -0.00319    |\n",
      "|    value_loss         | 1.59        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 36216832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012706472 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.75        |\n",
      "|    mean_step_reward   | 0.39548123  |\n",
      "|    n_updates          | 17680       |\n",
      "|    policyGradLoss     | -0.00617    |\n",
      "|    value_loss         | 1.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 36225024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015717195 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.242       |\n",
      "|    mean_step_reward   | 0.40802902  |\n",
      "|    n_updates          | 17684       |\n",
      "|    policyGradLoss     | -0.00566    |\n",
      "|    value_loss         | 1.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 36233216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014672955 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.17        |\n",
      "|    mean_step_reward   | 0.36358804  |\n",
      "|    n_updates          | 17688       |\n",
      "|    policyGradLoss     | -0.00607    |\n",
      "|    value_loss         | 1.81        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 36241408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016437948 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.395       |\n",
      "|    mean_step_reward   | 0.41085252  |\n",
      "|    n_updates          | 17692       |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 1.21        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 803        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 91         |\n",
      "|    total_timesteps    | 36249600   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01039697 |\n",
      "|    entropy_loss       | -1.71      |\n",
      "|    explained_variance | 0.982      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.46       |\n",
      "|    mean_step_reward   | 0.40311545 |\n",
      "|    n_updates          | 17696      |\n",
      "|    policyGradLoss     | -0.00534   |\n",
      "|    value_loss         | 2.54       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 800        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 102        |\n",
      "|    total_timesteps    | 36257792   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01151867 |\n",
      "|    entropy_loss       | -1.66      |\n",
      "|    explained_variance | 0.979      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.477      |\n",
      "|    mean_step_reward   | 0.3808022  |\n",
      "|    n_updates          | 17700      |\n",
      "|    policyGradLoss     | -0.00528   |\n",
      "|    value_loss         | 2.15       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 112         |\n",
      "|    total_timesteps    | 36265984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016657375 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.165       |\n",
      "|    mean_step_reward   | 0.43346137  |\n",
      "|    n_updates          | 17704       |\n",
      "|    policyGradLoss     | -0.00478    |\n",
      "|    value_loss         | 1.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 36274176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011511301 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.31        |\n",
      "|    mean_step_reward   | 0.37833846  |\n",
      "|    n_updates          | 17708       |\n",
      "|    policyGradLoss     | -2.58e-05   |\n",
      "|    value_loss         | 3.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 36282368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012538185 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.785       |\n",
      "|    mean_step_reward   | 0.40353212  |\n",
      "|    n_updates          | 17712       |\n",
      "|    policyGradLoss     | -0.00534    |\n",
      "|    value_loss         | 2.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 36290560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011893902 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.747       |\n",
      "|    mean_step_reward   | 0.397933    |\n",
      "|    n_updates          | 17716       |\n",
      "|    policyGradLoss     | -0.00558    |\n",
      "|    value_loss         | 1.94        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 36298752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013856707 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.42        |\n",
      "|    mean_step_reward   | 0.38296968  |\n",
      "|    n_updates          | 17720       |\n",
      "|    policyGradLoss     | -0.00202    |\n",
      "|    value_loss         | 4.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 36306944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016125001 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.257       |\n",
      "|    mean_step_reward   | 0.416219    |\n",
      "|    n_updates          | 17724       |\n",
      "|    policyGradLoss     | -0.00843    |\n",
      "|    value_loss         | 1.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 36315136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012027503 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.278       |\n",
      "|    mean_step_reward   | 0.40283588  |\n",
      "|    n_updates          | 17728       |\n",
      "|    policyGradLoss     | -0.00696    |\n",
      "|    value_loss         | 1.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 36323328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014887254 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.874       |\n",
      "|    mean_step_reward   | 0.42835134  |\n",
      "|    n_updates          | 17732       |\n",
      "|    policyGradLoss     | -0.00047    |\n",
      "|    value_loss         | 2.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 36331520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010072515 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.611       |\n",
      "|    mean_step_reward   | 0.422737    |\n",
      "|    n_updates          | 17736       |\n",
      "|    policyGradLoss     | -0.00537    |\n",
      "|    value_loss         | 1.97        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 36339712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010352889 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.259       |\n",
      "|    mean_step_reward   | 0.38561288  |\n",
      "|    n_updates          | 17740       |\n",
      "|    policyGradLoss     | -0.00345    |\n",
      "|    value_loss         | 1.92        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 36347904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019644206 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.357       |\n",
      "|    mean_step_reward   | 0.42395145  |\n",
      "|    n_updates          | 17744       |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.858       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 36356096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017057953 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.447       |\n",
      "|    mean_step_reward   | 0.40247425  |\n",
      "|    n_updates          | 17748       |\n",
      "|    policyGradLoss     | -0.00861    |\n",
      "|    value_loss         | 1.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 36364288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014487736 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.272       |\n",
      "|    mean_step_reward   | 0.41466907  |\n",
      "|    n_updates          | 17752       |\n",
      "|    policyGradLoss     | -0.00442    |\n",
      "|    value_loss         | 2.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 36372480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011192178 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.525       |\n",
      "|    mean_step_reward   | 0.42496154  |\n",
      "|    n_updates          | 17756       |\n",
      "|    policyGradLoss     | -0.00741    |\n",
      "|    value_loss         | 1.94        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 36380672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018262038 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.568       |\n",
      "|    mean_step_reward   | 0.36625397  |\n",
      "|    n_updates          | 17760       |\n",
      "|    policyGradLoss     | -0.00477    |\n",
      "|    value_loss         | 2.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 36388864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013719948 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.65        |\n",
      "|    mean_step_reward   | 0.42070958  |\n",
      "|    n_updates          | 17764       |\n",
      "|    policyGradLoss     | -0.00428    |\n",
      "|    value_loss         | 3.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 36397056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013529254 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.344       |\n",
      "|    mean_step_reward   | 0.40550566  |\n",
      "|    n_updates          | 17768       |\n",
      "|    policyGradLoss     | -0.00731    |\n",
      "|    value_loss         | 1.62        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 294        |\n",
      "|    total_timesteps    | 36405248   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00857175 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.986      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.457      |\n",
      "|    mean_step_reward   | 0.38569465 |\n",
      "|    n_updates          | 17772      |\n",
      "|    policyGradLoss     | -0.00645   |\n",
      "|    value_loss         | 1.86       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 36413440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015206776 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.781       |\n",
      "|    mean_step_reward   | 0.4186582   |\n",
      "|    n_updates          | 17776       |\n",
      "|    policyGradLoss     | -0.00548    |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 36421632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010973232 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.82        |\n",
      "|    mean_step_reward   | 0.36625245  |\n",
      "|    n_updates          | 17780       |\n",
      "|    policyGradLoss     | -0.00641    |\n",
      "|    value_loss         | 2.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 36429824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014864329 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.333       |\n",
      "|    mean_step_reward   | 0.37739903  |\n",
      "|    n_updates          | 17784       |\n",
      "|    policyGradLoss     | -0.00558    |\n",
      "|    value_loss         | 1.52        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 36438016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008824168 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.547       |\n",
      "|    mean_step_reward   | 0.38470846  |\n",
      "|    n_updates          | 17788       |\n",
      "|    policyGradLoss     | -0.00362    |\n",
      "|    value_loss         | 1.94        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_138.zip\n",
      "[EVAL] Mean Return: 537.581, Best Return: 544.248\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_138_537.58.mp4\n",
      "\n",
      "=== Round 140 | Learn 262144 steps (Total trained: 36438016) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1143     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 36446208 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 922         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 36454400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012119036 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.543       |\n",
      "|    mean_step_reward   | 0.48203424  |\n",
      "|    n_updates          | 17796       |\n",
      "|    policyGradLoss     | 0.00577     |\n",
      "|    value_loss         | 1.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 869         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 36462592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010362996 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.7         |\n",
      "|    mean_step_reward   | 0.36293754  |\n",
      "|    n_updates          | 17800       |\n",
      "|    policyGradLoss     | -0.00256    |\n",
      "|    value_loss         | 2.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 838         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 36470784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026756302 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.43        |\n",
      "|    mean_step_reward   | 0.41582155  |\n",
      "|    n_updates          | 17804       |\n",
      "|    policyGradLoss     | -0.00728    |\n",
      "|    value_loss         | 1.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 36478976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013205059 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.9         |\n",
      "|    mean_step_reward   | 0.39361697  |\n",
      "|    n_updates          | 17808       |\n",
      "|    policyGradLoss     | -0.000214   |\n",
      "|    value_loss         | 5.93        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 808        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 36487168   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01373404 |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.977      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.508      |\n",
      "|    mean_step_reward   | 0.44450346 |\n",
      "|    n_updates          | 17812      |\n",
      "|    policyGradLoss     | -0.00304   |\n",
      "|    value_loss         | 2.42       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 36495360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014385674 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.728       |\n",
      "|    mean_step_reward   | 0.39914507  |\n",
      "|    n_updates          | 17816       |\n",
      "|    policyGradLoss     | -0.00618    |\n",
      "|    value_loss         | 1.53        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 36503552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014683012 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.12        |\n",
      "|    mean_step_reward   | 0.35734957  |\n",
      "|    n_updates          | 17820       |\n",
      "|    policyGradLoss     | -0.00315    |\n",
      "|    value_loss         | 2.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 36511744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014265027 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.605       |\n",
      "|    mean_step_reward   | 0.41473088  |\n",
      "|    n_updates          | 17824       |\n",
      "|    policyGradLoss     | -0.00679    |\n",
      "|    value_loss         | 1.42        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 794        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 103        |\n",
      "|    total_timesteps    | 36519936   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01485965 |\n",
      "|    entropy_loss       | -1.68      |\n",
      "|    explained_variance | 0.99       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.709      |\n",
      "|    mean_step_reward   | 0.37770605 |\n",
      "|    n_updates          | 17828      |\n",
      "|    policyGradLoss     | -0.00721   |\n",
      "|    value_loss         | 1.5        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 36528128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013940736 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.229       |\n",
      "|    mean_step_reward   | 0.3755107   |\n",
      "|    n_updates          | 17832       |\n",
      "|    policyGradLoss     | -0.00429    |\n",
      "|    value_loss         | 2.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 36536320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015310988 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.563       |\n",
      "|    mean_step_reward   | 0.41890067  |\n",
      "|    n_updates          | 17836       |\n",
      "|    policyGradLoss     | -0.00728    |\n",
      "|    value_loss         | 1.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 36544512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012570087 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.301       |\n",
      "|    mean_step_reward   | 0.41270596  |\n",
      "|    n_updates          | 17840       |\n",
      "|    policyGradLoss     | -0.00581    |\n",
      "|    value_loss         | 2           |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 36552704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011188315 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.342       |\n",
      "|    mean_step_reward   | 0.43772182  |\n",
      "|    n_updates          | 17844       |\n",
      "|    policyGradLoss     | -0.00662    |\n",
      "|    value_loss         | 1.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 36560896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012357392 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.67        |\n",
      "|    mean_step_reward   | 0.3719387   |\n",
      "|    n_updates          | 17848       |\n",
      "|    policyGradLoss     | -0.00766    |\n",
      "|    value_loss         | 1.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 36569088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014628416 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.452       |\n",
      "|    mean_step_reward   | 0.46160585  |\n",
      "|    n_updates          | 17852       |\n",
      "|    policyGradLoss     | -0.00757    |\n",
      "|    value_loss         | 1.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 36577280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016304398 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.547       |\n",
      "|    mean_step_reward   | 0.42441258  |\n",
      "|    n_updates          | 17856       |\n",
      "|    policyGradLoss     | -0.00839    |\n",
      "|    value_loss         | 1.54        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 787          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 187          |\n",
      "|    total_timesteps    | 36585472     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0100544095 |\n",
      "|    entropy_loss       | -1.65        |\n",
      "|    explained_variance | 0.982        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.734        |\n",
      "|    mean_step_reward   | 0.4002553    |\n",
      "|    n_updates          | 17860        |\n",
      "|    policyGradLoss     | -0.00559     |\n",
      "|    value_loss         | 2.34         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 197         |\n",
      "|    total_timesteps    | 36593664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017452914 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.319       |\n",
      "|    mean_step_reward   | 0.4021907   |\n",
      "|    n_updates          | 17864       |\n",
      "|    policyGradLoss     | -0.00378    |\n",
      "|    value_loss         | 1.53        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 36601856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017690057 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0328      |\n",
      "|    mean_step_reward   | 0.39317855  |\n",
      "|    n_updates          | 17868       |\n",
      "|    policyGradLoss     | -0.00873    |\n",
      "|    value_loss         | 1.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 218         |\n",
      "|    total_timesteps    | 36610048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013260792 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.23        |\n",
      "|    mean_step_reward   | 0.3247485   |\n",
      "|    n_updates          | 17872       |\n",
      "|    policyGradLoss     | -0.00324    |\n",
      "|    value_loss         | 3.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 36618240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010109807 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.311       |\n",
      "|    mean_step_reward   | 0.4225211   |\n",
      "|    n_updates          | 17876       |\n",
      "|    policyGradLoss     | -0.00426    |\n",
      "|    value_loss         | 1.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 36626432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012692969 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.937       |\n",
      "|    mean_step_reward   | 0.37420183  |\n",
      "|    n_updates          | 17880       |\n",
      "|    policyGradLoss     | -0.00389    |\n",
      "|    value_loss         | 2.22        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 783        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 251        |\n",
      "|    total_timesteps    | 36634624   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01719047 |\n",
      "|    entropy_loss       | -1.58      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.17       |\n",
      "|    mean_step_reward   | 0.44995546 |\n",
      "|    n_updates          | 17884      |\n",
      "|    policyGradLoss     | -0.00621   |\n",
      "|    value_loss         | 1.49       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 36642816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014609261 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.412       |\n",
      "|    mean_step_reward   | 0.39823484  |\n",
      "|    n_updates          | 17888       |\n",
      "|    policyGradLoss     | -0.00584    |\n",
      "|    value_loss         | 1.72        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 36651008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011520048 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.457       |\n",
      "|    mean_step_reward   | 0.3306415   |\n",
      "|    n_updates          | 17892       |\n",
      "|    policyGradLoss     | -0.00685    |\n",
      "|    value_loss         | 2.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 36659200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016252296 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.127       |\n",
      "|    mean_step_reward   | 0.4483406   |\n",
      "|    n_updates          | 17896       |\n",
      "|    policyGradLoss     | -0.00883    |\n",
      "|    value_loss         | 0.996       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 36667392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010833867 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.899       |\n",
      "|    mean_step_reward   | 0.3993606   |\n",
      "|    n_updates          | 17900       |\n",
      "|    policyGradLoss     | -0.00504    |\n",
      "|    value_loss         | 2.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 303         |\n",
      "|    total_timesteps    | 36675584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013832799 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.649       |\n",
      "|    mean_step_reward   | 0.40750796  |\n",
      "|    n_updates          | 17904       |\n",
      "|    policyGradLoss     | -0.00697    |\n",
      "|    value_loss         | 1.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 313         |\n",
      "|    total_timesteps    | 36683776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021558963 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.654       |\n",
      "|    mean_step_reward   | 0.395747    |\n",
      "|    n_updates          | 17908       |\n",
      "|    policyGradLoss     | 0.00625     |\n",
      "|    value_loss         | 4.45        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 782       |\n",
      "|    iterations         | 31        |\n",
      "|    time_elapsed       | 324       |\n",
      "|    total_timesteps    | 36691968  |\n",
      "| train/                |           |\n",
      "|    approx_kl          | 0.0120175 |\n",
      "|    entropy_loss       | -1.64     |\n",
      "|    explained_variance | 0.959     |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    loss               | 1.04      |\n",
      "|    mean_step_reward   | 0.4348656 |\n",
      "|    n_updates          | 17912     |\n",
      "|    policyGradLoss     | -0.00369  |\n",
      "|    value_loss         | 2.91      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 335         |\n",
      "|    total_timesteps    | 36700160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014551854 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.326       |\n",
      "|    mean_step_reward   | 0.39838654  |\n",
      "|    n_updates          | 17916       |\n",
      "|    policyGradLoss     | -0.00308    |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_139.zip\n",
      "[EVAL] Mean Return: 538.352, Best Return: 545.018\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_139_538.35.mp4\n",
      "\n",
      "=== Round 141 | Learn 262144 steps (Total trained: 36700160) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1155     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 36708352 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 921         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 36716544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024455197 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.44        |\n",
      "|    mean_step_reward   | 0.43836284  |\n",
      "|    n_updates          | 17924       |\n",
      "|    policyGradLoss     | -0.00512    |\n",
      "|    value_loss         | 1.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 859         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 36724736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017341077 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.706       |\n",
      "|    mean_step_reward   | 0.37545675  |\n",
      "|    n_updates          | 17928       |\n",
      "|    policyGradLoss     | -0.00578    |\n",
      "|    value_loss         | 1.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 836         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 36732928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015347836 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.467       |\n",
      "|    mean_step_reward   | 0.39882514  |\n",
      "|    n_updates          | 17932       |\n",
      "|    policyGradLoss     | -0.00794    |\n",
      "|    value_loss         | 1.43        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 36741120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017981105 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.529       |\n",
      "|    mean_step_reward   | 0.38737604  |\n",
      "|    n_updates          | 17936       |\n",
      "|    policyGradLoss     | -0.00439    |\n",
      "|    value_loss         | 1.67        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 811        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 36749312   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01393814 |\n",
      "|    entropy_loss       | -1.65      |\n",
      "|    explained_variance | 0.992      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.47       |\n",
      "|    mean_step_reward   | 0.33855164 |\n",
      "|    n_updates          | 17940      |\n",
      "|    policyGradLoss     | -0.00827   |\n",
      "|    value_loss         | 1.15       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 36757504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016047878 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.953       |\n",
      "|    mean_step_reward   | 0.37504524  |\n",
      "|    n_updates          | 17944       |\n",
      "|    policyGradLoss     | -0.00935    |\n",
      "|    value_loss         | 1.24        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 798        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 82         |\n",
      "|    total_timesteps    | 36765696   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01354702 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.99       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.635      |\n",
      "|    mean_step_reward   | 0.37899077 |\n",
      "|    n_updates          | 17948      |\n",
      "|    policyGradLoss     | -0.00816   |\n",
      "|    value_loss         | 1.52       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 793        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 92         |\n",
      "|    total_timesteps    | 36773888   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01510502 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.982      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.592      |\n",
      "|    mean_step_reward   | 0.36880678 |\n",
      "|    n_updates          | 17952      |\n",
      "|    policyGradLoss     | -0.00572   |\n",
      "|    value_loss         | 2.15       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 791          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 103          |\n",
      "|    total_timesteps    | 36782080     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0122145675 |\n",
      "|    entropy_loss       | -1.63        |\n",
      "|    explained_variance | 0.986        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.01         |\n",
      "|    mean_step_reward   | 0.4198685    |\n",
      "|    n_updates          | 17956        |\n",
      "|    policyGradLoss     | -0.00598     |\n",
      "|    value_loss         | 1.69         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 36790272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014349639 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.677       |\n",
      "|    mean_step_reward   | 0.40016675  |\n",
      "|    n_updates          | 17960       |\n",
      "|    policyGradLoss     | -0.00666    |\n",
      "|    value_loss         | 1.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 36798464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016020581 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.437       |\n",
      "|    mean_step_reward   | 0.41349828  |\n",
      "|    n_updates          | 17964       |\n",
      "|    policyGradLoss     | -0.00841    |\n",
      "|    value_loss         | 1.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 36806656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027931578 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.571       |\n",
      "|    mean_step_reward   | 0.4269932   |\n",
      "|    n_updates          | 17968       |\n",
      "|    policyGradLoss     | -0.00933    |\n",
      "|    value_loss         | 2           |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 36814848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013955085 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.05        |\n",
      "|    mean_step_reward   | 0.4107536   |\n",
      "|    n_updates          | 17972       |\n",
      "|    policyGradLoss     | -0.00563    |\n",
      "|    value_loss         | 1.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 36823040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011799859 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.06        |\n",
      "|    mean_step_reward   | 0.44463715  |\n",
      "|    n_updates          | 17976       |\n",
      "|    policyGradLoss     | -0.00698    |\n",
      "|    value_loss         | 1.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 36831232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015459115 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.791       |\n",
      "|    mean_step_reward   | 0.39077938  |\n",
      "|    n_updates          | 17980       |\n",
      "|    policyGradLoss     | -0.00542    |\n",
      "|    value_loss         | 2.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 36839424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016446685 |\n",
      "|    entropy_loss       | -1.54       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.433       |\n",
      "|    mean_step_reward   | 0.46384424  |\n",
      "|    n_updates          | 17984       |\n",
      "|    policyGradLoss     | -0.00605    |\n",
      "|    value_loss         | 1.07        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 36847616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015957084 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.457       |\n",
      "|    mean_step_reward   | 0.374828    |\n",
      "|    n_updates          | 17988       |\n",
      "|    policyGradLoss     | -0.00496    |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 36855808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014169538 |\n",
      "|    entropy_loss       | -1.55       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.386       |\n",
      "|    mean_step_reward   | 0.44187012  |\n",
      "|    n_updates          | 17992       |\n",
      "|    policyGradLoss     | -0.00469    |\n",
      "|    value_loss         | 1.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 36864000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016699726 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.591       |\n",
      "|    mean_step_reward   | 0.3965869   |\n",
      "|    n_updates          | 17996       |\n",
      "|    policyGradLoss     | -0.00504    |\n",
      "|    value_loss         | 1.99        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 36872192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013935754 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.473       |\n",
      "|    mean_step_reward   | 0.42703503  |\n",
      "|    n_updates          | 18000       |\n",
      "|    policyGradLoss     | -0.00836    |\n",
      "|    value_loss         | 1.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 36880384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019403182 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.608       |\n",
      "|    mean_step_reward   | 0.40913233  |\n",
      "|    n_updates          | 18004       |\n",
      "|    policyGradLoss     | -0.00724    |\n",
      "|    value_loss         | 1.53        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 36888576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016079558 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.536       |\n",
      "|    mean_step_reward   | 0.4045415   |\n",
      "|    n_updates          | 18008       |\n",
      "|    policyGradLoss     | -0.00743    |\n",
      "|    value_loss         | 1.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 36896768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015023068 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.298       |\n",
      "|    mean_step_reward   | 0.403409    |\n",
      "|    n_updates          | 18012       |\n",
      "|    policyGradLoss     | -0.00746    |\n",
      "|    value_loss         | 1.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 36904960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021061093 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.314       |\n",
      "|    mean_step_reward   | 0.36251783  |\n",
      "|    n_updates          | 18016       |\n",
      "|    policyGradLoss     | -0.0069     |\n",
      "|    value_loss         | 1.65        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 36913152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016105622 |\n",
      "|    entropy_loss       | -1.54       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.919       |\n",
      "|    mean_step_reward   | 0.4591993   |\n",
      "|    n_updates          | 18020       |\n",
      "|    policyGradLoss     | -0.00807    |\n",
      "|    value_loss         | 0.901       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 36921344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014965881 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.45        |\n",
      "|    mean_step_reward   | 0.34617576  |\n",
      "|    n_updates          | 18024       |\n",
      "|    policyGradLoss     | -0.00528    |\n",
      "|    value_loss         | 1.9         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 36929536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020287788 |\n",
      "|    entropy_loss       | -1.54       |\n",
      "|    explained_variance | 0.996       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0767      |\n",
      "|    mean_step_reward   | 0.48031834  |\n",
      "|    n_updates          | 18028       |\n",
      "|    policyGradLoss     | -0.00898    |\n",
      "|    value_loss         | 0.621       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 36937728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016820813 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.51        |\n",
      "|    mean_step_reward   | 0.3659818   |\n",
      "|    n_updates          | 18032       |\n",
      "|    policyGradLoss     | -0.005      |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 36945920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025288519 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.353       |\n",
      "|    mean_step_reward   | 0.37606877  |\n",
      "|    n_updates          | 18036       |\n",
      "|    policyGradLoss     | -0.00474    |\n",
      "|    value_loss         | 4.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 36954112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021815497 |\n",
      "|    entropy_loss       | -1.56       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.571       |\n",
      "|    mean_step_reward   | 0.3947903   |\n",
      "|    n_updates          | 18040       |\n",
      "|    policyGradLoss     | 0.00325     |\n",
      "|    value_loss         | 4.03        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 775        |\n",
      "|    iterations         | 32         |\n",
      "|    time_elapsed       | 338        |\n",
      "|    total_timesteps    | 36962304   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.016734   |\n",
      "|    entropy_loss       | -1.63      |\n",
      "|    explained_variance | 0.99       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.571      |\n",
      "|    mean_step_reward   | 0.40110704 |\n",
      "|    n_updates          | 18044      |\n",
      "|    policyGradLoss     | -0.00366   |\n",
      "|    value_loss         | 1.58       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_140.zip\n",
      "[EVAL] Mean Return: 490.212, Best Return: 491.545\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_140_490.21.mp4\n",
      "\n",
      "=== Round 142 | Learn 262144 steps (Total trained: 36962304) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1153     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 36970496 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 925         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 36978688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012868541 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.52        |\n",
      "|    mean_step_reward   | 0.37490478  |\n",
      "|    n_updates          | 18052       |\n",
      "|    policyGradLoss     | -0.00699    |\n",
      "|    value_loss         | 2           |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 864         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 36986880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017168947 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.161       |\n",
      "|    mean_step_reward   | 0.38480604  |\n",
      "|    n_updates          | 18056       |\n",
      "|    policyGradLoss     | -0.00477    |\n",
      "|    value_loss         | 1.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 841         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 36995072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022049181 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.653       |\n",
      "|    mean_step_reward   | 0.4111533   |\n",
      "|    n_updates          | 18060       |\n",
      "|    policyGradLoss     | -0.00614    |\n",
      "|    value_loss         | 1.93        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 823        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 49         |\n",
      "|    total_timesteps    | 37003264   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02434725 |\n",
      "|    entropy_loss       | -1.58      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.727      |\n",
      "|    mean_step_reward   | 0.45692617 |\n",
      "|    n_updates          | 18064      |\n",
      "|    policyGradLoss     | -0.00729   |\n",
      "|    value_loss         | 1.4        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 37011456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024504967 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.675       |\n",
      "|    mean_step_reward   | 0.41637814  |\n",
      "|    n_updates          | 18068       |\n",
      "|    policyGradLoss     | -0.00349    |\n",
      "|    value_loss         | 2.5         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 37019648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017957557 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.603       |\n",
      "|    mean_step_reward   | 0.42801216  |\n",
      "|    n_updates          | 18072       |\n",
      "|    policyGradLoss     | -0.0054     |\n",
      "|    value_loss         | 1.83        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 801        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 81         |\n",
      "|    total_timesteps    | 37027840   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01692883 |\n",
      "|    entropy_loss       | -1.61      |\n",
      "|    explained_variance | 0.983      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.189      |\n",
      "|    mean_step_reward   | 0.3855689  |\n",
      "|    n_updates          | 18076      |\n",
      "|    policyGradLoss     | -0.00359   |\n",
      "|    value_loss         | 1.48       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 37036032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015469657 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.77        |\n",
      "|    mean_step_reward   | 0.4178832   |\n",
      "|    n_updates          | 18080       |\n",
      "|    policyGradLoss     | -0.00612    |\n",
      "|    value_loss         | 2.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 37044224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015512262 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.312       |\n",
      "|    mean_step_reward   | 0.46342605  |\n",
      "|    n_updates          | 18084       |\n",
      "|    policyGradLoss     | -0.00818    |\n",
      "|    value_loss         | 1.43        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 37052416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013307059 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.895       |\n",
      "|    mean_step_reward   | 0.38767996  |\n",
      "|    n_updates          | 18088       |\n",
      "|    policyGradLoss     | -0.00572    |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 37060608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015346631 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.929       |\n",
      "|    mean_step_reward   | 0.44231987  |\n",
      "|    n_updates          | 18092       |\n",
      "|    policyGradLoss     | -0.00594    |\n",
      "|    value_loss         | 1.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 37068800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012073256 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.519       |\n",
      "|    mean_step_reward   | 0.40426093  |\n",
      "|    n_updates          | 18096       |\n",
      "|    policyGradLoss     | -0.006      |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 790          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 145          |\n",
      "|    total_timesteps    | 37076992     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0139574045 |\n",
      "|    entropy_loss       | -1.59        |\n",
      "|    explained_variance | 0.984        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.419        |\n",
      "|    mean_step_reward   | 0.42593074   |\n",
      "|    n_updates          | 18100        |\n",
      "|    policyGradLoss     | -0.00631     |\n",
      "|    value_loss         | 1.84         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 37085184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010114349 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.83        |\n",
      "|    mean_step_reward   | 0.41070297  |\n",
      "|    n_updates          | 18104       |\n",
      "|    policyGradLoss     | -0.00515    |\n",
      "|    value_loss         | 1.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 37093376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012126214 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.405       |\n",
      "|    mean_step_reward   | 0.4188553   |\n",
      "|    n_updates          | 18108       |\n",
      "|    policyGradLoss     | -0.0016     |\n",
      "|    value_loss         | 1.98        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 37101568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015275045 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.681       |\n",
      "|    mean_step_reward   | 0.4007017   |\n",
      "|    n_updates          | 18112       |\n",
      "|    policyGradLoss     | -0.00597    |\n",
      "|    value_loss         | 2.41        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 786          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 187          |\n",
      "|    total_timesteps    | 37109760     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0142844785 |\n",
      "|    entropy_loss       | -1.61        |\n",
      "|    explained_variance | 0.987        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.94         |\n",
      "|    mean_step_reward   | 0.4243199    |\n",
      "|    n_updates          | 18116        |\n",
      "|    policyGradLoss     | -0.00858     |\n",
      "|    value_loss         | 1.87         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 37117952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014641728 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.01        |\n",
      "|    mean_step_reward   | 0.38839376  |\n",
      "|    n_updates          | 18120       |\n",
      "|    policyGradLoss     | -0.00741    |\n",
      "|    value_loss         | 1.8         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 783          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 209          |\n",
      "|    total_timesteps    | 37126144     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0143863065 |\n",
      "|    entropy_loss       | -1.6         |\n",
      "|    explained_variance | 0.987        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.11         |\n",
      "|    mean_step_reward   | 0.40604922   |\n",
      "|    n_updates          | 18124        |\n",
      "|    policyGradLoss     | -0.008       |\n",
      "|    value_loss         | 1.7          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 37134336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020388762 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.156       |\n",
      "|    mean_step_reward   | 0.4287125   |\n",
      "|    n_updates          | 18128       |\n",
      "|    policyGradLoss     | -0.0072     |\n",
      "|    value_loss         | 1.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 37142528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016829789 |\n",
      "|    entropy_loss       | -1.56       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.518       |\n",
      "|    mean_step_reward   | 0.45155764  |\n",
      "|    n_updates          | 18132       |\n",
      "|    policyGradLoss     | -0.0045     |\n",
      "|    value_loss         | 2.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 37150720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020473465 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.568       |\n",
      "|    mean_step_reward   | 0.35500628  |\n",
      "|    n_updates          | 18136       |\n",
      "|    policyGradLoss     | -0.00907    |\n",
      "|    value_loss         | 1.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 37158912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019113608 |\n",
      "|    entropy_loss       | -1.54       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.199       |\n",
      "|    mean_step_reward   | 0.42235273  |\n",
      "|    n_updates          | 18140       |\n",
      "|    policyGradLoss     | -0.00296    |\n",
      "|    value_loss         | 1.98        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 37167104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022684664 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.366       |\n",
      "|    mean_step_reward   | 0.40286618  |\n",
      "|    n_updates          | 18144       |\n",
      "|    policyGradLoss     | -0.00755    |\n",
      "|    value_loss         | 1.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 37175296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015778927 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.41        |\n",
      "|    mean_step_reward   | 0.38304794  |\n",
      "|    n_updates          | 18148       |\n",
      "|    policyGradLoss     | -0.00415    |\n",
      "|    value_loss         | 2.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 37183488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014117108 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.219       |\n",
      "|    mean_step_reward   | 0.4149269   |\n",
      "|    n_updates          | 18152       |\n",
      "|    policyGradLoss     | -0.0077     |\n",
      "|    value_loss         | 1.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 37191680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016178973 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.827       |\n",
      "|    mean_step_reward   | 0.36076155  |\n",
      "|    n_updates          | 18156       |\n",
      "|    policyGradLoss     | -0.0064     |\n",
      "|    value_loss         | 1.72        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 37199872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021456283 |\n",
      "|    entropy_loss       | -1.56       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.81        |\n",
      "|    mean_step_reward   | 0.43594337  |\n",
      "|    n_updates          | 18160       |\n",
      "|    policyGradLoss     | 0.00089     |\n",
      "|    value_loss         | 3.26        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 316        |\n",
      "|    total_timesteps    | 37208064   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.08657109 |\n",
      "|    entropy_loss       | -1.6       |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.312      |\n",
      "|    mean_step_reward   | 0.42252386 |\n",
      "|    n_updates          | 18164      |\n",
      "|    policyGradLoss     | -0.00552   |\n",
      "|    value_loss         | 1.81       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 37216256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012406845 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.17        |\n",
      "|    mean_step_reward   | 0.4166632   |\n",
      "|    n_updates          | 18168       |\n",
      "|    policyGradLoss     | -0.00169    |\n",
      "|    value_loss         | 1.8         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 37224448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016282067 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.2         |\n",
      "|    mean_step_reward   | 0.4627778   |\n",
      "|    n_updates          | 18172       |\n",
      "|    policyGradLoss     | -0.00579    |\n",
      "|    value_loss         | 2.15        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_141.zip\n",
      "[EVAL] Mean Return: 537.045, Best Return: 543.712\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_141_537.05.mp4\n",
      "\n",
      "=== Round 143 | Learn 262144 steps (Total trained: 37224448) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1136     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 37232640 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 917         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 37240832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019590631 |\n",
      "|    entropy_loss       | -1.56       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.201       |\n",
      "|    mean_step_reward   | 0.40092066  |\n",
      "|    n_updates          | 18180       |\n",
      "|    policyGradLoss     | -0.0076     |\n",
      "|    value_loss         | 1.11        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 852         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 37249024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012287879 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.67        |\n",
      "|    mean_step_reward   | 0.39003348  |\n",
      "|    n_updates          | 18184       |\n",
      "|    policyGradLoss     | -0.00278    |\n",
      "|    value_loss         | 1.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 832         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 37257216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015069339 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.808       |\n",
      "|    mean_step_reward   | 0.38814336  |\n",
      "|    n_updates          | 18188       |\n",
      "|    policyGradLoss     | 0.0102      |\n",
      "|    value_loss         | 3.34        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 37265408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012105304 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.683       |\n",
      "|    mean_step_reward   | 0.38365525  |\n",
      "|    n_updates          | 18192       |\n",
      "|    policyGradLoss     | 0.00285     |\n",
      "|    value_loss         | 1.52        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 808        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 37273600   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0163442  |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.982      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.66       |\n",
      "|    mean_step_reward   | 0.36285782 |\n",
      "|    n_updates          | 18196      |\n",
      "|    policyGradLoss     | -0.00359   |\n",
      "|    value_loss         | 1.75       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 37281792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009669045 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.595       |\n",
      "|    mean_step_reward   | 0.3810714   |\n",
      "|    n_updates          | 18200       |\n",
      "|    policyGradLoss     | -0.00743    |\n",
      "|    value_loss         | 1.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 37289984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014301348 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.893       |\n",
      "|    mean_step_reward   | 0.41575074  |\n",
      "|    n_updates          | 18204       |\n",
      "|    policyGradLoss     | -0.00563    |\n",
      "|    value_loss         | 1.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 37298176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014832589 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.287       |\n",
      "|    mean_step_reward   | 0.36380407  |\n",
      "|    n_updates          | 18208       |\n",
      "|    policyGradLoss     | -0.00505    |\n",
      "|    value_loss         | 1.55        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 37306368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017984457 |\n",
      "|    entropy_loss       | -1.55       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.64        |\n",
      "|    mean_step_reward   | 0.42664742  |\n",
      "|    n_updates          | 18212       |\n",
      "|    policyGradLoss     | -0.00622    |\n",
      "|    value_loss         | 1.27        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 787          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 114          |\n",
      "|    total_timesteps    | 37314560     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0148649085 |\n",
      "|    entropy_loss       | -1.62        |\n",
      "|    explained_variance | 0.988        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.611        |\n",
      "|    mean_step_reward   | 0.35354042   |\n",
      "|    n_updates          | 18216        |\n",
      "|    policyGradLoss     | -0.00697     |\n",
      "|    value_loss         | 1.4          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 37322752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018398106 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.395       |\n",
      "|    mean_step_reward   | 0.46087465  |\n",
      "|    n_updates          | 18220       |\n",
      "|    policyGradLoss     | -0.00553    |\n",
      "|    value_loss         | 1.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 37330944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023097608 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.645       |\n",
      "|    mean_step_reward   | 0.40867954  |\n",
      "|    n_updates          | 18224       |\n",
      "|    policyGradLoss     | -0.0053     |\n",
      "|    value_loss         | 2.07        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 37339136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013462877 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.82        |\n",
      "|    mean_step_reward   | 0.4315462   |\n",
      "|    n_updates          | 18228       |\n",
      "|    policyGradLoss     | -0.00161    |\n",
      "|    value_loss         | 2.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 37347328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015288125 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.353       |\n",
      "|    mean_step_reward   | 0.41952074  |\n",
      "|    n_updates          | 18232       |\n",
      "|    policyGradLoss     | 7.3e-05     |\n",
      "|    value_loss         | 2.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 37355520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016313776 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.53        |\n",
      "|    mean_step_reward   | 0.39462295  |\n",
      "|    n_updates          | 18236       |\n",
      "|    policyGradLoss     | -0.00389    |\n",
      "|    value_loss         | 1.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 37363712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019101232 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.16        |\n",
      "|    mean_step_reward   | 0.39974537  |\n",
      "|    n_updates          | 18240       |\n",
      "|    policyGradLoss     | -0.00574    |\n",
      "|    value_loss         | 2.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 37371904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018678319 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.726       |\n",
      "|    mean_step_reward   | 0.33562487  |\n",
      "|    n_updates          | 18244       |\n",
      "|    policyGradLoss     | -0.00561    |\n",
      "|    value_loss         | 2.05        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 199        |\n",
      "|    total_timesteps    | 37380096   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01368651 |\n",
      "|    entropy_loss       | -1.59      |\n",
      "|    explained_variance | 0.983      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.324      |\n",
      "|    mean_step_reward   | 0.41184407 |\n",
      "|    n_updates          | 18248      |\n",
      "|    policyGradLoss     | -0.00579   |\n",
      "|    value_loss         | 1.65       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 37388288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013092991 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.74        |\n",
      "|    mean_step_reward   | 0.3805428   |\n",
      "|    n_updates          | 18252       |\n",
      "|    policyGradLoss     | -0.00466    |\n",
      "|    value_loss         | 1.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 37396480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019352514 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.294       |\n",
      "|    mean_step_reward   | 0.37070048  |\n",
      "|    n_updates          | 18256       |\n",
      "|    policyGradLoss     | -0.00873    |\n",
      "|    value_loss         | 1.35        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 231        |\n",
      "|    total_timesteps    | 37404672   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02064332 |\n",
      "|    entropy_loss       | -1.62      |\n",
      "|    explained_variance | 0.992      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.309      |\n",
      "|    mean_step_reward   | 0.34586722 |\n",
      "|    n_updates          | 18260      |\n",
      "|    policyGradLoss     | -0.00902   |\n",
      "|    value_loss         | 1.06       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 37412864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014035221 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.883       |\n",
      "|    mean_step_reward   | 0.4182984   |\n",
      "|    n_updates          | 18264       |\n",
      "|    policyGradLoss     | -0.00583    |\n",
      "|    value_loss         | 1.47        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 252        |\n",
      "|    total_timesteps    | 37421056   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02056354 |\n",
      "|    entropy_loss       | -1.6       |\n",
      "|    explained_variance | 0.99       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.642      |\n",
      "|    mean_step_reward   | 0.40431416 |\n",
      "|    n_updates          | 18268      |\n",
      "|    policyGradLoss     | -0.00548   |\n",
      "|    value_loss         | 1.69       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 37429248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010218625 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.423       |\n",
      "|    mean_step_reward   | 0.38811314  |\n",
      "|    n_updates          | 18272       |\n",
      "|    policyGradLoss     | -0.00647    |\n",
      "|    value_loss         | 1.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 37437440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010252874 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.64        |\n",
      "|    mean_step_reward   | 0.4043021   |\n",
      "|    n_updates          | 18276       |\n",
      "|    policyGradLoss     | -0.00342    |\n",
      "|    value_loss         | 2.11        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 775          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 285          |\n",
      "|    total_timesteps    | 37445632     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0111989025 |\n",
      "|    entropy_loss       | -1.63        |\n",
      "|    explained_variance | 0.986        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.519        |\n",
      "|    mean_step_reward   | 0.3602209    |\n",
      "|    n_updates          | 18280        |\n",
      "|    policyGradLoss     | -0.0058      |\n",
      "|    value_loss         | 1.95         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 37453824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015867218 |\n",
      "|    entropy_loss       | -1.57       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.124       |\n",
      "|    mean_step_reward   | 0.43944883  |\n",
      "|    n_updates          | 18284       |\n",
      "|    policyGradLoss     | -0.00256    |\n",
      "|    value_loss         | 1.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 37462016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014377567 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.31        |\n",
      "|    mean_step_reward   | 0.3675933   |\n",
      "|    n_updates          | 18288       |\n",
      "|    policyGradLoss     | -0.00661    |\n",
      "|    value_loss         | 1.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 37470208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020058688 |\n",
      "|    entropy_loss       | -1.55       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.246       |\n",
      "|    mean_step_reward   | 0.46694326  |\n",
      "|    n_updates          | 18292       |\n",
      "|    policyGradLoss     | -0.00865    |\n",
      "|    value_loss         | 1.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 37478400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016830985 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.452       |\n",
      "|    mean_step_reward   | 0.36877054  |\n",
      "|    n_updates          | 18296       |\n",
      "|    policyGradLoss     | -0.00638    |\n",
      "|    value_loss         | 1.6         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 773        |\n",
      "|    iterations         | 32         |\n",
      "|    time_elapsed       | 338        |\n",
      "|    total_timesteps    | 37486592   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0137014  |\n",
      "|    entropy_loss       | -1.58      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.309      |\n",
      "|    mean_step_reward   | 0.40640616 |\n",
      "|    n_updates          | 18300      |\n",
      "|    policyGradLoss     | -0.00604   |\n",
      "|    value_loss         | 1.37       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_142.zip\n",
      "[EVAL] Mean Return: 540.303, Best Return: 546.969\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_142_540.30.mp4\n",
      "\n",
      "=== Round 144 | Learn 262144 steps (Total trained: 37486592) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1120     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 37494784 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 904        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 37502976   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00969067 |\n",
      "|    entropy_loss       | -1.62      |\n",
      "|    explained_variance | 0.986      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.93       |\n",
      "|    mean_step_reward   | 0.3786374  |\n",
      "|    n_updates          | 18308      |\n",
      "|    policyGradLoss     | -0.00285   |\n",
      "|    value_loss         | 2.16       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 854        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 37511168   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02523077 |\n",
      "|    entropy_loss       | -1.56      |\n",
      "|    explained_variance | 0.971      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.564      |\n",
      "|    mean_step_reward   | 0.4600832  |\n",
      "|    n_updates          | 18312      |\n",
      "|    policyGradLoss     | -0.00219   |\n",
      "|    value_loss         | 4.32       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 831          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 39           |\n",
      "|    total_timesteps    | 37519360     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0130344145 |\n",
      "|    entropy_loss       | -1.64        |\n",
      "|    explained_variance | 0.988        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.359        |\n",
      "|    mean_step_reward   | 0.38941652   |\n",
      "|    n_updates          | 18316        |\n",
      "|    policyGradLoss     | -0.00391     |\n",
      "|    value_loss         | 1.99         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 37527552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016000777 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.899       |\n",
      "|    mean_step_reward   | 0.4444918   |\n",
      "|    n_updates          | 18320       |\n",
      "|    policyGradLoss     | -0.00459    |\n",
      "|    value_loss         | 1.82        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 37535744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020504091 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.515       |\n",
      "|    mean_step_reward   | 0.3937794   |\n",
      "|    n_updates          | 18324       |\n",
      "|    policyGradLoss     | -0.0065     |\n",
      "|    value_loss         | 1.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 37543936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011120882 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.03        |\n",
      "|    mean_step_reward   | 0.40767336  |\n",
      "|    n_updates          | 18328       |\n",
      "|    policyGradLoss     | -0.003      |\n",
      "|    value_loss         | 2.57        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 799        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 81         |\n",
      "|    total_timesteps    | 37552128   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.017216   |\n",
      "|    entropy_loss       | -1.61      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.607      |\n",
      "|    mean_step_reward   | 0.39306584 |\n",
      "|    n_updates          | 18332      |\n",
      "|    policyGradLoss     | -0.00984   |\n",
      "|    value_loss         | 1.43       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 37560320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010990353 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.03        |\n",
      "|    mean_step_reward   | 0.38790676  |\n",
      "|    n_updates          | 18336       |\n",
      "|    policyGradLoss     | -0.00155    |\n",
      "|    value_loss         | 2.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 37568512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014307035 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.05        |\n",
      "|    mean_step_reward   | 0.37260887  |\n",
      "|    n_updates          | 18340       |\n",
      "|    policyGradLoss     | -0.00864    |\n",
      "|    value_loss         | 1.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 37576704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012210872 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.11        |\n",
      "|    mean_step_reward   | 0.4253996   |\n",
      "|    n_updates          | 18344       |\n",
      "|    policyGradLoss     | -0.00519    |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 37584896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012112286 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.513       |\n",
      "|    mean_step_reward   | 0.44603443  |\n",
      "|    n_updates          | 18348       |\n",
      "|    policyGradLoss     | -0.00409    |\n",
      "|    value_loss         | 1.88        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 37593088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010647457 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.45        |\n",
      "|    mean_step_reward   | 0.39633048  |\n",
      "|    n_updates          | 18352       |\n",
      "|    policyGradLoss     | -0.00199    |\n",
      "|    value_loss         | 4.65        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 788        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 145        |\n",
      "|    total_timesteps    | 37601280   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01329922 |\n",
      "|    entropy_loss       | -1.6       |\n",
      "|    explained_variance | 0.986      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.616      |\n",
      "|    mean_step_reward   | 0.37707448 |\n",
      "|    n_updates          | 18356      |\n",
      "|    policyGradLoss     | -0.00704   |\n",
      "|    value_loss         | 1.31       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 37609472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018622003 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.234       |\n",
      "|    mean_step_reward   | 0.3965923   |\n",
      "|    n_updates          | 18360       |\n",
      "|    policyGradLoss     | -0.00338    |\n",
      "|    value_loss         | 4.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 37617664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013313857 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.903       |\n",
      "|    mean_step_reward   | 0.35095936  |\n",
      "|    n_updates          | 18364       |\n",
      "|    policyGradLoss     | -0.00412    |\n",
      "|    value_loss         | 2.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 37625856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014127776 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.664       |\n",
      "|    mean_step_reward   | 0.43417075  |\n",
      "|    n_updates          | 18368       |\n",
      "|    policyGradLoss     | -0.00586    |\n",
      "|    value_loss         | 1.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 37634048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017290616 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.74        |\n",
      "|    mean_step_reward   | 0.3115965   |\n",
      "|    n_updates          | 18372       |\n",
      "|    policyGradLoss     | -0.00514    |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 37642240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012459682 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.444       |\n",
      "|    mean_step_reward   | 0.41396776  |\n",
      "|    n_updates          | 18376       |\n",
      "|    policyGradLoss     | -0.00364    |\n",
      "|    value_loss         | 1.89        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 37650432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013854835 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.03        |\n",
      "|    mean_step_reward   | 0.41771144  |\n",
      "|    n_updates          | 18380       |\n",
      "|    policyGradLoss     | -0.00672    |\n",
      "|    value_loss         | 1.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 37658624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013698919 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.33        |\n",
      "|    mean_step_reward   | 0.3975649   |\n",
      "|    n_updates          | 18384       |\n",
      "|    policyGradLoss     | -0.00749    |\n",
      "|    value_loss         | 1.93        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 37666816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023328729 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0933      |\n",
      "|    mean_step_reward   | 0.42715466  |\n",
      "|    n_updates          | 18388       |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.553       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 37675008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013000886 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.714       |\n",
      "|    mean_step_reward   | 0.39047372  |\n",
      "|    n_updates          | 18392       |\n",
      "|    policyGradLoss     | -0.00415    |\n",
      "|    value_loss         | 2           |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 37683200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010409684 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.793       |\n",
      "|    mean_step_reward   | 0.40177768  |\n",
      "|    n_updates          | 18396       |\n",
      "|    policyGradLoss     | -0.00465    |\n",
      "|    value_loss         | 2.09        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 37691392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014625872 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.421       |\n",
      "|    mean_step_reward   | 0.3744502   |\n",
      "|    n_updates          | 18400       |\n",
      "|    policyGradLoss     | -0.00477    |\n",
      "|    value_loss         | 1.32        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 780        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 272        |\n",
      "|    total_timesteps    | 37699584   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01246394 |\n",
      "|    entropy_loss       | -1.66      |\n",
      "|    explained_variance | 0.985      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.544      |\n",
      "|    mean_step_reward   | 0.3572809  |\n",
      "|    n_updates          | 18404      |\n",
      "|    policyGradLoss     | -0.00817   |\n",
      "|    value_loss         | 1.95       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 37707776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017399639 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.769       |\n",
      "|    mean_step_reward   | 0.45854378  |\n",
      "|    n_updates          | 18408       |\n",
      "|    policyGradLoss     | -0.00622    |\n",
      "|    value_loss         | 1.59        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 37715968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023679348 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.404       |\n",
      "|    mean_step_reward   | 0.40429884  |\n",
      "|    n_updates          | 18412       |\n",
      "|    policyGradLoss     | -0.00615    |\n",
      "|    value_loss         | 1.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 37724160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010028706 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.18        |\n",
      "|    mean_step_reward   | 0.4272407   |\n",
      "|    n_updates          | 18416       |\n",
      "|    policyGradLoss     | -0.0032     |\n",
      "|    value_loss         | 2.34        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 37732352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012396362 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.905       |\n",
      "|    mean_step_reward   | 0.40509778  |\n",
      "|    n_updates          | 18420       |\n",
      "|    policyGradLoss     | -0.0024     |\n",
      "|    value_loss         | 4.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 37740544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018028159 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.388       |\n",
      "|    mean_step_reward   | 0.39820606  |\n",
      "|    n_updates          | 18424       |\n",
      "|    policyGradLoss     | 0.000552    |\n",
      "|    value_loss         | 1.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 37748736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013323089 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.371       |\n",
      "|    mean_step_reward   | 0.4252284   |\n",
      "|    n_updates          | 18428       |\n",
      "|    policyGradLoss     | -0.00474    |\n",
      "|    value_loss         | 1.69        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_143.zip\n",
      "[EVAL] Mean Return: 542.245, Best Return: 548.245\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_143_542.24.mp4\n",
      "\n",
      "=== Round 145 | Learn 262144 steps (Total trained: 37748736) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1157     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 37756928 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 938         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 37765120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018775009 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.422       |\n",
      "|    mean_step_reward   | 0.41739222  |\n",
      "|    n_updates          | 18436       |\n",
      "|    policyGradLoss     | -0.00949    |\n",
      "|    value_loss         | 1.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 877         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 37773312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010512626 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.3         |\n",
      "|    mean_step_reward   | 0.44111133  |\n",
      "|    n_updates          | 18440       |\n",
      "|    policyGradLoss     | -0.00429    |\n",
      "|    value_loss         | 2.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 848         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 37781504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016041793 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.298       |\n",
      "|    mean_step_reward   | 0.3690204   |\n",
      "|    n_updates          | 18444       |\n",
      "|    policyGradLoss     | -0.0046     |\n",
      "|    value_loss         | 1.74        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 832         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 37789696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013480027 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.578       |\n",
      "|    mean_step_reward   | 0.42525953  |\n",
      "|    n_updates          | 18448       |\n",
      "|    policyGradLoss     | -0.00561    |\n",
      "|    value_loss         | 1.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 37797888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013601063 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.569       |\n",
      "|    mean_step_reward   | 0.44090748  |\n",
      "|    n_updates          | 18452       |\n",
      "|    policyGradLoss     | -0.00315    |\n",
      "|    value_loss         | 2.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 37806080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013126457 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.459       |\n",
      "|    mean_step_reward   | 0.44755352  |\n",
      "|    n_updates          | 18456       |\n",
      "|    policyGradLoss     | -0.00616    |\n",
      "|    value_loss         | 1.88        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 37814272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011121379 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.952       |\n",
      "|    mean_step_reward   | 0.35768276  |\n",
      "|    n_updates          | 18460       |\n",
      "|    policyGradLoss     | -0.003      |\n",
      "|    value_loss         | 1.99        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 37822464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012832055 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.325       |\n",
      "|    mean_step_reward   | 0.40373385  |\n",
      "|    n_updates          | 18464       |\n",
      "|    policyGradLoss     | -0.00664    |\n",
      "|    value_loss         | 1.52        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 37830656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012181071 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.53        |\n",
      "|    mean_step_reward   | 0.4403954   |\n",
      "|    n_updates          | 18468       |\n",
      "|    policyGradLoss     | -0.00653    |\n",
      "|    value_loss         | 1.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 37838848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015446945 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.454       |\n",
      "|    mean_step_reward   | 0.40673757  |\n",
      "|    n_updates          | 18472       |\n",
      "|    policyGradLoss     | -0.00565    |\n",
      "|    value_loss         | 2.43        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 790          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 124          |\n",
      "|    total_timesteps    | 37847040     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0149782915 |\n",
      "|    entropy_loss       | -1.61        |\n",
      "|    explained_variance | 0.968        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.884        |\n",
      "|    mean_step_reward   | 0.42011112   |\n",
      "|    n_updates          | 18476        |\n",
      "|    policyGradLoss     | -0.00099     |\n",
      "|    value_loss         | 2.93         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 37855232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011686685 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.352       |\n",
      "|    mean_step_reward   | 0.36394683  |\n",
      "|    n_updates          | 18480       |\n",
      "|    policyGradLoss     | -0.00345    |\n",
      "|    value_loss         | 2.71        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 37863424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016618764 |\n",
      "|    entropy_loss       | -1.57       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.15        |\n",
      "|    mean_step_reward   | 0.38906848  |\n",
      "|    n_updates          | 18484       |\n",
      "|    policyGradLoss     | -0.00597    |\n",
      "|    value_loss         | 1.86        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 785       |\n",
      "|    iterations         | 15        |\n",
      "|    time_elapsed       | 156       |\n",
      "|    total_timesteps    | 37871616  |\n",
      "| train/                |           |\n",
      "|    approx_kl          | 0.009773  |\n",
      "|    entropy_loss       | -1.63     |\n",
      "|    explained_variance | 0.954     |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    loss               | 0.408     |\n",
      "|    mean_step_reward   | 0.361439  |\n",
      "|    n_updates          | 18488     |\n",
      "|    policyGradLoss     | -0.000978 |\n",
      "|    value_loss         | 3.31      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 37879808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010304218 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.845       |\n",
      "|    mean_step_reward   | 0.41923717  |\n",
      "|    n_updates          | 18492       |\n",
      "|    policyGradLoss     | 0.00146     |\n",
      "|    value_loss         | 2.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 37888000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016797187 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.959       |\n",
      "|    mean_step_reward   | 0.38910496  |\n",
      "|    n_updates          | 18496       |\n",
      "|    policyGradLoss     | -0.00385    |\n",
      "|    value_loss         | 2.23        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 783          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 188          |\n",
      "|    total_timesteps    | 37896192     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0109685175 |\n",
      "|    entropy_loss       | -1.67        |\n",
      "|    explained_variance | 0.975        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.04         |\n",
      "|    mean_step_reward   | 0.37282327   |\n",
      "|    n_updates          | 18500        |\n",
      "|    policyGradLoss     | 0.000116     |\n",
      "|    value_loss         | 2.19         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 37904384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013462744 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.167       |\n",
      "|    mean_step_reward   | 0.41446862  |\n",
      "|    n_updates          | 18504       |\n",
      "|    policyGradLoss     | -0.00747    |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 782          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 209          |\n",
      "|    total_timesteps    | 37912576     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0120733585 |\n",
      "|    entropy_loss       | -1.63        |\n",
      "|    explained_variance | 0.984        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.702        |\n",
      "|    mean_step_reward   | 0.40101174   |\n",
      "|    n_updates          | 18508        |\n",
      "|    policyGradLoss     | -0.00134     |\n",
      "|    value_loss         | 2.15         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 37920768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012274026 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.189       |\n",
      "|    mean_step_reward   | 0.42605     |\n",
      "|    n_updates          | 18512       |\n",
      "|    policyGradLoss     | -0.00334    |\n",
      "|    value_loss         | 2.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 37928960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009620211 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.31        |\n",
      "|    mean_step_reward   | 0.4169066   |\n",
      "|    n_updates          | 18516       |\n",
      "|    policyGradLoss     | -0.00694    |\n",
      "|    value_loss         | 1.75        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 780        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 241        |\n",
      "|    total_timesteps    | 37937152   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01609864 |\n",
      "|    entropy_loss       | -1.6       |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.355      |\n",
      "|    mean_step_reward   | 0.44911695 |\n",
      "|    n_updates          | 18520      |\n",
      "|    policyGradLoss     | -0.00901   |\n",
      "|    value_loss         | 1.3        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 37945344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015317026 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.991       |\n",
      "|    mean_step_reward   | 0.40079004  |\n",
      "|    n_updates          | 18524       |\n",
      "|    policyGradLoss     | 0.0074      |\n",
      "|    value_loss         | 4.88        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 37953536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016819032 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.687       |\n",
      "|    mean_step_reward   | 0.41534507  |\n",
      "|    n_updates          | 18528       |\n",
      "|    policyGradLoss     | 0.000784    |\n",
      "|    value_loss         | 3.79        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 273        |\n",
      "|    total_timesteps    | 37961728   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0129712  |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.983      |\n",
      "|    mean_step_reward   | 0.37953997 |\n",
      "|    n_updates          | 18532      |\n",
      "|    policyGradLoss     | -0.00485   |\n",
      "|    value_loss         | 2.02       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 37969920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017610567 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.676       |\n",
      "|    mean_step_reward   | 0.43845028  |\n",
      "|    n_updates          | 18536       |\n",
      "|    policyGradLoss     | -0.00806    |\n",
      "|    value_loss         | 1.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 37978112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015809486 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.523       |\n",
      "|    mean_step_reward   | 0.39180377  |\n",
      "|    n_updates          | 18540       |\n",
      "|    policyGradLoss     | -0.00386    |\n",
      "|    value_loss         | 1.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 37986304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014063006 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.938       |\n",
      "|    mean_step_reward   | 0.41873276  |\n",
      "|    n_updates          | 18544       |\n",
      "|    policyGradLoss     | -0.0044     |\n",
      "|    value_loss         | 1.9         |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 776       |\n",
      "|    iterations         | 30        |\n",
      "|    time_elapsed       | 316       |\n",
      "|    total_timesteps    | 37994496  |\n",
      "| train/                |           |\n",
      "|    approx_kl          | 0.0138765 |\n",
      "|    entropy_loss       | -1.63     |\n",
      "|    explained_variance | 0.985     |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    loss               | 0.618     |\n",
      "|    mean_step_reward   | 0.4178176 |\n",
      "|    n_updates          | 18548     |\n",
      "|    policyGradLoss     | -0.00482  |\n",
      "|    value_loss         | 2.01      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 38002688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010148137 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.359       |\n",
      "|    mean_step_reward   | 0.36377305  |\n",
      "|    n_updates          | 18552       |\n",
      "|    policyGradLoss     | -0.00346    |\n",
      "|    value_loss         | 2.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 38010880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011690099 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.491       |\n",
      "|    mean_step_reward   | 0.44238216  |\n",
      "|    n_updates          | 18556       |\n",
      "|    policyGradLoss     | -0.00293    |\n",
      "|    value_loss         | 2.39        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_144.zip\n",
      "[EVAL] Mean Return: 542.501, Best Return: 549.168\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_144_542.50.mp4\n",
      "\n",
      "=== Round 146 | Learn 262144 steps (Total trained: 38010880) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1122     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 38019072 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 908         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 38027264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013545315 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.557       |\n",
      "|    mean_step_reward   | 0.4330132   |\n",
      "|    n_updates          | 18564       |\n",
      "|    policyGradLoss     | -0.00451    |\n",
      "|    value_loss         | 1.82        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 850       |\n",
      "|    iterations         | 3         |\n",
      "|    time_elapsed       | 28        |\n",
      "|    total_timesteps    | 38035456  |\n",
      "| train/                |           |\n",
      "|    approx_kl          | 0.0158839 |\n",
      "|    entropy_loss       | -1.62     |\n",
      "|    explained_variance | 0.99      |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    loss               | 1.09      |\n",
      "|    mean_step_reward   | 0.4521828 |\n",
      "|    n_updates          | 18568     |\n",
      "|    policyGradLoss     | -0.00715  |\n",
      "|    value_loss         | 1.49      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 829        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 39         |\n",
      "|    total_timesteps    | 38043648   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01922568 |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.99       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.468      |\n",
      "|    mean_step_reward   | 0.40806302 |\n",
      "|    n_updates          | 18572      |\n",
      "|    policyGradLoss     | -0.00503   |\n",
      "|    value_loss         | 1.58       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 816        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 50         |\n",
      "|    total_timesteps    | 38051840   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01628914 |\n",
      "|    entropy_loss       | -1.6       |\n",
      "|    explained_variance | 0.988      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.431      |\n",
      "|    mean_step_reward   | 0.42515057 |\n",
      "|    n_updates          | 18576      |\n",
      "|    policyGradLoss     | -0.00637   |\n",
      "|    value_loss         | 1.71       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 38060032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013392212 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.502       |\n",
      "|    mean_step_reward   | 0.40601724  |\n",
      "|    n_updates          | 18580       |\n",
      "|    policyGradLoss     | -0.00522    |\n",
      "|    value_loss         | 1.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 38068224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013816498 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.862       |\n",
      "|    mean_step_reward   | 0.43000326  |\n",
      "|    n_updates          | 18584       |\n",
      "|    policyGradLoss     | 0.00249     |\n",
      "|    value_loss         | 2.34        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 38076416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014178309 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.46        |\n",
      "|    mean_step_reward   | 0.42800832  |\n",
      "|    n_updates          | 18588       |\n",
      "|    policyGradLoss     | -0.00639    |\n",
      "|    value_loss         | 1.89        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 794        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 92         |\n",
      "|    total_timesteps    | 38084608   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01578083 |\n",
      "|    entropy_loss       | -1.63      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.587      |\n",
      "|    mean_step_reward   | 0.42257228 |\n",
      "|    n_updates          | 18592      |\n",
      "|    policyGradLoss     | -0.00537   |\n",
      "|    value_loss         | 1.64       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 38092800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014270054 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.543       |\n",
      "|    mean_step_reward   | 0.41494676  |\n",
      "|    n_updates          | 18596       |\n",
      "|    policyGradLoss     | -0.00675    |\n",
      "|    value_loss         | 1.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 38100992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017038163 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.45        |\n",
      "|    mean_step_reward   | 0.4365928   |\n",
      "|    n_updates          | 18600       |\n",
      "|    policyGradLoss     | -0.00696    |\n",
      "|    value_loss         | 1.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 38109184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022673517 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.856       |\n",
      "|    mean_step_reward   | 0.41977498  |\n",
      "|    n_updates          | 18604       |\n",
      "|    policyGradLoss     | -0.00577    |\n",
      "|    value_loss         | 1.92        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 38117376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021246033 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.378       |\n",
      "|    mean_step_reward   | 0.37223333  |\n",
      "|    n_updates          | 18608       |\n",
      "|    policyGradLoss     | -0.00655    |\n",
      "|    value_loss         | 1.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 38125568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013940886 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.203       |\n",
      "|    mean_step_reward   | 0.4090823   |\n",
      "|    n_updates          | 18612       |\n",
      "|    policyGradLoss     | -0.00677    |\n",
      "|    value_loss         | 1.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 38133760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020274606 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.27        |\n",
      "|    mean_step_reward   | 0.39453387  |\n",
      "|    n_updates          | 18616       |\n",
      "|    policyGradLoss     | -0.0046     |\n",
      "|    value_loss         | 2.15        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 783        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 167        |\n",
      "|    total_timesteps    | 38141952   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01757624 |\n",
      "|    entropy_loss       | -1.65      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.972      |\n",
      "|    mean_step_reward   | 0.3652045  |\n",
      "|    n_updates          | 18620      |\n",
      "|    policyGradLoss     | -0.00908   |\n",
      "|    value_loss         | 1.73       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 38150144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012939446 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.762       |\n",
      "|    mean_step_reward   | 0.39851177  |\n",
      "|    n_updates          | 18624       |\n",
      "|    policyGradLoss     | -0.0062     |\n",
      "|    value_loss         | 1.64        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 38158336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022105621 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.451       |\n",
      "|    mean_step_reward   | 0.37848276  |\n",
      "|    n_updates          | 18628       |\n",
      "|    policyGradLoss     | -0.00331    |\n",
      "|    value_loss         | 1.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 38166528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016883984 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.117       |\n",
      "|    mean_step_reward   | 0.36902684  |\n",
      "|    n_updates          | 18632       |\n",
      "|    policyGradLoss     | -0.00905    |\n",
      "|    value_loss         | 1.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 38174720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018019088 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.169       |\n",
      "|    mean_step_reward   | 0.4021172   |\n",
      "|    n_updates          | 18636       |\n",
      "|    policyGradLoss     | -0.00742    |\n",
      "|    value_loss         | 1.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 38182912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012884225 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.459       |\n",
      "|    mean_step_reward   | 0.3950227   |\n",
      "|    n_updates          | 18640       |\n",
      "|    policyGradLoss     | -0.00271    |\n",
      "|    value_loss         | 2.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 38191104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011956827 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.881       |\n",
      "|    mean_step_reward   | 0.4101007   |\n",
      "|    n_updates          | 18644       |\n",
      "|    policyGradLoss     | -0.00375    |\n",
      "|    value_loss         | 2.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 38199296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018357275 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.341       |\n",
      "|    mean_step_reward   | 0.39518696  |\n",
      "|    n_updates          | 18648       |\n",
      "|    policyGradLoss     | -0.00598    |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 38207488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020335568 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.568       |\n",
      "|    mean_step_reward   | 0.4059101   |\n",
      "|    n_updates          | 18652       |\n",
      "|    policyGradLoss     | -0.00858    |\n",
      "|    value_loss         | 1.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 38215680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016297363 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.888       |\n",
      "|    mean_step_reward   | 0.38125232  |\n",
      "|    n_updates          | 18656       |\n",
      "|    policyGradLoss     | -0.00401    |\n",
      "|    value_loss         | 2.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 38223872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010715496 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.293       |\n",
      "|    mean_step_reward   | 0.40019858  |\n",
      "|    n_updates          | 18660       |\n",
      "|    policyGradLoss     | -0.00677    |\n",
      "|    value_loss         | 1.45        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 38232064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014015662 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.348       |\n",
      "|    mean_step_reward   | 0.33481508  |\n",
      "|    n_updates          | 18664       |\n",
      "|    policyGradLoss     | -0.00637    |\n",
      "|    value_loss         | 1.32        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 773        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 296        |\n",
      "|    total_timesteps    | 38240256   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01531707 |\n",
      "|    entropy_loss       | -1.62      |\n",
      "|    explained_variance | 0.988      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.01       |\n",
      "|    mean_step_reward   | 0.39008838 |\n",
      "|    n_updates          | 18668      |\n",
      "|    policyGradLoss     | -0.00761   |\n",
      "|    value_loss         | 1.52       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 307         |\n",
      "|    total_timesteps    | 38248448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012423245 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.676       |\n",
      "|    mean_step_reward   | 0.4088644   |\n",
      "|    n_updates          | 18672       |\n",
      "|    policyGradLoss     | -0.00492    |\n",
      "|    value_loss         | 1.89        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 38256640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016600348 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.483       |\n",
      "|    mean_step_reward   | 0.43083596  |\n",
      "|    n_updates          | 18676       |\n",
      "|    policyGradLoss     | -0.00104    |\n",
      "|    value_loss         | 3.32        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 773        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 328        |\n",
      "|    total_timesteps    | 38264832   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01253208 |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.962      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.786      |\n",
      "|    mean_step_reward   | 0.3673331  |\n",
      "|    n_updates          | 18680      |\n",
      "|    policyGradLoss     | -0.000665  |\n",
      "|    value_loss         | 3.3        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 38273024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015991664 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.187       |\n",
      "|    mean_step_reward   | 0.4302467   |\n",
      "|    n_updates          | 18684       |\n",
      "|    policyGradLoss     | -0.00597    |\n",
      "|    value_loss         | 1.21        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_145.zip\n",
      "[EVAL] Mean Return: 542.272, Best Return: 549.606\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_145_542.27.mp4\n",
      "\n",
      "=== Round 147 | Learn 262144 steps (Total trained: 38273024) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1098     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 38281216 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 900         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 38289408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011799587 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.864       |\n",
      "|    mean_step_reward   | 0.40564454  |\n",
      "|    n_updates          | 18692       |\n",
      "|    policyGradLoss     | -0.00123    |\n",
      "|    value_loss         | 2.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 851         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 38297600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014477953 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.22        |\n",
      "|    mean_step_reward   | 0.42421705  |\n",
      "|    n_updates          | 18696       |\n",
      "|    policyGradLoss     | -0.00212    |\n",
      "|    value_loss         | 1.94        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 828         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 38305792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015080046 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.419       |\n",
      "|    mean_step_reward   | 0.3624263   |\n",
      "|    n_updates          | 18700       |\n",
      "|    policyGradLoss     | -0.0059     |\n",
      "|    value_loss         | 1.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 38313984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013356743 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.492       |\n",
      "|    mean_step_reward   | 0.41339993  |\n",
      "|    n_updates          | 18704       |\n",
      "|    policyGradLoss     | -0.00657    |\n",
      "|    value_loss         | 1.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 38322176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012913471 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.03        |\n",
      "|    mean_step_reward   | 0.40411508  |\n",
      "|    n_updates          | 18708       |\n",
      "|    policyGradLoss     | -0.00456    |\n",
      "|    value_loss         | 2.65        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 38330368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017949782 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.479       |\n",
      "|    mean_step_reward   | 0.38132498  |\n",
      "|    n_updates          | 18712       |\n",
      "|    policyGradLoss     | -0.00717    |\n",
      "|    value_loss         | 1.43        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 38338560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018137487 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.633       |\n",
      "|    mean_step_reward   | 0.39149183  |\n",
      "|    n_updates          | 18716       |\n",
      "|    policyGradLoss     | -0.00529    |\n",
      "|    value_loss         | 2.53        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 38346752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016307205 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.703       |\n",
      "|    mean_step_reward   | 0.41953123  |\n",
      "|    n_updates          | 18720       |\n",
      "|    policyGradLoss     | -0.00587    |\n",
      "|    value_loss         | 1.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 38354944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020318858 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.71        |\n",
      "|    mean_step_reward   | 0.37258786  |\n",
      "|    n_updates          | 18724       |\n",
      "|    policyGradLoss     | 0.00185     |\n",
      "|    value_loss         | 4.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 38363136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016922578 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.707       |\n",
      "|    mean_step_reward   | 0.38817123  |\n",
      "|    n_updates          | 18728       |\n",
      "|    policyGradLoss     | 0.00151     |\n",
      "|    value_loss         | 1.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 38371328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011956591 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.915       |\n",
      "|    mean_step_reward   | 0.40014368  |\n",
      "|    n_updates          | 18732       |\n",
      "|    policyGradLoss     | -0.00528    |\n",
      "|    value_loss         | 1.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 38379520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013640543 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.819       |\n",
      "|    mean_step_reward   | 0.4451962   |\n",
      "|    n_updates          | 18736       |\n",
      "|    policyGradLoss     | -0.00656    |\n",
      "|    value_loss         | 1.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 38387712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011097336 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.739       |\n",
      "|    mean_step_reward   | 0.34364885  |\n",
      "|    n_updates          | 18740       |\n",
      "|    policyGradLoss     | -0.00548    |\n",
      "|    value_loss         | 2.04        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 38395904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009683447 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.734       |\n",
      "|    mean_step_reward   | 0.3721124   |\n",
      "|    n_updates          | 18744       |\n",
      "|    policyGradLoss     | -0.00271    |\n",
      "|    value_loss         | 1.87        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 785        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 166        |\n",
      "|    total_timesteps    | 38404096   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01401823 |\n",
      "|    entropy_loss       | -1.65      |\n",
      "|    explained_variance | 0.982      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.738      |\n",
      "|    mean_step_reward   | 0.3637376  |\n",
      "|    n_updates          | 18748      |\n",
      "|    policyGradLoss     | -0.00615   |\n",
      "|    value_loss         | 1.89       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 38412288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024942532 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.912       |\n",
      "|    mean_step_reward   | 0.4096576   |\n",
      "|    n_updates          | 18752       |\n",
      "|    policyGradLoss     | 0.00791     |\n",
      "|    value_loss         | 3.64        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 38420480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010492304 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.15        |\n",
      "|    mean_step_reward   | 0.37292096  |\n",
      "|    n_updates          | 18756       |\n",
      "|    policyGradLoss     | -0.00424    |\n",
      "|    value_loss         | 1.68        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 782        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 198        |\n",
      "|    total_timesteps    | 38428672   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01259002 |\n",
      "|    entropy_loss       | -1.61      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.561      |\n",
      "|    mean_step_reward   | 0.37138522 |\n",
      "|    n_updates          | 18760      |\n",
      "|    policyGradLoss     | -0.00897   |\n",
      "|    value_loss         | 1.58       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 781        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 209        |\n",
      "|    total_timesteps    | 38436864   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01694359 |\n",
      "|    entropy_loss       | -1.65      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.541      |\n",
      "|    mean_step_reward   | 0.4098241  |\n",
      "|    n_updates          | 18764      |\n",
      "|    policyGradLoss     | -0.00607   |\n",
      "|    value_loss         | 1.5        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 781        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 220        |\n",
      "|    total_timesteps    | 38445056   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01872664 |\n",
      "|    entropy_loss       | -1.63      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.451      |\n",
      "|    mean_step_reward   | 0.4143768  |\n",
      "|    n_updates          | 18768      |\n",
      "|    policyGradLoss     | -0.00818   |\n",
      "|    value_loss         | 1.4        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 38453248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011950875 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.688       |\n",
      "|    mean_step_reward   | 0.40154904  |\n",
      "|    n_updates          | 18772       |\n",
      "|    policyGradLoss     | -0.00387    |\n",
      "|    value_loss         | 2.48        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 779          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 241          |\n",
      "|    total_timesteps    | 38461440     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0109323915 |\n",
      "|    entropy_loss       | -1.6         |\n",
      "|    explained_variance | 0.925        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.56         |\n",
      "|    mean_step_reward   | 0.39454693   |\n",
      "|    n_updates          | 18776        |\n",
      "|    policyGradLoss     | 0.00143      |\n",
      "|    value_loss         | 7.29         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 252        |\n",
      "|    total_timesteps    | 38469632   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01569853 |\n",
      "|    entropy_loss       | -1.66      |\n",
      "|    explained_variance | 0.949      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.527      |\n",
      "|    mean_step_reward   | 0.38494444 |\n",
      "|    n_updates          | 18780      |\n",
      "|    policyGradLoss     | -0.000947  |\n",
      "|    value_loss         | 3.77       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 38477824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013633026 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.618       |\n",
      "|    mean_step_reward   | 0.3831808   |\n",
      "|    n_updates          | 18784       |\n",
      "|    policyGradLoss     | -0.00501    |\n",
      "|    value_loss         | 3.37        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 273        |\n",
      "|    total_timesteps    | 38486016   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01458757 |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.965      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.676      |\n",
      "|    mean_step_reward   | 0.3919103  |\n",
      "|    n_updates          | 18788      |\n",
      "|    policyGradLoss     | -0.001     |\n",
      "|    value_loss         | 2.57       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 38494208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012767047 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.23        |\n",
      "|    mean_step_reward   | 0.3821367   |\n",
      "|    n_updates          | 18792       |\n",
      "|    policyGradLoss     | -0.00496    |\n",
      "|    value_loss         | 2.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 38502400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019706221 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.668       |\n",
      "|    mean_step_reward   | 0.44536313  |\n",
      "|    n_updates          | 18796       |\n",
      "|    policyGradLoss     | -0.00642    |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 38510592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013642515 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.26        |\n",
      "|    mean_step_reward   | 0.40329355  |\n",
      "|    n_updates          | 18800       |\n",
      "|    policyGradLoss     | -0.00348    |\n",
      "|    value_loss         | 2.72        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 38518784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011782067 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.454       |\n",
      "|    mean_step_reward   | 0.40294623  |\n",
      "|    n_updates          | 18804       |\n",
      "|    policyGradLoss     | -0.00716    |\n",
      "|    value_loss         | 1.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 38526976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013491081 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.598       |\n",
      "|    mean_step_reward   | 0.40918547  |\n",
      "|    n_updates          | 18808       |\n",
      "|    policyGradLoss     | -0.00485    |\n",
      "|    value_loss         | 1.6         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 775        |\n",
      "|    iterations         | 32         |\n",
      "|    time_elapsed       | 337        |\n",
      "|    total_timesteps    | 38535168   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01108267 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.945      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.15       |\n",
      "|    mean_step_reward   | 0.37991387 |\n",
      "|    n_updates          | 18812      |\n",
      "|    policyGradLoss     | -0.000806  |\n",
      "|    value_loss         | 4.18       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_146.zip\n",
      "[EVAL] Mean Return: 539.625, Best Return: 546.958\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_146_539.62.mp4\n",
      "\n",
      "=== Round 148 | Learn 262144 steps (Total trained: 38535168) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1129     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 38543360 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 904         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 38551552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013919942 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.12        |\n",
      "|    mean_step_reward   | 0.43077514  |\n",
      "|    n_updates          | 18820       |\n",
      "|    policyGradLoss     | -0.0055     |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 855         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 38559744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008553765 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.07        |\n",
      "|    mean_step_reward   | 0.37630793  |\n",
      "|    n_updates          | 18824       |\n",
      "|    policyGradLoss     | -0.00373    |\n",
      "|    value_loss         | 2.09        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 836         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 38567936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009961352 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.669       |\n",
      "|    mean_step_reward   | 0.43207157  |\n",
      "|    n_updates          | 18828       |\n",
      "|    policyGradLoss     | -0.00262    |\n",
      "|    value_loss         | 2.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 38576128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013680359 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.9         |\n",
      "|    mean_step_reward   | 0.35913     |\n",
      "|    n_updates          | 18832       |\n",
      "|    policyGradLoss     | -0.000691   |\n",
      "|    value_loss         | 2.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 38584320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012403995 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.304       |\n",
      "|    mean_step_reward   | 0.39174914  |\n",
      "|    n_updates          | 18836       |\n",
      "|    policyGradLoss     | -0.00664    |\n",
      "|    value_loss         | 1.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 38592512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008887503 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.1         |\n",
      "|    mean_step_reward   | 0.37627518  |\n",
      "|    n_updates          | 18840       |\n",
      "|    policyGradLoss     | -0.00444    |\n",
      "|    value_loss         | 2.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 38600704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012637293 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.686       |\n",
      "|    mean_step_reward   | 0.3961426   |\n",
      "|    n_updates          | 18844       |\n",
      "|    policyGradLoss     | -0.00232    |\n",
      "|    value_loss         | 2.65        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 38608896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015032053 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.458       |\n",
      "|    mean_step_reward   | 0.42926615  |\n",
      "|    n_updates          | 18848       |\n",
      "|    policyGradLoss     | -0.00309    |\n",
      "|    value_loss         | 1.86        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 798          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 102          |\n",
      "|    total_timesteps    | 38617088     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0153146945 |\n",
      "|    entropy_loss       | -1.65        |\n",
      "|    explained_variance | 0.988        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.675        |\n",
      "|    mean_step_reward   | 0.40869692   |\n",
      "|    n_updates          | 18852        |\n",
      "|    policyGradLoss     | -0.00695     |\n",
      "|    value_loss         | 1.78         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 38625280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011340747 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.719       |\n",
      "|    mean_step_reward   | 0.4305272   |\n",
      "|    n_updates          | 18856       |\n",
      "|    policyGradLoss     | -0.00466    |\n",
      "|    value_loss         | 3.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 38633472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009452308 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.921       |\n",
      "|    mean_step_reward   | 0.34120905  |\n",
      "|    n_updates          | 18860       |\n",
      "|    policyGradLoss     | -0.00418    |\n",
      "|    value_loss         | 2.74        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 788          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 135          |\n",
      "|    total_timesteps    | 38641664     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0105208745 |\n",
      "|    entropy_loss       | -1.6         |\n",
      "|    explained_variance | 0.974        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.264        |\n",
      "|    mean_step_reward   | 0.40627006   |\n",
      "|    n_updates          | 18864        |\n",
      "|    policyGradLoss     | -0.00291     |\n",
      "|    value_loss         | 1.95         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 38649856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010797686 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.813       |\n",
      "|    mean_step_reward   | 0.4169624   |\n",
      "|    n_updates          | 18868       |\n",
      "|    policyGradLoss     | -0.00133    |\n",
      "|    value_loss         | 2.96        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 38658048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010988474 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.679       |\n",
      "|    mean_step_reward   | 0.43220297  |\n",
      "|    n_updates          | 18872       |\n",
      "|    policyGradLoss     | -0.00365    |\n",
      "|    value_loss         | 1.98        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 38666240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013376383 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.709       |\n",
      "|    mean_step_reward   | 0.3736315   |\n",
      "|    n_updates          | 18876       |\n",
      "|    policyGradLoss     | -0.00165    |\n",
      "|    value_loss         | 3.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 38674432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017098878 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.674       |\n",
      "|    mean_step_reward   | 0.37319016  |\n",
      "|    n_updates          | 18880       |\n",
      "|    policyGradLoss     | 0.00141     |\n",
      "|    value_loss         | 2.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 38682624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019806772 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.179       |\n",
      "|    mean_step_reward   | 0.40965477  |\n",
      "|    n_updates          | 18884       |\n",
      "|    policyGradLoss     | -0.00362    |\n",
      "|    value_loss         | 1.61        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 38690816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013673119 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.311       |\n",
      "|    mean_step_reward   | 0.36493212  |\n",
      "|    n_updates          | 18888       |\n",
      "|    policyGradLoss     | -0.00513    |\n",
      "|    value_loss         | 1.9         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 38699008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011617603 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.14        |\n",
      "|    mean_step_reward   | 0.37935454  |\n",
      "|    n_updates          | 18892       |\n",
      "|    policyGradLoss     | -0.00347    |\n",
      "|    value_loss         | 1.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 38707200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013522223 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.631       |\n",
      "|    mean_step_reward   | 0.388803    |\n",
      "|    n_updates          | 18896       |\n",
      "|    policyGradLoss     | -0.00444    |\n",
      "|    value_loss         | 1.65        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 38715392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016443007 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.995       |\n",
      "|    mean_step_reward   | 0.38928062  |\n",
      "|    n_updates          | 18900       |\n",
      "|    policyGradLoss     | -0.00628    |\n",
      "|    value_loss         | 1.82        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 38723584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014940415 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.54        |\n",
      "|    mean_step_reward   | 0.375301    |\n",
      "|    n_updates          | 18904       |\n",
      "|    policyGradLoss     | -0.0054     |\n",
      "|    value_loss         | 1.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 38731776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016815223 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0826      |\n",
      "|    mean_step_reward   | 0.3633045   |\n",
      "|    n_updates          | 18908       |\n",
      "|    policyGradLoss     | -0.00674    |\n",
      "|    value_loss         | 1.48        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 781        |\n",
      "|    iterations         | 25         |\n",
      "|    time_elapsed       | 262        |\n",
      "|    total_timesteps    | 38739968   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01624652 |\n",
      "|    entropy_loss       | -1.62      |\n",
      "|    explained_variance | 0.983      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.589      |\n",
      "|    mean_step_reward   | 0.39047858 |\n",
      "|    n_updates          | 18912      |\n",
      "|    policyGradLoss     | -0.00362   |\n",
      "|    value_loss         | 1.81       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 38748160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015302808 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.17        |\n",
      "|    mean_step_reward   | 0.39744836  |\n",
      "|    n_updates          | 18916       |\n",
      "|    policyGradLoss     | 0.00239     |\n",
      "|    value_loss         | 4.69        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 781        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 283        |\n",
      "|    total_timesteps    | 38756352   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01804644 |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.988      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.19       |\n",
      "|    mean_step_reward   | 0.41870016 |\n",
      "|    n_updates          | 18920      |\n",
      "|    policyGradLoss     | -0.00607   |\n",
      "|    value_loss         | 1.91       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 38764544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021630798 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.475       |\n",
      "|    mean_step_reward   | 0.38023412  |\n",
      "|    n_updates          | 18924       |\n",
      "|    policyGradLoss     | 0.0175      |\n",
      "|    value_loss         | 2.74        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 38772736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016157497 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.31        |\n",
      "|    mean_step_reward   | 0.37050462  |\n",
      "|    n_updates          | 18928       |\n",
      "|    policyGradLoss     | 0.0064      |\n",
      "|    value_loss         | 2.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 314         |\n",
      "|    total_timesteps    | 38780928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010444289 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.614       |\n",
      "|    mean_step_reward   | 0.40009826  |\n",
      "|    n_updates          | 18932       |\n",
      "|    policyGradLoss     | 7.62e-05    |\n",
      "|    value_loss         | 4           |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 325        |\n",
      "|    total_timesteps    | 38789120   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00924716 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.938      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.4        |\n",
      "|    mean_step_reward   | 0.3941666  |\n",
      "|    n_updates          | 18936      |\n",
      "|    policyGradLoss     | 0.00906    |\n",
      "|    value_loss         | 4.54       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 38797312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012553612 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.746       |\n",
      "|    mean_step_reward   | 0.40459228  |\n",
      "|    n_updates          | 18940       |\n",
      "|    policyGradLoss     | 0.00302     |\n",
      "|    value_loss         | 2.69        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_147.zip\n",
      "[EVAL] Mean Return: 547.719, Best Return: 554.386\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_147_547.72.mp4\n",
      "\n",
      "=== Round 149 | Learn 262144 steps (Total trained: 38797312) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1130     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 38805504 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 908         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 38813696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015533638 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.17        |\n",
      "|    mean_step_reward   | 0.36588806  |\n",
      "|    n_updates          | 18948       |\n",
      "|    policyGradLoss     | -0.00479    |\n",
      "|    value_loss         | 2.41        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 859          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 38821888     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0140858535 |\n",
      "|    entropy_loss       | -1.65        |\n",
      "|    explained_variance | 0.981        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.441        |\n",
      "|    mean_step_reward   | 0.42945525   |\n",
      "|    n_updates          | 18952        |\n",
      "|    policyGradLoss     | -0.00372     |\n",
      "|    value_loss         | 1.44         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 831        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 39         |\n",
      "|    total_timesteps    | 38830080   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01042144 |\n",
      "|    entropy_loss       | -1.71      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1          |\n",
      "|    mean_step_reward   | 0.39367953 |\n",
      "|    n_updates          | 18956      |\n",
      "|    policyGradLoss     | -0.00568   |\n",
      "|    value_loss         | 2.09       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 38838272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013874976 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.314       |\n",
      "|    mean_step_reward   | 0.39632934  |\n",
      "|    n_updates          | 18960       |\n",
      "|    policyGradLoss     | -0.00183    |\n",
      "|    value_loss         | 2.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 38846464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011430355 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.792       |\n",
      "|    mean_step_reward   | 0.38867873  |\n",
      "|    n_updates          | 18964       |\n",
      "|    policyGradLoss     | 0.00346     |\n",
      "|    value_loss         | 1.89        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 804        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 71         |\n",
      "|    total_timesteps    | 38854656   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01256471 |\n",
      "|    entropy_loss       | -1.68      |\n",
      "|    explained_variance | 0.976      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.34       |\n",
      "|    mean_step_reward   | 0.37334    |\n",
      "|    n_updates          | 18968      |\n",
      "|    policyGradLoss     | -0.00615   |\n",
      "|    value_loss         | 1.78       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 38862848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015561546 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.314       |\n",
      "|    mean_step_reward   | 0.4084475   |\n",
      "|    n_updates          | 18972       |\n",
      "|    policyGradLoss     | -0.0108     |\n",
      "|    value_loss         | 1.09        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 38871040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011365501 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.76        |\n",
      "|    mean_step_reward   | 0.35893792  |\n",
      "|    n_updates          | 18976       |\n",
      "|    policyGradLoss     | -0.00284    |\n",
      "|    value_loss         | 2.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 38879232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015011176 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.576       |\n",
      "|    mean_step_reward   | 0.402995    |\n",
      "|    n_updates          | 18980       |\n",
      "|    policyGradLoss     | -0.00516    |\n",
      "|    value_loss         | 1.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 38887424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015053692 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.397       |\n",
      "|    mean_step_reward   | 0.32097003  |\n",
      "|    n_updates          | 18984       |\n",
      "|    policyGradLoss     | -0.00858    |\n",
      "|    value_loss         | 0.945       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 38895616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013357501 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.439       |\n",
      "|    mean_step_reward   | 0.42068812  |\n",
      "|    n_updates          | 18988       |\n",
      "|    policyGradLoss     | -0.00795    |\n",
      "|    value_loss         | 1.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 38903808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013316652 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.821       |\n",
      "|    mean_step_reward   | 0.42473897  |\n",
      "|    n_updates          | 18992       |\n",
      "|    policyGradLoss     | -0.00571    |\n",
      "|    value_loss         | 1.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 38912000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012264588 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.611       |\n",
      "|    mean_step_reward   | 0.44896552  |\n",
      "|    n_updates          | 18996       |\n",
      "|    policyGradLoss     | -0.00772    |\n",
      "|    value_loss         | 1.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 38920192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013583633 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.993       |\n",
      "|    mean_step_reward   | 0.43568146  |\n",
      "|    n_updates          | 19000       |\n",
      "|    policyGradLoss     | -0.00501    |\n",
      "|    value_loss         | 1.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 38928384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017054401 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.467       |\n",
      "|    mean_step_reward   | 0.38325387  |\n",
      "|    n_updates          | 19004       |\n",
      "|    policyGradLoss     | 0.00445     |\n",
      "|    value_loss         | 3.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 38936576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013824891 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.27        |\n",
      "|    mean_step_reward   | 0.372074    |\n",
      "|    n_updates          | 19008       |\n",
      "|    policyGradLoss     | -0.00644    |\n",
      "|    value_loss         | 1.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 38944768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010010846 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.889       |\n",
      "|    mean_step_reward   | 0.45522326  |\n",
      "|    n_updates          | 19012       |\n",
      "|    policyGradLoss     | -0.00383    |\n",
      "|    value_loss         | 2.04        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 38952960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011023941 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.451       |\n",
      "|    mean_step_reward   | 0.40975714  |\n",
      "|    n_updates          | 19016       |\n",
      "|    policyGradLoss     | -0.005      |\n",
      "|    value_loss         | 1.89        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 38961152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014471804 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.635       |\n",
      "|    mean_step_reward   | 0.41161513  |\n",
      "|    n_updates          | 19020       |\n",
      "|    policyGradLoss     | -0.00415    |\n",
      "|    value_loss         | 2.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 38969344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016511435 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.686       |\n",
      "|    mean_step_reward   | 0.43756843  |\n",
      "|    n_updates          | 19024       |\n",
      "|    policyGradLoss     | -0.0062     |\n",
      "|    value_loss         | 1.59        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 783          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 229          |\n",
      "|    total_timesteps    | 38977536     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0129449945 |\n",
      "|    entropy_loss       | -1.64        |\n",
      "|    explained_variance | 0.988        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.26         |\n",
      "|    mean_step_reward   | 0.38598657   |\n",
      "|    n_updates          | 19028        |\n",
      "|    policyGradLoss     | -0.00722     |\n",
      "|    value_loss         | 1.78         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 782          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 240          |\n",
      "|    total_timesteps    | 38985728     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0116795385 |\n",
      "|    entropy_loss       | -1.64        |\n",
      "|    explained_variance | 0.989        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.114        |\n",
      "|    mean_step_reward   | 0.37851518   |\n",
      "|    n_updates          | 19032        |\n",
      "|    policyGradLoss     | -0.00805     |\n",
      "|    value_loss         | 1.27         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 38993920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013097262 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.593       |\n",
      "|    mean_step_reward   | 0.419688    |\n",
      "|    n_updates          | 19036       |\n",
      "|    policyGradLoss     | -0.00566    |\n",
      "|    value_loss         | 1.81        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 782          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 261          |\n",
      "|    total_timesteps    | 39002112     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0114520695 |\n",
      "|    entropy_loss       | -1.66        |\n",
      "|    explained_variance | 0.981        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.742        |\n",
      "|    mean_step_reward   | 0.43202922   |\n",
      "|    n_updates          | 19040        |\n",
      "|    policyGradLoss     | -0.00285     |\n",
      "|    value_loss         | 2.27         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 39010304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014134565 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.831       |\n",
      "|    mean_step_reward   | 0.41298974  |\n",
      "|    n_updates          | 19044       |\n",
      "|    policyGradLoss     | -0.00934    |\n",
      "|    value_loss         | 1.72        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 39018496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011690663 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.372       |\n",
      "|    mean_step_reward   | 0.40984547  |\n",
      "|    n_updates          | 19048       |\n",
      "|    policyGradLoss     | -0.00298    |\n",
      "|    value_loss         | 2.08        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 780          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 293          |\n",
      "|    total_timesteps    | 39026688     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0121963015 |\n",
      "|    entropy_loss       | -1.63        |\n",
      "|    explained_variance | 0.969        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.502        |\n",
      "|    mean_step_reward   | 0.39844438   |\n",
      "|    n_updates          | 19052        |\n",
      "|    policyGradLoss     | -0.00141     |\n",
      "|    value_loss         | 2.28         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 39034880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012991706 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.348       |\n",
      "|    mean_step_reward   | 0.40894264  |\n",
      "|    n_updates          | 19056       |\n",
      "|    policyGradLoss     | -0.00761    |\n",
      "|    value_loss         | 1.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 39043072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014023663 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.426       |\n",
      "|    mean_step_reward   | 0.38157505  |\n",
      "|    n_updates          | 19060       |\n",
      "|    policyGradLoss     | -0.00675    |\n",
      "|    value_loss         | 1.23        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 325        |\n",
      "|    total_timesteps    | 39051264   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01265499 |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.929      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 2.18       |\n",
      "|    mean_step_reward   | 0.39042738 |\n",
      "|    n_updates          | 19064      |\n",
      "|    policyGradLoss     | 0.00157    |\n",
      "|    value_loss         | 7.44       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 39059456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013141902 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.16        |\n",
      "|    mean_step_reward   | 0.35149056  |\n",
      "|    n_updates          | 19068       |\n",
      "|    policyGradLoss     | 0.00401     |\n",
      "|    value_loss         | 3.69        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_148.zip\n",
      "[EVAL] Mean Return: 542.185, Best Return: 548.852\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_148_542.19.mp4\n",
      "\n",
      "=== Round 150 | Learn 262144 steps (Total trained: 39059456) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1114     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 39067648 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 885         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 39075840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011191668 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.941       |\n",
      "|    mean_step_reward   | 0.41515929  |\n",
      "|    n_updates          | 19076       |\n",
      "|    policyGradLoss     | 0.000859    |\n",
      "|    value_loss         | 3.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 838         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 39084032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010362621 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.11        |\n",
      "|    mean_step_reward   | 0.38088644  |\n",
      "|    n_updates          | 19080       |\n",
      "|    policyGradLoss     | -0.000962   |\n",
      "|    value_loss         | 3.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 39092224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012456512 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.362       |\n",
      "|    mean_step_reward   | 0.36055708  |\n",
      "|    n_updates          | 19084       |\n",
      "|    policyGradLoss     | -0.00565    |\n",
      "|    value_loss         | 1.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 39100416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016091432 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.388       |\n",
      "|    mean_step_reward   | 0.3729632   |\n",
      "|    n_updates          | 19088       |\n",
      "|    policyGradLoss     | -0.00927    |\n",
      "|    value_loss         | 1.81        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 39108608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010563003 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.696       |\n",
      "|    mean_step_reward   | 0.39631993  |\n",
      "|    n_updates          | 19092       |\n",
      "|    policyGradLoss     | -0.00577    |\n",
      "|    value_loss         | 1.77        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 797        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 71         |\n",
      "|    total_timesteps    | 39116800   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00983704 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.985      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.715      |\n",
      "|    mean_step_reward   | 0.35606956 |\n",
      "|    n_updates          | 19096      |\n",
      "|    policyGradLoss     | -0.00433   |\n",
      "|    value_loss         | 1.98       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 39124992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010968103 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.578       |\n",
      "|    mean_step_reward   | 0.38838285  |\n",
      "|    n_updates          | 19100       |\n",
      "|    policyGradLoss     | -0.00385    |\n",
      "|    value_loss         | 2.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 39133184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011224144 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.542       |\n",
      "|    mean_step_reward   | 0.40426913  |\n",
      "|    n_updates          | 19104       |\n",
      "|    policyGradLoss     | -0.00584    |\n",
      "|    value_loss         | 1.59        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 39141376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011641493 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.746       |\n",
      "|    mean_step_reward   | 0.39488158  |\n",
      "|    n_updates          | 19108       |\n",
      "|    policyGradLoss     | -0.00126    |\n",
      "|    value_loss         | 4.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 39149568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013293146 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.536       |\n",
      "|    mean_step_reward   | 0.4160149   |\n",
      "|    n_updates          | 19112       |\n",
      "|    policyGradLoss     | -0.00449    |\n",
      "|    value_loss         | 1.52        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 39157760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017945375 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.81        |\n",
      "|    mean_step_reward   | 0.39916858  |\n",
      "|    n_updates          | 19116       |\n",
      "|    policyGradLoss     | 0.00134     |\n",
      "|    value_loss         | 4.22        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 784          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 135          |\n",
      "|    total_timesteps    | 39165952     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0108386595 |\n",
      "|    entropy_loss       | -1.67        |\n",
      "|    explained_variance | 0.976        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.777        |\n",
      "|    mean_step_reward   | 0.4015793    |\n",
      "|    n_updates          | 19120        |\n",
      "|    policyGradLoss     | -0.00342     |\n",
      "|    value_loss         | 2.81         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 39174144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011375053 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.65        |\n",
      "|    mean_step_reward   | 0.38191044  |\n",
      "|    n_updates          | 19124       |\n",
      "|    policyGradLoss     | -0.00148    |\n",
      "|    value_loss         | 4.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 39182336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016448293 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.68        |\n",
      "|    mean_step_reward   | 0.3760887   |\n",
      "|    n_updates          | 19128       |\n",
      "|    policyGradLoss     | -0.00327    |\n",
      "|    value_loss         | 1.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 39190528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014390816 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.379       |\n",
      "|    mean_step_reward   | 0.38640535  |\n",
      "|    n_updates          | 19132       |\n",
      "|    policyGradLoss     | -0.00816    |\n",
      "|    value_loss         | 1.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 39198720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012936024 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.496       |\n",
      "|    mean_step_reward   | 0.40226713  |\n",
      "|    n_updates          | 19136       |\n",
      "|    policyGradLoss     | -0.00679    |\n",
      "|    value_loss         | 1.49        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 189        |\n",
      "|    total_timesteps    | 39206912   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01655057 |\n",
      "|    entropy_loss       | -1.65      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.368      |\n",
      "|    mean_step_reward   | 0.3987719  |\n",
      "|    n_updates          | 19140      |\n",
      "|    policyGradLoss     | -0.00782   |\n",
      "|    value_loss         | 1.58       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 39215104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011270478 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.04        |\n",
      "|    mean_step_reward   | 0.43099684  |\n",
      "|    n_updates          | 19144       |\n",
      "|    policyGradLoss     | -0.00307    |\n",
      "|    value_loss         | 4.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 39223296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009217781 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.388       |\n",
      "|    mean_step_reward   | 0.3488152   |\n",
      "|    n_updates          | 19148       |\n",
      "|    policyGradLoss     | -0.00716    |\n",
      "|    value_loss         | 1.53        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 39231488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012262446 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.05        |\n",
      "|    mean_step_reward   | 0.4271623   |\n",
      "|    n_updates          | 19152       |\n",
      "|    policyGradLoss     | 5.18e-05    |\n",
      "|    value_loss         | 4.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 39239680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010485698 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.507       |\n",
      "|    mean_step_reward   | 0.41808647  |\n",
      "|    n_updates          | 19156       |\n",
      "|    policyGradLoss     | -0.00184    |\n",
      "|    value_loss         | 2.67        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 776        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 242        |\n",
      "|    total_timesteps    | 39247872   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01220555 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.956      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.845      |\n",
      "|    mean_step_reward   | 0.36533877 |\n",
      "|    n_updates          | 19160      |\n",
      "|    policyGradLoss     | -0.00331   |\n",
      "|    value_loss         | 2.81       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 39256064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012183543 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.432       |\n",
      "|    mean_step_reward   | 0.4287204   |\n",
      "|    n_updates          | 19164       |\n",
      "|    policyGradLoss     | -0.00757    |\n",
      "|    value_loss         | 1.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 39264256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011571609 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.723       |\n",
      "|    mean_step_reward   | 0.38411123  |\n",
      "|    n_updates          | 19168       |\n",
      "|    policyGradLoss     | -0.00579    |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 39272448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025472127 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.991       |\n",
      "|    mean_step_reward   | 0.45132354  |\n",
      "|    n_updates          | 19172       |\n",
      "|    policyGradLoss     | -0.00678    |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 776        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 284        |\n",
      "|    total_timesteps    | 39280640   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01122941 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.28       |\n",
      "|    mean_step_reward   | 0.37379953 |\n",
      "|    n_updates          | 19176      |\n",
      "|    policyGradLoss     | -0.00598   |\n",
      "|    value_loss         | 1.75       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 776        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 295        |\n",
      "|    total_timesteps    | 39288832   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01860186 |\n",
      "|    entropy_loss       | -1.66      |\n",
      "|    explained_variance | 0.994      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.581      |\n",
      "|    mean_step_reward   | 0.40995926 |\n",
      "|    n_updates          | 19180      |\n",
      "|    policyGradLoss     | -0.0126    |\n",
      "|    value_loss         | 0.936      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 39297024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012719074 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.155       |\n",
      "|    mean_step_reward   | 0.43679428  |\n",
      "|    n_updates          | 19184       |\n",
      "|    policyGradLoss     | -0.00933    |\n",
      "|    value_loss         | 1.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 39305216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011399501 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.493       |\n",
      "|    mean_step_reward   | 0.43496603  |\n",
      "|    n_updates          | 19188       |\n",
      "|    policyGradLoss     | -0.0065     |\n",
      "|    value_loss         | 1.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 39313408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012050446 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.06        |\n",
      "|    mean_step_reward   | 0.3995328   |\n",
      "|    n_updates          | 19192       |\n",
      "|    policyGradLoss     | -0.00776    |\n",
      "|    value_loss         | 1.81        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 39321600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008999499 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.781       |\n",
      "|    mean_step_reward   | 0.3975612   |\n",
      "|    n_updates          | 19196       |\n",
      "|    policyGradLoss     | -0.0012     |\n",
      "|    value_loss         | 3.79        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_149.zip\n",
      "[EVAL] Mean Return: 535.168, Best Return: 543.168\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_149_535.17.mp4\n",
      "\n",
      "=== Round 151 | Learn 262144 steps (Total trained: 39321600) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1156     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 39329792 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 928        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 39337984   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01609219 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.992      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.207      |\n",
      "|    mean_step_reward   | 0.41168827 |\n",
      "|    n_updates          | 19204      |\n",
      "|    policyGradLoss     | -0.00908   |\n",
      "|    value_loss         | 1.13       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 871         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 39346176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015577342 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.598       |\n",
      "|    mean_step_reward   | 0.37736395  |\n",
      "|    n_updates          | 19208       |\n",
      "|    policyGradLoss     | -0.00866    |\n",
      "|    value_loss         | 1.59        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 844         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 39354368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011569266 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.608       |\n",
      "|    mean_step_reward   | 0.43233955  |\n",
      "|    n_updates          | 19212       |\n",
      "|    policyGradLoss     | -0.00848    |\n",
      "|    value_loss         | 1.61        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 830        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 49         |\n",
      "|    total_timesteps    | 39362560   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01100808 |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.985      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.453      |\n",
      "|    mean_step_reward   | 0.4400465  |\n",
      "|    n_updates          | 19216      |\n",
      "|    policyGradLoss     | -0.00664   |\n",
      "|    value_loss         | 1.92       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 817          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 60           |\n",
      "|    total_timesteps    | 39370752     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0107492935 |\n",
      "|    entropy_loss       | -1.7         |\n",
      "|    explained_variance | 0.988        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.409        |\n",
      "|    mean_step_reward   | 0.3679939    |\n",
      "|    n_updates          | 19220        |\n",
      "|    policyGradLoss     | -0.00691     |\n",
      "|    value_loss         | 1.7          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 39378944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011571571 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.86        |\n",
      "|    mean_step_reward   | 0.45043817  |\n",
      "|    n_updates          | 19224       |\n",
      "|    policyGradLoss     | -0.0065     |\n",
      "|    value_loss         | 1.76        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 39387136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016304586 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.489       |\n",
      "|    mean_step_reward   | 0.4675956   |\n",
      "|    n_updates          | 19228       |\n",
      "|    policyGradLoss     | -0.00562    |\n",
      "|    value_loss         | 1.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 39395328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010899655 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.801       |\n",
      "|    mean_step_reward   | 0.34868956  |\n",
      "|    n_updates          | 19232       |\n",
      "|    policyGradLoss     | -0.00395    |\n",
      "|    value_loss         | 2.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 39403520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009721217 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.687       |\n",
      "|    mean_step_reward   | 0.41664615  |\n",
      "|    n_updates          | 19236       |\n",
      "|    policyGradLoss     | -0.00624    |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 39411712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012743468 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.951       |\n",
      "|    mean_step_reward   | 0.37290937  |\n",
      "|    n_updates          | 19240       |\n",
      "|    policyGradLoss     | -0.00297    |\n",
      "|    value_loss         | 3.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 39419904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013254978 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.42        |\n",
      "|    mean_step_reward   | 0.37428945  |\n",
      "|    n_updates          | 19244       |\n",
      "|    policyGradLoss     | -0.00549    |\n",
      "|    value_loss         | 2.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 39428096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011859847 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.744       |\n",
      "|    mean_step_reward   | 0.37329495  |\n",
      "|    n_updates          | 19248       |\n",
      "|    policyGradLoss     | -0.00613    |\n",
      "|    value_loss         | 1.42        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 784          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 146          |\n",
      "|    total_timesteps    | 39436288     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0138462875 |\n",
      "|    entropy_loss       | -1.66        |\n",
      "|    explained_variance | 0.986        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.812        |\n",
      "|    mean_step_reward   | 0.3566823    |\n",
      "|    n_updates          | 19252        |\n",
      "|    policyGradLoss     | -0.00611     |\n",
      "|    value_loss         | 1.93         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 39444480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012941101 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.59        |\n",
      "|    mean_step_reward   | 0.41289926  |\n",
      "|    n_updates          | 19256       |\n",
      "|    policyGradLoss     | -0.00257    |\n",
      "|    value_loss         | 2.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 39452672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014872907 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.644       |\n",
      "|    mean_step_reward   | 0.38052446  |\n",
      "|    n_updates          | 19260       |\n",
      "|    policyGradLoss     | -0.00245    |\n",
      "|    value_loss         | 2.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 39460864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014748212 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.82        |\n",
      "|    mean_step_reward   | 0.4148656   |\n",
      "|    n_updates          | 19264       |\n",
      "|    policyGradLoss     | -0.00731    |\n",
      "|    value_loss         | 1.75        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 39469056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017408526 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.302       |\n",
      "|    mean_step_reward   | 0.38951012  |\n",
      "|    n_updates          | 19268       |\n",
      "|    policyGradLoss     | -0.00678    |\n",
      "|    value_loss         | 1.9         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 39477248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012570759 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.863       |\n",
      "|    mean_step_reward   | 0.40808487  |\n",
      "|    n_updates          | 19272       |\n",
      "|    policyGradLoss     | -0.00262    |\n",
      "|    value_loss         | 2.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 39485440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017436627 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.486       |\n",
      "|    mean_step_reward   | 0.4435687   |\n",
      "|    n_updates          | 19276       |\n",
      "|    policyGradLoss     | -0.00738    |\n",
      "|    value_loss         | 1.22        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 220        |\n",
      "|    total_timesteps    | 39493632   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01382706 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.36       |\n",
      "|    mean_step_reward   | 0.36582816 |\n",
      "|    n_updates          | 19280      |\n",
      "|    policyGradLoss     | -0.00689   |\n",
      "|    value_loss         | 2.15       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 39501824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013159892 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.468       |\n",
      "|    mean_step_reward   | 0.45694488  |\n",
      "|    n_updates          | 19284       |\n",
      "|    policyGradLoss     | -0.00687    |\n",
      "|    value_loss         | 1.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 39510016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014474835 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.452       |\n",
      "|    mean_step_reward   | 0.4240601   |\n",
      "|    n_updates          | 19288       |\n",
      "|    policyGradLoss     | -0.00916    |\n",
      "|    value_loss         | 1.34        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 39518208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014984231 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.604       |\n",
      "|    mean_step_reward   | 0.35181004  |\n",
      "|    n_updates          | 19292       |\n",
      "|    policyGradLoss     | -0.00693    |\n",
      "|    value_loss         | 1.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 39526400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013302666 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.395       |\n",
      "|    mean_step_reward   | 0.43465832  |\n",
      "|    n_updates          | 19296       |\n",
      "|    policyGradLoss     | -0.00633    |\n",
      "|    value_loss         | 1.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 39534592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012515912 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.2         |\n",
      "|    mean_step_reward   | 0.4010002   |\n",
      "|    n_updates          | 19300       |\n",
      "|    policyGradLoss     | -0.00758    |\n",
      "|    value_loss         | 1.92        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 39542784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009771744 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.01        |\n",
      "|    mean_step_reward   | 0.41600722  |\n",
      "|    n_updates          | 19304       |\n",
      "|    policyGradLoss     | 0.000572    |\n",
      "|    value_loss         | 2.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 39550976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012619564 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.711       |\n",
      "|    mean_step_reward   | 0.41737622  |\n",
      "|    n_updates          | 19308       |\n",
      "|    policyGradLoss     | -0.00269    |\n",
      "|    value_loss         | 4.95        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 775        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 306        |\n",
      "|    total_timesteps    | 39559168   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01448733 |\n",
      "|    entropy_loss       | -1.63      |\n",
      "|    explained_variance | 0.99       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.523      |\n",
      "|    mean_step_reward   | 0.40988207 |\n",
      "|    n_updates          | 19312      |\n",
      "|    policyGradLoss     | -0.00777   |\n",
      "|    value_loss         | 1.45       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 775        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 316        |\n",
      "|    total_timesteps    | 39567360   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01562873 |\n",
      "|    entropy_loss       | -1.6       |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.543      |\n",
      "|    mean_step_reward   | 0.42622274 |\n",
      "|    n_updates          | 19316      |\n",
      "|    policyGradLoss     | -0.00611   |\n",
      "|    value_loss         | 1.34       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 775          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 327          |\n",
      "|    total_timesteps    | 39575552     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0116527565 |\n",
      "|    entropy_loss       | -1.7         |\n",
      "|    explained_variance | 0.982        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.753        |\n",
      "|    mean_step_reward   | 0.38121498   |\n",
      "|    n_updates          | 19320        |\n",
      "|    policyGradLoss     | -0.00274     |\n",
      "|    value_loss         | 2.53         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 39583744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026965786 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.314       |\n",
      "|    mean_step_reward   | 0.41154492  |\n",
      "|    n_updates          | 19324       |\n",
      "|    policyGradLoss     | -0.0101     |\n",
      "|    value_loss         | 0.93        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_150.zip\n",
      "[EVAL] Mean Return: 542.874, Best Return: 549.541\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_150_542.87.mp4\n",
      "\n",
      "=== Round 152 | Learn 262144 steps (Total trained: 39583744) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1161     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 39591936 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 915         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 39600128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026770497 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.112       |\n",
      "|    mean_step_reward   | 0.42494202  |\n",
      "|    n_updates          | 19332       |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.567       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 861        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 39608320   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01656573 |\n",
      "|    entropy_loss       | -1.66      |\n",
      "|    explained_variance | 0.99       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.668      |\n",
      "|    mean_step_reward   | 0.38550532 |\n",
      "|    n_updates          | 19336      |\n",
      "|    policyGradLoss     | -0.00769   |\n",
      "|    value_loss         | 1.79       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 39616512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015671644 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.599       |\n",
      "|    mean_step_reward   | 0.42527825  |\n",
      "|    n_updates          | 19340       |\n",
      "|    policyGradLoss     | 0.00106     |\n",
      "|    value_loss         | 4.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 39624704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012062242 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.01        |\n",
      "|    mean_step_reward   | 0.4429528   |\n",
      "|    n_updates          | 19344       |\n",
      "|    policyGradLoss     | -0.00394    |\n",
      "|    value_loss         | 1.72        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 815        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 39632896   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01159753 |\n",
      "|    entropy_loss       | -1.62      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.546      |\n",
      "|    mean_step_reward   | 0.41105938 |\n",
      "|    n_updates          | 19348      |\n",
      "|    policyGradLoss     | -0.00616   |\n",
      "|    value_loss         | 1.68       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 39641088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019915272 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.426       |\n",
      "|    mean_step_reward   | 0.426467    |\n",
      "|    n_updates          | 19352       |\n",
      "|    policyGradLoss     | -0.00901    |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 39649280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016479773 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.4         |\n",
      "|    mean_step_reward   | 0.4046573   |\n",
      "|    n_updates          | 19356       |\n",
      "|    policyGradLoss     | -0.00582    |\n",
      "|    value_loss         | 1.65        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 796        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 92         |\n",
      "|    total_timesteps    | 39657472   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01645606 |\n",
      "|    entropy_loss       | -1.6       |\n",
      "|    explained_variance | 0.993      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.183      |\n",
      "|    mean_step_reward   | 0.47713712 |\n",
      "|    n_updates          | 19360      |\n",
      "|    policyGradLoss     | -0.0056    |\n",
      "|    value_loss         | 1.2        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 39665664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012706065 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.591       |\n",
      "|    mean_step_reward   | 0.41365618  |\n",
      "|    n_updates          | 19364       |\n",
      "|    policyGradLoss     | -0.00726    |\n",
      "|    value_loss         | 2           |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 788        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 114        |\n",
      "|    total_timesteps    | 39673856   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01758572 |\n",
      "|    entropy_loss       | -1.6       |\n",
      "|    explained_variance | 0.992      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.233      |\n",
      "|    mean_step_reward   | 0.46961737 |\n",
      "|    n_updates          | 19368      |\n",
      "|    policyGradLoss     | -0.0107    |\n",
      "|    value_loss         | 1.33       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 39682048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012283451 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.177       |\n",
      "|    mean_step_reward   | 0.4112311   |\n",
      "|    n_updates          | 19372       |\n",
      "|    policyGradLoss     | -0.0065     |\n",
      "|    value_loss         | 1.66        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 39690240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010558164 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.459       |\n",
      "|    mean_step_reward   | 0.40992588  |\n",
      "|    n_updates          | 19376       |\n",
      "|    policyGradLoss     | -0.00373    |\n",
      "|    value_loss         | 2.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 39698432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016292581 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.681       |\n",
      "|    mean_step_reward   | 0.41448614  |\n",
      "|    n_updates          | 19380       |\n",
      "|    policyGradLoss     | -0.0066     |\n",
      "|    value_loss         | 1.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 39706624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012731697 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.641       |\n",
      "|    mean_step_reward   | 0.37980556  |\n",
      "|    n_updates          | 19384       |\n",
      "|    policyGradLoss     | -0.00467    |\n",
      "|    value_loss         | 1.61        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 39714816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015704442 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.603       |\n",
      "|    mean_step_reward   | 0.4466058   |\n",
      "|    n_updates          | 19388       |\n",
      "|    policyGradLoss     | -0.00603    |\n",
      "|    value_loss         | 1.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 39723008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013697986 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.819       |\n",
      "|    mean_step_reward   | 0.4016897   |\n",
      "|    n_updates          | 19392       |\n",
      "|    policyGradLoss     | -0.00551    |\n",
      "|    value_loss         | 1.92        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 780        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 188        |\n",
      "|    total_timesteps    | 39731200   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01811853 |\n",
      "|    entropy_loss       | -1.62      |\n",
      "|    explained_variance | 0.993      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.194      |\n",
      "|    mean_step_reward   | 0.45523572 |\n",
      "|    n_updates          | 19396      |\n",
      "|    policyGradLoss     | -0.00532   |\n",
      "|    value_loss         | 1.19       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 39739392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013661248 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.926       |\n",
      "|    mean_step_reward   | 0.3327068   |\n",
      "|    n_updates          | 19400       |\n",
      "|    policyGradLoss     | -0.00622    |\n",
      "|    value_loss         | 1.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 39747584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015698997 |\n",
      "|    entropy_loss       | -1.56       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0761      |\n",
      "|    mean_step_reward   | 0.45419076  |\n",
      "|    n_updates          | 19404       |\n",
      "|    policyGradLoss     | -0.00658    |\n",
      "|    value_loss         | 0.971       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 39755776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010255579 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.488       |\n",
      "|    mean_step_reward   | 0.4157552   |\n",
      "|    n_updates          | 19408       |\n",
      "|    policyGradLoss     | -0.00442    |\n",
      "|    value_loss         | 1.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 39763968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015378209 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.937       |\n",
      "|    mean_step_reward   | 0.43019512  |\n",
      "|    n_updates          | 19412       |\n",
      "|    policyGradLoss     | -0.00571    |\n",
      "|    value_loss         | 1.93        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 39772160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013877083 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.318       |\n",
      "|    mean_step_reward   | 0.4564078   |\n",
      "|    n_updates          | 19416       |\n",
      "|    policyGradLoss     | -0.00509    |\n",
      "|    value_loss         | 2.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 39780352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017055163 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.711       |\n",
      "|    mean_step_reward   | 0.37397867  |\n",
      "|    n_updates          | 19420       |\n",
      "|    policyGradLoss     | -0.0043     |\n",
      "|    value_loss         | 1.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 39788544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029249629 |\n",
      "|    entropy_loss       | -1.55       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.686       |\n",
      "|    mean_step_reward   | 0.43552554  |\n",
      "|    n_updates          | 19424       |\n",
      "|    policyGradLoss     | -0.00786    |\n",
      "|    value_loss         | 1.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 39796736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018109659 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.657       |\n",
      "|    mean_step_reward   | 0.3406309   |\n",
      "|    n_updates          | 19428       |\n",
      "|    policyGradLoss     | -0.00736    |\n",
      "|    value_loss         | 1.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 39804928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014941928 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.795       |\n",
      "|    mean_step_reward   | 0.37193462  |\n",
      "|    n_updates          | 19432       |\n",
      "|    policyGradLoss     | -0.00789    |\n",
      "|    value_loss         | 1.09        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 39813120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011664339 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.06        |\n",
      "|    mean_step_reward   | 0.39120066  |\n",
      "|    n_updates          | 19436       |\n",
      "|    policyGradLoss     | -0.00235    |\n",
      "|    value_loss         | 2.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 39821312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014360705 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.7         |\n",
      "|    mean_step_reward   | 0.35177895  |\n",
      "|    n_updates          | 19440       |\n",
      "|    policyGradLoss     | -0.00199    |\n",
      "|    value_loss         | 4.9         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 39829504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010781032 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.613       |\n",
      "|    mean_step_reward   | 0.4286454   |\n",
      "|    n_updates          | 19444       |\n",
      "|    policyGradLoss     | -0.00613    |\n",
      "|    value_loss         | 1.09        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 39837696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011547861 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.243       |\n",
      "|    mean_step_reward   | 0.41541353  |\n",
      "|    n_updates          | 19448       |\n",
      "|    policyGradLoss     | -0.00841    |\n",
      "|    value_loss         | 1.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 39845888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016153403 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.25        |\n",
      "|    mean_step_reward   | 0.45314702  |\n",
      "|    n_updates          | 19452       |\n",
      "|    policyGradLoss     | -0.006      |\n",
      "|    value_loss         | 1.71        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_151.zip\n",
      "[EVAL] Mean Return: 543.280, Best Return: 548.613\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_151_543.28.mp4\n",
      "\n",
      "=== Round 153 | Learn 262144 steps (Total trained: 39845888) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1106     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 39854080 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 896         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 39862272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012563874 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.96        |\n",
      "|    mean_step_reward   | 0.400704    |\n",
      "|    n_updates          | 19460       |\n",
      "|    policyGradLoss     | -0.00798    |\n",
      "|    value_loss         | 1.92        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 846         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 39870464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017862238 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.15        |\n",
      "|    mean_step_reward   | 0.4115025   |\n",
      "|    n_updates          | 19464       |\n",
      "|    policyGradLoss     | -0.00674    |\n",
      "|    value_loss         | 1.63        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 827        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 39         |\n",
      "|    total_timesteps    | 39878656   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01642611 |\n",
      "|    entropy_loss       | -1.6       |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.537      |\n",
      "|    mean_step_reward   | 0.46529418 |\n",
      "|    n_updates          | 19468      |\n",
      "|    policyGradLoss     | -0.00714   |\n",
      "|    value_loss         | 1.51       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 39886848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010344894 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.21        |\n",
      "|    mean_step_reward   | 0.40731305  |\n",
      "|    n_updates          | 19472       |\n",
      "|    policyGradLoss     | -0.00216    |\n",
      "|    value_loss         | 2.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 39895040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010909159 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.646       |\n",
      "|    mean_step_reward   | 0.45292243  |\n",
      "|    n_updates          | 19476       |\n",
      "|    policyGradLoss     | -0.00237    |\n",
      "|    value_loss         | 1.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 39903232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010753455 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.663       |\n",
      "|    mean_step_reward   | 0.41999096  |\n",
      "|    n_updates          | 19480       |\n",
      "|    policyGradLoss     | -0.00433    |\n",
      "|    value_loss         | 1.88        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 39911424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014309039 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.539       |\n",
      "|    mean_step_reward   | 0.41798726  |\n",
      "|    n_updates          | 19484       |\n",
      "|    policyGradLoss     | -0.00789    |\n",
      "|    value_loss         | 1.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 39919616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009928899 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.891       |\n",
      "|    mean_step_reward   | 0.43245035  |\n",
      "|    n_updates          | 19488       |\n",
      "|    policyGradLoss     | -0.00638    |\n",
      "|    value_loss         | 1.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 39927808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013971578 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.19        |\n",
      "|    mean_step_reward   | 0.41720518  |\n",
      "|    n_updates          | 19492       |\n",
      "|    policyGradLoss     | 0.000679    |\n",
      "|    value_loss         | 1.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 39936000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017222479 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.347       |\n",
      "|    mean_step_reward   | 0.44328254  |\n",
      "|    n_updates          | 19496       |\n",
      "|    policyGradLoss     | -0.0117     |\n",
      "|    value_loss         | 1.21        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 785          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 125          |\n",
      "|    total_timesteps    | 39944192     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0115614645 |\n",
      "|    entropy_loss       | -1.7         |\n",
      "|    explained_variance | 0.984        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.06         |\n",
      "|    mean_step_reward   | 0.33937153   |\n",
      "|    n_updates          | 19500        |\n",
      "|    policyGradLoss     | -0.00438     |\n",
      "|    value_loss         | 2.23         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 39952384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019428015 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.35        |\n",
      "|    mean_step_reward   | 0.40564424  |\n",
      "|    n_updates          | 19504       |\n",
      "|    policyGradLoss     | -0.00198    |\n",
      "|    value_loss         | 2.46        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 39960576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010538032 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.02        |\n",
      "|    mean_step_reward   | 0.40940636  |\n",
      "|    n_updates          | 19508       |\n",
      "|    policyGradLoss     | -0.00693    |\n",
      "|    value_loss         | 1.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 39968768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016621701 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.729       |\n",
      "|    mean_step_reward   | 0.4019973   |\n",
      "|    n_updates          | 19512       |\n",
      "|    policyGradLoss     | -0.00822    |\n",
      "|    value_loss         | 1.62        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 783        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 167        |\n",
      "|    total_timesteps    | 39976960   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01966455 |\n",
      "|    entropy_loss       | -1.63      |\n",
      "|    explained_variance | 0.988      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.31       |\n",
      "|    mean_step_reward   | 0.3242243  |\n",
      "|    n_updates          | 19516      |\n",
      "|    policyGradLoss     | -0.00976   |\n",
      "|    value_loss         | 1.32       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 39985152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016240634 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.924       |\n",
      "|    mean_step_reward   | 0.39246756  |\n",
      "|    n_updates          | 19520       |\n",
      "|    policyGradLoss     | -0.00817    |\n",
      "|    value_loss         | 1.55        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 39993344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015932966 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.161       |\n",
      "|    mean_step_reward   | 0.3484221   |\n",
      "|    n_updates          | 19524       |\n",
      "|    policyGradLoss     | -0.00801    |\n",
      "|    value_loss         | 0.981       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 782        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 198        |\n",
      "|    total_timesteps    | 40001536   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01749375 |\n",
      "|    entropy_loss       | -1.6       |\n",
      "|    explained_variance | 0.992      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.08       |\n",
      "|    mean_step_reward   | 0.49164808 |\n",
      "|    n_updates          | 19528      |\n",
      "|    policyGradLoss     | -0.0056    |\n",
      "|    value_loss         | 1.42       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 40009728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012161901 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 3.78        |\n",
      "|    mean_step_reward   | 0.40749675  |\n",
      "|    n_updates          | 19532       |\n",
      "|    policyGradLoss     | -0.00276    |\n",
      "|    value_loss         | 6.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 40017920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018043198 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.541       |\n",
      "|    mean_step_reward   | 0.44357225  |\n",
      "|    n_updates          | 19536       |\n",
      "|    policyGradLoss     | -0.00299    |\n",
      "|    value_loss         | 1.64        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 40026112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014438317 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.07        |\n",
      "|    mean_step_reward   | 0.4088763   |\n",
      "|    n_updates          | 19540       |\n",
      "|    policyGradLoss     | -0.00657    |\n",
      "|    value_loss         | 1.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 40034304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011549015 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.651       |\n",
      "|    mean_step_reward   | 0.4524696   |\n",
      "|    n_updates          | 19544       |\n",
      "|    policyGradLoss     | -0.00509    |\n",
      "|    value_loss         | 1.48        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 780        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 251        |\n",
      "|    total_timesteps    | 40042496   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01425866 |\n",
      "|    entropy_loss       | -1.61      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.04       |\n",
      "|    mean_step_reward   | 0.43602413 |\n",
      "|    n_updates          | 19548      |\n",
      "|    policyGradLoss     | -0.0066    |\n",
      "|    value_loss         | 1.55       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 40050688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012884436 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.534       |\n",
      "|    mean_step_reward   | 0.39720377  |\n",
      "|    n_updates          | 19552       |\n",
      "|    policyGradLoss     | -0.00594    |\n",
      "|    value_loss         | 1.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 40058880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015893925 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.828       |\n",
      "|    mean_step_reward   | 0.4313911   |\n",
      "|    n_updates          | 19556       |\n",
      "|    policyGradLoss     | -0.00673    |\n",
      "|    value_loss         | 1.5         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 40067072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010987422 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.17        |\n",
      "|    mean_step_reward   | 0.4122265   |\n",
      "|    n_updates          | 19560       |\n",
      "|    policyGradLoss     | -0.00736    |\n",
      "|    value_loss         | 1.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 40075264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014972152 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.351       |\n",
      "|    mean_step_reward   | 0.40033564  |\n",
      "|    n_updates          | 19564       |\n",
      "|    policyGradLoss     | -0.00704    |\n",
      "|    value_loss         | 1.74        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 40083456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016266897 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.699       |\n",
      "|    mean_step_reward   | 0.3718189   |\n",
      "|    n_updates          | 19568       |\n",
      "|    policyGradLoss     | -0.0109     |\n",
      "|    value_loss         | 1.06        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 316        |\n",
      "|    total_timesteps    | 40091648   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0154308  |\n",
      "|    entropy_loss       | -1.63      |\n",
      "|    explained_variance | 0.99       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.01       |\n",
      "|    mean_step_reward   | 0.40641478 |\n",
      "|    n_updates          | 19572      |\n",
      "|    policyGradLoss     | -0.00652   |\n",
      "|    value_loss         | 1.53       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 326        |\n",
      "|    total_timesteps    | 40099840   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01845926 |\n",
      "|    entropy_loss       | -1.62      |\n",
      "|    explained_variance | 0.967      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.556      |\n",
      "|    mean_step_reward   | 0.40980488 |\n",
      "|    n_updates          | 19576      |\n",
      "|    policyGradLoss     | -0.00445   |\n",
      "|    value_loss         | 2.78       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 40108032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011547968 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.526       |\n",
      "|    mean_step_reward   | 0.39564922  |\n",
      "|    n_updates          | 19580       |\n",
      "|    policyGradLoss     | -0.00452    |\n",
      "|    value_loss         | 2.11        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_152.zip\n",
      "[EVAL] Mean Return: 536.492, Best Return: 543.159\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_152_536.49.mp4\n",
      "\n",
      "=== Round 154 | Learn 262144 steps (Total trained: 40108032) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1098     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 40116224 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 922        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 40124416   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01371626 |\n",
      "|    entropy_loss       | -1.6       |\n",
      "|    explained_variance | 0.984      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.677      |\n",
      "|    mean_step_reward   | 0.37658763 |\n",
      "|    n_updates          | 19588      |\n",
      "|    policyGradLoss     | -0.00569   |\n",
      "|    value_loss         | 1.52       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 867         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 40132608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014998716 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.267       |\n",
      "|    mean_step_reward   | 0.35184282  |\n",
      "|    n_updates          | 19592       |\n",
      "|    policyGradLoss     | -0.00319    |\n",
      "|    value_loss         | 1.86        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 839         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 40140800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012759125 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.922       |\n",
      "|    mean_step_reward   | 0.3729458   |\n",
      "|    n_updates          | 19596       |\n",
      "|    policyGradLoss     | -0.00498    |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 831         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 40148992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019399077 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.14        |\n",
      "|    mean_step_reward   | 0.3545296   |\n",
      "|    n_updates          | 19600       |\n",
      "|    policyGradLoss     | -0.00896    |\n",
      "|    value_loss         | 1.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 40157184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015639784 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.307       |\n",
      "|    mean_step_reward   | 0.3824998   |\n",
      "|    n_updates          | 19604       |\n",
      "|    policyGradLoss     | -0.00558    |\n",
      "|    value_loss         | 1.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 40165376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015669577 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 2.91        |\n",
      "|    mean_step_reward   | 0.38953054  |\n",
      "|    n_updates          | 19608       |\n",
      "|    policyGradLoss     | -0.00102    |\n",
      "|    value_loss         | 4.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 40173568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013375748 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.659       |\n",
      "|    mean_step_reward   | 0.39447984  |\n",
      "|    n_updates          | 19612       |\n",
      "|    policyGradLoss     | -0.00689    |\n",
      "|    value_loss         | 1.61        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 40181760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016788788 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.28        |\n",
      "|    mean_step_reward   | 0.39627802  |\n",
      "|    n_updates          | 19616       |\n",
      "|    policyGradLoss     | -0.00984    |\n",
      "|    value_loss         | 1.23        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 796        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 102        |\n",
      "|    total_timesteps    | 40189952   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01494544 |\n",
      "|    entropy_loss       | -1.61      |\n",
      "|    explained_variance | 0.95       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.27       |\n",
      "|    mean_step_reward   | 0.39834714 |\n",
      "|    n_updates          | 19620      |\n",
      "|    policyGradLoss     | 0.0038     |\n",
      "|    value_loss         | 4.03       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 792          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 113          |\n",
      "|    total_timesteps    | 40198144     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0135280145 |\n",
      "|    entropy_loss       | -1.65        |\n",
      "|    explained_variance | 0.987        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.94         |\n",
      "|    mean_step_reward   | 0.36675805   |\n",
      "|    n_updates          | 19624        |\n",
      "|    policyGradLoss     | -0.00766     |\n",
      "|    value_loss         | 1.86         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 40206336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026508257 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.191       |\n",
      "|    mean_step_reward   | 0.38265803  |\n",
      "|    n_updates          | 19628       |\n",
      "|    policyGradLoss     | -0.0078     |\n",
      "|    value_loss         | 0.916       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 40214528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011191751 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.61        |\n",
      "|    mean_step_reward   | 0.4403491   |\n",
      "|    n_updates          | 19632       |\n",
      "|    policyGradLoss     | -0.00656    |\n",
      "|    value_loss         | 1.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 40222720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012090111 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.945       |\n",
      "|    mean_step_reward   | 0.40066427  |\n",
      "|    n_updates          | 19636       |\n",
      "|    policyGradLoss     | -0.00312    |\n",
      "|    value_loss         | 2.11        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 40230912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013742741 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.977       |\n",
      "|    mean_step_reward   | 0.46401826  |\n",
      "|    n_updates          | 19640       |\n",
      "|    policyGradLoss     | -0.00747    |\n",
      "|    value_loss         | 1.35        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 785          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 166          |\n",
      "|    total_timesteps    | 40239104     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0109878145 |\n",
      "|    entropy_loss       | -1.66        |\n",
      "|    explained_variance | 0.986        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.406        |\n",
      "|    mean_step_reward   | 0.36503762   |\n",
      "|    n_updates          | 19644        |\n",
      "|    policyGradLoss     | -0.00293     |\n",
      "|    value_loss         | 1.92         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 40247296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016813513 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.277       |\n",
      "|    mean_step_reward   | 0.43221498  |\n",
      "|    n_updates          | 19648       |\n",
      "|    policyGradLoss     | -0.00577    |\n",
      "|    value_loss         | 0.871       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 40255488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012295315 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.336       |\n",
      "|    mean_step_reward   | 0.38007477  |\n",
      "|    n_updates          | 19652       |\n",
      "|    policyGradLoss     | -0.00582    |\n",
      "|    value_loss         | 1.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 40263680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011884682 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.713       |\n",
      "|    mean_step_reward   | 0.45967972  |\n",
      "|    n_updates          | 19656       |\n",
      "|    policyGradLoss     | -0.00255    |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 785        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 208        |\n",
      "|    total_timesteps    | 40271872   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01301217 |\n",
      "|    entropy_loss       | -1.66      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.319      |\n",
      "|    mean_step_reward   | 0.40131253 |\n",
      "|    n_updates          | 19660      |\n",
      "|    policyGradLoss     | -0.00696   |\n",
      "|    value_loss         | 1.45       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 218         |\n",
      "|    total_timesteps    | 40280064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016615085 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.22        |\n",
      "|    mean_step_reward   | 0.4281155   |\n",
      "|    n_updates          | 19664       |\n",
      "|    policyGradLoss     | -0.00719    |\n",
      "|    value_loss         | 1.72        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 40288256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019465815 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.256       |\n",
      "|    mean_step_reward   | 0.40924972  |\n",
      "|    n_updates          | 19668       |\n",
      "|    policyGradLoss     | -0.00137    |\n",
      "|    value_loss         | 2.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 239         |\n",
      "|    total_timesteps    | 40296448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012073205 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.642       |\n",
      "|    mean_step_reward   | 0.39840063  |\n",
      "|    n_updates          | 19672       |\n",
      "|    policyGradLoss     | -0.00577    |\n",
      "|    value_loss         | 1.67        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 783        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 250        |\n",
      "|    total_timesteps    | 40304640   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01457438 |\n",
      "|    entropy_loss       | -1.61      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.871      |\n",
      "|    mean_step_reward   | 0.3976485  |\n",
      "|    n_updates          | 19676      |\n",
      "|    policyGradLoss     | -0.00791   |\n",
      "|    value_loss         | 1.58       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 40312832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013422482 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.737       |\n",
      "|    mean_step_reward   | 0.400369    |\n",
      "|    n_updates          | 19680       |\n",
      "|    policyGradLoss     | -0.00622    |\n",
      "|    value_loss         | 1.82        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 40321024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013919765 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.384       |\n",
      "|    mean_step_reward   | 0.4076223   |\n",
      "|    n_updates          | 19684       |\n",
      "|    policyGradLoss     | -0.00553    |\n",
      "|    value_loss         | 1.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 40329216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007532123 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.761       |\n",
      "|    mean_step_reward   | 0.43080163  |\n",
      "|    n_updates          | 19688       |\n",
      "|    policyGradLoss     | -0.00468    |\n",
      "|    value_loss         | 1.59        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 40337408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008949481 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.1         |\n",
      "|    mean_step_reward   | 0.39522356  |\n",
      "|    n_updates          | 19692       |\n",
      "|    policyGradLoss     | -0.00243    |\n",
      "|    value_loss         | 2.04        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 782          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 303          |\n",
      "|    total_timesteps    | 40345600     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0119424425 |\n",
      "|    entropy_loss       | -1.63        |\n",
      "|    explained_variance | 0.979        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.232        |\n",
      "|    mean_step_reward   | 0.4034077    |\n",
      "|    n_updates          | 19696        |\n",
      "|    policyGradLoss     | -0.00505     |\n",
      "|    value_loss         | 2.05         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 314         |\n",
      "|    total_timesteps    | 40353792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012697334 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.608       |\n",
      "|    mean_step_reward   | 0.45163444  |\n",
      "|    n_updates          | 19700       |\n",
      "|    policyGradLoss     | -0.00422    |\n",
      "|    value_loss         | 1.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 324         |\n",
      "|    total_timesteps    | 40361984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013527705 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.703       |\n",
      "|    mean_step_reward   | 0.45043626  |\n",
      "|    n_updates          | 19704       |\n",
      "|    policyGradLoss     | -0.00554    |\n",
      "|    value_loss         | 1.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 335         |\n",
      "|    total_timesteps    | 40370176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008274196 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.678       |\n",
      "|    mean_step_reward   | 0.41977936  |\n",
      "|    n_updates          | 19708       |\n",
      "|    policyGradLoss     | -0.00355    |\n",
      "|    value_loss         | 1.71        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_153.zip\n",
      "[EVAL] Mean Return: 541.615, Best Return: 548.949\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_153_541.62.mp4\n",
      "\n",
      "=== Round 155 | Learn 262144 steps (Total trained: 40370176) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1124     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 40378368 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 920         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 40386560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015083667 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.352       |\n",
      "|    mean_step_reward   | 0.45787758  |\n",
      "|    n_updates          | 19716       |\n",
      "|    policyGradLoss     | -0.00447    |\n",
      "|    value_loss         | 1.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 865         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 40394752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012457442 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.635       |\n",
      "|    mean_step_reward   | 0.39618644  |\n",
      "|    n_updates          | 19720       |\n",
      "|    policyGradLoss     | -0.00733    |\n",
      "|    value_loss         | 1.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 840         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 40402944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011452546 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.965       |\n",
      "|    mean_step_reward   | 0.42235985  |\n",
      "|    n_updates          | 19724       |\n",
      "|    policyGradLoss     | -0.00529    |\n",
      "|    value_loss         | 1.88        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 830         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 40411136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013303113 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.29        |\n",
      "|    mean_step_reward   | 0.41309613  |\n",
      "|    n_updates          | 19728       |\n",
      "|    policyGradLoss     | -0.00628    |\n",
      "|    value_loss         | 1.72        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 819        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 59         |\n",
      "|    total_timesteps    | 40419328   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01724261 |\n",
      "|    entropy_loss       | -1.62      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.76       |\n",
      "|    mean_step_reward   | 0.40553367 |\n",
      "|    n_updates          | 19732      |\n",
      "|    policyGradLoss     | -0.00575   |\n",
      "|    value_loss         | 1.36       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 40427520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016533967 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.355       |\n",
      "|    mean_step_reward   | 0.41572577  |\n",
      "|    n_updates          | 19736       |\n",
      "|    policyGradLoss     | -0.00588    |\n",
      "|    value_loss         | 1.82        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 40435712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016078765 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.33        |\n",
      "|    mean_step_reward   | 0.43233985  |\n",
      "|    n_updates          | 19740       |\n",
      "|    policyGradLoss     | -0.00288    |\n",
      "|    value_loss         | 4.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 40443904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011839582 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.532       |\n",
      "|    mean_step_reward   | 0.41607118  |\n",
      "|    n_updates          | 19744       |\n",
      "|    policyGradLoss     | -0.00501    |\n",
      "|    value_loss         | 2.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 40452096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013433945 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.999       |\n",
      "|    mean_step_reward   | 0.4245711   |\n",
      "|    n_updates          | 19748       |\n",
      "|    policyGradLoss     | -0.00626    |\n",
      "|    value_loss         | 1.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 40460288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016882574 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.373       |\n",
      "|    mean_step_reward   | 0.4516      |\n",
      "|    n_updates          | 19752       |\n",
      "|    policyGradLoss     | -0.00598    |\n",
      "|    value_loss         | 1.43        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 40468480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015981004 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.812       |\n",
      "|    mean_step_reward   | 0.43268695  |\n",
      "|    n_updates          | 19756       |\n",
      "|    policyGradLoss     | -0.00522    |\n",
      "|    value_loss         | 1.89        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 40476672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014120825 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.425       |\n",
      "|    mean_step_reward   | 0.41650456  |\n",
      "|    n_updates          | 19760       |\n",
      "|    policyGradLoss     | -0.00528    |\n",
      "|    value_loss         | 1.81        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 787        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 145        |\n",
      "|    total_timesteps    | 40484864   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01749796 |\n",
      "|    entropy_loss       | -1.6       |\n",
      "|    explained_variance | 0.984      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.415      |\n",
      "|    mean_step_reward   | 0.41112256 |\n",
      "|    n_updates          | 19764      |\n",
      "|    policyGradLoss     | -0.0034    |\n",
      "|    value_loss         | 1.92       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 40493056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016687717 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.586       |\n",
      "|    mean_step_reward   | 0.4317227   |\n",
      "|    n_updates          | 19768       |\n",
      "|    policyGradLoss     | -0.00799    |\n",
      "|    value_loss         | 1.66        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 40501248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013194479 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.349       |\n",
      "|    mean_step_reward   | 0.3724832   |\n",
      "|    n_updates          | 19772       |\n",
      "|    policyGradLoss     | -0.00694    |\n",
      "|    value_loss         | 1.66        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 40509440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017978104 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.631       |\n",
      "|    mean_step_reward   | 0.36878264  |\n",
      "|    n_updates          | 19776       |\n",
      "|    policyGradLoss     | -0.00817    |\n",
      "|    value_loss         | 1.24        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 784        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 188        |\n",
      "|    total_timesteps    | 40517632   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01620979 |\n",
      "|    entropy_loss       | -1.6       |\n",
      "|    explained_variance | 0.993      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.341      |\n",
      "|    mean_step_reward   | 0.42055845 |\n",
      "|    n_updates          | 19780      |\n",
      "|    policyGradLoss     | -0.008     |\n",
      "|    value_loss         | 1.01       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 40525824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016967364 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.555       |\n",
      "|    mean_step_reward   | 0.38825703  |\n",
      "|    n_updates          | 19784       |\n",
      "|    policyGradLoss     | -0.00279    |\n",
      "|    value_loss         | 2.92        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 40534016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017071309 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.708       |\n",
      "|    mean_step_reward   | 0.42226166  |\n",
      "|    n_updates          | 19788       |\n",
      "|    policyGradLoss     | -0.00517    |\n",
      "|    value_loss         | 1.5         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 40542208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011585718 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.588       |\n",
      "|    mean_step_reward   | 0.41630858  |\n",
      "|    n_updates          | 19792       |\n",
      "|    policyGradLoss     | -0.00549    |\n",
      "|    value_loss         | 1.52        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 40550400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016035464 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.25        |\n",
      "|    mean_step_reward   | 0.40256655  |\n",
      "|    n_updates          | 19796       |\n",
      "|    policyGradLoss     | -0.00822    |\n",
      "|    value_loss         | 1.82        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 781        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 240        |\n",
      "|    total_timesteps    | 40558592   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01583198 |\n",
      "|    entropy_loss       | -1.62      |\n",
      "|    explained_variance | 0.99       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.274      |\n",
      "|    mean_step_reward   | 0.39057326 |\n",
      "|    n_updates          | 19800      |\n",
      "|    policyGradLoss     | -0.00781   |\n",
      "|    value_loss         | 1.46       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 40566784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017903574 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.35        |\n",
      "|    mean_step_reward   | 0.39983803  |\n",
      "|    n_updates          | 19804       |\n",
      "|    policyGradLoss     | -0.00387    |\n",
      "|    value_loss         | 5.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 40574976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015927192 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.268       |\n",
      "|    mean_step_reward   | 0.39944282  |\n",
      "|    n_updates          | 19808       |\n",
      "|    policyGradLoss     | -0.007      |\n",
      "|    value_loss         | 1.65        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 40583168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020140978 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.19        |\n",
      "|    mean_step_reward   | 0.37002578  |\n",
      "|    n_updates          | 19812       |\n",
      "|    policyGradLoss     | 0.00225     |\n",
      "|    value_loss         | 4.46        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 40591360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017783178 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.988       |\n",
      "|    mean_step_reward   | 0.399463    |\n",
      "|    n_updates          | 19816       |\n",
      "|    policyGradLoss     | 0.000663    |\n",
      "|    value_loss         | 1.92        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 40599552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013672255 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.718       |\n",
      "|    mean_step_reward   | 0.40124464  |\n",
      "|    n_updates          | 19820       |\n",
      "|    policyGradLoss     | -0.00549    |\n",
      "|    value_loss         | 2.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 40607744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010735314 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.707       |\n",
      "|    mean_step_reward   | 0.36526233  |\n",
      "|    n_updates          | 19824       |\n",
      "|    policyGradLoss     | -0.00282    |\n",
      "|    value_loss         | 3.08        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 315        |\n",
      "|    total_timesteps    | 40615936   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01325855 |\n",
      "|    entropy_loss       | -1.61      |\n",
      "|    explained_variance | 0.986      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.434      |\n",
      "|    mean_step_reward   | 0.44699067 |\n",
      "|    n_updates          | 19828      |\n",
      "|    policyGradLoss     | -0.00208   |\n",
      "|    value_loss         | 1.3        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 40624128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019084409 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.935       |\n",
      "|    mean_step_reward   | 0.4257952   |\n",
      "|    n_updates          | 19832       |\n",
      "|    policyGradLoss     | -0.00495    |\n",
      "|    value_loss         | 1.64        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 40632320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014237246 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.64        |\n",
      "|    mean_step_reward   | 0.39265665  |\n",
      "|    n_updates          | 19836       |\n",
      "|    policyGradLoss     | -0.00147    |\n",
      "|    value_loss         | 1.71        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_154.zip\n",
      "[EVAL] Mean Return: 543.304, Best Return: 549.970\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_154_543.30.mp4\n",
      "\n",
      "=== Round 156 | Learn 262144 steps (Total trained: 40632320) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1088     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 40640512 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 901         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 40648704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013712841 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.12        |\n",
      "|    mean_step_reward   | 0.4292869   |\n",
      "|    n_updates          | 19844       |\n",
      "|    policyGradLoss     | -0.000461   |\n",
      "|    value_loss         | 4.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 853         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 40656896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014483917 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.22        |\n",
      "|    mean_step_reward   | 0.41765928  |\n",
      "|    n_updates          | 19848       |\n",
      "|    policyGradLoss     | -0.00707    |\n",
      "|    value_loss         | 1.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 838         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 40665088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011878058 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.774       |\n",
      "|    mean_step_reward   | 0.4362627   |\n",
      "|    n_updates          | 19852       |\n",
      "|    policyGradLoss     | -0.00591    |\n",
      "|    value_loss         | 1.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 823         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 40673280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014254119 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.237       |\n",
      "|    mean_step_reward   | 0.37255466  |\n",
      "|    n_updates          | 19856       |\n",
      "|    policyGradLoss     | -0.00556    |\n",
      "|    value_loss         | 1.97        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 40681472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013688043 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.296       |\n",
      "|    mean_step_reward   | 0.46229547  |\n",
      "|    n_updates          | 19860       |\n",
      "|    policyGradLoss     | -0.00683    |\n",
      "|    value_loss         | 1.06        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 811        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 70         |\n",
      "|    total_timesteps    | 40689664   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01028079 |\n",
      "|    entropy_loss       | -1.68      |\n",
      "|    explained_variance | 0.979      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.05       |\n",
      "|    mean_step_reward   | 0.32791406 |\n",
      "|    n_updates          | 19864      |\n",
      "|    policyGradLoss     | -0.00308   |\n",
      "|    value_loss         | 2.55       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 40697856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017114341 |\n",
      "|    entropy_loss       | -1.56       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.362       |\n",
      "|    mean_step_reward   | 0.3947458   |\n",
      "|    n_updates          | 19868       |\n",
      "|    policyGradLoss     | -0.00647    |\n",
      "|    value_loss         | 1.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 40706048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016925035 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.541       |\n",
      "|    mean_step_reward   | 0.2964843   |\n",
      "|    n_updates          | 19872       |\n",
      "|    policyGradLoss     | -0.00713    |\n",
      "|    value_loss         | 1.8         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 40714240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015636116 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.12        |\n",
      "|    mean_step_reward   | 0.3269005   |\n",
      "|    n_updates          | 19876       |\n",
      "|    policyGradLoss     | -0.00788    |\n",
      "|    value_loss         | 1.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 40722432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015081037 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.559       |\n",
      "|    mean_step_reward   | 0.37838235  |\n",
      "|    n_updates          | 19880       |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.993       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 40730624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014920773 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.715       |\n",
      "|    mean_step_reward   | 0.32184866  |\n",
      "|    n_updates          | 19884       |\n",
      "|    policyGradLoss     | -0.00387    |\n",
      "|    value_loss         | 1.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 40738816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021277452 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.245       |\n",
      "|    mean_step_reward   | 0.41595703  |\n",
      "|    n_updates          | 19888       |\n",
      "|    policyGradLoss     | -0.0078     |\n",
      "|    value_loss         | 0.995       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 40747008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011640359 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.601       |\n",
      "|    mean_step_reward   | 0.397048    |\n",
      "|    n_updates          | 19892       |\n",
      "|    policyGradLoss     | -0.00613    |\n",
      "|    value_loss         | 1.8         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 786        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 156        |\n",
      "|    total_timesteps    | 40755200   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01655039 |\n",
      "|    entropy_loss       | -1.6       |\n",
      "|    explained_variance | 0.99       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.305      |\n",
      "|    mean_step_reward   | 0.40774733 |\n",
      "|    n_updates          | 19896      |\n",
      "|    policyGradLoss     | -0.00843   |\n",
      "|    value_loss         | 1.36       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 40763392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013709555 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.382       |\n",
      "|    mean_step_reward   | 0.4318537   |\n",
      "|    n_updates          | 19900       |\n",
      "|    policyGradLoss     | -0.0022     |\n",
      "|    value_loss         | 2.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 40771584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015731582 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 2.17        |\n",
      "|    mean_step_reward   | 0.38109666  |\n",
      "|    n_updates          | 19904       |\n",
      "|    policyGradLoss     | -0.00183    |\n",
      "|    value_loss         | 5.65        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 782        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 188        |\n",
      "|    total_timesteps    | 40779776   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0142647  |\n",
      "|    entropy_loss       | -1.61      |\n",
      "|    explained_variance | 0.985      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.928      |\n",
      "|    mean_step_reward   | 0.42863172 |\n",
      "|    n_updates          | 19908      |\n",
      "|    policyGradLoss     | -0.00499   |\n",
      "|    value_loss         | 1.38       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 40787968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010024796 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.01        |\n",
      "|    mean_step_reward   | 0.38894957  |\n",
      "|    n_updates          | 19912       |\n",
      "|    policyGradLoss     | -0.0024     |\n",
      "|    value_loss         | 1.65        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 40796160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013873099 |\n",
      "|    entropy_loss       | -1.57       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.349       |\n",
      "|    mean_step_reward   | 0.43911633  |\n",
      "|    n_updates          | 19916       |\n",
      "|    policyGradLoss     | -0.00225    |\n",
      "|    value_loss         | 3.86        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 40804352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014236267 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.984       |\n",
      "|    mean_step_reward   | 0.43030876  |\n",
      "|    n_updates          | 19920       |\n",
      "|    policyGradLoss     | -0.00546    |\n",
      "|    value_loss         | 1.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 40812544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020166038 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.337       |\n",
      "|    mean_step_reward   | 0.4152792   |\n",
      "|    n_updates          | 19924       |\n",
      "|    policyGradLoss     | -0.00698    |\n",
      "|    value_loss         | 1.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 40820736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010360377 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.848       |\n",
      "|    mean_step_reward   | 0.4132933   |\n",
      "|    n_updates          | 19928       |\n",
      "|    policyGradLoss     | -0.00469    |\n",
      "|    value_loss         | 2.09        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 40828928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017480426 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0788      |\n",
      "|    mean_step_reward   | 0.34937355  |\n",
      "|    n_updates          | 19932       |\n",
      "|    policyGradLoss     | -0.00996    |\n",
      "|    value_loss         | 1.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 40837120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016602373 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.34        |\n",
      "|    mean_step_reward   | 0.3610685   |\n",
      "|    n_updates          | 19936       |\n",
      "|    policyGradLoss     | -0.00391    |\n",
      "|    value_loss         | 2.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 40845312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012679245 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.711       |\n",
      "|    mean_step_reward   | 0.38894075  |\n",
      "|    n_updates          | 19940       |\n",
      "|    policyGradLoss     | -0.00732    |\n",
      "|    value_loss         | 1.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 40853504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015764173 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.672       |\n",
      "|    mean_step_reward   | 0.37737828  |\n",
      "|    n_updates          | 19944       |\n",
      "|    policyGradLoss     | -0.00253    |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 40861696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008626318 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.927       |\n",
      "|    mean_step_reward   | 0.38026834  |\n",
      "|    n_updates          | 19948       |\n",
      "|    policyGradLoss     | -0.00169    |\n",
      "|    value_loss         | 1.95        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 40869888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014445309 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.566       |\n",
      "|    mean_step_reward   | 0.38938433  |\n",
      "|    n_updates          | 19952       |\n",
      "|    policyGradLoss     | -0.00953    |\n",
      "|    value_loss         | 1.55        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 40878080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014797488 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.465       |\n",
      "|    mean_step_reward   | 0.3541538   |\n",
      "|    n_updates          | 19956       |\n",
      "|    policyGradLoss     | -0.00548    |\n",
      "|    value_loss         | 1.66        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 40886272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014569636 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.363       |\n",
      "|    mean_step_reward   | 0.4053176   |\n",
      "|    n_updates          | 19960       |\n",
      "|    policyGradLoss     | -0.00768    |\n",
      "|    value_loss         | 0.971       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 40894464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014315081 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.533       |\n",
      "|    mean_step_reward   | 0.4170213   |\n",
      "|    n_updates          | 19964       |\n",
      "|    policyGradLoss     | -0.00441    |\n",
      "|    value_loss         | 1.82        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_155.zip\n",
      "[EVAL] Mean Return: 535.866, Best Return: 543.199\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_155_535.87.mp4\n",
      "\n",
      "=== Round 157 | Learn 262144 steps (Total trained: 40894464) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1117     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 40902656 |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 917          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 40910848     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0145466495 |\n",
      "|    entropy_loss       | -1.59        |\n",
      "|    explained_variance | 0.971        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.94         |\n",
      "|    mean_step_reward   | 0.4227357    |\n",
      "|    n_updates          | 19972        |\n",
      "|    policyGradLoss     | -0.00168     |\n",
      "|    value_loss         | 2.42         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 871         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 40919040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010124368 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.976       |\n",
      "|    mean_step_reward   | 0.4486798   |\n",
      "|    n_updates          | 19976       |\n",
      "|    policyGradLoss     | -0.00415    |\n",
      "|    value_loss         | 2.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 846         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 40927232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014334179 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.06        |\n",
      "|    mean_step_reward   | 0.41465926  |\n",
      "|    n_updates          | 19980       |\n",
      "|    policyGradLoss     | -0.00728    |\n",
      "|    value_loss         | 1.84        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 833         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 40935424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013697185 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.64        |\n",
      "|    mean_step_reward   | 0.45485517  |\n",
      "|    n_updates          | 19984       |\n",
      "|    policyGradLoss     | -0.00468    |\n",
      "|    value_loss         | 1.96        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 823         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 40943616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013940816 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.739       |\n",
      "|    mean_step_reward   | 0.39002153  |\n",
      "|    n_updates          | 19988       |\n",
      "|    policyGradLoss     | -0.00554    |\n",
      "|    value_loss         | 1.65        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 40951808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019018177 |\n",
      "|    entropy_loss       | -1.56       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.395       |\n",
      "|    mean_step_reward   | 0.4341967   |\n",
      "|    n_updates          | 19992       |\n",
      "|    policyGradLoss     | -0.00983    |\n",
      "|    value_loss         | 1.03        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 811        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 80         |\n",
      "|    total_timesteps    | 40960000   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01029585 |\n",
      "|    entropy_loss       | -1.61      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.366      |\n",
      "|    mean_step_reward   | 0.43889934 |\n",
      "|    n_updates          | 19996      |\n",
      "|    policyGradLoss     | -0.00286   |\n",
      "|    value_loss         | 1.81       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 40968192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012606844 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.377       |\n",
      "|    mean_step_reward   | 0.4204505   |\n",
      "|    n_updates          | 20000       |\n",
      "|    policyGradLoss     | -0.0055     |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 40976384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011392133 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.303       |\n",
      "|    mean_step_reward   | 0.46867377  |\n",
      "|    n_updates          | 20004       |\n",
      "|    policyGradLoss     | -0.00271    |\n",
      "|    value_loss         | 1.48        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 794          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 113          |\n",
      "|    total_timesteps    | 40984576     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0154484715 |\n",
      "|    entropy_loss       | -1.58        |\n",
      "|    explained_variance | 0.989        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.611        |\n",
      "|    mean_step_reward   | 0.42144978   |\n",
      "|    n_updates          | 20008        |\n",
      "|    policyGradLoss     | -0.00469     |\n",
      "|    value_loss         | 1.6          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 40992768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013780387 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.27        |\n",
      "|    mean_step_reward   | 0.40470243  |\n",
      "|    n_updates          | 20012       |\n",
      "|    policyGradLoss     | -0.00387    |\n",
      "|    value_loss         | 1.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 41000960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014403951 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.498       |\n",
      "|    mean_step_reward   | 0.39163142  |\n",
      "|    n_updates          | 20016       |\n",
      "|    policyGradLoss     | -0.00627    |\n",
      "|    value_loss         | 1.46        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 41009152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018821113 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.56        |\n",
      "|    mean_step_reward   | 0.45277777  |\n",
      "|    n_updates          | 20020       |\n",
      "|    policyGradLoss     | 0.00186     |\n",
      "|    value_loss         | 4.98        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 41017344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012096893 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.734       |\n",
      "|    mean_step_reward   | 0.42706898  |\n",
      "|    n_updates          | 20024       |\n",
      "|    policyGradLoss     | -0.00348    |\n",
      "|    value_loss         | 2.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 41025536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013169806 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.861       |\n",
      "|    mean_step_reward   | 0.41992033  |\n",
      "|    n_updates          | 20028       |\n",
      "|    policyGradLoss     | -0.00134    |\n",
      "|    value_loss         | 2.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 41033728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012721571 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.352       |\n",
      "|    mean_step_reward   | 0.37889123  |\n",
      "|    n_updates          | 20032       |\n",
      "|    policyGradLoss     | -0.00655    |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 41041920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019035874 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.777       |\n",
      "|    mean_step_reward   | 0.38559943  |\n",
      "|    n_updates          | 20036       |\n",
      "|    policyGradLoss     | -0.00618    |\n",
      "|    value_loss         | 1.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 41050112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016856886 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.187       |\n",
      "|    mean_step_reward   | 0.4094685   |\n",
      "|    n_updates          | 20040       |\n",
      "|    policyGradLoss     | -0.00579    |\n",
      "|    value_loss         | 1.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 41058304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009841059 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.864       |\n",
      "|    mean_step_reward   | 0.3787222   |\n",
      "|    n_updates          | 20044       |\n",
      "|    policyGradLoss     | -0.00259    |\n",
      "|    value_loss         | 2.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 41066496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012795371 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.483       |\n",
      "|    mean_step_reward   | 0.4392978   |\n",
      "|    n_updates          | 20048       |\n",
      "|    policyGradLoss     | -0.00575    |\n",
      "|    value_loss         | 1.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 41074688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017683906 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.727       |\n",
      "|    mean_step_reward   | 0.3945707   |\n",
      "|    n_updates          | 20052       |\n",
      "|    policyGradLoss     | -0.00789    |\n",
      "|    value_loss         | 1.5         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 41082880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016349964 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.726       |\n",
      "|    mean_step_reward   | 0.41620597  |\n",
      "|    n_updates          | 20056       |\n",
      "|    policyGradLoss     | -0.00546    |\n",
      "|    value_loss         | 1.5         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 41091072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017272085 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.878       |\n",
      "|    mean_step_reward   | 0.36940145  |\n",
      "|    n_updates          | 20060       |\n",
      "|    policyGradLoss     | -0.00932    |\n",
      "|    value_loss         | 1.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 41099264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012025025 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.369       |\n",
      "|    mean_step_reward   | 0.34655893  |\n",
      "|    n_updates          | 20064       |\n",
      "|    policyGradLoss     | -0.00829    |\n",
      "|    value_loss         | 1.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 41107456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019014556 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.743       |\n",
      "|    mean_step_reward   | 0.4056058   |\n",
      "|    n_updates          | 20068       |\n",
      "|    policyGradLoss     | -0.00896    |\n",
      "|    value_loss         | 1.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 41115648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015459646 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.24        |\n",
      "|    mean_step_reward   | 0.43224373  |\n",
      "|    n_updates          | 20072       |\n",
      "|    policyGradLoss     | -0.00641    |\n",
      "|    value_loss         | 2.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 41123840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017566938 |\n",
      "|    entropy_loss       | -1.57       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.171       |\n",
      "|    mean_step_reward   | 0.428652    |\n",
      "|    n_updates          | 20076       |\n",
      "|    policyGradLoss     | -0.00581    |\n",
      "|    value_loss         | 1.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 41132032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016317796 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.372       |\n",
      "|    mean_step_reward   | 0.43635684  |\n",
      "|    n_updates          | 20080       |\n",
      "|    policyGradLoss     | -0.00683    |\n",
      "|    value_loss         | 1.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 41140224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013570411 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.56        |\n",
      "|    mean_step_reward   | 0.41358274  |\n",
      "|    n_updates          | 20084       |\n",
      "|    policyGradLoss     | -0.00654    |\n",
      "|    value_loss         | 2.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 41148416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011546612 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.365       |\n",
      "|    mean_step_reward   | 0.44849074  |\n",
      "|    n_updates          | 20088       |\n",
      "|    policyGradLoss     | -0.00696    |\n",
      "|    value_loss         | 1.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 41156608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023652095 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.42        |\n",
      "|    mean_step_reward   | 0.3694244   |\n",
      "|    n_updates          | 20092       |\n",
      "|    policyGradLoss     | -0.00215    |\n",
      "|    value_loss         | 4.46        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_156.zip\n",
      "[EVAL] Mean Return: 538.316, Best Return: 544.983\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_156_538.32.mp4\n",
      "\n",
      "=== Round 158 | Learn 262144 steps (Total trained: 41156608) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1143     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 41164800 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 937         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 41172992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016647315 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.1         |\n",
      "|    mean_step_reward   | 0.43718886  |\n",
      "|    n_updates          | 20100       |\n",
      "|    policyGradLoss     | -0.00481    |\n",
      "|    value_loss         | 1.79        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 870        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 41181184   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0138915  |\n",
      "|    entropy_loss       | -1.63      |\n",
      "|    explained_variance | 0.979      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.883      |\n",
      "|    mean_step_reward   | 0.41818976 |\n",
      "|    n_updates          | 20104      |\n",
      "|    policyGradLoss     | -0.00547   |\n",
      "|    value_loss         | 2.09       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 846          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 38           |\n",
      "|    total_timesteps    | 41189376     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0133270845 |\n",
      "|    entropy_loss       | -1.62        |\n",
      "|    explained_variance | 0.992        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.797        |\n",
      "|    mean_step_reward   | 0.43920916   |\n",
      "|    n_updates          | 20108        |\n",
      "|    policyGradLoss     | -0.00636     |\n",
      "|    value_loss         | 1.28         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 830         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 41197568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017854337 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.302       |\n",
      "|    mean_step_reward   | 0.38055104  |\n",
      "|    n_updates          | 20112       |\n",
      "|    policyGradLoss     | -0.00868    |\n",
      "|    value_loss         | 1.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 41205760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021635234 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.926       |\n",
      "|    mean_step_reward   | 0.4809119   |\n",
      "|    n_updates          | 20116       |\n",
      "|    policyGradLoss     | -0.00637    |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 41213952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012092752 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.433       |\n",
      "|    mean_step_reward   | 0.42746806  |\n",
      "|    n_updates          | 20120       |\n",
      "|    policyGradLoss     | -0.00477    |\n",
      "|    value_loss         | 2.09        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 41222144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014240188 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.41        |\n",
      "|    mean_step_reward   | 0.4311188   |\n",
      "|    n_updates          | 20124       |\n",
      "|    policyGradLoss     | -0.00715    |\n",
      "|    value_loss         | 1.56        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 804        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 91         |\n",
      "|    total_timesteps    | 41230336   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02061577 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.17       |\n",
      "|    mean_step_reward   | 0.32237154 |\n",
      "|    n_updates          | 20128      |\n",
      "|    policyGradLoss     | -0.00716   |\n",
      "|    value_loss         | 1.56       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 41238528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016951127 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.728       |\n",
      "|    mean_step_reward   | 0.372302    |\n",
      "|    n_updates          | 20132       |\n",
      "|    policyGradLoss     | 0.00153     |\n",
      "|    value_loss         | 1.87        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 798        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 112        |\n",
      "|    total_timesteps    | 41246720   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01500967 |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.818      |\n",
      "|    mean_step_reward   | 0.38322946 |\n",
      "|    n_updates          | 20136      |\n",
      "|    policyGradLoss     | -0.0035    |\n",
      "|    value_loss         | 2.01       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 41254912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015355246 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.398       |\n",
      "|    mean_step_reward   | 0.40550333  |\n",
      "|    n_updates          | 20140       |\n",
      "|    policyGradLoss     | -0.00328    |\n",
      "|    value_loss         | 2.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 133         |\n",
      "|    total_timesteps    | 41263104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021350162 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 5.95        |\n",
      "|    mean_step_reward   | 0.4666962   |\n",
      "|    n_updates          | 20144       |\n",
      "|    policyGradLoss     | 0.00369     |\n",
      "|    value_loss         | 8.46        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 41271296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010238463 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 2.01        |\n",
      "|    mean_step_reward   | 0.42416814  |\n",
      "|    n_updates          | 20148       |\n",
      "|    policyGradLoss     | -0.00284    |\n",
      "|    value_loss         | 2.36        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 792        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 155        |\n",
      "|    total_timesteps    | 41279488   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01278043 |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.969      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.769      |\n",
      "|    mean_step_reward   | 0.43762693 |\n",
      "|    n_updates          | 20152      |\n",
      "|    policyGradLoss     | -0.00265   |\n",
      "|    value_loss         | 2.32       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 41287680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013150039 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.888       |\n",
      "|    mean_step_reward   | 0.39549315  |\n",
      "|    n_updates          | 20156       |\n",
      "|    policyGradLoss     | -0.00709    |\n",
      "|    value_loss         | 1.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 41295872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012884833 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.844       |\n",
      "|    mean_step_reward   | 0.40954778  |\n",
      "|    n_updates          | 20160       |\n",
      "|    policyGradLoss     | 0.00292     |\n",
      "|    value_loss         | 3.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 41304064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011811112 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.408       |\n",
      "|    mean_step_reward   | 0.4220218   |\n",
      "|    n_updates          | 20164       |\n",
      "|    policyGradLoss     | -0.00519    |\n",
      "|    value_loss         | 2.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 197         |\n",
      "|    total_timesteps    | 41312256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009986447 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.92        |\n",
      "|    mean_step_reward   | 0.37780884  |\n",
      "|    n_updates          | 20168       |\n",
      "|    policyGradLoss     | -0.00478    |\n",
      "|    value_loss         | 2.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 41320448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014049383 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.304       |\n",
      "|    mean_step_reward   | 0.46485123  |\n",
      "|    n_updates          | 20172       |\n",
      "|    policyGradLoss     | -0.00564    |\n",
      "|    value_loss         | 1.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 218         |\n",
      "|    total_timesteps    | 41328640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013578154 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.34        |\n",
      "|    mean_step_reward   | 0.38198513  |\n",
      "|    n_updates          | 20176       |\n",
      "|    policyGradLoss     | -0.00783    |\n",
      "|    value_loss         | 1.67        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 785        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 229        |\n",
      "|    total_timesteps    | 41336832   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01456132 |\n",
      "|    entropy_loss       | -1.65      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.336      |\n",
      "|    mean_step_reward   | 0.40274927 |\n",
      "|    n_updates          | 20180      |\n",
      "|    policyGradLoss     | -0.00963   |\n",
      "|    value_loss         | 1.23       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 41345024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018342832 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.543       |\n",
      "|    mean_step_reward   | 0.39711726  |\n",
      "|    n_updates          | 20184       |\n",
      "|    policyGradLoss     | -0.00892    |\n",
      "|    value_loss         | 1.53        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 41353216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011851804 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.09        |\n",
      "|    mean_step_reward   | 0.37258512  |\n",
      "|    n_updates          | 20188       |\n",
      "|    policyGradLoss     | -0.00619    |\n",
      "|    value_loss         | 2.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 41361408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015381159 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.261       |\n",
      "|    mean_step_reward   | 0.4340209   |\n",
      "|    n_updates          | 20192       |\n",
      "|    policyGradLoss     | -0.00715    |\n",
      "|    value_loss         | 1.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 41369600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013686135 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.743       |\n",
      "|    mean_step_reward   | 0.38158724  |\n",
      "|    n_updates          | 20196       |\n",
      "|    policyGradLoss     | -0.00377    |\n",
      "|    value_loss         | 2.46        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 41377792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013943888 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.487       |\n",
      "|    mean_step_reward   | 0.41529903  |\n",
      "|    n_updates          | 20200       |\n",
      "|    policyGradLoss     | -0.00423    |\n",
      "|    value_loss         | 1.92        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 781        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 293        |\n",
      "|    total_timesteps    | 41385984   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01826989 |\n",
      "|    entropy_loss       | -1.66      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.49       |\n",
      "|    mean_step_reward   | 0.36370862 |\n",
      "|    n_updates          | 20204      |\n",
      "|    policyGradLoss     | 7.42e-05   |\n",
      "|    value_loss         | 1.63       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 41394176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014042439 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.529       |\n",
      "|    mean_step_reward   | 0.4038297   |\n",
      "|    n_updates          | 20208       |\n",
      "|    policyGradLoss     | -0.00524    |\n",
      "|    value_loss         | 1.93        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 314         |\n",
      "|    total_timesteps    | 41402368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010923509 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.621       |\n",
      "|    mean_step_reward   | 0.37680328  |\n",
      "|    n_updates          | 20212       |\n",
      "|    policyGradLoss     | -0.00648    |\n",
      "|    value_loss         | 1.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 41410560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016689442 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.92        |\n",
      "|    mean_step_reward   | 0.39288154  |\n",
      "|    n_updates          | 20216       |\n",
      "|    policyGradLoss     | -0.00454    |\n",
      "|    value_loss         | 2.11        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 41418752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021521917 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.23        |\n",
      "|    mean_step_reward   | 0.41833097  |\n",
      "|    n_updates          | 20220       |\n",
      "|    policyGradLoss     | -0.0111     |\n",
      "|    value_loss         | 1.04        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_157.zip\n",
      "[EVAL] Mean Return: 543.519, Best Return: 550.185\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_157_543.52.mp4\n",
      "\n",
      "=== Round 159 | Learn 262144 steps (Total trained: 41418752) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1121     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 41426944 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 934        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 41435136   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01195449 |\n",
      "|    entropy_loss       | -1.61      |\n",
      "|    explained_variance | 0.99       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.377      |\n",
      "|    mean_step_reward   | 0.44444805 |\n",
      "|    n_updates          | 20228      |\n",
      "|    policyGradLoss     | -0.004     |\n",
      "|    value_loss         | 1.51       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 870         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 41443328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016321363 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.758       |\n",
      "|    mean_step_reward   | 0.40321445  |\n",
      "|    n_updates          | 20232       |\n",
      "|    policyGradLoss     | -0.00181    |\n",
      "|    value_loss         | 3.61        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 849         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 41451520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013723323 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.68        |\n",
      "|    mean_step_reward   | 0.40123874  |\n",
      "|    n_updates          | 20236       |\n",
      "|    policyGradLoss     | -0.00145    |\n",
      "|    value_loss         | 2.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 41459712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014823016 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.306       |\n",
      "|    mean_step_reward   | 0.45871842  |\n",
      "|    n_updates          | 20240       |\n",
      "|    policyGradLoss     | -0.00591    |\n",
      "|    value_loss         | 1.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 41467904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012330491 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.31        |\n",
      "|    mean_step_reward   | 0.40967268  |\n",
      "|    n_updates          | 20244       |\n",
      "|    policyGradLoss     | -0.00759    |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 41476096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017183159 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.7         |\n",
      "|    mean_step_reward   | 0.4004621   |\n",
      "|    n_updates          | 20248       |\n",
      "|    policyGradLoss     | -0.00641    |\n",
      "|    value_loss         | 1.77        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 806        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 81         |\n",
      "|    total_timesteps    | 41484288   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0163182  |\n",
      "|    entropy_loss       | -1.6       |\n",
      "|    explained_variance | 0.993      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.761      |\n",
      "|    mean_step_reward   | 0.42868066 |\n",
      "|    n_updates          | 20252      |\n",
      "|    policyGradLoss     | -0.00894   |\n",
      "|    value_loss         | 1.15       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 41492480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013659209 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.1         |\n",
      "|    mean_step_reward   | 0.38390082  |\n",
      "|    n_updates          | 20256       |\n",
      "|    policyGradLoss     | -0.00831    |\n",
      "|    value_loss         | 1.71        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 41500672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013045803 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.434       |\n",
      "|    mean_step_reward   | 0.4312148   |\n",
      "|    n_updates          | 20260       |\n",
      "|    policyGradLoss     | -0.00822    |\n",
      "|    value_loss         | 1.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 112         |\n",
      "|    total_timesteps    | 41508864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018342786 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.809       |\n",
      "|    mean_step_reward   | 0.35015813  |\n",
      "|    n_updates          | 20264       |\n",
      "|    policyGradLoss     | -0.00714    |\n",
      "|    value_loss         | 1.24        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 793        |\n",
      "|    iterations         | 12         |\n",
      "|    time_elapsed       | 123        |\n",
      "|    total_timesteps    | 41517056   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01832967 |\n",
      "|    entropy_loss       | -1.6       |\n",
      "|    explained_variance | 0.992      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.427      |\n",
      "|    mean_step_reward   | 0.40733624 |\n",
      "|    n_updates          | 20268      |\n",
      "|    policyGradLoss     | -0.0106    |\n",
      "|    value_loss         | 1.22       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 41525248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010654042 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.586       |\n",
      "|    mean_step_reward   | 0.3846298   |\n",
      "|    n_updates          | 20272       |\n",
      "|    policyGradLoss     | -0.005      |\n",
      "|    value_loss         | 1.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 41533440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022017177 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.442       |\n",
      "|    mean_step_reward   | 0.3784116   |\n",
      "|    n_updates          | 20276       |\n",
      "|    policyGradLoss     | -0.000191   |\n",
      "|    value_loss         | 1.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 41541632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012462539 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.169       |\n",
      "|    mean_step_reward   | 0.34401238  |\n",
      "|    n_updates          | 20280       |\n",
      "|    policyGradLoss     | -0.00662    |\n",
      "|    value_loss         | 1.93        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 785          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 166          |\n",
      "|    total_timesteps    | 41549824     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0140253175 |\n",
      "|    entropy_loss       | -1.63        |\n",
      "|    explained_variance | 0.988        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.306        |\n",
      "|    mean_step_reward   | 0.37768495   |\n",
      "|    n_updates          | 20284        |\n",
      "|    policyGradLoss     | -0.00495     |\n",
      "|    value_loss         | 1.32         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 41558016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013444101 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.13        |\n",
      "|    mean_step_reward   | 0.3610351   |\n",
      "|    n_updates          | 20288       |\n",
      "|    policyGradLoss     | -0.00163    |\n",
      "|    value_loss         | 3.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 41566208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011364131 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.813       |\n",
      "|    mean_step_reward   | 0.38094842  |\n",
      "|    n_updates          | 20292       |\n",
      "|    policyGradLoss     | -0.00654    |\n",
      "|    value_loss         | 1.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 41574400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016705811 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.304       |\n",
      "|    mean_step_reward   | 0.4134053   |\n",
      "|    n_updates          | 20296       |\n",
      "|    policyGradLoss     | -0.00559    |\n",
      "|    value_loss         | 1.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 41582592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015600168 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.628       |\n",
      "|    mean_step_reward   | 0.40152884  |\n",
      "|    n_updates          | 20300       |\n",
      "|    policyGradLoss     | -0.00328    |\n",
      "|    value_loss         | 2.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 41590784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015531668 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.691       |\n",
      "|    mean_step_reward   | 0.38330448  |\n",
      "|    n_updates          | 20304       |\n",
      "|    policyGradLoss     | -0.00378    |\n",
      "|    value_loss         | 1.9         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 41598976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017198771 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.674       |\n",
      "|    mean_step_reward   | 0.45676506  |\n",
      "|    n_updates          | 20308       |\n",
      "|    policyGradLoss     | -0.00683    |\n",
      "|    value_loss         | 1.86        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 41607168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012408171 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.08        |\n",
      "|    mean_step_reward   | 0.37477407  |\n",
      "|    n_updates          | 20312       |\n",
      "|    policyGradLoss     | -0.00418    |\n",
      "|    value_loss         | 1.96        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 41615360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014284868 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.598       |\n",
      "|    mean_step_reward   | 0.36506614  |\n",
      "|    n_updates          | 20316       |\n",
      "|    policyGradLoss     | -0.00811    |\n",
      "|    value_loss         | 1.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 41623552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015535415 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.683       |\n",
      "|    mean_step_reward   | 0.37870067  |\n",
      "|    n_updates          | 20320       |\n",
      "|    policyGradLoss     | -0.00684    |\n",
      "|    value_loss         | 1.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 41631744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016420843 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.175       |\n",
      "|    mean_step_reward   | 0.37863714  |\n",
      "|    n_updates          | 20324       |\n",
      "|    policyGradLoss     | -0.0114     |\n",
      "|    value_loss         | 0.909       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 41639936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014168084 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.951       |\n",
      "|    mean_step_reward   | 0.3384274   |\n",
      "|    n_updates          | 20328       |\n",
      "|    policyGradLoss     | -0.00577    |\n",
      "|    value_loss         | 1.82        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 41648128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012041975 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.916       |\n",
      "|    mean_step_reward   | 0.39566806  |\n",
      "|    n_updates          | 20332       |\n",
      "|    policyGradLoss     | -0.00123    |\n",
      "|    value_loss         | 2.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 41656320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009684228 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.355       |\n",
      "|    mean_step_reward   | 0.39869308  |\n",
      "|    n_updates          | 20336       |\n",
      "|    policyGradLoss     | -0.0052     |\n",
      "|    value_loss         | 1.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 41664512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013522554 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.412       |\n",
      "|    mean_step_reward   | 0.3593716   |\n",
      "|    n_updates          | 20340       |\n",
      "|    policyGradLoss     | -0.00588    |\n",
      "|    value_loss         | 1.63        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 326        |\n",
      "|    total_timesteps    | 41672704   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01352787 |\n",
      "|    entropy_loss       | -1.6       |\n",
      "|    explained_variance | 0.994      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.527      |\n",
      "|    mean_step_reward   | 0.42961484 |\n",
      "|    n_updates          | 20344      |\n",
      "|    policyGradLoss     | -0.00856   |\n",
      "|    value_loss         | 0.89       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 41680896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015112499 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.763       |\n",
      "|    mean_step_reward   | 0.35414425  |\n",
      "|    n_updates          | 20348       |\n",
      "|    policyGradLoss     | -0.00481    |\n",
      "|    value_loss         | 1.78        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_158.zip\n",
      "[EVAL] Mean Return: 536.749, Best Return: 543.415\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_158_536.75.mp4\n",
      "\n",
      "=== Round 160 | Learn 262144 steps (Total trained: 41680896) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1117     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 41689088 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 949        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 41697280   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01259605 |\n",
      "|    entropy_loss       | -1.63      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.542      |\n",
      "|    mean_step_reward   | 0.42278734 |\n",
      "|    n_updates          | 20356      |\n",
      "|    policyGradLoss     | -0.00596   |\n",
      "|    value_loss         | 1.57       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 880         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 41705472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010253004 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.72        |\n",
      "|    mean_step_reward   | 0.42675564  |\n",
      "|    n_updates          | 20360       |\n",
      "|    policyGradLoss     | -0.00428    |\n",
      "|    value_loss         | 1.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 849         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 41713664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015582088 |\n",
      "|    entropy_loss       | -1.56       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.19        |\n",
      "|    mean_step_reward   | 0.49111092  |\n",
      "|    n_updates          | 20364       |\n",
      "|    policyGradLoss     | -0.00395    |\n",
      "|    value_loss         | 1.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 834         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 41721856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016711384 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.34        |\n",
      "|    mean_step_reward   | 0.39710474  |\n",
      "|    n_updates          | 20368       |\n",
      "|    policyGradLoss     | -0.00276    |\n",
      "|    value_loss         | 2.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 41730048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016209314 |\n",
      "|    entropy_loss       | -1.57       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.594       |\n",
      "|    mean_step_reward   | 0.45657128  |\n",
      "|    n_updates          | 20372       |\n",
      "|    policyGradLoss     | -0.00713    |\n",
      "|    value_loss         | 0.965       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 41738240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012393674 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.601       |\n",
      "|    mean_step_reward   | 0.38221866  |\n",
      "|    n_updates          | 20376       |\n",
      "|    policyGradLoss     | -0.0045     |\n",
      "|    value_loss         | 1.88        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 41746432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013002841 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.377       |\n",
      "|    mean_step_reward   | 0.48356616  |\n",
      "|    n_updates          | 20380       |\n",
      "|    policyGradLoss     | -0.00643    |\n",
      "|    value_loss         | 1.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 41754624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012673759 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.993       |\n",
      "|    mean_step_reward   | 0.43944567  |\n",
      "|    n_updates          | 20384       |\n",
      "|    policyGradLoss     | -0.00451    |\n",
      "|    value_loss         | 2.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 41762816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012364382 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.692       |\n",
      "|    mean_step_reward   | 0.3453101   |\n",
      "|    n_updates          | 20388       |\n",
      "|    policyGradLoss     | -0.00644    |\n",
      "|    value_loss         | 1.76        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 41771008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018950157 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.264       |\n",
      "|    mean_step_reward   | 0.41156685  |\n",
      "|    n_updates          | 20392       |\n",
      "|    policyGradLoss     | -0.00883    |\n",
      "|    value_loss         | 0.982       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 41779200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011563922 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.33        |\n",
      "|    mean_step_reward   | 0.3741032   |\n",
      "|    n_updates          | 20396       |\n",
      "|    policyGradLoss     | -0.00528    |\n",
      "|    value_loss         | 1.74        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 790          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 134          |\n",
      "|    total_timesteps    | 41787392     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0151078245 |\n",
      "|    entropy_loss       | -1.61        |\n",
      "|    explained_variance | 0.986        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.798        |\n",
      "|    mean_step_reward   | 0.42100447   |\n",
      "|    n_updates          | 20400        |\n",
      "|    policyGradLoss     | -0.00614     |\n",
      "|    value_loss         | 1.86         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 41795584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011850105 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.446       |\n",
      "|    mean_step_reward   | 0.3866824   |\n",
      "|    n_updates          | 20404       |\n",
      "|    policyGradLoss     | 0.000931    |\n",
      "|    value_loss         | 1.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 41803776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016000647 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.706       |\n",
      "|    mean_step_reward   | 0.38881326  |\n",
      "|    n_updates          | 20408       |\n",
      "|    policyGradLoss     | -0.00422    |\n",
      "|    value_loss         | 2.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 41811968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017525202 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.851       |\n",
      "|    mean_step_reward   | 0.4473555   |\n",
      "|    n_updates          | 20412       |\n",
      "|    policyGradLoss     | -0.00892    |\n",
      "|    value_loss         | 1.12        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 785        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 177        |\n",
      "|    total_timesteps    | 41820160   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01758641 |\n",
      "|    entropy_loss       | -1.62      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.786      |\n",
      "|    mean_step_reward   | 0.3263479  |\n",
      "|    n_updates          | 20416      |\n",
      "|    policyGradLoss     | -0.00646   |\n",
      "|    value_loss         | 1.55       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 41828352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015029417 |\n",
      "|    entropy_loss       | -1.56       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.242       |\n",
      "|    mean_step_reward   | 0.42135453  |\n",
      "|    n_updates          | 20420       |\n",
      "|    policyGradLoss     | -0.00727    |\n",
      "|    value_loss         | 1.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 41836544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014733812 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.304       |\n",
      "|    mean_step_reward   | 0.39215785  |\n",
      "|    n_updates          | 20424       |\n",
      "|    policyGradLoss     | -0.00691    |\n",
      "|    value_loss         | 1.38        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 782        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 209        |\n",
      "|    total_timesteps    | 41844736   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01857243 |\n",
      "|    entropy_loss       | -1.59      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.27       |\n",
      "|    mean_step_reward   | 0.37052435 |\n",
      "|    n_updates          | 20428      |\n",
      "|    policyGradLoss     | -0.00653   |\n",
      "|    value_loss         | 1.63       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 780        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 220        |\n",
      "|    total_timesteps    | 41852928   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01387302 |\n",
      "|    entropy_loss       | -1.6       |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.379      |\n",
      "|    mean_step_reward   | 0.38116008 |\n",
      "|    n_updates          | 20432      |\n",
      "|    policyGradLoss     | -0.00435   |\n",
      "|    value_loss         | 1.27       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 41861120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010628258 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.352       |\n",
      "|    mean_step_reward   | 0.39931053  |\n",
      "|    n_updates          | 20436       |\n",
      "|    policyGradLoss     | -0.00411    |\n",
      "|    value_loss         | 2.16        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 781        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 241        |\n",
      "|    total_timesteps    | 41869312   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01546109 |\n",
      "|    entropy_loss       | -1.58      |\n",
      "|    explained_variance | 0.978      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.21       |\n",
      "|    mean_step_reward   | 0.42730978 |\n",
      "|    n_updates          | 20440      |\n",
      "|    policyGradLoss     | -0.00402   |\n",
      "|    value_loss         | 2.48       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 780        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 251        |\n",
      "|    total_timesteps    | 41877504   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01664491 |\n",
      "|    entropy_loss       | -1.62      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.268      |\n",
      "|    mean_step_reward   | 0.39525846 |\n",
      "|    n_updates          | 20444      |\n",
      "|    policyGradLoss     | -0.00616   |\n",
      "|    value_loss         | 1.8        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 41885696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012508905 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.319       |\n",
      "|    mean_step_reward   | 0.44630414  |\n",
      "|    n_updates          | 20448       |\n",
      "|    policyGradLoss     | -0.00592    |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 41893888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011947226 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.438       |\n",
      "|    mean_step_reward   | 0.42306566  |\n",
      "|    n_updates          | 20452       |\n",
      "|    policyGradLoss     | -0.00356    |\n",
      "|    value_loss         | 1.81        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 41902080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012963379 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.464       |\n",
      "|    mean_step_reward   | 0.3804868   |\n",
      "|    n_updates          | 20456       |\n",
      "|    policyGradLoss     | -0.00324    |\n",
      "|    value_loss         | 2.09        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 41910272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015771095 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.544       |\n",
      "|    mean_step_reward   | 0.4627626   |\n",
      "|    n_updates          | 20460       |\n",
      "|    policyGradLoss     | -0.00534    |\n",
      "|    value_loss         | 1.42        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 304        |\n",
      "|    total_timesteps    | 41918464   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02133151 |\n",
      "|    entropy_loss       | -1.63      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.873      |\n",
      "|    mean_step_reward   | 0.43894234 |\n",
      "|    n_updates          | 20464      |\n",
      "|    policyGradLoss     | -0.00474   |\n",
      "|    value_loss         | 2.03       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 41926656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013648729 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.16        |\n",
      "|    mean_step_reward   | 0.43110394  |\n",
      "|    n_updates          | 20468       |\n",
      "|    policyGradLoss     | -0.00509    |\n",
      "|    value_loss         | 1.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 41934848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013265306 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.655       |\n",
      "|    mean_step_reward   | 0.39125845  |\n",
      "|    n_updates          | 20472       |\n",
      "|    policyGradLoss     | -0.00857    |\n",
      "|    value_loss         | 1.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 41943040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016607426 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.713       |\n",
      "|    mean_step_reward   | 0.39615113  |\n",
      "|    n_updates          | 20476       |\n",
      "|    policyGradLoss     | -0.00754    |\n",
      "|    value_loss         | 1.66        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_159.zip\n",
      "[EVAL] Mean Return: 420.143, Best Return: 424.810\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_159_420.14.mp4\n",
      "\n",
      "=== Round 161 | Learn 262144 steps (Total trained: 41943040) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1108     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 41951232 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 903         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 41959424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014339831 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.225       |\n",
      "|    mean_step_reward   | 0.36434466  |\n",
      "|    n_updates          | 20484       |\n",
      "|    policyGradLoss     | -0.00497    |\n",
      "|    value_loss         | 1.88        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 849         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 41967616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012849405 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.451       |\n",
      "|    mean_step_reward   | 0.46195307  |\n",
      "|    n_updates          | 20488       |\n",
      "|    policyGradLoss     | -0.00748    |\n",
      "|    value_loss         | 1.36        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 822          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 39           |\n",
      "|    total_timesteps    | 41975808     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0154994875 |\n",
      "|    entropy_loss       | -1.66        |\n",
      "|    explained_variance | 0.99         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.627        |\n",
      "|    mean_step_reward   | 0.36608198   |\n",
      "|    n_updates          | 20492        |\n",
      "|    policyGradLoss     | -0.00438     |\n",
      "|    value_loss         | 1.37         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 41984000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015196683 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.302       |\n",
      "|    mean_step_reward   | 0.3879009   |\n",
      "|    n_updates          | 20496       |\n",
      "|    policyGradLoss     | -0.00798    |\n",
      "|    value_loss         | 1.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 41992192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009551481 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.738       |\n",
      "|    mean_step_reward   | 0.41371554  |\n",
      "|    n_updates          | 20500       |\n",
      "|    policyGradLoss     | -0.00233    |\n",
      "|    value_loss         | 2.13        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 802        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 71         |\n",
      "|    total_timesteps    | 42000384   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01197426 |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.976      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.988      |\n",
      "|    mean_step_reward   | 0.3218016  |\n",
      "|    n_updates          | 20504      |\n",
      "|    policyGradLoss     | -0.00468   |\n",
      "|    value_loss         | 1.77       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 42008576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011337683 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.271       |\n",
      "|    mean_step_reward   | 0.43275398  |\n",
      "|    n_updates          | 20508       |\n",
      "|    policyGradLoss     | -0.00215    |\n",
      "|    value_loss         | 1.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 42016768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015175734 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.975       |\n",
      "|    mean_step_reward   | 0.34364313  |\n",
      "|    n_updates          | 20512       |\n",
      "|    policyGradLoss     | -0.00324    |\n",
      "|    value_loss         | 1.98        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 42024960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019002937 |\n",
      "|    entropy_loss       | -1.57       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.08        |\n",
      "|    mean_step_reward   | 0.48569155  |\n",
      "|    n_updates          | 20516       |\n",
      "|    policyGradLoss     | 0.000172    |\n",
      "|    value_loss         | 4.86        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 42033152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019163951 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.734       |\n",
      "|    mean_step_reward   | 0.40086925  |\n",
      "|    n_updates          | 20520       |\n",
      "|    policyGradLoss     | -0.0037     |\n",
      "|    value_loss         | 2.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 42041344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016916946 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.333       |\n",
      "|    mean_step_reward   | 0.38710862  |\n",
      "|    n_updates          | 20524       |\n",
      "|    policyGradLoss     | -0.00568    |\n",
      "|    value_loss         | 1.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 42049536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024455998 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.276       |\n",
      "|    mean_step_reward   | 0.419       |\n",
      "|    n_updates          | 20528       |\n",
      "|    policyGradLoss     | -0.00578    |\n",
      "|    value_loss         | 1.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 42057728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011574356 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.8         |\n",
      "|    mean_step_reward   | 0.39592314  |\n",
      "|    n_updates          | 20532       |\n",
      "|    policyGradLoss     | -0.00313    |\n",
      "|    value_loss         | 2.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 42065920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012609001 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.385       |\n",
      "|    mean_step_reward   | 0.4319025   |\n",
      "|    n_updates          | 20536       |\n",
      "|    policyGradLoss     | -0.00638    |\n",
      "|    value_loss         | 1.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 42074112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014325318 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.543       |\n",
      "|    mean_step_reward   | 0.38024694  |\n",
      "|    n_updates          | 20540       |\n",
      "|    policyGradLoss     | -0.00471    |\n",
      "|    value_loss         | 1.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 42082304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013547156 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.616       |\n",
      "|    mean_step_reward   | 0.34260666  |\n",
      "|    n_updates          | 20544       |\n",
      "|    policyGradLoss     | -0.00937    |\n",
      "|    value_loss         | 1.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 42090496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017249068 |\n",
      "|    entropy_loss       | -1.57       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.3         |\n",
      "|    mean_step_reward   | 0.43622345  |\n",
      "|    n_updates          | 20548       |\n",
      "|    policyGradLoss     | -0.00931    |\n",
      "|    value_loss         | 0.969       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 42098688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011251461 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.02        |\n",
      "|    mean_step_reward   | 0.4048465   |\n",
      "|    n_updates          | 20552       |\n",
      "|    policyGradLoss     | -0.00249    |\n",
      "|    value_loss         | 2.27        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 210        |\n",
      "|    total_timesteps    | 42106880   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01987693 |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.99       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.51       |\n",
      "|    mean_step_reward   | 0.3857887  |\n",
      "|    n_updates          | 20556      |\n",
      "|    policyGradLoss     | -0.0072    |\n",
      "|    value_loss         | 1.26       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 42115072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020793116 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.539       |\n",
      "|    mean_step_reward   | 0.39910108  |\n",
      "|    n_updates          | 20560       |\n",
      "|    policyGradLoss     | -0.00743    |\n",
      "|    value_loss         | 1.11        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 42123264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015919741 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.953       |\n",
      "|    mean_step_reward   | 0.38959825  |\n",
      "|    n_updates          | 20564       |\n",
      "|    policyGradLoss     | -0.00875    |\n",
      "|    value_loss         | 1.89        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 42131456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015656322 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.338       |\n",
      "|    mean_step_reward   | 0.3943882   |\n",
      "|    n_updates          | 20568       |\n",
      "|    policyGradLoss     | -0.00426    |\n",
      "|    value_loss         | 2.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 42139648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009180492 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.707       |\n",
      "|    mean_step_reward   | 0.3946765   |\n",
      "|    n_updates          | 20572       |\n",
      "|    policyGradLoss     | -0.0015     |\n",
      "|    value_loss         | 3           |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 42147840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011229303 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.916       |\n",
      "|    mean_step_reward   | 0.39102468  |\n",
      "|    n_updates          | 20576       |\n",
      "|    policyGradLoss     | -0.00692    |\n",
      "|    value_loss         | 2.09        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 42156032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016895492 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.904       |\n",
      "|    mean_step_reward   | 0.40056717  |\n",
      "|    n_updates          | 20580       |\n",
      "|    policyGradLoss     | -0.00149    |\n",
      "|    value_loss         | 1.9         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 42164224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013574909 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.436       |\n",
      "|    mean_step_reward   | 0.40248024  |\n",
      "|    n_updates          | 20584       |\n",
      "|    policyGradLoss     | -0.00511    |\n",
      "|    value_loss         | 1.75        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 42172416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013729412 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.346       |\n",
      "|    mean_step_reward   | 0.45171112  |\n",
      "|    n_updates          | 20588       |\n",
      "|    policyGradLoss     | -0.00478    |\n",
      "|    value_loss         | 1.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 307         |\n",
      "|    total_timesteps    | 42180608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012595994 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.766       |\n",
      "|    mean_step_reward   | 0.38441157  |\n",
      "|    n_updates          | 20592       |\n",
      "|    policyGradLoss     | -0.00561    |\n",
      "|    value_loss         | 2.81        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 42188800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021464948 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.139       |\n",
      "|    mean_step_reward   | 0.4073699   |\n",
      "|    n_updates          | 20596       |\n",
      "|    policyGradLoss     | -0.00574    |\n",
      "|    value_loss         | 0.954       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 42196992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013276827 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.232       |\n",
      "|    mean_step_reward   | 0.40120023  |\n",
      "|    n_updates          | 20600       |\n",
      "|    policyGradLoss     | -0.00711    |\n",
      "|    value_loss         | 1.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 42205184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012947256 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.592       |\n",
      "|    mean_step_reward   | 0.38970533  |\n",
      "|    n_updates          | 20604       |\n",
      "|    policyGradLoss     | -0.00331    |\n",
      "|    value_loss         | 2.16        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_160.zip\n",
      "[EVAL] Mean Return: 542.855, Best Return: 549.521\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_160_542.85.mp4\n",
      "\n",
      "=== Round 162 | Learn 262144 steps (Total trained: 42205184) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1143     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 42213376 |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 922          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 42221568     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0150622325 |\n",
      "|    entropy_loss       | -1.61        |\n",
      "|    explained_variance | 0.989        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.674        |\n",
      "|    mean_step_reward   | 0.38963613   |\n",
      "|    n_updates          | 20612        |\n",
      "|    policyGradLoss     | -0.00621     |\n",
      "|    value_loss         | 1.55         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 870         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 42229760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011656934 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.462       |\n",
      "|    mean_step_reward   | 0.43621665  |\n",
      "|    n_updates          | 20616       |\n",
      "|    policyGradLoss     | -0.00334    |\n",
      "|    value_loss         | 2.07        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 842        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 38         |\n",
      "|    total_timesteps    | 42237952   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01243373 |\n",
      "|    entropy_loss       | -1.61      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.52       |\n",
      "|    mean_step_reward   | 0.38822418 |\n",
      "|    n_updates          | 20620      |\n",
      "|    policyGradLoss     | -0.00638   |\n",
      "|    value_loss         | 1.39       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 42246144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015450562 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.821       |\n",
      "|    mean_step_reward   | 0.4330541   |\n",
      "|    n_updates          | 20624       |\n",
      "|    policyGradLoss     | -0.00736    |\n",
      "|    value_loss         | 1.59        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 42254336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010491694 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.655       |\n",
      "|    mean_step_reward   | 0.4041857   |\n",
      "|    n_updates          | 20628       |\n",
      "|    policyGradLoss     | -0.00684    |\n",
      "|    value_loss         | 2.04        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 808        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 70         |\n",
      "|    total_timesteps    | 42262528   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02117737 |\n",
      "|    entropy_loss       | -1.6       |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.418      |\n",
      "|    mean_step_reward   | 0.42007595 |\n",
      "|    n_updates          | 20632      |\n",
      "|    policyGradLoss     | -0.00964   |\n",
      "|    value_loss         | 1.45       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 42270720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013372729 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.22        |\n",
      "|    mean_step_reward   | 0.45371044  |\n",
      "|    n_updates          | 20636       |\n",
      "|    policyGradLoss     | -0.00613    |\n",
      "|    value_loss         | 2.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 42278912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014391824 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.224       |\n",
      "|    mean_step_reward   | 0.44577354  |\n",
      "|    n_updates          | 20640       |\n",
      "|    policyGradLoss     | -0.00434    |\n",
      "|    value_loss         | 1.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 42287104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012414316 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.344       |\n",
      "|    mean_step_reward   | 0.45207718  |\n",
      "|    n_updates          | 20644       |\n",
      "|    policyGradLoss     | -0.00566    |\n",
      "|    value_loss         | 1.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 42295296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013870662 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.963       |\n",
      "|    mean_step_reward   | 0.44311947  |\n",
      "|    n_updates          | 20648       |\n",
      "|    policyGradLoss     | -0.00453    |\n",
      "|    value_loss         | 2.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 42303488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016067859 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.802       |\n",
      "|    mean_step_reward   | 0.39251795  |\n",
      "|    n_updates          | 20652       |\n",
      "|    policyGradLoss     | -0.0076     |\n",
      "|    value_loss         | 1.65        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 42311680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012266474 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.427       |\n",
      "|    mean_step_reward   | 0.418849    |\n",
      "|    n_updates          | 20656       |\n",
      "|    policyGradLoss     | -0.00611    |\n",
      "|    value_loss         | 1.64        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 42319872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016846804 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.729       |\n",
      "|    mean_step_reward   | 0.41510367  |\n",
      "|    n_updates          | 20660       |\n",
      "|    policyGradLoss     | -0.00183    |\n",
      "|    value_loss         | 3.72        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 787        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 155        |\n",
      "|    total_timesteps    | 42328064   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01353736 |\n",
      "|    entropy_loss       | -1.6       |\n",
      "|    explained_variance | 0.992      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.592      |\n",
      "|    mean_step_reward   | 0.44623703 |\n",
      "|    n_updates          | 20664      |\n",
      "|    policyGradLoss     | -0.0109    |\n",
      "|    value_loss         | 1.18       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 42336256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012883274 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.06        |\n",
      "|    mean_step_reward   | 0.35327172  |\n",
      "|    n_updates          | 20668       |\n",
      "|    policyGradLoss     | -0.0066     |\n",
      "|    value_loss         | 2.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 42344448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013849815 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.21        |\n",
      "|    mean_step_reward   | 0.42995128  |\n",
      "|    n_updates          | 20672       |\n",
      "|    policyGradLoss     | -0.00169    |\n",
      "|    value_loss         | 2.46        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 784        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 187        |\n",
      "|    total_timesteps    | 42352640   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01580171 |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.577      |\n",
      "|    mean_step_reward   | 0.36747545 |\n",
      "|    n_updates          | 20676      |\n",
      "|    policyGradLoss     | -0.00587   |\n",
      "|    value_loss         | 1.85       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 42360832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015075182 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.508       |\n",
      "|    mean_step_reward   | 0.37501097  |\n",
      "|    n_updates          | 20680       |\n",
      "|    policyGradLoss     | 0.00151     |\n",
      "|    value_loss         | 3.61        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 42369024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015174745 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.637       |\n",
      "|    mean_step_reward   | 0.41695887  |\n",
      "|    n_updates          | 20684       |\n",
      "|    policyGradLoss     | -0.00515    |\n",
      "|    value_loss         | 1.76        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 782          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 219          |\n",
      "|    total_timesteps    | 42377216     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0155064035 |\n",
      "|    entropy_loss       | -1.67        |\n",
      "|    explained_variance | 0.986        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.618        |\n",
      "|    mean_step_reward   | 0.36446893   |\n",
      "|    n_updates          | 20688        |\n",
      "|    policyGradLoss     | -0.00478     |\n",
      "|    value_loss         | 1.72         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 780        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 230        |\n",
      "|    total_timesteps    | 42385408   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01578968 |\n",
      "|    entropy_loss       | -1.61      |\n",
      "|    explained_variance | 0.99       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.344      |\n",
      "|    mean_step_reward   | 0.46149236 |\n",
      "|    n_updates          | 20692      |\n",
      "|    policyGradLoss     | -0.00647   |\n",
      "|    value_loss         | 1.37       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 42393600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013448341 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.12        |\n",
      "|    mean_step_reward   | 0.34329003  |\n",
      "|    n_updates          | 20696       |\n",
      "|    policyGradLoss     | -0.00583    |\n",
      "|    value_loss         | 2.07        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 42401792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017685406 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.206       |\n",
      "|    mean_step_reward   | 0.4073732   |\n",
      "|    n_updates          | 20700       |\n",
      "|    policyGradLoss     | -0.00911    |\n",
      "|    value_loss         | 0.675       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 781        |\n",
      "|    iterations         | 25         |\n",
      "|    time_elapsed       | 262        |\n",
      "|    total_timesteps    | 42409984   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01878329 |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.993      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.352      |\n",
      "|    mean_step_reward   | 0.40760273 |\n",
      "|    n_updates          | 20704      |\n",
      "|    policyGradLoss     | -0.00736   |\n",
      "|    value_loss         | 1.26       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 42418176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014175419 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.862       |\n",
      "|    mean_step_reward   | 0.4155649   |\n",
      "|    n_updates          | 20708       |\n",
      "|    policyGradLoss     | -0.00618    |\n",
      "|    value_loss         | 1.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 42426368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010492854 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.503       |\n",
      "|    mean_step_reward   | 0.4437569   |\n",
      "|    n_updates          | 20712       |\n",
      "|    policyGradLoss     | -0.00514    |\n",
      "|    value_loss         | 1.71        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 42434560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009289438 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.241       |\n",
      "|    mean_step_reward   | 0.38291264  |\n",
      "|    n_updates          | 20716       |\n",
      "|    policyGradLoss     | -0.00507    |\n",
      "|    value_loss         | 1.89        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 42442752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022287909 |\n",
      "|    entropy_loss       | -1.57       |\n",
      "|    explained_variance | 0.996       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.157       |\n",
      "|    mean_step_reward   | 0.47630328  |\n",
      "|    n_updates          | 20720       |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.641       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 42450944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013259029 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.17        |\n",
      "|    mean_step_reward   | 0.3928988   |\n",
      "|    n_updates          | 20724       |\n",
      "|    policyGradLoss     | -0.00408    |\n",
      "|    value_loss         | 2.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 42459136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019990865 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.06        |\n",
      "|    mean_step_reward   | 0.37014133  |\n",
      "|    n_updates          | 20728       |\n",
      "|    policyGradLoss     | -0.00703    |\n",
      "|    value_loss         | 1.71        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 778       |\n",
      "|    iterations         | 32        |\n",
      "|    time_elapsed       | 336       |\n",
      "|    total_timesteps    | 42467328  |\n",
      "| train/                |           |\n",
      "|    approx_kl          | 0.0286122 |\n",
      "|    entropy_loss       | -1.59     |\n",
      "|    explained_variance | 0.994     |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    loss               | 0.124     |\n",
      "|    mean_step_reward   | 0.4219759 |\n",
      "|    n_updates          | 20732     |\n",
      "|    policyGradLoss     | -0.00813  |\n",
      "|    value_loss         | 0.925     |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_161.zip\n",
      "[EVAL] Mean Return: 539.502, Best Return: 546.835\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_161_539.50.mp4\n",
      "\n",
      "=== Round 163 | Learn 262144 steps (Total trained: 42467328) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1107     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 42475520 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 892         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 42483712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015687447 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.158       |\n",
      "|    mean_step_reward   | 0.46617082  |\n",
      "|    n_updates          | 20740       |\n",
      "|    policyGradLoss     | -0.0109     |\n",
      "|    value_loss         | 0.956       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 853         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 42491904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018670967 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.769       |\n",
      "|    mean_step_reward   | 0.34897318  |\n",
      "|    n_updates          | 20744       |\n",
      "|    policyGradLoss     | -0.0067     |\n",
      "|    value_loss         | 1.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 830         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 42500096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024866454 |\n",
      "|    entropy_loss       | -1.56       |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.487       |\n",
      "|    mean_step_reward   | 0.47173348  |\n",
      "|    n_updates          | 20748       |\n",
      "|    policyGradLoss     | -0.0058     |\n",
      "|    value_loss         | 0.913       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 42508288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015290389 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.06        |\n",
      "|    mean_step_reward   | 0.3992404   |\n",
      "|    n_updates          | 20752       |\n",
      "|    policyGradLoss     | -0.0036     |\n",
      "|    value_loss         | 2.59        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 42516480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014908148 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.685       |\n",
      "|    mean_step_reward   | 0.4551596   |\n",
      "|    n_updates          | 20756       |\n",
      "|    policyGradLoss     | -0.0062     |\n",
      "|    value_loss         | 1.26        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 806        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 71         |\n",
      "|    total_timesteps    | 42524672   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01437258 |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.984      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.72       |\n",
      "|    mean_step_reward   | 0.40610224 |\n",
      "|    n_updates          | 20760      |\n",
      "|    policyGradLoss     | -0.00568   |\n",
      "|    value_loss         | 2.35       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 42532864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016614068 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.437       |\n",
      "|    mean_step_reward   | 0.48775497  |\n",
      "|    n_updates          | 20764       |\n",
      "|    policyGradLoss     | -0.00821    |\n",
      "|    value_loss         | 1.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 42541056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012621888 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.86        |\n",
      "|    mean_step_reward   | 0.3841042   |\n",
      "|    n_updates          | 20768       |\n",
      "|    policyGradLoss     | -0.00585    |\n",
      "|    value_loss         | 2.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 42549248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019728225 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.283       |\n",
      "|    mean_step_reward   | 0.44972074  |\n",
      "|    n_updates          | 20772       |\n",
      "|    policyGradLoss     | -0.00729    |\n",
      "|    value_loss         | 1.55        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 42557440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016777076 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.436       |\n",
      "|    mean_step_reward   | 0.4333307   |\n",
      "|    n_updates          | 20776       |\n",
      "|    policyGradLoss     | -0.00695    |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 42565632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017374398 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.872       |\n",
      "|    mean_step_reward   | 0.4392751   |\n",
      "|    n_updates          | 20780       |\n",
      "|    policyGradLoss     | -0.00661    |\n",
      "|    value_loss         | 1.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 42573824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013231363 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.514       |\n",
      "|    mean_step_reward   | 0.40469995  |\n",
      "|    n_updates          | 20784       |\n",
      "|    policyGradLoss     | -0.00735    |\n",
      "|    value_loss         | 1           |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 783        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 146        |\n",
      "|    total_timesteps    | 42582016   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01727201 |\n",
      "|    entropy_loss       | -1.62      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.153      |\n",
      "|    mean_step_reward   | 0.43467152 |\n",
      "|    n_updates          | 20788      |\n",
      "|    policyGradLoss     | -0.00675   |\n",
      "|    value_loss         | 1.61       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 42590208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012639381 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.625       |\n",
      "|    mean_step_reward   | 0.45280385  |\n",
      "|    n_updates          | 20792       |\n",
      "|    policyGradLoss     | -0.00635    |\n",
      "|    value_loss         | 1.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 42598400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014718184 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.492       |\n",
      "|    mean_step_reward   | 0.447398    |\n",
      "|    n_updates          | 20796       |\n",
      "|    policyGradLoss     | -0.00529    |\n",
      "|    value_loss         | 1.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 42606592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016053488 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.563       |\n",
      "|    mean_step_reward   | 0.39239925  |\n",
      "|    n_updates          | 20800       |\n",
      "|    policyGradLoss     | -0.0075     |\n",
      "|    value_loss         | 1.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 42614784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013560308 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.673       |\n",
      "|    mean_step_reward   | 0.4649322   |\n",
      "|    n_updates          | 20804       |\n",
      "|    policyGradLoss     | -0.00519    |\n",
      "|    value_loss         | 1.43        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 42622976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013086973 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.21        |\n",
      "|    mean_step_reward   | 0.38971     |\n",
      "|    n_updates          | 20808       |\n",
      "|    policyGradLoss     | -0.00365    |\n",
      "|    value_loss         | 2.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 42631168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012146037 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.212       |\n",
      "|    mean_step_reward   | 0.46718284  |\n",
      "|    n_updates          | 20812       |\n",
      "|    policyGradLoss     | -0.00479    |\n",
      "|    value_loss         | 1.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 42639360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013103815 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.709       |\n",
      "|    mean_step_reward   | 0.3770921   |\n",
      "|    n_updates          | 20816       |\n",
      "|    policyGradLoss     | -0.00545    |\n",
      "|    value_loss         | 1.97        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 42647552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011503456 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.733       |\n",
      "|    mean_step_reward   | 0.42293015  |\n",
      "|    n_updates          | 20820       |\n",
      "|    policyGradLoss     | -0.00553    |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 42655744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018401662 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.413       |\n",
      "|    mean_step_reward   | 0.43397593  |\n",
      "|    n_updates          | 20824       |\n",
      "|    policyGradLoss     | -0.00949    |\n",
      "|    value_loss         | 0.994       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 42663936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019133076 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.647       |\n",
      "|    mean_step_reward   | 0.37950248  |\n",
      "|    n_updates          | 20828       |\n",
      "|    policyGradLoss     | -0.00313    |\n",
      "|    value_loss         | 2.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 42672128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012467582 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.79        |\n",
      "|    mean_step_reward   | 0.4131316   |\n",
      "|    n_updates          | 20832       |\n",
      "|    policyGradLoss     | -0.00817    |\n",
      "|    value_loss         | 1.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 42680320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010862587 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.587       |\n",
      "|    mean_step_reward   | 0.35583544  |\n",
      "|    n_updates          | 20836       |\n",
      "|    policyGradLoss     | -0.00324    |\n",
      "|    value_loss         | 2.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 42688512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014524195 |\n",
      "|    entropy_loss       | -1.56       |\n",
      "|    explained_variance | 0.997       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.139       |\n",
      "|    mean_step_reward   | 0.50505245  |\n",
      "|    n_updates          | 20840       |\n",
      "|    policyGradLoss     | -0.00804    |\n",
      "|    value_loss         | 0.578       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 42696704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011069413 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.685       |\n",
      "|    mean_step_reward   | 0.36173153  |\n",
      "|    n_updates          | 20844       |\n",
      "|    policyGradLoss     | -0.00416    |\n",
      "|    value_loss         | 2.24        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 780        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 304        |\n",
      "|    total_timesteps    | 42704896   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02291617 |\n",
      "|    entropy_loss       | -1.53      |\n",
      "|    explained_variance | 0.996      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.198      |\n",
      "|    mean_step_reward   | 0.5117549  |\n",
      "|    n_updates          | 20848      |\n",
      "|    policyGradLoss     | -0.00885   |\n",
      "|    value_loss         | 0.667      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 42713088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013111396 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.46        |\n",
      "|    mean_step_reward   | 0.34747094  |\n",
      "|    n_updates          | 20852       |\n",
      "|    policyGradLoss     | -0.00502    |\n",
      "|    value_loss         | 1.99        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 42721280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016917529 |\n",
      "|    entropy_loss       | -1.57       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.11        |\n",
      "|    mean_step_reward   | 0.42412597  |\n",
      "|    n_updates          | 20856       |\n",
      "|    policyGradLoss     | -0.00615    |\n",
      "|    value_loss         | 1.04        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 42729472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014066733 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.433       |\n",
      "|    mean_step_reward   | 0.39095354  |\n",
      "|    n_updates          | 20860       |\n",
      "|    policyGradLoss     | -0.00447    |\n",
      "|    value_loss         | 1.3         |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_162.zip\n",
      "[EVAL] Mean Return: 543.879, Best Return: 551.213\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_162_543.88.mp4\n",
      "\n",
      "=== Round 164 | Learn 262144 steps (Total trained: 42729472) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1101     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 42737664 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 895         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 42745856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012835918 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.42        |\n",
      "|    mean_step_reward   | 0.41113663  |\n",
      "|    n_updates          | 20868       |\n",
      "|    policyGradLoss     | -0.00797    |\n",
      "|    value_loss         | 1.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 855         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 42754048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013252598 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.728       |\n",
      "|    mean_step_reward   | 0.36259604  |\n",
      "|    n_updates          | 20872       |\n",
      "|    policyGradLoss     | -0.00753    |\n",
      "|    value_loss         | 1.72        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 832         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 42762240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013634494 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.397       |\n",
      "|    mean_step_reward   | 0.43168595  |\n",
      "|    n_updates          | 20876       |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 1.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 42770432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027053665 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.298       |\n",
      "|    mean_step_reward   | 0.41824025  |\n",
      "|    n_updates          | 20880       |\n",
      "|    policyGradLoss     | -0.00205    |\n",
      "|    value_loss         | 1.07        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 42778624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015383483 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.1         |\n",
      "|    mean_step_reward   | 0.36743063  |\n",
      "|    n_updates          | 20884       |\n",
      "|    policyGradLoss     | -0.00553    |\n",
      "|    value_loss         | 2.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 42786816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015227243 |\n",
      "|    entropy_loss       | -1.57       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.164       |\n",
      "|    mean_step_reward   | 0.44455695  |\n",
      "|    n_updates          | 20888       |\n",
      "|    policyGradLoss     | -0.00306    |\n",
      "|    value_loss         | 0.888       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 42795008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010299391 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.848       |\n",
      "|    mean_step_reward   | 0.4275163   |\n",
      "|    n_updates          | 20892       |\n",
      "|    policyGradLoss     | -0.0053     |\n",
      "|    value_loss         | 1.88        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 42803200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018092358 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.14        |\n",
      "|    mean_step_reward   | 0.44522256  |\n",
      "|    n_updates          | 20896       |\n",
      "|    policyGradLoss     | -0.00693    |\n",
      "|    value_loss         | 1.43        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 42811392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015008479 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.444       |\n",
      "|    mean_step_reward   | 0.45860383  |\n",
      "|    n_updates          | 20900       |\n",
      "|    policyGradLoss     | -0.00705    |\n",
      "|    value_loss         | 1.11        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 112         |\n",
      "|    total_timesteps    | 42819584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015037743 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.15        |\n",
      "|    mean_step_reward   | 0.36636302  |\n",
      "|    n_updates          | 20904       |\n",
      "|    policyGradLoss     | -0.00606    |\n",
      "|    value_loss         | 2.04        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 42827776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021681394 |\n",
      "|    entropy_loss       | -1.56       |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0735      |\n",
      "|    mean_step_reward   | 0.43143642  |\n",
      "|    n_updates          | 20908       |\n",
      "|    policyGradLoss     | -0.00892    |\n",
      "|    value_loss         | 0.658       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 133         |\n",
      "|    total_timesteps    | 42835968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017078677 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.11        |\n",
      "|    mean_step_reward   | 0.38538542  |\n",
      "|    n_updates          | 20912       |\n",
      "|    policyGradLoss     | -0.00628    |\n",
      "|    value_loss         | 1.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 42844160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015890734 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.569       |\n",
      "|    mean_step_reward   | 0.36309552  |\n",
      "|    n_updates          | 20916       |\n",
      "|    policyGradLoss     | -0.00838    |\n",
      "|    value_loss         | 1.71        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 42852352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020267434 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.442       |\n",
      "|    mean_step_reward   | 0.43369108  |\n",
      "|    n_updates          | 20920       |\n",
      "|    policyGradLoss     | -0.00405    |\n",
      "|    value_loss         | 4.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 42860544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014276985 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.894       |\n",
      "|    mean_step_reward   | 0.35167456  |\n",
      "|    n_updates          | 20924       |\n",
      "|    policyGradLoss     | -0.00364    |\n",
      "|    value_loss         | 2.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 42868736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017920595 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.716       |\n",
      "|    mean_step_reward   | 0.41340685  |\n",
      "|    n_updates          | 20928       |\n",
      "|    policyGradLoss     | -0.00989    |\n",
      "|    value_loss         | 1.19        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 788        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 187        |\n",
      "|    total_timesteps    | 42876928   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01368324 |\n",
      "|    entropy_loss       | -1.63      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.83       |\n",
      "|    mean_step_reward   | 0.37218678 |\n",
      "|    n_updates          | 20932      |\n",
      "|    policyGradLoss     | -0.00763   |\n",
      "|    value_loss         | 1.59       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 786        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 197        |\n",
      "|    total_timesteps    | 42885120   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01789802 |\n",
      "|    entropy_loss       | -1.6       |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.586      |\n",
      "|    mean_step_reward   | 0.41399705 |\n",
      "|    n_updates          | 20936      |\n",
      "|    policyGradLoss     | -0.00626   |\n",
      "|    value_loss         | 1.19       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 785        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 208        |\n",
      "|    total_timesteps    | 42893312   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01470982 |\n",
      "|    entropy_loss       | -1.63      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.15       |\n",
      "|    mean_step_reward   | 0.37700212 |\n",
      "|    n_updates          | 20940      |\n",
      "|    policyGradLoss     | -0.0104    |\n",
      "|    value_loss         | 1.49       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 42901504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014086109 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.701       |\n",
      "|    mean_step_reward   | 0.37443733  |\n",
      "|    n_updates          | 20944       |\n",
      "|    policyGradLoss     | -0.0048     |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 42909696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014370902 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.22        |\n",
      "|    mean_step_reward   | 0.43126982  |\n",
      "|    n_updates          | 20948       |\n",
      "|    policyGradLoss     | -0.00981    |\n",
      "|    value_loss         | 1.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 42917888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015484443 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.902       |\n",
      "|    mean_step_reward   | 0.38948092  |\n",
      "|    n_updates          | 20952       |\n",
      "|    policyGradLoss     | -0.00626    |\n",
      "|    value_loss         | 1.82        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 250         |\n",
      "|    total_timesteps    | 42926080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014360262 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.467       |\n",
      "|    mean_step_reward   | 0.45728183  |\n",
      "|    n_updates          | 20956       |\n",
      "|    policyGradLoss     | -0.00592    |\n",
      "|    value_loss         | 1.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 42934272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010076593 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.72        |\n",
      "|    mean_step_reward   | 0.4262346   |\n",
      "|    n_updates          | 20960       |\n",
      "|    policyGradLoss     | -0.00298    |\n",
      "|    value_loss         | 1.8         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 42942464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011643163 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.853       |\n",
      "|    mean_step_reward   | 0.43285468  |\n",
      "|    n_updates          | 20964       |\n",
      "|    policyGradLoss     | -0.00602    |\n",
      "|    value_loss         | 2.07        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 42950656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011111718 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.581       |\n",
      "|    mean_step_reward   | 0.4170034   |\n",
      "|    n_updates          | 20968       |\n",
      "|    policyGradLoss     | -0.00698    |\n",
      "|    value_loss         | 1.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 42958848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018435586 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.452       |\n",
      "|    mean_step_reward   | 0.44159395  |\n",
      "|    n_updates          | 20972       |\n",
      "|    policyGradLoss     | -0.00965    |\n",
      "|    value_loss         | 1           |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 303         |\n",
      "|    total_timesteps    | 42967040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021122456 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.937       |\n",
      "|    mean_step_reward   | 0.40479565  |\n",
      "|    n_updates          | 20976       |\n",
      "|    policyGradLoss     | -0.00556    |\n",
      "|    value_loss         | 2.04        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 314         |\n",
      "|    total_timesteps    | 42975232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017562497 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.585       |\n",
      "|    mean_step_reward   | 0.46327865  |\n",
      "|    n_updates          | 20980       |\n",
      "|    policyGradLoss     | -0.00719    |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 780          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 325          |\n",
      "|    total_timesteps    | 42983424     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0103341155 |\n",
      "|    entropy_loss       | -1.63        |\n",
      "|    explained_variance | 0.991        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.747        |\n",
      "|    mean_step_reward   | 0.41741166   |\n",
      "|    n_updates          | 20984        |\n",
      "|    policyGradLoss     | -0.00559     |\n",
      "|    value_loss         | 1.79         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 42991616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010720542 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.807       |\n",
      "|    mean_step_reward   | 0.39863634  |\n",
      "|    n_updates          | 20988       |\n",
      "|    policyGradLoss     | -0.00367    |\n",
      "|    value_loss         | 2.3         |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_163.zip\n",
      "[EVAL] Mean Return: 542.999, Best Return: 549.666\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_163_543.00.mp4\n",
      "\n",
      "=== Round 165 | Learn 262144 steps (Total trained: 42991616) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1139     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 42999808 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 914         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 43008000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020244198 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.14        |\n",
      "|    mean_step_reward   | 0.37523225  |\n",
      "|    n_updates          | 20996       |\n",
      "|    policyGradLoss     | 0.0048      |\n",
      "|    value_loss         | 4.07        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 861         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 43016192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015114965 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.312       |\n",
      "|    mean_step_reward   | 0.4126759   |\n",
      "|    n_updates          | 21000       |\n",
      "|    policyGradLoss     | -0.00743    |\n",
      "|    value_loss         | 1.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 835         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 43024384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017874546 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.752       |\n",
      "|    mean_step_reward   | 0.35530287  |\n",
      "|    n_updates          | 21004       |\n",
      "|    policyGradLoss     | -0.000985   |\n",
      "|    value_loss         | 3.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 43032576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013913941 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.542       |\n",
      "|    mean_step_reward   | 0.40602058  |\n",
      "|    n_updates          | 21008       |\n",
      "|    policyGradLoss     | -0.00278    |\n",
      "|    value_loss         | 2.09        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 809        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 43040768   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01457932 |\n",
      "|    entropy_loss       | -1.59      |\n",
      "|    explained_variance | 0.993      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.448      |\n",
      "|    mean_step_reward   | 0.44880432 |\n",
      "|    n_updates          | 21012      |\n",
      "|    policyGradLoss     | -0.00829   |\n",
      "|    value_loss         | 1.29       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 804          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 71           |\n",
      "|    total_timesteps    | 43048960     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0135871675 |\n",
      "|    entropy_loss       | -1.63        |\n",
      "|    explained_variance | 0.99         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.66         |\n",
      "|    mean_step_reward   | 0.3883577    |\n",
      "|    n_updates          | 21016        |\n",
      "|    policyGradLoss     | -0.00775     |\n",
      "|    value_loss         | 1.5          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 43057152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018014895 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.275       |\n",
      "|    mean_step_reward   | 0.389198    |\n",
      "|    n_updates          | 21020       |\n",
      "|    policyGradLoss     | -0.00924    |\n",
      "|    value_loss         | 1.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 43065344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016621958 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.783       |\n",
      "|    mean_step_reward   | 0.38846824  |\n",
      "|    n_updates          | 21024       |\n",
      "|    policyGradLoss     | -0.00935    |\n",
      "|    value_loss         | 1.5         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 43073536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014011487 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.342       |\n",
      "|    mean_step_reward   | 0.44993043  |\n",
      "|    n_updates          | 21028       |\n",
      "|    policyGradLoss     | -0.00739    |\n",
      "|    value_loss         | 1.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 43081728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010780036 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.711       |\n",
      "|    mean_step_reward   | 0.4383427   |\n",
      "|    n_updates          | 21032       |\n",
      "|    policyGradLoss     | -0.00745    |\n",
      "|    value_loss         | 1.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 43089920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018047119 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.816       |\n",
      "|    mean_step_reward   | 0.36726782  |\n",
      "|    n_updates          | 21036       |\n",
      "|    policyGradLoss     | -0.00696    |\n",
      "|    value_loss         | 1.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 43098112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013278028 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.325       |\n",
      "|    mean_step_reward   | 0.4372186   |\n",
      "|    n_updates          | 21040       |\n",
      "|    policyGradLoss     | -0.00736    |\n",
      "|    value_loss         | 1.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 43106304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009317378 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.28        |\n",
      "|    mean_step_reward   | 0.36858553  |\n",
      "|    n_updates          | 21044       |\n",
      "|    policyGradLoss     | -0.005      |\n",
      "|    value_loss         | 1.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 43114496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018127233 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.666       |\n",
      "|    mean_step_reward   | 0.3657747   |\n",
      "|    n_updates          | 21048       |\n",
      "|    policyGradLoss     | -0.00689    |\n",
      "|    value_loss         | 1.52        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 788        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 166        |\n",
      "|    total_timesteps    | 43122688   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01987568 |\n",
      "|    entropy_loss       | -1.62      |\n",
      "|    explained_variance | 0.995      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.473      |\n",
      "|    mean_step_reward   | 0.40008342 |\n",
      "|    n_updates          | 21052      |\n",
      "|    policyGradLoss     | -0.0128    |\n",
      "|    value_loss         | 0.813      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 43130880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010997718 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.73        |\n",
      "|    mean_step_reward   | 0.37827295  |\n",
      "|    n_updates          | 21056       |\n",
      "|    policyGradLoss     | -0.00385    |\n",
      "|    value_loss         | 1.98        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 787        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 187        |\n",
      "|    total_timesteps    | 43139072   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01683084 |\n",
      "|    entropy_loss       | -1.62      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.59       |\n",
      "|    mean_step_reward   | 0.40870655 |\n",
      "|    n_updates          | 21060      |\n",
      "|    policyGradLoss     | -0.00628   |\n",
      "|    value_loss         | 1.39       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 197         |\n",
      "|    total_timesteps    | 43147264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013494454 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.02        |\n",
      "|    mean_step_reward   | 0.41675943  |\n",
      "|    n_updates          | 21064       |\n",
      "|    policyGradLoss     | -0.0039     |\n",
      "|    value_loss         | 4.81        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 786        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 208        |\n",
      "|    total_timesteps    | 43155456   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01919451 |\n",
      "|    entropy_loss       | -1.59      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.645      |\n",
      "|    mean_step_reward   | 0.47347033 |\n",
      "|    n_updates          | 21068      |\n",
      "|    policyGradLoss     | -0.00236   |\n",
      "|    value_loss         | 1.83       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 785        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 218        |\n",
      "|    total_timesteps    | 43163648   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01223495 |\n",
      "|    entropy_loss       | -1.61      |\n",
      "|    explained_variance | 0.982      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.505      |\n",
      "|    mean_step_reward   | 0.43352208 |\n",
      "|    n_updates          | 21072      |\n",
      "|    policyGradLoss     | -0.00305   |\n",
      "|    value_loss         | 2.39       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 43171840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011069487 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.888       |\n",
      "|    mean_step_reward   | 0.37380257  |\n",
      "|    n_updates          | 21076       |\n",
      "|    policyGradLoss     | -0.00534    |\n",
      "|    value_loss         | 1.53        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 43180032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020041782 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.631       |\n",
      "|    mean_step_reward   | 0.41381067  |\n",
      "|    n_updates          | 21080       |\n",
      "|    policyGradLoss     | -0.00534    |\n",
      "|    value_loss         | 1.53        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 783        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 250        |\n",
      "|    total_timesteps    | 43188224   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0194058  |\n",
      "|    entropy_loss       | -1.65      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.819      |\n",
      "|    mean_step_reward   | 0.42802966 |\n",
      "|    n_updates          | 21084      |\n",
      "|    policyGradLoss     | -0.00463   |\n",
      "|    value_loss         | 2.32       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 783        |\n",
      "|    iterations         | 25         |\n",
      "|    time_elapsed       | 261        |\n",
      "|    total_timesteps    | 43196416   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0120872  |\n",
      "|    entropy_loss       | -1.62      |\n",
      "|    explained_variance | 0.99       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.988      |\n",
      "|    mean_step_reward   | 0.43855822 |\n",
      "|    n_updates          | 21088      |\n",
      "|    policyGradLoss     | -0.00521   |\n",
      "|    value_loss         | 1.45       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 43204608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018296298 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.66        |\n",
      "|    mean_step_reward   | 0.4571395   |\n",
      "|    n_updates          | 21092       |\n",
      "|    policyGradLoss     | -0.00684    |\n",
      "|    value_loss         | 1.94        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 783        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 282        |\n",
      "|    total_timesteps    | 43212800   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01504197 |\n",
      "|    entropy_loss       | -1.6       |\n",
      "|    explained_variance | 0.986      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.497      |\n",
      "|    mean_step_reward   | 0.39560074 |\n",
      "|    n_updates          | 21096      |\n",
      "|    policyGradLoss     | -0.00718   |\n",
      "|    value_loss         | 1.81       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 43220992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014857077 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.468       |\n",
      "|    mean_step_reward   | 0.45742598  |\n",
      "|    n_updates          | 21100       |\n",
      "|    policyGradLoss     | -0.00737    |\n",
      "|    value_loss         | 1.36        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 783        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 303        |\n",
      "|    total_timesteps    | 43229184   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01577232 |\n",
      "|    entropy_loss       | -1.66      |\n",
      "|    explained_variance | 0.985      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.05       |\n",
      "|    mean_step_reward   | 0.360733   |\n",
      "|    n_updates          | 21104      |\n",
      "|    policyGradLoss     | -0.00505   |\n",
      "|    value_loss         | 2.2        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 313         |\n",
      "|    total_timesteps    | 43237376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020556346 |\n",
      "|    entropy_loss       | -1.56       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.425       |\n",
      "|    mean_step_reward   | 0.45496944  |\n",
      "|    n_updates          | 21108       |\n",
      "|    policyGradLoss     | -0.0051     |\n",
      "|    value_loss         | 1.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 324         |\n",
      "|    total_timesteps    | 43245568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014856937 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.26        |\n",
      "|    mean_step_reward   | 0.32455996  |\n",
      "|    n_updates          | 21112       |\n",
      "|    policyGradLoss     | -0.00223    |\n",
      "|    value_loss         | 1.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 335         |\n",
      "|    total_timesteps    | 43253760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022408579 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.425       |\n",
      "|    mean_step_reward   | 0.43374854  |\n",
      "|    n_updates          | 21116       |\n",
      "|    policyGradLoss     | -0.00723    |\n",
      "|    value_loss         | 1.46        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_164.zip\n",
      "[EVAL] Mean Return: 542.791, Best Return: 549.458\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_164_542.79.mp4\n",
      "\n",
      "=== Round 166 | Learn 262144 steps (Total trained: 43253760) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1086     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 43261952 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 908         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 43270144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013504708 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.557       |\n",
      "|    mean_step_reward   | 0.3902916   |\n",
      "|    n_updates          | 21124       |\n",
      "|    policyGradLoss     | -0.00468    |\n",
      "|    value_loss         | 2.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 860         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 43278336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013812662 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.385       |\n",
      "|    mean_step_reward   | 0.47263178  |\n",
      "|    n_updates          | 21128       |\n",
      "|    policyGradLoss     | -0.0079     |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 842         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 43286528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014417546 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.542       |\n",
      "|    mean_step_reward   | 0.39298153  |\n",
      "|    n_updates          | 21132       |\n",
      "|    policyGradLoss     | -0.00341    |\n",
      "|    value_loss         | 1.97        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 43294720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018733134 |\n",
      "|    entropy_loss       | -1.56       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.464       |\n",
      "|    mean_step_reward   | 0.4734923   |\n",
      "|    n_updates          | 21136       |\n",
      "|    policyGradLoss     | -0.00306    |\n",
      "|    value_loss         | 2.66        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 43302912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010675395 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.875       |\n",
      "|    mean_step_reward   | 0.38468966  |\n",
      "|    n_updates          | 21140       |\n",
      "|    policyGradLoss     | -0.000782   |\n",
      "|    value_loss         | 2.75        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 43311104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022851892 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.309       |\n",
      "|    mean_step_reward   | 0.42622358  |\n",
      "|    n_updates          | 21144       |\n",
      "|    policyGradLoss     | -0.00726    |\n",
      "|    value_loss         | 0.819       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 43319296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017420307 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 5.12        |\n",
      "|    mean_step_reward   | 0.3583621   |\n",
      "|    n_updates          | 21148       |\n",
      "|    policyGradLoss     | -0.00286    |\n",
      "|    value_loss         | 5.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 43327488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016701829 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.698       |\n",
      "|    mean_step_reward   | 0.37641436  |\n",
      "|    n_updates          | 21152       |\n",
      "|    policyGradLoss     | -0.00491    |\n",
      "|    value_loss         | 1.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 43335680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019808881 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.344       |\n",
      "|    mean_step_reward   | 0.44151908  |\n",
      "|    n_updates          | 21156       |\n",
      "|    policyGradLoss     | -0.00412    |\n",
      "|    value_loss         | 1.11        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 796          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 113          |\n",
      "|    total_timesteps    | 43343872     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0134870345 |\n",
      "|    entropy_loss       | -1.63        |\n",
      "|    explained_variance | 0.984        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.08         |\n",
      "|    mean_step_reward   | 0.38952363   |\n",
      "|    n_updates          | 21160        |\n",
      "|    policyGradLoss     | -0.00524     |\n",
      "|    value_loss         | 2.24         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 43352064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017986067 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.268       |\n",
      "|    mean_step_reward   | 0.39854956  |\n",
      "|    n_updates          | 21164       |\n",
      "|    policyGradLoss     | -0.00892    |\n",
      "|    value_loss         | 1.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 43360256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011362782 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.862       |\n",
      "|    mean_step_reward   | 0.39736387  |\n",
      "|    n_updates          | 21168       |\n",
      "|    policyGradLoss     | -0.00338    |\n",
      "|    value_loss         | 2.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 43368448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015183525 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.578       |\n",
      "|    mean_step_reward   | 0.39508992  |\n",
      "|    n_updates          | 21172       |\n",
      "|    policyGradLoss     | -0.00536    |\n",
      "|    value_loss         | 1.8         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 43376640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017839089 |\n",
      "|    entropy_loss       | -1.56       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.272       |\n",
      "|    mean_step_reward   | 0.43551195  |\n",
      "|    n_updates          | 21176       |\n",
      "|    policyGradLoss     | -0.00542    |\n",
      "|    value_loss         | 1.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 43384832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014267537 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.932       |\n",
      "|    mean_step_reward   | 0.4026276   |\n",
      "|    n_updates          | 21180       |\n",
      "|    policyGradLoss     | -0.00601    |\n",
      "|    value_loss         | 1.74        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 789        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 176        |\n",
      "|    total_timesteps    | 43393024   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01993934 |\n",
      "|    entropy_loss       | -1.59      |\n",
      "|    explained_variance | 0.993      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.451      |\n",
      "|    mean_step_reward   | 0.45095545 |\n",
      "|    n_updates          | 21184      |\n",
      "|    policyGradLoss     | -0.00793   |\n",
      "|    value_loss         | 1.23       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 43401216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012292266 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.23        |\n",
      "|    mean_step_reward   | 0.42063785  |\n",
      "|    n_updates          | 21188       |\n",
      "|    policyGradLoss     | -0.00283    |\n",
      "|    value_loss         | 3.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 43409408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015012449 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.16        |\n",
      "|    mean_step_reward   | 0.43778777  |\n",
      "|    n_updates          | 21192       |\n",
      "|    policyGradLoss     | -0.0023     |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 43417600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014650371 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.305       |\n",
      "|    mean_step_reward   | 0.3761654   |\n",
      "|    n_updates          | 21196       |\n",
      "|    policyGradLoss     | -0.00444    |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 218         |\n",
      "|    total_timesteps    | 43425792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012910912 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1           |\n",
      "|    mean_step_reward   | 0.38390994  |\n",
      "|    n_updates          | 21200       |\n",
      "|    policyGradLoss     | -0.00663    |\n",
      "|    value_loss         | 1.43        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 43433984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015078233 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.644       |\n",
      "|    mean_step_reward   | 0.43536657  |\n",
      "|    n_updates          | 21204       |\n",
      "|    policyGradLoss     | -0.00625    |\n",
      "|    value_loss         | 1.72        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 239         |\n",
      "|    total_timesteps    | 43442176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012068129 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.434       |\n",
      "|    mean_step_reward   | 0.4156303   |\n",
      "|    n_updates          | 21208       |\n",
      "|    policyGradLoss     | -0.00563    |\n",
      "|    value_loss         | 1.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 250         |\n",
      "|    total_timesteps    | 43450368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011863289 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.44        |\n",
      "|    mean_step_reward   | 0.3633351   |\n",
      "|    n_updates          | 21212       |\n",
      "|    policyGradLoss     | -0.00598    |\n",
      "|    value_loss         | 1.64        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 43458560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013954787 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.182       |\n",
      "|    mean_step_reward   | 0.40494567  |\n",
      "|    n_updates          | 21216       |\n",
      "|    policyGradLoss     | -0.0062     |\n",
      "|    value_loss         | 1.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 43466752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014166142 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.78        |\n",
      "|    mean_step_reward   | 0.38638094  |\n",
      "|    n_updates          | 21220       |\n",
      "|    policyGradLoss     | -0.00653    |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 43474944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019161481 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.303       |\n",
      "|    mean_step_reward   | 0.4341018   |\n",
      "|    n_updates          | 21224       |\n",
      "|    policyGradLoss     | -0.00838    |\n",
      "|    value_loss         | 0.909       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 43483136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017817322 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.435       |\n",
      "|    mean_step_reward   | 0.36280608  |\n",
      "|    n_updates          | 21228       |\n",
      "|    policyGradLoss     | -0.00761    |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 783        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 303        |\n",
      "|    total_timesteps    | 43491328   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01838893 |\n",
      "|    entropy_loss       | -1.56      |\n",
      "|    explained_variance | 0.993      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.369      |\n",
      "|    mean_step_reward   | 0.413071   |\n",
      "|    n_updates          | 21232      |\n",
      "|    policyGradLoss     | -0.00848   |\n",
      "|    value_loss         | 0.961      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 314         |\n",
      "|    total_timesteps    | 43499520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012660924 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.16        |\n",
      "|    mean_step_reward   | 0.38007975  |\n",
      "|    n_updates          | 21236       |\n",
      "|    policyGradLoss     | -0.00556    |\n",
      "|    value_loss         | 2.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 324         |\n",
      "|    total_timesteps    | 43507712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013613053 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.481       |\n",
      "|    mean_step_reward   | 0.44107717  |\n",
      "|    n_updates          | 21240       |\n",
      "|    policyGradLoss     | -0.00799    |\n",
      "|    value_loss         | 1.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 335         |\n",
      "|    total_timesteps    | 43515904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014542952 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.7         |\n",
      "|    mean_step_reward   | 0.38244855  |\n",
      "|    n_updates          | 21244       |\n",
      "|    policyGradLoss     | -0.00526    |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_165.zip\n",
      "[EVAL] Mean Return: 543.193, Best Return: 550.527\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_165_543.19.mp4\n",
      "\n",
      "=== Round 167 | Learn 262144 steps (Total trained: 43515904) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1161     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 43524096 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 928         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 43532288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014016049 |\n",
      "|    entropy_loss       | -1.57       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.528       |\n",
      "|    mean_step_reward   | 0.4316551   |\n",
      "|    n_updates          | 21252       |\n",
      "|    policyGradLoss     | -0.00682    |\n",
      "|    value_loss         | 1.45        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 876         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 43540480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021641478 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.201       |\n",
      "|    mean_step_reward   | 0.36852032  |\n",
      "|    n_updates          | 21256       |\n",
      "|    policyGradLoss     | -0.00723    |\n",
      "|    value_loss         | 1.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 843         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 43548672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014665723 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.536       |\n",
      "|    mean_step_reward   | 0.45249736  |\n",
      "|    n_updates          | 21260       |\n",
      "|    policyGradLoss     | -0.00636    |\n",
      "|    value_loss         | 1.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 835         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 43556864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017885135 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.13        |\n",
      "|    mean_step_reward   | 0.40805346  |\n",
      "|    n_updates          | 21264       |\n",
      "|    policyGradLoss     | -0.00494    |\n",
      "|    value_loss         | 1.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 823         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 43565056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012272401 |\n",
      "|    entropy_loss       | -1.56       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.54        |\n",
      "|    mean_step_reward   | 0.47916812  |\n",
      "|    n_updates          | 21268       |\n",
      "|    policyGradLoss     | -0.00678    |\n",
      "|    value_loss         | 1.15        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 814        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 70         |\n",
      "|    total_timesteps    | 43573248   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01640677 |\n",
      "|    entropy_loss       | -1.63      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.954      |\n",
      "|    mean_step_reward   | 0.40088958 |\n",
      "|    n_updates          | 21272      |\n",
      "|    policyGradLoss     | -0.00288   |\n",
      "|    value_loss         | 2.31       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 807          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 81           |\n",
      "|    total_timesteps    | 43581440     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0130875325 |\n",
      "|    entropy_loss       | -1.58        |\n",
      "|    explained_variance | 0.991        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.377        |\n",
      "|    mean_step_reward   | 0.40630656   |\n",
      "|    n_updates          | 21276        |\n",
      "|    policyGradLoss     | -0.00626     |\n",
      "|    value_loss         | 1.2          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 43589632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016194424 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.789       |\n",
      "|    mean_step_reward   | 0.44060814  |\n",
      "|    n_updates          | 21280       |\n",
      "|    policyGradLoss     | -0.00473    |\n",
      "|    value_loss         | 1.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 43597824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012849845 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.712       |\n",
      "|    mean_step_reward   | 0.4114451   |\n",
      "|    n_updates          | 21284       |\n",
      "|    policyGradLoss     | -0.00434    |\n",
      "|    value_loss         | 1.55        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 112         |\n",
      "|    total_timesteps    | 43606016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013832652 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.297       |\n",
      "|    mean_step_reward   | 0.41237986  |\n",
      "|    n_updates          | 21288       |\n",
      "|    policyGradLoss     | -0.00675    |\n",
      "|    value_loss         | 1.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 43614208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019349054 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.839       |\n",
      "|    mean_step_reward   | 0.35096496  |\n",
      "|    n_updates          | 21292       |\n",
      "|    policyGradLoss     | -0.00888    |\n",
      "|    value_loss         | 1.07        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 133         |\n",
      "|    total_timesteps    | 43622400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025505804 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.129       |\n",
      "|    mean_step_reward   | 0.41454226  |\n",
      "|    n_updates          | 21296       |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.857       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 43630592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011069538 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.12        |\n",
      "|    mean_step_reward   | 0.3819577   |\n",
      "|    n_updates          | 21300       |\n",
      "|    policyGradLoss     | -0.00261    |\n",
      "|    value_loss         | 2.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 43638784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010772865 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.892       |\n",
      "|    mean_step_reward   | 0.39602625  |\n",
      "|    n_updates          | 21304       |\n",
      "|    policyGradLoss     | -0.00702    |\n",
      "|    value_loss         | 1.56        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 790          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 165          |\n",
      "|    total_timesteps    | 43646976     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0131795835 |\n",
      "|    entropy_loss       | -1.62        |\n",
      "|    explained_variance | 0.992        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.237        |\n",
      "|    mean_step_reward   | 0.43988472   |\n",
      "|    n_updates          | 21308        |\n",
      "|    policyGradLoss     | -0.00641     |\n",
      "|    value_loss         | 1.46         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 43655168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014327543 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.909       |\n",
      "|    mean_step_reward   | 0.44996977  |\n",
      "|    n_updates          | 21312       |\n",
      "|    policyGradLoss     | -0.00757    |\n",
      "|    value_loss         | 1.63        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 788          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 186          |\n",
      "|    total_timesteps    | 43663360     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0099654365 |\n",
      "|    entropy_loss       | -1.6         |\n",
      "|    explained_variance | 0.993        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.55         |\n",
      "|    mean_step_reward   | 0.43789172   |\n",
      "|    n_updates          | 21316        |\n",
      "|    policyGradLoss     | -0.00646     |\n",
      "|    value_loss         | 1.44         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 197         |\n",
      "|    total_timesteps    | 43671552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019005992 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.857       |\n",
      "|    mean_step_reward   | 0.38403237  |\n",
      "|    n_updates          | 21320       |\n",
      "|    policyGradLoss     | -0.00639    |\n",
      "|    value_loss         | 1.52        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 788          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 207          |\n",
      "|    total_timesteps    | 43679744     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0146317575 |\n",
      "|    entropy_loss       | -1.6         |\n",
      "|    explained_variance | 0.994        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.351        |\n",
      "|    mean_step_reward   | 0.43031627   |\n",
      "|    n_updates          | 21324        |\n",
      "|    policyGradLoss     | -0.00788     |\n",
      "|    value_loss         | 1.14         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 218         |\n",
      "|    total_timesteps    | 43687936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017470386 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.881       |\n",
      "|    mean_step_reward   | 0.4147782   |\n",
      "|    n_updates          | 21328       |\n",
      "|    policyGradLoss     | -0.000238   |\n",
      "|    value_loss         | 5.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 228         |\n",
      "|    total_timesteps    | 43696128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013947524 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.12        |\n",
      "|    mean_step_reward   | 0.454714    |\n",
      "|    n_updates          | 21332       |\n",
      "|    policyGradLoss     | -0.00551    |\n",
      "|    value_loss         | 1.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 239         |\n",
      "|    total_timesteps    | 43704320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012049893 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.895       |\n",
      "|    mean_step_reward   | 0.422335    |\n",
      "|    n_updates          | 21336       |\n",
      "|    policyGradLoss     | -0.00708    |\n",
      "|    value_loss         | 1.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 249         |\n",
      "|    total_timesteps    | 43712512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012083583 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.471       |\n",
      "|    mean_step_reward   | 0.3703309   |\n",
      "|    n_updates          | 21340       |\n",
      "|    policyGradLoss     | -0.00634    |\n",
      "|    value_loss         | 1.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 260         |\n",
      "|    total_timesteps    | 43720704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013923379 |\n",
      "|    entropy_loss       | -1.57       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.298       |\n",
      "|    mean_step_reward   | 0.42351758  |\n",
      "|    n_updates          | 21344       |\n",
      "|    policyGradLoss     | -0.00839    |\n",
      "|    value_loss         | 0.981       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 786        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 270        |\n",
      "|    total_timesteps    | 43728896   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01245642 |\n",
      "|    entropy_loss       | -1.65      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.09       |\n",
      "|    mean_step_reward   | 0.41923544 |\n",
      "|    n_updates          | 21348      |\n",
      "|    policyGradLoss     | -0.00527   |\n",
      "|    value_loss         | 2.14       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 281         |\n",
      "|    total_timesteps    | 43737088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011068289 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.699       |\n",
      "|    mean_step_reward   | 0.4669615   |\n",
      "|    n_updates          | 21352       |\n",
      "|    policyGradLoss     | -0.00454    |\n",
      "|    value_loss         | 1.82        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 43745280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013467263 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.641       |\n",
      "|    mean_step_reward   | 0.4632511   |\n",
      "|    n_updates          | 21356       |\n",
      "|    policyGradLoss     | -0.00357    |\n",
      "|    value_loss         | 2.01        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 784       |\n",
      "|    iterations         | 29        |\n",
      "|    time_elapsed       | 302       |\n",
      "|    total_timesteps    | 43753472  |\n",
      "| train/                |           |\n",
      "|    approx_kl          | 0.0174622 |\n",
      "|    entropy_loss       | -1.62     |\n",
      "|    explained_variance | 0.988     |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    loss               | 0.255     |\n",
      "|    mean_step_reward   | 0.3840071 |\n",
      "|    n_updates          | 21360     |\n",
      "|    policyGradLoss     | -0.00593  |\n",
      "|    value_loss         | 1.68      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 784        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 313        |\n",
      "|    total_timesteps    | 43761664   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02091837 |\n",
      "|    entropy_loss       | -1.6       |\n",
      "|    explained_variance | 0.994      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.8        |\n",
      "|    mean_step_reward   | 0.3809467  |\n",
      "|    n_updates          | 21364      |\n",
      "|    policyGradLoss     | -0.0107    |\n",
      "|    value_loss         | 0.836      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 785        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 323        |\n",
      "|    total_timesteps    | 43769856   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01563136 |\n",
      "|    entropy_loss       | -1.65      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.738      |\n",
      "|    mean_step_reward   | 0.39341885 |\n",
      "|    n_updates          | 21368      |\n",
      "|    policyGradLoss     | -0.00702   |\n",
      "|    value_loss         | 1.37       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 334         |\n",
      "|    total_timesteps    | 43778048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015124205 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.222       |\n",
      "|    mean_step_reward   | 0.43027171  |\n",
      "|    n_updates          | 21372       |\n",
      "|    policyGradLoss     | -0.007      |\n",
      "|    value_loss         | 1.56        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_166.zip\n",
      "[EVAL] Mean Return: 537.822, Best Return: 545.156\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_166_537.82.mp4\n",
      "\n",
      "=== Round 168 | Learn 262144 steps (Total trained: 43778048) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1124     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 43786240 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 900         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 43794432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012308968 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.142       |\n",
      "|    mean_step_reward   | 0.42525023  |\n",
      "|    n_updates          | 21380       |\n",
      "|    policyGradLoss     | -0.00593    |\n",
      "|    value_loss         | 1.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 857         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 43802624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016675808 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.703       |\n",
      "|    mean_step_reward   | 0.3994795   |\n",
      "|    n_updates          | 21384       |\n",
      "|    policyGradLoss     | -0.00677    |\n",
      "|    value_loss         | 2.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 836         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 43810816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014195999 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.698       |\n",
      "|    mean_step_reward   | 0.44052428  |\n",
      "|    n_updates          | 21388       |\n",
      "|    policyGradLoss     | -0.00375    |\n",
      "|    value_loss         | 2.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 827         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 43819008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015486885 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.507       |\n",
      "|    mean_step_reward   | 0.39758074  |\n",
      "|    n_updates          | 21392       |\n",
      "|    policyGradLoss     | -0.00606    |\n",
      "|    value_loss         | 2.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 43827200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019126194 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.431       |\n",
      "|    mean_step_reward   | 0.38540086  |\n",
      "|    n_updates          | 21396       |\n",
      "|    policyGradLoss     | -0.00923    |\n",
      "|    value_loss         | 1.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 43835392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017334642 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.987       |\n",
      "|    mean_step_reward   | 0.4107669   |\n",
      "|    n_updates          | 21400       |\n",
      "|    policyGradLoss     | -0.00642    |\n",
      "|    value_loss         | 1.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 43843584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011962155 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.865       |\n",
      "|    mean_step_reward   | 0.4578333   |\n",
      "|    n_updates          | 21404       |\n",
      "|    policyGradLoss     | -0.00538    |\n",
      "|    value_loss         | 1.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 43851776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013791289 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.448       |\n",
      "|    mean_step_reward   | 0.4652858   |\n",
      "|    n_updates          | 21408       |\n",
      "|    policyGradLoss     | -0.00439    |\n",
      "|    value_loss         | 1.11        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 43859968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011053431 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.966       |\n",
      "|    mean_step_reward   | 0.4339151   |\n",
      "|    n_updates          | 21412       |\n",
      "|    policyGradLoss     | 0.0079      |\n",
      "|    value_loss         | 2.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 112         |\n",
      "|    total_timesteps    | 43868160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016260777 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.699       |\n",
      "|    mean_step_reward   | 0.45736936  |\n",
      "|    n_updates          | 21416       |\n",
      "|    policyGradLoss     | -0.00662    |\n",
      "|    value_loss         | 2.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 43876352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013575604 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.725       |\n",
      "|    mean_step_reward   | 0.41239625  |\n",
      "|    n_updates          | 21420       |\n",
      "|    policyGradLoss     | -0.00531    |\n",
      "|    value_loss         | 2.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 133         |\n",
      "|    total_timesteps    | 43884544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017117038 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.589       |\n",
      "|    mean_step_reward   | 0.33540216  |\n",
      "|    n_updates          | 21424       |\n",
      "|    policyGradLoss     | -0.0023     |\n",
      "|    value_loss         | 1.84        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 43892736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015708257 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.433       |\n",
      "|    mean_step_reward   | 0.41911238  |\n",
      "|    n_updates          | 21428       |\n",
      "|    policyGradLoss     | -0.000103   |\n",
      "|    value_loss         | 3.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 43900928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015729021 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.666       |\n",
      "|    mean_step_reward   | 0.404319    |\n",
      "|    n_updates          | 21432       |\n",
      "|    policyGradLoss     | 0.00829     |\n",
      "|    value_loss         | 2.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 43909120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018873237 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.463       |\n",
      "|    mean_step_reward   | 0.4292177   |\n",
      "|    n_updates          | 21436       |\n",
      "|    policyGradLoss     | 0.00398     |\n",
      "|    value_loss         | 4.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 43917312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014970561 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.856       |\n",
      "|    mean_step_reward   | 0.3615201   |\n",
      "|    n_updates          | 21440       |\n",
      "|    policyGradLoss     | 0.00263     |\n",
      "|    value_loss         | 4.72        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 186         |\n",
      "|    total_timesteps    | 43925504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017930344 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.321       |\n",
      "|    mean_step_reward   | 0.41595042  |\n",
      "|    n_updates          | 21444       |\n",
      "|    policyGradLoss     | -0.00136    |\n",
      "|    value_loss         | 2.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 197         |\n",
      "|    total_timesteps    | 43933696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019114662 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.858       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 2.47        |\n",
      "|    mean_step_reward   | 0.3666064   |\n",
      "|    n_updates          | 21448       |\n",
      "|    policyGradLoss     | 0.0112      |\n",
      "|    value_loss         | 10.6        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 43941888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015085658 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1           |\n",
      "|    mean_step_reward   | 0.36670506  |\n",
      "|    n_updates          | 21452       |\n",
      "|    policyGradLoss     | -0.000931   |\n",
      "|    value_loss         | 3.04        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 43950080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020422842 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.25        |\n",
      "|    mean_step_reward   | 0.46620327  |\n",
      "|    n_updates          | 21456       |\n",
      "|    policyGradLoss     | 0.00734     |\n",
      "|    value_loss         | 7.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 43958272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010358028 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.446       |\n",
      "|    mean_step_reward   | 0.3406809   |\n",
      "|    n_updates          | 21460       |\n",
      "|    policyGradLoss     | -0.000233   |\n",
      "|    value_loss         | 2.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 43966464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016465224 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.25        |\n",
      "|    mean_step_reward   | 0.490036    |\n",
      "|    n_updates          | 21464       |\n",
      "|    policyGradLoss     | -0.00146    |\n",
      "|    value_loss         | 1.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 250         |\n",
      "|    total_timesteps    | 43974656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010367539 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.558       |\n",
      "|    mean_step_reward   | 0.3088133   |\n",
      "|    n_updates          | 21468       |\n",
      "|    policyGradLoss     | -0.00499    |\n",
      "|    value_loss         | 2.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 43982848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016180484 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.29        |\n",
      "|    mean_step_reward   | 0.41966742  |\n",
      "|    n_updates          | 21472       |\n",
      "|    policyGradLoss     | -0.00711    |\n",
      "|    value_loss         | 1.19        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 782          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 272          |\n",
      "|    total_timesteps    | 43991040     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0104176905 |\n",
      "|    entropy_loss       | -1.68        |\n",
      "|    explained_variance | 0.99         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.718        |\n",
      "|    mean_step_reward   | 0.41590002   |\n",
      "|    n_updates          | 21476        |\n",
      "|    policyGradLoss     | -0.00569     |\n",
      "|    value_loss         | 1.65         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 43999232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012834033 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.518       |\n",
      "|    mean_step_reward   | 0.3695183   |\n",
      "|    n_updates          | 21480       |\n",
      "|    policyGradLoss     | -0.00573    |\n",
      "|    value_loss         | 1.93        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 44007424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016763927 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.28        |\n",
      "|    mean_step_reward   | 0.46087885  |\n",
      "|    n_updates          | 21484       |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 1.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 44015616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014197864 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.16        |\n",
      "|    mean_step_reward   | 0.30092776  |\n",
      "|    n_updates          | 21488       |\n",
      "|    policyGradLoss     | -0.000364   |\n",
      "|    value_loss         | 2.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 44023808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020552605 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0887      |\n",
      "|    mean_step_reward   | 0.40261865  |\n",
      "|    n_updates          | 21492       |\n",
      "|    policyGradLoss     | -0.0137     |\n",
      "|    value_loss         | 0.509       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 44032000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015242763 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.719       |\n",
      "|    mean_step_reward   | 0.32287294  |\n",
      "|    n_updates          | 21496       |\n",
      "|    policyGradLoss     | -0.00766    |\n",
      "|    value_loss         | 1.76        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 335         |\n",
      "|    total_timesteps    | 44040192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016105916 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.799       |\n",
      "|    mean_step_reward   | 0.41541395  |\n",
      "|    n_updates          | 21500       |\n",
      "|    policyGradLoss     | -0.00818    |\n",
      "|    value_loss         | 1.53        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_167.zip\n",
      "[EVAL] Mean Return: 542.622, Best Return: 549.955\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_167_542.62.mp4\n",
      "\n",
      "=== Round 169 | Learn 262144 steps (Total trained: 44040192) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1164     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 44048384 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 953         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 44056576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017765494 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.754       |\n",
      "|    mean_step_reward   | 0.34407324  |\n",
      "|    n_updates          | 21508       |\n",
      "|    policyGradLoss     | -0.00768    |\n",
      "|    value_loss         | 1.55        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 874         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 44064768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016087385 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0637      |\n",
      "|    mean_step_reward   | 0.38589358  |\n",
      "|    n_updates          | 21512       |\n",
      "|    policyGradLoss     | -0.00813    |\n",
      "|    value_loss         | 0.996       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 845         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 44072960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016213976 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.85        |\n",
      "|    mean_step_reward   | 0.37906513  |\n",
      "|    n_updates          | 21516       |\n",
      "|    policyGradLoss     | -0.0072     |\n",
      "|    value_loss         | 1.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 833         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 44081152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012349341 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.548       |\n",
      "|    mean_step_reward   | 0.4233859   |\n",
      "|    n_updates          | 21520       |\n",
      "|    policyGradLoss     | -0.00678    |\n",
      "|    value_loss         | 1.41        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 826        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 59         |\n",
      "|    total_timesteps    | 44089344   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01419048 |\n",
      "|    entropy_loss       | -1.63      |\n",
      "|    explained_variance | 0.99       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.44       |\n",
      "|    mean_step_reward   | 0.4609415  |\n",
      "|    n_updates          | 21524      |\n",
      "|    policyGradLoss     | -0.00619   |\n",
      "|    value_loss         | 1.75       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 44097536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012193395 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.807       |\n",
      "|    mean_step_reward   | 0.4294051   |\n",
      "|    n_updates          | 21528       |\n",
      "|    policyGradLoss     | -0.00927    |\n",
      "|    value_loss         | 1.76        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 80          |\n",
      "|    total_timesteps    | 44105728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016234409 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.887       |\n",
      "|    mean_step_reward   | 0.4186548   |\n",
      "|    n_updates          | 21532       |\n",
      "|    policyGradLoss     | -0.00754    |\n",
      "|    value_loss         | 1.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 90          |\n",
      "|    total_timesteps    | 44113920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021828424 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.04        |\n",
      "|    mean_step_reward   | 0.44229633  |\n",
      "|    n_updates          | 21536       |\n",
      "|    policyGradLoss     | -0.00282    |\n",
      "|    value_loss         | 1.59        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 806        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 101        |\n",
      "|    total_timesteps    | 44122112   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02131528 |\n",
      "|    entropy_loss       | -1.61      |\n",
      "|    explained_variance | 0.992      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.276      |\n",
      "|    mean_step_reward   | 0.41519737 |\n",
      "|    n_updates          | 21540      |\n",
      "|    policyGradLoss     | -0.00772   |\n",
      "|    value_loss         | 1.22       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 111         |\n",
      "|    total_timesteps    | 44130304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009367028 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.545       |\n",
      "|    mean_step_reward   | 0.40503582  |\n",
      "|    n_updates          | 21544       |\n",
      "|    policyGradLoss     | -0.00616    |\n",
      "|    value_loss         | 1.99        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 122         |\n",
      "|    total_timesteps    | 44138496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013948068 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.02        |\n",
      "|    mean_step_reward   | 0.47084293  |\n",
      "|    n_updates          | 21548       |\n",
      "|    policyGradLoss     | -0.00889    |\n",
      "|    value_loss         | 1.84        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 132         |\n",
      "|    total_timesteps    | 44146688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012894839 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.474       |\n",
      "|    mean_step_reward   | 0.42731047  |\n",
      "|    n_updates          | 21552       |\n",
      "|    policyGradLoss     | -0.00703    |\n",
      "|    value_loss         | 1.66        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 143         |\n",
      "|    total_timesteps    | 44154880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013923953 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.676       |\n",
      "|    mean_step_reward   | 0.4001993   |\n",
      "|    n_updates          | 21556       |\n",
      "|    policyGradLoss     | -0.00619    |\n",
      "|    value_loss         | 1.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 153         |\n",
      "|    total_timesteps    | 44163072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022197071 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.933       |\n",
      "|    mean_step_reward   | 0.45905128  |\n",
      "|    n_updates          | 21560       |\n",
      "|    policyGradLoss     | -0.00936    |\n",
      "|    value_loss         | 1.07        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 798          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 164          |\n",
      "|    total_timesteps    | 44171264     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0141261015 |\n",
      "|    entropy_loss       | -1.66        |\n",
      "|    explained_variance | 0.989        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.02         |\n",
      "|    mean_step_reward   | 0.38407195   |\n",
      "|    n_updates          | 21564        |\n",
      "|    policyGradLoss     | -0.00639     |\n",
      "|    value_loss         | 1.71         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 174         |\n",
      "|    total_timesteps    | 44179456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018486734 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.282       |\n",
      "|    mean_step_reward   | 0.40307492  |\n",
      "|    n_updates          | 21568       |\n",
      "|    policyGradLoss     | -0.0114     |\n",
      "|    value_loss         | 1.32        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 796        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 185        |\n",
      "|    total_timesteps    | 44187648   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0111926  |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.524      |\n",
      "|    mean_step_reward   | 0.45141688 |\n",
      "|    n_updates          | 21572      |\n",
      "|    policyGradLoss     | -0.0082    |\n",
      "|    value_loss         | 1.86       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 195         |\n",
      "|    total_timesteps    | 44195840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014740681 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.935       |\n",
      "|    mean_step_reward   | 0.41652566  |\n",
      "|    n_updates          | 21576       |\n",
      "|    policyGradLoss     | -0.00603    |\n",
      "|    value_loss         | 1.51        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 795        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 206        |\n",
      "|    total_timesteps    | 44204032   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01605786 |\n",
      "|    entropy_loss       | -1.6       |\n",
      "|    explained_variance | 0.992      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.826      |\n",
      "|    mean_step_reward   | 0.41299787 |\n",
      "|    n_updates          | 21580      |\n",
      "|    policyGradLoss     | -0.00994   |\n",
      "|    value_loss         | 0.981      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 793        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 216        |\n",
      "|    total_timesteps    | 44212224   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01307803 |\n",
      "|    entropy_loss       | -1.66      |\n",
      "|    explained_variance | 0.988      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.3        |\n",
      "|    mean_step_reward   | 0.40484405 |\n",
      "|    n_updates          | 21584      |\n",
      "|    policyGradLoss     | -0.00488   |\n",
      "|    value_loss         | 2.03       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 227         |\n",
      "|    total_timesteps    | 44220416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019562397 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.912       |\n",
      "|    mean_step_reward   | 0.44863257  |\n",
      "|    n_updates          | 21588       |\n",
      "|    policyGradLoss     | -0.00471    |\n",
      "|    value_loss         | 2.83        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 237         |\n",
      "|    total_timesteps    | 44228608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012017017 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.53        |\n",
      "|    mean_step_reward   | 0.41386893  |\n",
      "|    n_updates          | 21592       |\n",
      "|    policyGradLoss     | -0.00257    |\n",
      "|    value_loss         | 2.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 247         |\n",
      "|    total_timesteps    | 44236800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017462777 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.846       |\n",
      "|    mean_step_reward   | 0.43822366  |\n",
      "|    n_updates          | 21596       |\n",
      "|    policyGradLoss     | -0.00875    |\n",
      "|    value_loss         | 1.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 258         |\n",
      "|    total_timesteps    | 44244992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009555341 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.829       |\n",
      "|    mean_step_reward   | 0.42924502  |\n",
      "|    n_updates          | 21600       |\n",
      "|    policyGradLoss     | -0.00628    |\n",
      "|    value_loss         | 2.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 268         |\n",
      "|    total_timesteps    | 44253184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012100601 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.54        |\n",
      "|    mean_step_reward   | 0.4383732   |\n",
      "|    n_updates          | 21604       |\n",
      "|    policyGradLoss     | -0.00443    |\n",
      "|    value_loss         | 1.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 279         |\n",
      "|    total_timesteps    | 44261376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012494344 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.864       |\n",
      "|    mean_step_reward   | 0.42956418  |\n",
      "|    n_updates          | 21608       |\n",
      "|    policyGradLoss     | -0.00488    |\n",
      "|    value_loss         | 1.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 289         |\n",
      "|    total_timesteps    | 44269568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015864464 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.977       |\n",
      "|    mean_step_reward   | 0.40765703  |\n",
      "|    n_updates          | 21612       |\n",
      "|    policyGradLoss     | -0.00526    |\n",
      "|    value_loss         | 2.09        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 300         |\n",
      "|    total_timesteps    | 44277760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018600728 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.773       |\n",
      "|    mean_step_reward   | 0.41546887  |\n",
      "|    n_updates          | 21616       |\n",
      "|    policyGradLoss     | -0.00927    |\n",
      "|    value_loss         | 1.39        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 789        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 311        |\n",
      "|    total_timesteps    | 44285952   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01265314 |\n",
      "|    entropy_loss       | -1.62      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.688      |\n",
      "|    mean_step_reward   | 0.47317386 |\n",
      "|    n_updates          | 21620      |\n",
      "|    policyGradLoss     | -0.00457   |\n",
      "|    value_loss         | 1.8        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 321         |\n",
      "|    total_timesteps    | 44294144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022635642 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0685      |\n",
      "|    mean_step_reward   | 0.40440312  |\n",
      "|    n_updates          | 21624       |\n",
      "|    policyGradLoss     | -0.00804    |\n",
      "|    value_loss         | 1.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 331         |\n",
      "|    total_timesteps    | 44302336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015338216 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.433       |\n",
      "|    mean_step_reward   | 0.46553603  |\n",
      "|    n_updates          | 21628       |\n",
      "|    policyGradLoss     | -0.00434    |\n",
      "|    value_loss         | 1.33        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_168.zip\n",
      "[EVAL] Mean Return: 545.408, Best Return: 552.075\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_168_545.41.mp4\n",
      "\n",
      "=== Round 170 | Learn 262144 steps (Total trained: 44302336) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1145     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 44310528 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 918         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 44318720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012947025 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.379       |\n",
      "|    mean_step_reward   | 0.43453738  |\n",
      "|    n_updates          | 21636       |\n",
      "|    policyGradLoss     | -0.00698    |\n",
      "|    value_loss         | 1.6         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 869        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 44326912   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01588399 |\n",
      "|    entropy_loss       | -1.61      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.628      |\n",
      "|    mean_step_reward   | 0.45787126 |\n",
      "|    n_updates          | 21640      |\n",
      "|    policyGradLoss     | -0.00551   |\n",
      "|    value_loss         | 1.9        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 844         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 44335104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016719166 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.558       |\n",
      "|    mean_step_reward   | 0.45870513  |\n",
      "|    n_updates          | 21644       |\n",
      "|    policyGradLoss     | -0.00591    |\n",
      "|    value_loss         | 1.83        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 833          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 49           |\n",
      "|    total_timesteps    | 44343296     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0142736025 |\n",
      "|    entropy_loss       | -1.62        |\n",
      "|    explained_variance | 0.988        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.497        |\n",
      "|    mean_step_reward   | 0.3929338    |\n",
      "|    n_updates          | 21648        |\n",
      "|    policyGradLoss     | -0.00442     |\n",
      "|    value_loss         | 1.74         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 44351488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017273165 |\n",
      "|    entropy_loss       | -1.57       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.115       |\n",
      "|    mean_step_reward   | 0.4116769   |\n",
      "|    n_updates          | 21652       |\n",
      "|    policyGradLoss     | -0.0117     |\n",
      "|    value_loss         | 0.75        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 44359680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014915628 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.399       |\n",
      "|    mean_step_reward   | 0.36740178  |\n",
      "|    n_updates          | 21656       |\n",
      "|    policyGradLoss     | -0.0079     |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 44367872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016697807 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.309       |\n",
      "|    mean_step_reward   | 0.46873736  |\n",
      "|    n_updates          | 21660       |\n",
      "|    policyGradLoss     | -0.00626    |\n",
      "|    value_loss         | 1.43        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 44376064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015462568 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.87        |\n",
      "|    mean_step_reward   | 0.41943783  |\n",
      "|    n_updates          | 21664       |\n",
      "|    policyGradLoss     | -0.00625    |\n",
      "|    value_loss         | 1.45        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 44384256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014643572 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.44        |\n",
      "|    mean_step_reward   | 0.39630413  |\n",
      "|    n_updates          | 21668       |\n",
      "|    policyGradLoss     | -0.00543    |\n",
      "|    value_loss         | 1.46        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 112         |\n",
      "|    total_timesteps    | 44392448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022160266 |\n",
      "|    entropy_loss       | -1.57       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.373       |\n",
      "|    mean_step_reward   | 0.46363965  |\n",
      "|    n_updates          | 21672       |\n",
      "|    policyGradLoss     | -0.00824    |\n",
      "|    value_loss         | 0.984       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 44400640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009683957 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.92        |\n",
      "|    mean_step_reward   | 0.39510974  |\n",
      "|    n_updates          | 21676       |\n",
      "|    policyGradLoss     | -0.00542    |\n",
      "|    value_loss         | 2.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 44408832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021239333 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.285       |\n",
      "|    mean_step_reward   | 0.47080943  |\n",
      "|    n_updates          | 21680       |\n",
      "|    policyGradLoss     | -0.00836    |\n",
      "|    value_loss         | 1.02        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 793        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 144        |\n",
      "|    total_timesteps    | 44417024   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01555753 |\n",
      "|    entropy_loss       | -1.64      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.223      |\n",
      "|    mean_step_reward   | 0.40414008 |\n",
      "|    n_updates          | 21684      |\n",
      "|    policyGradLoss     | -0.00765   |\n",
      "|    value_loss         | 1.5        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 44425216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016342716 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.309       |\n",
      "|    mean_step_reward   | 0.41826978  |\n",
      "|    n_updates          | 21688       |\n",
      "|    policyGradLoss     | -0.00151    |\n",
      "|    value_loss         | 3.28        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 791          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 165          |\n",
      "|    total_timesteps    | 44433408     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0151578775 |\n",
      "|    entropy_loss       | -1.62        |\n",
      "|    explained_variance | 0.98         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.356        |\n",
      "|    mean_step_reward   | 0.39069775   |\n",
      "|    n_updates          | 21692        |\n",
      "|    policyGradLoss     | -0.0052      |\n",
      "|    value_loss         | 2.15         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 44441600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015969146 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.318       |\n",
      "|    mean_step_reward   | 0.406724    |\n",
      "|    n_updates          | 21696       |\n",
      "|    policyGradLoss     | -0.0063     |\n",
      "|    value_loss         | 1.52        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 44449792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016053844 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.491       |\n",
      "|    mean_step_reward   | 0.4249088   |\n",
      "|    n_updates          | 21700       |\n",
      "|    policyGradLoss     | -0.00717    |\n",
      "|    value_loss         | 1.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 197         |\n",
      "|    total_timesteps    | 44457984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015267763 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.194       |\n",
      "|    mean_step_reward   | 0.38299066  |\n",
      "|    n_updates          | 21704       |\n",
      "|    policyGradLoss     | -0.00858    |\n",
      "|    value_loss         | 1.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 44466176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012027359 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.439       |\n",
      "|    mean_step_reward   | 0.42456603  |\n",
      "|    n_updates          | 21708       |\n",
      "|    policyGradLoss     | -0.00677    |\n",
      "|    value_loss         | 1.6         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 786          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 218          |\n",
      "|    total_timesteps    | 44474368     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0145324655 |\n",
      "|    entropy_loss       | -1.6         |\n",
      "|    explained_variance | 0.99         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.359        |\n",
      "|    mean_step_reward   | 0.40669826   |\n",
      "|    n_updates          | 21712        |\n",
      "|    policyGradLoss     | -0.00586     |\n",
      "|    value_loss         | 1.48         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 786        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 229        |\n",
      "|    total_timesteps    | 44482560   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01229379 |\n",
      "|    entropy_loss       | -1.61      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.341      |\n",
      "|    mean_step_reward   | 0.4346375  |\n",
      "|    n_updates          | 21716      |\n",
      "|    policyGradLoss     | -0.00315   |\n",
      "|    value_loss         | 1.65       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 239         |\n",
      "|    total_timesteps    | 44490752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013770561 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.37        |\n",
      "|    mean_step_reward   | 0.36806592  |\n",
      "|    n_updates          | 21720       |\n",
      "|    policyGradLoss     | -0.00436    |\n",
      "|    value_loss         | 1.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 250         |\n",
      "|    total_timesteps    | 44498944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015289427 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.36        |\n",
      "|    mean_step_reward   | 0.42271265  |\n",
      "|    n_updates          | 21724       |\n",
      "|    policyGradLoss     | -0.00336    |\n",
      "|    value_loss         | 1.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 260         |\n",
      "|    total_timesteps    | 44507136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021940954 |\n",
      "|    entropy_loss       | -1.57       |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.536       |\n",
      "|    mean_step_reward   | 0.43437943  |\n",
      "|    n_updates          | 21728       |\n",
      "|    policyGradLoss     | -0.00896    |\n",
      "|    value_loss         | 0.873       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 44515328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015955027 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.44        |\n",
      "|    mean_step_reward   | 0.42102885  |\n",
      "|    n_updates          | 21732       |\n",
      "|    policyGradLoss     | -0.00511    |\n",
      "|    value_loss         | 1.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 281         |\n",
      "|    total_timesteps    | 44523520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015419981 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.5         |\n",
      "|    mean_step_reward   | 0.47903702  |\n",
      "|    n_updates          | 21736       |\n",
      "|    policyGradLoss     | -0.0063     |\n",
      "|    value_loss         | 1.46        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 44531712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017464807 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.787       |\n",
      "|    mean_step_reward   | 0.3717608   |\n",
      "|    n_updates          | 21740       |\n",
      "|    policyGradLoss     | -0.00496    |\n",
      "|    value_loss         | 2.07        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 303         |\n",
      "|    total_timesteps    | 44539904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015649267 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.428       |\n",
      "|    mean_step_reward   | 0.41680038  |\n",
      "|    n_updates          | 21744       |\n",
      "|    policyGradLoss     | -0.006      |\n",
      "|    value_loss         | 1.18        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 783          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 313          |\n",
      "|    total_timesteps    | 44548096     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0121732205 |\n",
      "|    entropy_loss       | -1.62        |\n",
      "|    explained_variance | 0.99         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.514        |\n",
      "|    mean_step_reward   | 0.39620543   |\n",
      "|    n_updates          | 21748        |\n",
      "|    policyGradLoss     | -0.00609     |\n",
      "|    value_loss         | 1.59         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 323         |\n",
      "|    total_timesteps    | 44556288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013209483 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.747       |\n",
      "|    mean_step_reward   | 0.40585545  |\n",
      "|    n_updates          | 21752       |\n",
      "|    policyGradLoss     | -0.00666    |\n",
      "|    value_loss         | 1.59        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 334         |\n",
      "|    total_timesteps    | 44564480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019728389 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.45        |\n",
      "|    mean_step_reward   | 0.44139162  |\n",
      "|    n_updates          | 21756       |\n",
      "|    policyGradLoss     | -0.00865    |\n",
      "|    value_loss         | 1.35        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_169.zip\n",
      "[EVAL] Mean Return: 542.523, Best Return: 549.190\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_169_542.52.mp4\n",
      "\n",
      "=== Round 171 | Learn 262144 steps (Total trained: 44564480) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1161     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 44572672 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 925         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 44580864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014012416 |\n",
      "|    entropy_loss       | -1.57       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.509       |\n",
      "|    mean_step_reward   | 0.43773627  |\n",
      "|    n_updates          | 21764       |\n",
      "|    policyGradLoss     | -0.000824   |\n",
      "|    value_loss         | 2.16        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 873          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 44589056     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0153451925 |\n",
      "|    entropy_loss       | -1.66        |\n",
      "|    explained_variance | 0.987        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.867        |\n",
      "|    mean_step_reward   | 0.38236898   |\n",
      "|    n_updates          | 21768        |\n",
      "|    policyGradLoss     | -0.00482     |\n",
      "|    value_loss         | 2            |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 842         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 44597248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023031995 |\n",
      "|    entropy_loss       | -1.56       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.268       |\n",
      "|    mean_step_reward   | 0.39994782  |\n",
      "|    n_updates          | 21772       |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.582       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 829         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 44605440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012431342 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.927       |\n",
      "|    mean_step_reward   | 0.44151202  |\n",
      "|    n_updates          | 21776       |\n",
      "|    policyGradLoss     | -0.00234    |\n",
      "|    value_loss         | 1.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 44613632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011629838 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.868       |\n",
      "|    mean_step_reward   | 0.41836149  |\n",
      "|    n_updates          | 21780       |\n",
      "|    policyGradLoss     | -0.00266    |\n",
      "|    value_loss         | 2.11        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 44621824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018223334 |\n",
      "|    entropy_loss       | -1.56       |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.126       |\n",
      "|    mean_step_reward   | 0.46723598  |\n",
      "|    n_updates          | 21784       |\n",
      "|    policyGradLoss     | -0.00765    |\n",
      "|    value_loss         | 0.9         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 806        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 81         |\n",
      "|    total_timesteps    | 44630016   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0148775  |\n",
      "|    entropy_loss       | -1.62      |\n",
      "|    explained_variance | 0.963      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 3.94       |\n",
      "|    mean_step_reward   | 0.40205854 |\n",
      "|    n_updates          | 21788      |\n",
      "|    policyGradLoss     | -0.00369   |\n",
      "|    value_loss         | 6.22       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 44638208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022860698 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.202       |\n",
      "|    mean_step_reward   | 0.4273236   |\n",
      "|    n_updates          | 21792       |\n",
      "|    policyGradLoss     | -0.00242    |\n",
      "|    value_loss         | 1.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 44646400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015701868 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.311       |\n",
      "|    mean_step_reward   | 0.382874    |\n",
      "|    n_updates          | 21796       |\n",
      "|    policyGradLoss     | -0.00885    |\n",
      "|    value_loss         | 1.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 112         |\n",
      "|    total_timesteps    | 44654592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021823775 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.357       |\n",
      "|    mean_step_reward   | 0.4384447   |\n",
      "|    n_updates          | 21800       |\n",
      "|    policyGradLoss     | -0.00579    |\n",
      "|    value_loss         | 1.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 122         |\n",
      "|    total_timesteps    | 44662784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026585484 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.573       |\n",
      "|    mean_step_reward   | 0.4058673   |\n",
      "|    n_updates          | 21804       |\n",
      "|    policyGradLoss     | -0.00929    |\n",
      "|    value_loss         | 1.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 133         |\n",
      "|    total_timesteps    | 44670976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014471295 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.416       |\n",
      "|    mean_step_reward   | 0.3961056   |\n",
      "|    n_updates          | 21808       |\n",
      "|    policyGradLoss     | -0.00836    |\n",
      "|    value_loss         | 1.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 143         |\n",
      "|    total_timesteps    | 44679168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015276545 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.13        |\n",
      "|    mean_step_reward   | 0.41922843  |\n",
      "|    n_updates          | 21812       |\n",
      "|    policyGradLoss     | -0.00684    |\n",
      "|    value_loss         | 2.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 44687360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015230872 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.643       |\n",
      "|    mean_step_reward   | 0.4153728   |\n",
      "|    n_updates          | 21816       |\n",
      "|    policyGradLoss     | -0.00802    |\n",
      "|    value_loss         | 1.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 164         |\n",
      "|    total_timesteps    | 44695552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017849606 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.338       |\n",
      "|    mean_step_reward   | 0.3911425   |\n",
      "|    n_updates          | 21820       |\n",
      "|    policyGradLoss     | -0.0051     |\n",
      "|    value_loss         | 1.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 175         |\n",
      "|    total_timesteps    | 44703744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014595857 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.445       |\n",
      "|    mean_step_reward   | 0.43075523  |\n",
      "|    n_updates          | 21824       |\n",
      "|    policyGradLoss     | -0.00752    |\n",
      "|    value_loss         | 1.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 186         |\n",
      "|    total_timesteps    | 44711936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013944984 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.258       |\n",
      "|    mean_step_reward   | 0.4246534   |\n",
      "|    n_updates          | 21828       |\n",
      "|    policyGradLoss     | -0.00788    |\n",
      "|    value_loss         | 1.24        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 790        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 196        |\n",
      "|    total_timesteps    | 44720128   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01712463 |\n",
      "|    entropy_loss       | -1.6       |\n",
      "|    explained_variance | 0.992      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.341      |\n",
      "|    mean_step_reward   | 0.41683242 |\n",
      "|    n_updates          | 21832      |\n",
      "|    policyGradLoss     | -0.00749   |\n",
      "|    value_loss         | 1.51       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 790       |\n",
      "|    iterations         | 20        |\n",
      "|    time_elapsed       | 207       |\n",
      "|    total_timesteps    | 44728320  |\n",
      "| train/                |           |\n",
      "|    approx_kl          | 0.0164833 |\n",
      "|    entropy_loss       | -1.59     |\n",
      "|    explained_variance | 0.991     |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    loss               | 0.949     |\n",
      "|    mean_step_reward   | 0.4024687 |\n",
      "|    n_updates          | 21836     |\n",
      "|    policyGradLoss     | -0.00612  |\n",
      "|    value_loss         | 1.56      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 789        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 217        |\n",
      "|    total_timesteps    | 44736512   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02131252 |\n",
      "|    entropy_loss       | -1.61      |\n",
      "|    explained_variance | 0.992      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.457      |\n",
      "|    mean_step_reward   | 0.38647363 |\n",
      "|    n_updates          | 21840      |\n",
      "|    policyGradLoss     | -0.00949   |\n",
      "|    value_loss         | 1.06       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 789        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 228        |\n",
      "|    total_timesteps    | 44744704   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01803189 |\n",
      "|    entropy_loss       | -1.58      |\n",
      "|    explained_variance | 0.992      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.815      |\n",
      "|    mean_step_reward   | 0.45566308 |\n",
      "|    n_updates          | 21844      |\n",
      "|    policyGradLoss     | -0.00814   |\n",
      "|    value_loss         | 1.34       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 239         |\n",
      "|    total_timesteps    | 44752896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021403693 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.657       |\n",
      "|    mean_step_reward   | 0.41509557  |\n",
      "|    n_updates          | 21848       |\n",
      "|    policyGradLoss     | -0.00622    |\n",
      "|    value_loss         | 1.73        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 787        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 249        |\n",
      "|    total_timesteps    | 44761088   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01601499 |\n",
      "|    entropy_loss       | -1.61      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.711      |\n",
      "|    mean_step_reward   | 0.37386864 |\n",
      "|    n_updates          | 21852      |\n",
      "|    policyGradLoss     | -0.00795   |\n",
      "|    value_loss         | 1.21       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 787        |\n",
      "|    iterations         | 25         |\n",
      "|    time_elapsed       | 259        |\n",
      "|    total_timesteps    | 44769280   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02010576 |\n",
      "|    entropy_loss       | -1.63      |\n",
      "|    explained_variance | 0.993      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.417      |\n",
      "|    mean_step_reward   | 0.3765354  |\n",
      "|    n_updates          | 21856      |\n",
      "|    policyGradLoss     | -0.00899   |\n",
      "|    value_loss         | 1.1        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 270         |\n",
      "|    total_timesteps    | 44777472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018319525 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.284       |\n",
      "|    mean_step_reward   | 0.3716173   |\n",
      "|    n_updates          | 21860       |\n",
      "|    policyGradLoss     | -0.008      |\n",
      "|    value_loss         | 1.33        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 788        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 280        |\n",
      "|    total_timesteps    | 44785664   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01684428 |\n",
      "|    entropy_loss       | -1.58      |\n",
      "|    explained_variance | 0.992      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.56       |\n",
      "|    mean_step_reward   | 0.45645523 |\n",
      "|    n_updates          | 21864      |\n",
      "|    policyGradLoss     | -0.00679   |\n",
      "|    value_loss         | 1.21       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 291         |\n",
      "|    total_timesteps    | 44793856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013370464 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.14        |\n",
      "|    mean_step_reward   | 0.42797834  |\n",
      "|    n_updates          | 21868       |\n",
      "|    policyGradLoss     | -0.00621    |\n",
      "|    value_loss         | 1.55        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 301         |\n",
      "|    total_timesteps    | 44802048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016762316 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.293       |\n",
      "|    mean_step_reward   | 0.41187015  |\n",
      "|    n_updates          | 21872       |\n",
      "|    policyGradLoss     | -0.00774    |\n",
      "|    value_loss         | 1.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 312         |\n",
      "|    total_timesteps    | 44810240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010456925 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.802       |\n",
      "|    mean_step_reward   | 0.45994112  |\n",
      "|    n_updates          | 21876       |\n",
      "|    policyGradLoss     | -0.00228    |\n",
      "|    value_loss         | 3.34        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 786          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 322          |\n",
      "|    total_timesteps    | 44818432     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0123716965 |\n",
      "|    entropy_loss       | -1.6         |\n",
      "|    explained_variance | 0.965        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.597        |\n",
      "|    mean_step_reward   | 0.42612475   |\n",
      "|    n_updates          | 21880        |\n",
      "|    policyGradLoss     | -0.00216     |\n",
      "|    value_loss         | 3.7          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 785          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 333          |\n",
      "|    total_timesteps    | 44826624     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0140855415 |\n",
      "|    entropy_loss       | -1.62        |\n",
      "|    explained_variance | 0.989        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.816        |\n",
      "|    mean_step_reward   | 0.42169356   |\n",
      "|    n_updates          | 21884        |\n",
      "|    policyGradLoss     | -0.00689     |\n",
      "|    value_loss         | 1.41         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_170.zip\n",
      "[EVAL] Mean Return: 538.829, Best Return: 545.495\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_170_538.83.mp4\n",
      "\n",
      "=== Round 172 | Learn 262144 steps (Total trained: 44826624) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1106     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 44834816 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 912         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 44843008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012572829 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.28        |\n",
      "|    mean_step_reward   | 0.3409308   |\n",
      "|    n_updates          | 21892       |\n",
      "|    policyGradLoss     | -5.05e-05   |\n",
      "|    value_loss         | 1.8         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 861         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 44851200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011666356 |\n",
      "|    entropy_loss       | -1.57       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.58        |\n",
      "|    mean_step_reward   | 0.45744258  |\n",
      "|    n_updates          | 21896       |\n",
      "|    policyGradLoss     | -0.00267    |\n",
      "|    value_loss         | 1.83        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 840         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 44859392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009118808 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.5         |\n",
      "|    mean_step_reward   | 0.46192792  |\n",
      "|    n_updates          | 21900       |\n",
      "|    policyGradLoss     | -0.000536   |\n",
      "|    value_loss         | 2.34        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 829         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 44867584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012445152 |\n",
      "|    entropy_loss       | -1.57       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.438       |\n",
      "|    mean_step_reward   | 0.44388336  |\n",
      "|    n_updates          | 21904       |\n",
      "|    policyGradLoss     | -0.00817    |\n",
      "|    value_loss         | 1.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 44875776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024790233 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.757       |\n",
      "|    mean_step_reward   | 0.4183377   |\n",
      "|    n_updates          | 21908       |\n",
      "|    policyGradLoss     | -0.0109     |\n",
      "|    value_loss         | 1.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 44883968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011483805 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.356       |\n",
      "|    mean_step_reward   | 0.41171145  |\n",
      "|    n_updates          | 21912       |\n",
      "|    policyGradLoss     | -0.00536    |\n",
      "|    value_loss         | 1.46        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 80          |\n",
      "|    total_timesteps    | 44892160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015455355 |\n",
      "|    entropy_loss       | -1.56       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.409       |\n",
      "|    mean_step_reward   | 0.43788254  |\n",
      "|    n_updates          | 21916       |\n",
      "|    policyGradLoss     | -0.00881    |\n",
      "|    value_loss         | 1.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 44900352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017086254 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.611       |\n",
      "|    mean_step_reward   | 0.44500118  |\n",
      "|    n_updates          | 21920       |\n",
      "|    policyGradLoss     | -0.00759    |\n",
      "|    value_loss         | 1.52        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 101         |\n",
      "|    total_timesteps    | 44908544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011775951 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.6         |\n",
      "|    mean_step_reward   | 0.43981734  |\n",
      "|    n_updates          | 21924       |\n",
      "|    policyGradLoss     | -0.00425    |\n",
      "|    value_loss         | 1.59        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 112         |\n",
      "|    total_timesteps    | 44916736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022682361 |\n",
      "|    entropy_loss       | -1.57       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.68        |\n",
      "|    mean_step_reward   | 0.47584745  |\n",
      "|    n_updates          | 21928       |\n",
      "|    policyGradLoss     | -0.00104    |\n",
      "|    value_loss         | 5.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 122         |\n",
      "|    total_timesteps    | 44924928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011103689 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.55        |\n",
      "|    mean_step_reward   | 0.4310838   |\n",
      "|    n_updates          | 21932       |\n",
      "|    policyGradLoss     | -0.00538    |\n",
      "|    value_loss         | 1.71        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 133         |\n",
      "|    total_timesteps    | 44933120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014885627 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.705       |\n",
      "|    mean_step_reward   | 0.46549547  |\n",
      "|    n_updates          | 21936       |\n",
      "|    policyGradLoss     | -0.00541    |\n",
      "|    value_loss         | 1.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 44941312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012990439 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.04        |\n",
      "|    mean_step_reward   | 0.40074775  |\n",
      "|    n_updates          | 21940       |\n",
      "|    policyGradLoss     | -0.00621    |\n",
      "|    value_loss         | 1.82        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 44949504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017893218 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.114       |\n",
      "|    mean_step_reward   | 0.43415016  |\n",
      "|    n_updates          | 21944       |\n",
      "|    policyGradLoss     | -0.00717    |\n",
      "|    value_loss         | 1.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 44957696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011632693 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.93        |\n",
      "|    mean_step_reward   | 0.4210117   |\n",
      "|    n_updates          | 21948       |\n",
      "|    policyGradLoss     | -0.00637    |\n",
      "|    value_loss         | 1.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 44965888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013975834 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.346       |\n",
      "|    mean_step_reward   | 0.4352752   |\n",
      "|    n_updates          | 21952       |\n",
      "|    policyGradLoss     | -0.00759    |\n",
      "|    value_loss         | 1.44        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 788        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 186        |\n",
      "|    total_timesteps    | 44974080   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01597038 |\n",
      "|    entropy_loss       | -1.62      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.748      |\n",
      "|    mean_step_reward   | 0.39112583 |\n",
      "|    n_updates          | 21956      |\n",
      "|    policyGradLoss     | -0.00633   |\n",
      "|    value_loss         | 1.71       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 197         |\n",
      "|    total_timesteps    | 44982272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015349554 |\n",
      "|    entropy_loss       | -1.56       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.637       |\n",
      "|    mean_step_reward   | 0.47539243  |\n",
      "|    n_updates          | 21960       |\n",
      "|    policyGradLoss     | -0.00719    |\n",
      "|    value_loss         | 1.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 44990464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015952969 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.883       |\n",
      "|    mean_step_reward   | 0.39885056  |\n",
      "|    n_updates          | 21964       |\n",
      "|    policyGradLoss     | -0.00578    |\n",
      "|    value_loss         | 1.88        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 218         |\n",
      "|    total_timesteps    | 44998656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014106075 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.616       |\n",
      "|    mean_step_reward   | 0.42553055  |\n",
      "|    n_updates          | 21968       |\n",
      "|    policyGradLoss     | -0.00667    |\n",
      "|    value_loss         | 1.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 45006848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018002585 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.565       |\n",
      "|    mean_step_reward   | 0.39164692  |\n",
      "|    n_updates          | 21972       |\n",
      "|    policyGradLoss     | -0.00513    |\n",
      "|    value_loss         | 1.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 239         |\n",
      "|    total_timesteps    | 45015040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019592937 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.84        |\n",
      "|    mean_step_reward   | 0.42959613  |\n",
      "|    n_updates          | 21976       |\n",
      "|    policyGradLoss     | -0.0067     |\n",
      "|    value_loss         | 1.41        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 785        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 250        |\n",
      "|    total_timesteps    | 45023232   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01217642 |\n",
      "|    entropy_loss       | -1.62      |\n",
      "|    explained_variance | 0.985      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.463      |\n",
      "|    mean_step_reward   | 0.3907832  |\n",
      "|    n_updates          | 21980      |\n",
      "|    policyGradLoss     | -0.00586   |\n",
      "|    value_loss         | 1.73       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 260         |\n",
      "|    total_timesteps    | 45031424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015091233 |\n",
      "|    entropy_loss       | -1.55       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.265       |\n",
      "|    mean_step_reward   | 0.43196788  |\n",
      "|    n_updates          | 21984       |\n",
      "|    policyGradLoss     | -0.00693    |\n",
      "|    value_loss         | 1.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 45039616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009827453 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.46        |\n",
      "|    mean_step_reward   | 0.44118446  |\n",
      "|    n_updates          | 21988       |\n",
      "|    policyGradLoss     | -0.004      |\n",
      "|    value_loss         | 1.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 281         |\n",
      "|    total_timesteps    | 45047808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009413952 |\n",
      "|    entropy_loss       | -1.57       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.36        |\n",
      "|    mean_step_reward   | 0.43993703  |\n",
      "|    n_updates          | 21992       |\n",
      "|    policyGradLoss     | -0.0021     |\n",
      "|    value_loss         | 1.94        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 45056000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013295369 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.442       |\n",
      "|    mean_step_reward   | 0.43148786  |\n",
      "|    n_updates          | 21996       |\n",
      "|    policyGradLoss     | -0.0057     |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 302         |\n",
      "|    total_timesteps    | 45064192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011669356 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.608       |\n",
      "|    mean_step_reward   | 0.42134023  |\n",
      "|    n_updates          | 22000       |\n",
      "|    policyGradLoss     | -0.00585    |\n",
      "|    value_loss         | 1.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 313         |\n",
      "|    total_timesteps    | 45072384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015741281 |\n",
      "|    entropy_loss       | -1.57       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.745       |\n",
      "|    mean_step_reward   | 0.45539072  |\n",
      "|    n_updates          | 22004       |\n",
      "|    policyGradLoss     | -0.00549    |\n",
      "|    value_loss         | 1.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 323         |\n",
      "|    total_timesteps    | 45080576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021328235 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.746       |\n",
      "|    mean_step_reward   | 0.4168015   |\n",
      "|    n_updates          | 22008       |\n",
      "|    policyGradLoss     | -0.00529    |\n",
      "|    value_loss         | 1.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 334         |\n",
      "|    total_timesteps    | 45088768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012314126 |\n",
      "|    entropy_loss       | -1.54       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.384       |\n",
      "|    mean_step_reward   | 0.4830914   |\n",
      "|    n_updates          | 22012       |\n",
      "|    policyGradLoss     | -0.00482    |\n",
      "|    value_loss         | 1.3         |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_171.zip\n",
      "[EVAL] Mean Return: 542.215, Best Return: 549.548\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_171_542.22.mp4\n",
      "\n",
      "=== Round 173 | Learn 262144 steps (Total trained: 45088768) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1155     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 45096960 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 920         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 45105152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014302738 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.287       |\n",
      "|    mean_step_reward   | 0.42720658  |\n",
      "|    n_updates          | 22020       |\n",
      "|    policyGradLoss     | -0.00627    |\n",
      "|    value_loss         | 1.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 866         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 45113344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020835318 |\n",
      "|    entropy_loss       | -1.54       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00737     |\n",
      "|    mean_step_reward   | 0.43006223  |\n",
      "|    n_updates          | 22024       |\n",
      "|    policyGradLoss     | -0.00193    |\n",
      "|    value_loss         | 0.768       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 842        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 38         |\n",
      "|    total_timesteps    | 45121536   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01827252 |\n",
      "|    entropy_loss       | -1.65      |\n",
      "|    explained_variance | 0.99       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.666      |\n",
      "|    mean_step_reward   | 0.3195427  |\n",
      "|    n_updates          | 22028      |\n",
      "|    policyGradLoss     | -0.00886   |\n",
      "|    value_loss         | 1.41       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 45129728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016205896 |\n",
      "|    entropy_loss       | -1.56       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.401       |\n",
      "|    mean_step_reward   | 0.46718845  |\n",
      "|    n_updates          | 22032       |\n",
      "|    policyGradLoss     | -0.0088     |\n",
      "|    value_loss         | 0.927       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 45137920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012506589 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.25        |\n",
      "|    mean_step_reward   | 0.37368345  |\n",
      "|    n_updates          | 22036       |\n",
      "|    policyGradLoss     | -0.00394    |\n",
      "|    value_loss         | 1.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 45146112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014550963 |\n",
      "|    entropy_loss       | -1.55       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.23        |\n",
      "|    mean_step_reward   | 0.46671534  |\n",
      "|    n_updates          | 22040       |\n",
      "|    policyGradLoss     | -0.00142    |\n",
      "|    value_loss         | 3.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 45154304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011223174 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.887       |\n",
      "|    mean_step_reward   | 0.39637882  |\n",
      "|    n_updates          | 22044       |\n",
      "|    policyGradLoss     | -0.00557    |\n",
      "|    value_loss         | 2.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 45162496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018100843 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.326       |\n",
      "|    mean_step_reward   | 0.35386848  |\n",
      "|    n_updates          | 22048       |\n",
      "|    policyGradLoss     | -0.00605    |\n",
      "|    value_loss         | 1.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 45170688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029162219 |\n",
      "|    entropy_loss       | -1.57       |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.195       |\n",
      "|    mean_step_reward   | 0.41047472  |\n",
      "|    n_updates          | 22052       |\n",
      "|    policyGradLoss     | -0.0088     |\n",
      "|    value_loss         | 0.695       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 799          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 112          |\n",
      "|    total_timesteps    | 45178880     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0148232505 |\n",
      "|    entropy_loss       | -1.6         |\n",
      "|    explained_variance | 0.988        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.05         |\n",
      "|    mean_step_reward   | 0.41640264   |\n",
      "|    n_updates          | 22056        |\n",
      "|    policyGradLoss     | -0.00338     |\n",
      "|    value_loss         | 2.06         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 798        |\n",
      "|    iterations         | 12         |\n",
      "|    time_elapsed       | 123        |\n",
      "|    total_timesteps    | 45187072   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01710824 |\n",
      "|    entropy_loss       | -1.6       |\n",
      "|    explained_variance | 0.994      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.13       |\n",
      "|    mean_step_reward   | 0.45292574 |\n",
      "|    n_updates          | 22060      |\n",
      "|    policyGradLoss     | -0.00711   |\n",
      "|    value_loss         | 1.12       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 133         |\n",
      "|    total_timesteps    | 45195264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009395294 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.587       |\n",
      "|    mean_step_reward   | 0.41074145  |\n",
      "|    n_updates          | 22064       |\n",
      "|    policyGradLoss     | -0.00422    |\n",
      "|    value_loss         | 1.92        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 795        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 144        |\n",
      "|    total_timesteps    | 45203456   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01321539 |\n",
      "|    entropy_loss       | -1.55      |\n",
      "|    explained_variance | 0.992      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.538      |\n",
      "|    mean_step_reward   | 0.5001324  |\n",
      "|    n_updates          | 22068      |\n",
      "|    policyGradLoss     | -0.00592   |\n",
      "|    value_loss         | 1.43       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 45211648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015690159 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.638       |\n",
      "|    mean_step_reward   | 0.39373583  |\n",
      "|    n_updates          | 22072       |\n",
      "|    policyGradLoss     | -0.00618    |\n",
      "|    value_loss         | 1.82        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 45219840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016841773 |\n",
      "|    entropy_loss       | -1.55       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.661       |\n",
      "|    mean_step_reward   | 0.450241    |\n",
      "|    n_updates          | 22076       |\n",
      "|    policyGradLoss     | -0.0068     |\n",
      "|    value_loss         | 1.28        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 792          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 175          |\n",
      "|    total_timesteps    | 45228032     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0124249635 |\n",
      "|    entropy_loss       | -1.62        |\n",
      "|    explained_variance | 0.99         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.545        |\n",
      "|    mean_step_reward   | 0.39683676   |\n",
      "|    n_updates          | 22080        |\n",
      "|    policyGradLoss     | -0.00531     |\n",
      "|    value_loss         | 1.74         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 185         |\n",
      "|    total_timesteps    | 45236224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015397103 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.642       |\n",
      "|    mean_step_reward   | 0.46252137  |\n",
      "|    n_updates          | 22084       |\n",
      "|    policyGradLoss     | -0.00523    |\n",
      "|    value_loss         | 1.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 196         |\n",
      "|    total_timesteps    | 45244416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016860012 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 2.47        |\n",
      "|    mean_step_reward   | 0.48662344  |\n",
      "|    n_updates          | 22088       |\n",
      "|    policyGradLoss     | -0.00241    |\n",
      "|    value_loss         | 6.8         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 206         |\n",
      "|    total_timesteps    | 45252608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013085527 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.539       |\n",
      "|    mean_step_reward   | 0.39674395  |\n",
      "|    n_updates          | 22092       |\n",
      "|    policyGradLoss     | -0.00434    |\n",
      "|    value_loss         | 2.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 217         |\n",
      "|    total_timesteps    | 45260800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026075762 |\n",
      "|    entropy_loss       | -1.52       |\n",
      "|    explained_variance | 0.996       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0271      |\n",
      "|    mean_step_reward   | 0.48276925  |\n",
      "|    n_updates          | 22096       |\n",
      "|    policyGradLoss     | -0.00924    |\n",
      "|    value_loss         | 0.367       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 790        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 227        |\n",
      "|    total_timesteps    | 45268992   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01135942 |\n",
      "|    entropy_loss       | -1.65      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.647      |\n",
      "|    mean_step_reward   | 0.39054143 |\n",
      "|    n_updates          | 22100      |\n",
      "|    policyGradLoss     | 0.00012    |\n",
      "|    value_loss         | 2.27       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 238         |\n",
      "|    total_timesteps    | 45277184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013838603 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.672       |\n",
      "|    mean_step_reward   | 0.42427307  |\n",
      "|    n_updates          | 22104       |\n",
      "|    policyGradLoss     | 0.000155    |\n",
      "|    value_loss         | 1.65        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 248         |\n",
      "|    total_timesteps    | 45285376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016168788 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.281       |\n",
      "|    mean_step_reward   | 0.4514132   |\n",
      "|    n_updates          | 22108       |\n",
      "|    policyGradLoss     | -0.00771    |\n",
      "|    value_loss         | 1.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 259         |\n",
      "|    total_timesteps    | 45293568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012474902 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.03        |\n",
      "|    mean_step_reward   | 0.36481306  |\n",
      "|    n_updates          | 22112       |\n",
      "|    policyGradLoss     | -0.00431    |\n",
      "|    value_loss         | 2.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 269         |\n",
      "|    total_timesteps    | 45301760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027040716 |\n",
      "|    entropy_loss       | -1.53       |\n",
      "|    explained_variance | 0.996       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0659      |\n",
      "|    mean_step_reward   | 0.47535774  |\n",
      "|    n_updates          | 22116       |\n",
      "|    policyGradLoss     | -0.00996    |\n",
      "|    value_loss         | 0.432       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 789          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 280          |\n",
      "|    total_timesteps    | 45309952     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0092109945 |\n",
      "|    entropy_loss       | -1.66        |\n",
      "|    explained_variance | 0.986        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.922        |\n",
      "|    mean_step_reward   | 0.39986336   |\n",
      "|    n_updates          | 22120        |\n",
      "|    policyGradLoss     | -0.00358     |\n",
      "|    value_loss         | 2.52         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 290         |\n",
      "|    total_timesteps    | 45318144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015808279 |\n",
      "|    entropy_loss       | -1.57       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.95        |\n",
      "|    mean_step_reward   | 0.40557867  |\n",
      "|    n_updates          | 22124       |\n",
      "|    policyGradLoss     | 0.000386    |\n",
      "|    value_loss         | 5.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 301         |\n",
      "|    total_timesteps    | 45326336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014284821 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.682       |\n",
      "|    mean_step_reward   | 0.38522208  |\n",
      "|    n_updates          | 22128       |\n",
      "|    policyGradLoss     | -0.000544   |\n",
      "|    value_loss         | 2.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 311         |\n",
      "|    total_timesteps    | 45334528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009791376 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.608       |\n",
      "|    mean_step_reward   | 0.4147544   |\n",
      "|    n_updates          | 22132       |\n",
      "|    policyGradLoss     | -0.00256    |\n",
      "|    value_loss         | 1.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 322         |\n",
      "|    total_timesteps    | 45342720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016023967 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.782       |\n",
      "|    mean_step_reward   | 0.46151704  |\n",
      "|    n_updates          | 22136       |\n",
      "|    policyGradLoss     | -0.0051     |\n",
      "|    value_loss         | 1.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 45350912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012003683 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.982       |\n",
      "|    mean_step_reward   | 0.363532    |\n",
      "|    n_updates          | 22140       |\n",
      "|    policyGradLoss     | -0.00333    |\n",
      "|    value_loss         | 2.87        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_172.zip\n",
      "[EVAL] Mean Return: 542.735, Best Return: 550.068\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_172_542.73.mp4\n",
      "\n",
      "=== Round 174 | Learn 262144 steps (Total trained: 45350912) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1130     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 45359104 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 919         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 45367296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015561959 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.09        |\n",
      "|    mean_step_reward   | 0.39943433  |\n",
      "|    n_updates          | 22148       |\n",
      "|    policyGradLoss     | -0.00207    |\n",
      "|    value_loss         | 2.75        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 860         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 45375488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015152847 |\n",
      "|    entropy_loss       | -1.56       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.339       |\n",
      "|    mean_step_reward   | 0.44652414  |\n",
      "|    n_updates          | 22152       |\n",
      "|    policyGradLoss     | -0.0069     |\n",
      "|    value_loss         | 1.46        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 832         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 45383680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011847936 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.653       |\n",
      "|    mean_step_reward   | 0.4074743   |\n",
      "|    n_updates          | 22156       |\n",
      "|    policyGradLoss     | -0.00508    |\n",
      "|    value_loss         | 1.5         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 45391872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011404615 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.65        |\n",
      "|    mean_step_reward   | 0.4055758   |\n",
      "|    n_updates          | 22160       |\n",
      "|    policyGradLoss     | -0.00362    |\n",
      "|    value_loss         | 2.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 45400064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013678052 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1           |\n",
      "|    mean_step_reward   | 0.46220893  |\n",
      "|    n_updates          | 22164       |\n",
      "|    policyGradLoss     | -0.00662    |\n",
      "|    value_loss         | 1.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 45408256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013006978 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.725       |\n",
      "|    mean_step_reward   | 0.37375537  |\n",
      "|    n_updates          | 22168       |\n",
      "|    policyGradLoss     | -0.00678    |\n",
      "|    value_loss         | 1.94        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 45416448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014930926 |\n",
      "|    entropy_loss       | -1.57       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.437       |\n",
      "|    mean_step_reward   | 0.431202    |\n",
      "|    n_updates          | 22172       |\n",
      "|    policyGradLoss     | -0.00488    |\n",
      "|    value_loss         | 1.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 45424640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011308385 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.934       |\n",
      "|    mean_step_reward   | 0.40832818  |\n",
      "|    n_updates          | 22176       |\n",
      "|    policyGradLoss     | -0.00437    |\n",
      "|    value_loss         | 1.66        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 796          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 102          |\n",
      "|    total_timesteps    | 45432832     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0142708225 |\n",
      "|    entropy_loss       | -1.61        |\n",
      "|    explained_variance | 0.985        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.915        |\n",
      "|    mean_step_reward   | 0.4804004    |\n",
      "|    n_updates          | 22180        |\n",
      "|    policyGradLoss     | -0.00331     |\n",
      "|    value_loss         | 2.15         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 45441024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009108799 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.906       |\n",
      "|    mean_step_reward   | 0.43388355  |\n",
      "|    n_updates          | 22184       |\n",
      "|    policyGradLoss     | -0.00484    |\n",
      "|    value_loss         | 2.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 45449216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015065594 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.94        |\n",
      "|    mean_step_reward   | 0.42084384  |\n",
      "|    n_updates          | 22188       |\n",
      "|    policyGradLoss     | -0.00295    |\n",
      "|    value_loss         | 1.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 45457408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019480791 |\n",
      "|    entropy_loss       | -1.57       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.182       |\n",
      "|    mean_step_reward   | 0.44109493  |\n",
      "|    n_updates          | 22192       |\n",
      "|    policyGradLoss     | -0.0114     |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 45465600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021750525 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.253       |\n",
      "|    mean_step_reward   | 0.40502104  |\n",
      "|    n_updates          | 22196       |\n",
      "|    policyGradLoss     | -0.00395    |\n",
      "|    value_loss         | 1.83        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 45473792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016761074 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.362       |\n",
      "|    mean_step_reward   | 0.45939118  |\n",
      "|    n_updates          | 22200       |\n",
      "|    policyGradLoss     | -0.00835    |\n",
      "|    value_loss         | 1.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 45481984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018100407 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.896       |\n",
      "|    mean_step_reward   | 0.34338373  |\n",
      "|    n_updates          | 22204       |\n",
      "|    policyGradLoss     | -0.00864    |\n",
      "|    value_loss         | 1.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 45490176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011164392 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.427       |\n",
      "|    mean_step_reward   | 0.3654917   |\n",
      "|    n_updates          | 22208       |\n",
      "|    policyGradLoss     | -0.0071     |\n",
      "|    value_loss         | 1.45        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 45498368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012458319 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.761       |\n",
      "|    mean_step_reward   | 0.38246343  |\n",
      "|    n_updates          | 22212       |\n",
      "|    policyGradLoss     | -0.00673    |\n",
      "|    value_loss         | 1.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 197         |\n",
      "|    total_timesteps    | 45506560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018992748 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.55        |\n",
      "|    mean_step_reward   | 0.39373267  |\n",
      "|    n_updates          | 22216       |\n",
      "|    policyGradLoss     | -0.00658    |\n",
      "|    value_loss         | 1.81        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 45514752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020676749 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.574       |\n",
      "|    mean_step_reward   | 0.37006217  |\n",
      "|    n_updates          | 22220       |\n",
      "|    policyGradLoss     | -0.00384    |\n",
      "|    value_loss         | 2.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 45522944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018400073 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.429       |\n",
      "|    mean_step_reward   | 0.3565451   |\n",
      "|    n_updates          | 22224       |\n",
      "|    policyGradLoss     | -0.00836    |\n",
      "|    value_loss         | 1.32        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 785        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 229        |\n",
      "|    total_timesteps    | 45531136   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01546772 |\n",
      "|    entropy_loss       | -1.6       |\n",
      "|    explained_variance | 0.992      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.473      |\n",
      "|    mean_step_reward   | 0.43794277 |\n",
      "|    n_updates          | 22228      |\n",
      "|    policyGradLoss     | -0.00751   |\n",
      "|    value_loss         | 1.26       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 45539328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014243571 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.365       |\n",
      "|    mean_step_reward   | 0.3923741   |\n",
      "|    n_updates          | 22232       |\n",
      "|    policyGradLoss     | -0.00666    |\n",
      "|    value_loss         | 1.97        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 250         |\n",
      "|    total_timesteps    | 45547520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014574669 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.359       |\n",
      "|    mean_step_reward   | 0.37143424  |\n",
      "|    n_updates          | 22236       |\n",
      "|    policyGradLoss     | -0.00941    |\n",
      "|    value_loss         | 1.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 45555712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017026132 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.865       |\n",
      "|    mean_step_reward   | 0.41123444  |\n",
      "|    n_updates          | 22240       |\n",
      "|    policyGradLoss     | -0.00883    |\n",
      "|    value_loss         | 1           |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 45563904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011332977 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.806       |\n",
      "|    mean_step_reward   | 0.42178077  |\n",
      "|    n_updates          | 22244       |\n",
      "|    policyGradLoss     | -0.00707    |\n",
      "|    value_loss         | 1.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 281         |\n",
      "|    total_timesteps    | 45572096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016349189 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.159       |\n",
      "|    mean_step_reward   | 0.4275388   |\n",
      "|    n_updates          | 22248       |\n",
      "|    policyGradLoss     | -0.00724    |\n",
      "|    value_loss         | 1.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 45580288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010146676 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.05        |\n",
      "|    mean_step_reward   | 0.38798532  |\n",
      "|    n_updates          | 22252       |\n",
      "|    policyGradLoss     | -0.00349    |\n",
      "|    value_loss         | 2           |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 303         |\n",
      "|    total_timesteps    | 45588480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009532083 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.757       |\n",
      "|    mean_step_reward   | 0.40350989  |\n",
      "|    n_updates          | 22256       |\n",
      "|    policyGradLoss     | -0.00633    |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 313         |\n",
      "|    total_timesteps    | 45596672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017616168 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.562       |\n",
      "|    mean_step_reward   | 0.44220054  |\n",
      "|    n_updates          | 22260       |\n",
      "|    policyGradLoss     | -0.00603    |\n",
      "|    value_loss         | 1.3         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 783          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 324          |\n",
      "|    total_timesteps    | 45604864     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0136923045 |\n",
      "|    entropy_loss       | -1.61        |\n",
      "|    explained_variance | 0.989        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.548        |\n",
      "|    mean_step_reward   | 0.3875959    |\n",
      "|    n_updates          | 22264        |\n",
      "|    policyGradLoss     | -0.00624     |\n",
      "|    value_loss         | 1.56         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 334         |\n",
      "|    total_timesteps    | 45613056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014795797 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.717       |\n",
      "|    mean_step_reward   | 0.39328712  |\n",
      "|    n_updates          | 22268       |\n",
      "|    policyGradLoss     | -0.00671    |\n",
      "|    value_loss         | 1.34        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_173.zip\n",
      "[EVAL] Mean Return: 21.140, Best Return: 21.807\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_173_21.14.mp4\n",
      "\n",
      "=== Round 175 | Learn 262144 steps (Total trained: 45613056) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1121     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 45621248 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 912         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 45629440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016805546 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.397       |\n",
      "|    mean_step_reward   | 0.41473943  |\n",
      "|    n_updates          | 22276       |\n",
      "|    policyGradLoss     | -0.00996    |\n",
      "|    value_loss         | 1.61        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 871        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 45637632   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01691404 |\n",
      "|    entropy_loss       | -1.61      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.347      |\n",
      "|    mean_step_reward   | 0.38820434 |\n",
      "|    n_updates          | 22280      |\n",
      "|    policyGradLoss     | -0.00875   |\n",
      "|    value_loss         | 1.3        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 845         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 45645824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014722247 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.68        |\n",
      "|    mean_step_reward   | 0.46309206  |\n",
      "|    n_updates          | 22284       |\n",
      "|    policyGradLoss     | -0.007      |\n",
      "|    value_loss         | 1.43        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 45654016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019828107 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.59        |\n",
      "|    mean_step_reward   | 0.37614852  |\n",
      "|    n_updates          | 22288       |\n",
      "|    policyGradLoss     | -0.00574    |\n",
      "|    value_loss         | 2.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 45662208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014057053 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.365       |\n",
      "|    mean_step_reward   | 0.44537213  |\n",
      "|    n_updates          | 22292       |\n",
      "|    policyGradLoss     | -0.0077     |\n",
      "|    value_loss         | 1.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 45670400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010097731 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.54        |\n",
      "|    mean_step_reward   | 0.44421935  |\n",
      "|    n_updates          | 22296       |\n",
      "|    policyGradLoss     | -0.00397    |\n",
      "|    value_loss         | 1.98        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 45678592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012603539 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.72        |\n",
      "|    mean_step_reward   | 0.39344156  |\n",
      "|    n_updates          | 22300       |\n",
      "|    policyGradLoss     | -0.00636    |\n",
      "|    value_loss         | 1.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 45686784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015701827 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.19        |\n",
      "|    mean_step_reward   | 0.41722563  |\n",
      "|    n_updates          | 22304       |\n",
      "|    policyGradLoss     | -5.95e-05   |\n",
      "|    value_loss         | 4.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 45694976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011808136 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.917       |\n",
      "|    mean_step_reward   | 0.36769265  |\n",
      "|    n_updates          | 22308       |\n",
      "|    policyGradLoss     | -0.00413    |\n",
      "|    value_loss         | 1.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 45703168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027203642 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.233       |\n",
      "|    mean_step_reward   | 0.4281839   |\n",
      "|    n_updates          | 22312       |\n",
      "|    policyGradLoss     | -0.0108     |\n",
      "|    value_loss         | 0.665       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 45711360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019750465 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.678       |\n",
      "|    mean_step_reward   | 0.35781363  |\n",
      "|    n_updates          | 22316       |\n",
      "|    policyGradLoss     | -0.00495    |\n",
      "|    value_loss         | 1.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 45719552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013073086 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.542       |\n",
      "|    mean_step_reward   | 0.43978474  |\n",
      "|    n_updates          | 22320       |\n",
      "|    policyGradLoss     | -0.00675    |\n",
      "|    value_loss         | 2.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 45727744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016576828 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.717       |\n",
      "|    mean_step_reward   | 0.3728906   |\n",
      "|    n_updates          | 22324       |\n",
      "|    policyGradLoss     | -0.00606    |\n",
      "|    value_loss         | 1.65        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 45735936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014725419 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.364       |\n",
      "|    mean_step_reward   | 0.3742354   |\n",
      "|    n_updates          | 22328       |\n",
      "|    policyGradLoss     | -0.00873    |\n",
      "|    value_loss         | 1.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 45744128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013024181 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.949       |\n",
      "|    mean_step_reward   | 0.44572544  |\n",
      "|    n_updates          | 22332       |\n",
      "|    policyGradLoss     | -0.00483    |\n",
      "|    value_loss         | 1.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 45752320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010757642 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.35        |\n",
      "|    mean_step_reward   | 0.40907124  |\n",
      "|    n_updates          | 22336       |\n",
      "|    policyGradLoss     | -0.00398    |\n",
      "|    value_loss         | 1.88        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 45760512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010530327 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.905       |\n",
      "|    mean_step_reward   | 0.45470434  |\n",
      "|    n_updates          | 22340       |\n",
      "|    policyGradLoss     | -0.00445    |\n",
      "|    value_loss         | 1.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 45768704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014781114 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.322       |\n",
      "|    mean_step_reward   | 0.42164397  |\n",
      "|    n_updates          | 22344       |\n",
      "|    policyGradLoss     | -0.00529    |\n",
      "|    value_loss         | 1.59        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 784          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 208          |\n",
      "|    total_timesteps    | 45776896     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0143867545 |\n",
      "|    entropy_loss       | -1.6         |\n",
      "|    explained_variance | 0.993        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.474        |\n",
      "|    mean_step_reward   | 0.41609722   |\n",
      "|    n_updates          | 22348        |\n",
      "|    policyGradLoss     | -0.00667     |\n",
      "|    value_loss         | 1.2          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 45785088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016945258 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.886       |\n",
      "|    mean_step_reward   | 0.41173643  |\n",
      "|    n_updates          | 22352       |\n",
      "|    policyGradLoss     | -0.00749    |\n",
      "|    value_loss         | 1.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 45793280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012752667 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.829       |\n",
      "|    mean_step_reward   | 0.43198445  |\n",
      "|    n_updates          | 22356       |\n",
      "|    policyGradLoss     | -0.00593    |\n",
      "|    value_loss         | 1.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 45801472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011268225 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.678       |\n",
      "|    mean_step_reward   | 0.43607134  |\n",
      "|    n_updates          | 22360       |\n",
      "|    policyGradLoss     | -0.00607    |\n",
      "|    value_loss         | 1.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 45809664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012625239 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.937       |\n",
      "|    mean_step_reward   | 0.43697482  |\n",
      "|    n_updates          | 22364       |\n",
      "|    policyGradLoss     | -0.00365    |\n",
      "|    value_loss         | 2.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 45817856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014009833 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.173       |\n",
      "|    mean_step_reward   | 0.41050786  |\n",
      "|    n_updates          | 22368       |\n",
      "|    policyGradLoss     | -0.00868    |\n",
      "|    value_loss         | 1.17        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 782        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 272        |\n",
      "|    total_timesteps    | 45826048   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01546569 |\n",
      "|    entropy_loss       | -1.66      |\n",
      "|    explained_variance | 0.988      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.53       |\n",
      "|    mean_step_reward   | 0.38596052 |\n",
      "|    n_updates          | 22372      |\n",
      "|    policyGradLoss     | -0.00613   |\n",
      "|    value_loss         | 1.87       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 45834240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015885446 |\n",
      "|    entropy_loss       | -1.56       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.242       |\n",
      "|    mean_step_reward   | 0.42302027  |\n",
      "|    n_updates          | 22376       |\n",
      "|    policyGradLoss     | -0.00612    |\n",
      "|    value_loss         | 1.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 45842432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012523605 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.65        |\n",
      "|    mean_step_reward   | 0.36923355  |\n",
      "|    n_updates          | 22380       |\n",
      "|    policyGradLoss     | -0.00618    |\n",
      "|    value_loss         | 1.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 45850624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014581244 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.243       |\n",
      "|    mean_step_reward   | 0.4372213   |\n",
      "|    n_updates          | 22384       |\n",
      "|    policyGradLoss     | -0.00773    |\n",
      "|    value_loss         | 1           |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 314         |\n",
      "|    total_timesteps    | 45858816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012549669 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.986       |\n",
      "|    mean_step_reward   | 0.3622333   |\n",
      "|    n_updates          | 22388       |\n",
      "|    policyGradLoss     | -0.00811    |\n",
      "|    value_loss         | 1.75        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 324         |\n",
      "|    total_timesteps    | 45867008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013136603 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.37        |\n",
      "|    mean_step_reward   | 0.40856132  |\n",
      "|    n_updates          | 22392       |\n",
      "|    policyGradLoss     | -0.00723    |\n",
      "|    value_loss         | 1.74        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 335         |\n",
      "|    total_timesteps    | 45875200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017684385 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.227       |\n",
      "|    mean_step_reward   | 0.40595853  |\n",
      "|    n_updates          | 22396       |\n",
      "|    policyGradLoss     | -0.0089     |\n",
      "|    value_loss         | 1.35        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_174.zip\n",
      "[EVAL] Mean Return: 542.762, Best Return: 550.429\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_174_542.76.mp4\n",
      "\n",
      "=== Round 176 | Learn 262144 steps (Total trained: 45875200) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1145     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 45883392 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 935         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 45891584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012738137 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.06        |\n",
      "|    mean_step_reward   | 0.43947238  |\n",
      "|    n_updates          | 22404       |\n",
      "|    policyGradLoss     | -0.00708    |\n",
      "|    value_loss         | 2.05        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 877        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 27         |\n",
      "|    total_timesteps    | 45899776   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01640324 |\n",
      "|    entropy_loss       | -1.61      |\n",
      "|    explained_variance | 0.992      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.17       |\n",
      "|    mean_step_reward   | 0.44792342 |\n",
      "|    n_updates          | 22408      |\n",
      "|    policyGradLoss     | -0.0075    |\n",
      "|    value_loss         | 1.52       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 842         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 45907968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019594964 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.77        |\n",
      "|    mean_step_reward   | 0.39004973  |\n",
      "|    n_updates          | 22412       |\n",
      "|    policyGradLoss     | -0.00758    |\n",
      "|    value_loss         | 1.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 45916160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019402206 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.623       |\n",
      "|    mean_step_reward   | 0.4276716   |\n",
      "|    n_updates          | 22416       |\n",
      "|    policyGradLoss     | -0.006      |\n",
      "|    value_loss         | 1.36        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 815        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 45924352   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02197955 |\n",
      "|    entropy_loss       | -1.56      |\n",
      "|    explained_variance | 0.993      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.456      |\n",
      "|    mean_step_reward   | 0.4299496  |\n",
      "|    n_updates          | 22420      |\n",
      "|    policyGradLoss     | -0.00894   |\n",
      "|    value_loss         | 1.05       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 45932544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022591535 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 3.18        |\n",
      "|    mean_step_reward   | 0.42269027  |\n",
      "|    n_updates          | 22424       |\n",
      "|    policyGradLoss     | -0.00266    |\n",
      "|    value_loss         | 5.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 45940736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016443525 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.595       |\n",
      "|    mean_step_reward   | 0.40537822  |\n",
      "|    n_updates          | 22428       |\n",
      "|    policyGradLoss     | 0.0269      |\n",
      "|    value_loss         | 2.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 45948928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015320302 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.142       |\n",
      "|    mean_step_reward   | 0.4544991   |\n",
      "|    n_updates          | 22432       |\n",
      "|    policyGradLoss     | -0.00731    |\n",
      "|    value_loss         | 1.34        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 799        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 102        |\n",
      "|    total_timesteps    | 45957120   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01746372 |\n",
      "|    entropy_loss       | -1.61      |\n",
      "|    explained_variance | 0.985      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.835      |\n",
      "|    mean_step_reward   | 0.34695637 |\n",
      "|    n_updates          | 22436      |\n",
      "|    policyGradLoss     | -0.00613   |\n",
      "|    value_loss         | 1.79       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 112         |\n",
      "|    total_timesteps    | 45965312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024511062 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.327       |\n",
      "|    mean_step_reward   | 0.4153127   |\n",
      "|    n_updates          | 22440       |\n",
      "|    policyGradLoss     | -0.0111     |\n",
      "|    value_loss         | 0.929       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 798       |\n",
      "|    iterations         | 12        |\n",
      "|    time_elapsed       | 123       |\n",
      "|    total_timesteps    | 45973504  |\n",
      "| train/                |           |\n",
      "|    approx_kl          | 0.0154726 |\n",
      "|    entropy_loss       | -1.65     |\n",
      "|    explained_variance | 0.989     |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    loss               | 1.18      |\n",
      "|    mean_step_reward   | 0.3867187 |\n",
      "|    n_updates          | 22444     |\n",
      "|    policyGradLoss     | -0.00583  |\n",
      "|    value_loss         | 1.82      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 133         |\n",
      "|    total_timesteps    | 45981696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020266589 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.298       |\n",
      "|    mean_step_reward   | 0.48497576  |\n",
      "|    n_updates          | 22448       |\n",
      "|    policyGradLoss     | -0.00739    |\n",
      "|    value_loss         | 1.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 45989888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010919282 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.15        |\n",
      "|    mean_step_reward   | 0.42621163  |\n",
      "|    n_updates          | 22452       |\n",
      "|    policyGradLoss     | -0.00208    |\n",
      "|    value_loss         | 2.26        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 794        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 154        |\n",
      "|    total_timesteps    | 45998080   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02322365 |\n",
      "|    entropy_loss       | -1.58      |\n",
      "|    explained_variance | 0.99       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.357      |\n",
      "|    mean_step_reward   | 0.42242962 |\n",
      "|    n_updates          | 22456      |\n",
      "|    policyGradLoss     | -0.00532   |\n",
      "|    value_loss         | 1.39       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 46006272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018940037 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.958       |\n",
      "|    mean_step_reward   | 0.4176918   |\n",
      "|    n_updates          | 22460       |\n",
      "|    policyGradLoss     | -0.00694    |\n",
      "|    value_loss         | 1.04        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 46014464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016975177 |\n",
      "|    entropy_loss       | -1.57       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.949       |\n",
      "|    mean_step_reward   | 0.42086238  |\n",
      "|    n_updates          | 22464       |\n",
      "|    policyGradLoss     | -0.00655    |\n",
      "|    value_loss         | 1.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 186         |\n",
      "|    total_timesteps    | 46022656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017489733 |\n",
      "|    entropy_loss       | -1.56       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.515       |\n",
      "|    mean_step_reward   | 0.48362064  |\n",
      "|    n_updates          | 22468       |\n",
      "|    policyGradLoss     | -0.00561    |\n",
      "|    value_loss         | 1.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 197         |\n",
      "|    total_timesteps    | 46030848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013118165 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.353       |\n",
      "|    mean_step_reward   | 0.41658103  |\n",
      "|    n_updates          | 22472       |\n",
      "|    policyGradLoss     | -0.00306    |\n",
      "|    value_loss         | 1.8         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 207         |\n",
      "|    total_timesteps    | 46039040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011246247 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.11        |\n",
      "|    mean_step_reward   | 0.43888846  |\n",
      "|    n_updates          | 22476       |\n",
      "|    policyGradLoss     | -0.00342    |\n",
      "|    value_loss         | 5.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 218         |\n",
      "|    total_timesteps    | 46047232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010282181 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.11        |\n",
      "|    mean_step_reward   | 0.4425431   |\n",
      "|    n_updates          | 22480       |\n",
      "|    policyGradLoss     | -9.37e-06   |\n",
      "|    value_loss         | 2.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 228         |\n",
      "|    total_timesteps    | 46055424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013194353 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.563       |\n",
      "|    mean_step_reward   | 0.4322967   |\n",
      "|    n_updates          | 22484       |\n",
      "|    policyGradLoss     | 0.000363    |\n",
      "|    value_loss         | 2.8         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 786        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 239        |\n",
      "|    total_timesteps    | 46063616   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01288325 |\n",
      "|    entropy_loss       | -1.61      |\n",
      "|    explained_variance | 0.978      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.563      |\n",
      "|    mean_step_reward   | 0.40174866 |\n",
      "|    n_updates          | 22488      |\n",
      "|    policyGradLoss     | -0.00366   |\n",
      "|    value_loss         | 1.93       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 787          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 249          |\n",
      "|    total_timesteps    | 46071808     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0146065615 |\n",
      "|    entropy_loss       | -1.59        |\n",
      "|    explained_variance | 0.991        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.53         |\n",
      "|    mean_step_reward   | 0.45224032   |\n",
      "|    n_updates          | 22492        |\n",
      "|    policyGradLoss     | -0.00509     |\n",
      "|    value_loss         | 1.27         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 260         |\n",
      "|    total_timesteps    | 46080000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018333571 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.976       |\n",
      "|    mean_step_reward   | 0.4397664   |\n",
      "|    n_updates          | 22496       |\n",
      "|    policyGradLoss     | -0.0027     |\n",
      "|    value_loss         | 1.59        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 46088192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010779232 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.709       |\n",
      "|    mean_step_reward   | 0.43984562  |\n",
      "|    n_updates          | 22500       |\n",
      "|    policyGradLoss     | -0.00537    |\n",
      "|    value_loss         | 1.81        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 281         |\n",
      "|    total_timesteps    | 46096384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014713861 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.642       |\n",
      "|    mean_step_reward   | 0.46525967  |\n",
      "|    n_updates          | 22504       |\n",
      "|    policyGradLoss     | -0.00641    |\n",
      "|    value_loss         | 1.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 291         |\n",
      "|    total_timesteps    | 46104576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015310153 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.433       |\n",
      "|    mean_step_reward   | 0.4403307   |\n",
      "|    n_updates          | 22508       |\n",
      "|    policyGradLoss     | -0.00678    |\n",
      "|    value_loss         | 1.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 302         |\n",
      "|    total_timesteps    | 46112768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015321022 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.35        |\n",
      "|    mean_step_reward   | 0.4177513   |\n",
      "|    n_updates          | 22512       |\n",
      "|    policyGradLoss     | -0.00644    |\n",
      "|    value_loss         | 1.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 313         |\n",
      "|    total_timesteps    | 46120960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024087813 |\n",
      "|    entropy_loss       | -1.55       |\n",
      "|    explained_variance | 0.996       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.293       |\n",
      "|    mean_step_reward   | 0.44345802  |\n",
      "|    n_updates          | 22516       |\n",
      "|    policyGradLoss     | -0.0108     |\n",
      "|    value_loss         | 0.679       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 784          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 323          |\n",
      "|    total_timesteps    | 46129152     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0149895195 |\n",
      "|    entropy_loss       | -1.61        |\n",
      "|    explained_variance | 0.991        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.373        |\n",
      "|    mean_step_reward   | 0.3937839    |\n",
      "|    n_updates          | 22520        |\n",
      "|    policyGradLoss     | -0.00685     |\n",
      "|    value_loss         | 1.52         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 334         |\n",
      "|    total_timesteps    | 46137344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014388463 |\n",
      "|    entropy_loss       | -1.55       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.397       |\n",
      "|    mean_step_reward   | 0.4858089   |\n",
      "|    n_updates          | 22524       |\n",
      "|    policyGradLoss     | -0.0048     |\n",
      "|    value_loss         | 1.18        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_175.zip\n",
      "[EVAL] Mean Return: 542.932, Best Return: 549.599\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_175_542.93.mp4\n",
      "\n",
      "=== Round 177 | Learn 262144 steps (Total trained: 46137344) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1128     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 46145536 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 931        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 46153728   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01783223 |\n",
      "|    entropy_loss       | -1.57      |\n",
      "|    explained_variance | 0.99       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.326      |\n",
      "|    mean_step_reward   | 0.45636854 |\n",
      "|    n_updates          | 22532      |\n",
      "|    policyGradLoss     | -0.00724   |\n",
      "|    value_loss         | 1.62       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 868         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 46161920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013580325 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.984       |\n",
      "|    mean_step_reward   | 0.38175887  |\n",
      "|    n_updates          | 22536       |\n",
      "|    policyGradLoss     | -0.00602    |\n",
      "|    value_loss         | 2.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 845         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 46170112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012529036 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.526       |\n",
      "|    mean_step_reward   | 0.3875369   |\n",
      "|    n_updates          | 22540       |\n",
      "|    policyGradLoss     | -0.00284    |\n",
      "|    value_loss         | 2.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 829         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 46178304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015332051 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.94        |\n",
      "|    mean_step_reward   | 0.4619647   |\n",
      "|    n_updates          | 22544       |\n",
      "|    policyGradLoss     | -0.00839    |\n",
      "|    value_loss         | 1.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 46186496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013655253 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.467       |\n",
      "|    mean_step_reward   | 0.39428076  |\n",
      "|    n_updates          | 22548       |\n",
      "|    policyGradLoss     | -0.00389    |\n",
      "|    value_loss         | 1.88        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 46194688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018677928 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.386       |\n",
      "|    mean_step_reward   | 0.46929136  |\n",
      "|    n_updates          | 22552       |\n",
      "|    policyGradLoss     | -0.0062     |\n",
      "|    value_loss         | 1.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 46202880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011804858 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.02        |\n",
      "|    mean_step_reward   | 0.3578771   |\n",
      "|    n_updates          | 22556       |\n",
      "|    policyGradLoss     | -0.00608    |\n",
      "|    value_loss         | 2.45        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 800        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 92         |\n",
      "|    total_timesteps    | 46211072   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01173399 |\n",
      "|    entropy_loss       | -1.57      |\n",
      "|    explained_variance | 0.992      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.193      |\n",
      "|    mean_step_reward   | 0.49202085 |\n",
      "|    n_updates          | 22560      |\n",
      "|    policyGradLoss     | -0.00675   |\n",
      "|    value_loss         | 1.12       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 46219264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012308234 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.772       |\n",
      "|    mean_step_reward   | 0.34361762  |\n",
      "|    n_updates          | 22564       |\n",
      "|    policyGradLoss     | -0.00441    |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 793        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 113        |\n",
      "|    total_timesteps    | 46227456   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01503461 |\n",
      "|    entropy_loss       | -1.58      |\n",
      "|    explained_variance | 0.988      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.914      |\n",
      "|    mean_step_reward   | 0.43924338 |\n",
      "|    n_updates          | 22568      |\n",
      "|    policyGradLoss     | -0.00633   |\n",
      "|    value_loss         | 1.69       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 46235648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015543027 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.495       |\n",
      "|    mean_step_reward   | 0.42409462  |\n",
      "|    n_updates          | 22572       |\n",
      "|    policyGradLoss     | -0.00995    |\n",
      "|    value_loss         | 1.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 46243840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012111366 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.629       |\n",
      "|    mean_step_reward   | 0.36040515  |\n",
      "|    n_updates          | 22576       |\n",
      "|    policyGradLoss     | -0.00661    |\n",
      "|    value_loss         | 1.76        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 46252032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018714402 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.35        |\n",
      "|    mean_step_reward   | 0.47466934  |\n",
      "|    n_updates          | 22580       |\n",
      "|    policyGradLoss     | -0.00576    |\n",
      "|    value_loss         | 1.72        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 46260224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013836374 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.732       |\n",
      "|    mean_step_reward   | 0.39128715  |\n",
      "|    n_updates          | 22584       |\n",
      "|    policyGradLoss     | -0.00465    |\n",
      "|    value_loss         | 1.96        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 46268416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017076988 |\n",
      "|    entropy_loss       | -1.57       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0899      |\n",
      "|    mean_step_reward   | 0.4175908   |\n",
      "|    n_updates          | 22588       |\n",
      "|    policyGradLoss     | -0.0082     |\n",
      "|    value_loss         | 0.903       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 786        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 177        |\n",
      "|    total_timesteps    | 46276608   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01697987 |\n",
      "|    entropy_loss       | -1.62      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.553      |\n",
      "|    mean_step_reward   | 0.42983413 |\n",
      "|    n_updates          | 22592      |\n",
      "|    policyGradLoss     | -0.00623   |\n",
      "|    value_loss         | 1.68       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 46284800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014875341 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.195       |\n",
      "|    mean_step_reward   | 0.45684433  |\n",
      "|    n_updates          | 22596       |\n",
      "|    policyGradLoss     | -0.00698    |\n",
      "|    value_loss         | 1.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 46292992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013301449 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.17        |\n",
      "|    mean_step_reward   | 0.4202432   |\n",
      "|    n_updates          | 22600       |\n",
      "|    policyGradLoss     | -0.0074     |\n",
      "|    value_loss         | 1.56        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 783          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 209          |\n",
      "|    total_timesteps    | 46301184     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0102992635 |\n",
      "|    entropy_loss       | -1.62        |\n",
      "|    explained_variance | 0.99         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.526        |\n",
      "|    mean_step_reward   | 0.44400072   |\n",
      "|    n_updates          | 22604        |\n",
      "|    policyGradLoss     | -0.00593     |\n",
      "|    value_loss         | 1.9          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 46309376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011965426 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.02        |\n",
      "|    mean_step_reward   | 0.45604223  |\n",
      "|    n_updates          | 22608       |\n",
      "|    policyGradLoss     | -0.00696    |\n",
      "|    value_loss         | 1.65        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 46317568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012783026 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.867       |\n",
      "|    mean_step_reward   | 0.38714787  |\n",
      "|    n_updates          | 22612       |\n",
      "|    policyGradLoss     | -0.00646    |\n",
      "|    value_loss         | 1.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 46325760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022508837 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.255       |\n",
      "|    mean_step_reward   | 0.42394134  |\n",
      "|    n_updates          | 22616       |\n",
      "|    policyGradLoss     | -0.00944    |\n",
      "|    value_loss         | 0.932       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 46333952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012564568 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.503       |\n",
      "|    mean_step_reward   | 0.4017197   |\n",
      "|    n_updates          | 22620       |\n",
      "|    policyGradLoss     | -0.00664    |\n",
      "|    value_loss         | 1.94        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 46342144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012512986 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.726       |\n",
      "|    mean_step_reward   | 0.43782085  |\n",
      "|    n_updates          | 22624       |\n",
      "|    policyGradLoss     | -0.00713    |\n",
      "|    value_loss         | 1.64        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 46350336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015427273 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.877       |\n",
      "|    mean_step_reward   | 0.45873195  |\n",
      "|    n_updates          | 22628       |\n",
      "|    policyGradLoss     | -0.00509    |\n",
      "|    value_loss         | 2.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 46358528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015915927 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.25        |\n",
      "|    mean_step_reward   | 0.34987378  |\n",
      "|    n_updates          | 22632       |\n",
      "|    policyGradLoss     | -0.0072     |\n",
      "|    value_loss         | 1.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 46366720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014493361 |\n",
      "|    entropy_loss       | -1.57       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.393       |\n",
      "|    mean_step_reward   | 0.48115605  |\n",
      "|    n_updates          | 22636       |\n",
      "|    policyGradLoss     | -0.00598    |\n",
      "|    value_loss         | 1.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 46374912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014809602 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.979       |\n",
      "|    mean_step_reward   | 0.3446027   |\n",
      "|    n_updates          | 22640       |\n",
      "|    policyGradLoss     | -0.00451    |\n",
      "|    value_loss         | 2.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 46383104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017943915 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.412       |\n",
      "|    mean_step_reward   | 0.45171925  |\n",
      "|    n_updates          | 22644       |\n",
      "|    policyGradLoss     | -0.00952    |\n",
      "|    value_loss         | 0.803       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 46391296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015771568 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.737       |\n",
      "|    mean_step_reward   | 0.35690966  |\n",
      "|    n_updates          | 22648       |\n",
      "|    policyGradLoss     | -0.00611    |\n",
      "|    value_loss         | 1.9         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 46399488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019462373 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.252       |\n",
      "|    mean_step_reward   | 0.37530267  |\n",
      "|    n_updates          | 22652       |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 1.12        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_176.zip\n",
      "[EVAL] Mean Return: 543.462, Best Return: 550.128\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_176_543.46.mp4\n",
      "\n",
      "=== Round 178 | Learn 262144 steps (Total trained: 46399488) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1081     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 46407680 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 896         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 46415872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017213155 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.532       |\n",
      "|    mean_step_reward   | 0.30915958  |\n",
      "|    n_updates          | 22660       |\n",
      "|    policyGradLoss     | -0.00623    |\n",
      "|    value_loss         | 1.88        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 848         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 46424064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021352794 |\n",
      "|    entropy_loss       | -1.54       |\n",
      "|    explained_variance | 0.997       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0478      |\n",
      "|    mean_step_reward   | 0.45247918  |\n",
      "|    n_updates          | 22664       |\n",
      "|    policyGradLoss     | -0.0104     |\n",
      "|    value_loss         | 0.409       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 46432256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012239222 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.05        |\n",
      "|    mean_step_reward   | 0.347373    |\n",
      "|    n_updates          | 22668       |\n",
      "|    policyGradLoss     | -0.00278    |\n",
      "|    value_loss         | 1.84        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 46440448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015606517 |\n",
      "|    entropy_loss       | -1.54       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.14        |\n",
      "|    mean_step_reward   | 0.4653141   |\n",
      "|    n_updates          | 22672       |\n",
      "|    policyGradLoss     | -0.0047     |\n",
      "|    value_loss         | 2.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 46448640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014271904 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.81        |\n",
      "|    mean_step_reward   | 0.36749512  |\n",
      "|    n_updates          | 22676       |\n",
      "|    policyGradLoss     | -0.00434    |\n",
      "|    value_loss         | 2.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 46456832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023347955 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.508       |\n",
      "|    mean_step_reward   | 0.34430194  |\n",
      "|    n_updates          | 22680       |\n",
      "|    policyGradLoss     | -0.00622    |\n",
      "|    value_loss         | 1.89        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 796        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 82         |\n",
      "|    total_timesteps    | 46465024   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01961255 |\n",
      "|    entropy_loss       | -1.56      |\n",
      "|    explained_variance | 0.993      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.425      |\n",
      "|    mean_step_reward   | 0.42446446 |\n",
      "|    n_updates          | 22684      |\n",
      "|    policyGradLoss     | -0.00768   |\n",
      "|    value_loss         | 0.956      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 46473216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013745943 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.56        |\n",
      "|    mean_step_reward   | 0.35469416  |\n",
      "|    n_updates          | 22688       |\n",
      "|    policyGradLoss     | 6.78e-05    |\n",
      "|    value_loss         | 4.83        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 46481408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015846562 |\n",
      "|    entropy_loss       | -1.55       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.171       |\n",
      "|    mean_step_reward   | 0.4648199   |\n",
      "|    n_updates          | 22692       |\n",
      "|    policyGradLoss     | -0.00644    |\n",
      "|    value_loss         | 0.819       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 46489600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011957847 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.612       |\n",
      "|    mean_step_reward   | 0.36075974  |\n",
      "|    n_updates          | 22696       |\n",
      "|    policyGradLoss     | -0.00352    |\n",
      "|    value_loss         | 2.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 46497792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012944844 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.742       |\n",
      "|    mean_step_reward   | 0.42379373  |\n",
      "|    n_updates          | 22700       |\n",
      "|    policyGradLoss     | -0.00505    |\n",
      "|    value_loss         | 1.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 46505984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019609563 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.341       |\n",
      "|    mean_step_reward   | 0.3673256   |\n",
      "|    n_updates          | 22704       |\n",
      "|    policyGradLoss     | -0.0114     |\n",
      "|    value_loss         | 1.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 46514176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011988115 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.568       |\n",
      "|    mean_step_reward   | 0.3645659   |\n",
      "|    n_updates          | 22708       |\n",
      "|    policyGradLoss     | -0.00453    |\n",
      "|    value_loss         | 1.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 46522368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014723471 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.25        |\n",
      "|    mean_step_reward   | 0.43174812  |\n",
      "|    n_updates          | 22712       |\n",
      "|    policyGradLoss     | -0.00686    |\n",
      "|    value_loss         | 1.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 46530560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008219611 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.498       |\n",
      "|    mean_step_reward   | 0.4510053   |\n",
      "|    n_updates          | 22716       |\n",
      "|    policyGradLoss     | -0.00304    |\n",
      "|    value_loss         | 1.71        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 46538752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011151589 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.546       |\n",
      "|    mean_step_reward   | 0.44407272  |\n",
      "|    n_updates          | 22720       |\n",
      "|    policyGradLoss     | -0.00595    |\n",
      "|    value_loss         | 1.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 46546944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018742632 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.329       |\n",
      "|    mean_step_reward   | 0.43090016  |\n",
      "|    n_updates          | 22724       |\n",
      "|    policyGradLoss     | -0.00848    |\n",
      "|    value_loss         | 1.09        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 46555136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013320062 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.552       |\n",
      "|    mean_step_reward   | 0.41785938  |\n",
      "|    n_updates          | 22728       |\n",
      "|    policyGradLoss     | -0.00484    |\n",
      "|    value_loss         | 1.75        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 46563328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016442813 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.01        |\n",
      "|    mean_step_reward   | 0.39396197  |\n",
      "|    n_updates          | 22732       |\n",
      "|    policyGradLoss     | -0.00573    |\n",
      "|    value_loss         | 1.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 46571520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014781065 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.298       |\n",
      "|    mean_step_reward   | 0.46205443  |\n",
      "|    n_updates          | 22736       |\n",
      "|    policyGradLoss     | -0.00662    |\n",
      "|    value_loss         | 0.997       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 46579712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018225878 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.918       |\n",
      "|    mean_step_reward   | 0.34831136  |\n",
      "|    n_updates          | 22740       |\n",
      "|    policyGradLoss     | -0.00376    |\n",
      "|    value_loss         | 3.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 46587904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018990025 |\n",
      "|    entropy_loss       | -1.55       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.338       |\n",
      "|    mean_step_reward   | 0.44169486  |\n",
      "|    n_updates          | 22744       |\n",
      "|    policyGradLoss     | -0.00664    |\n",
      "|    value_loss         | 0.748       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 46596096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011553485 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.59        |\n",
      "|    mean_step_reward   | 0.38282102  |\n",
      "|    n_updates          | 22748       |\n",
      "|    policyGradLoss     | -0.00491    |\n",
      "|    value_loss         | 1.86        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 46604288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019462183 |\n",
      "|    entropy_loss       | -1.54       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.519       |\n",
      "|    mean_step_reward   | 0.4452318   |\n",
      "|    n_updates          | 22752       |\n",
      "|    policyGradLoss     | -0.00337    |\n",
      "|    value_loss         | 1.75        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 46612480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012242904 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.09        |\n",
      "|    mean_step_reward   | 0.39584962  |\n",
      "|    n_updates          | 22756       |\n",
      "|    policyGradLoss     | -0.00547    |\n",
      "|    value_loss         | 1.98        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 283        |\n",
      "|    total_timesteps    | 46620672   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02185736 |\n",
      "|    entropy_loss       | -1.58      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.788      |\n",
      "|    mean_step_reward   | 0.3928936  |\n",
      "|    n_updates          | 22760      |\n",
      "|    policyGradLoss     | -0.00757   |\n",
      "|    value_loss         | 1.23       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 46628864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016305016 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.248       |\n",
      "|    mean_step_reward   | 0.43927372  |\n",
      "|    n_updates          | 22764       |\n",
      "|    policyGradLoss     | -0.00914    |\n",
      "|    value_loss         | 0.919       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 46637056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014363845 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.976       |\n",
      "|    mean_step_reward   | 0.45558012  |\n",
      "|    n_updates          | 22768       |\n",
      "|    policyGradLoss     | -0.00408    |\n",
      "|    value_loss         | 2.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 46645248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012794463 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.612       |\n",
      "|    mean_step_reward   | 0.43765396  |\n",
      "|    n_updates          | 22772       |\n",
      "|    policyGradLoss     | -0.00682    |\n",
      "|    value_loss         | 1.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 46653440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014625615 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.304       |\n",
      "|    mean_step_reward   | 0.3781463   |\n",
      "|    n_updates          | 22776       |\n",
      "|    policyGradLoss     | -0.00565    |\n",
      "|    value_loss         | 1.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 46661632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015816055 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.417       |\n",
      "|    mean_step_reward   | 0.4326951   |\n",
      "|    n_updates          | 22780       |\n",
      "|    policyGradLoss     | -0.00719    |\n",
      "|    value_loss         | 1.24        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_177.zip\n",
      "[EVAL] Mean Return: 540.701, Best Return: 547.368\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_177_540.70.mp4\n",
      "\n",
      "=== Round 179 | Learn 262144 steps (Total trained: 46661632) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1110     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 46669824 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 899         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 46678016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018571056 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.877       |\n",
      "|    mean_step_reward   | 0.38153395  |\n",
      "|    n_updates          | 22788       |\n",
      "|    policyGradLoss     | -0.00643    |\n",
      "|    value_loss         | 2.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 856         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 46686208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018257376 |\n",
      "|    entropy_loss       | -1.56       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.235       |\n",
      "|    mean_step_reward   | 0.45823693  |\n",
      "|    n_updates          | 22792       |\n",
      "|    policyGradLoss     | -0.00779    |\n",
      "|    value_loss         | 1.06        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 832        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 39         |\n",
      "|    total_timesteps    | 46694400   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01720671 |\n",
      "|    entropy_loss       | -1.63      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.33       |\n",
      "|    mean_step_reward   | 0.36286697 |\n",
      "|    n_updates          | 22796      |\n",
      "|    policyGradLoss     | -0.007     |\n",
      "|    value_loss         | 1.7        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 46702592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019095011 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.459       |\n",
      "|    mean_step_reward   | 0.39601618  |\n",
      "|    n_updates          | 22800       |\n",
      "|    policyGradLoss     | -0.00899    |\n",
      "|    value_loss         | 0.945       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 46710784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011116276 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.899       |\n",
      "|    mean_step_reward   | 0.44817644  |\n",
      "|    n_updates          | 22804       |\n",
      "|    policyGradLoss     | -0.0063     |\n",
      "|    value_loss         | 1.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 46718976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011434549 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.544       |\n",
      "|    mean_step_reward   | 0.4219216   |\n",
      "|    n_updates          | 22808       |\n",
      "|    policyGradLoss     | -0.00467    |\n",
      "|    value_loss         | 2.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 46727168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013535945 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.79        |\n",
      "|    mean_step_reward   | 0.46056333  |\n",
      "|    n_updates          | 22812       |\n",
      "|    policyGradLoss     | -0.00819    |\n",
      "|    value_loss         | 1.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 46735360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013144968 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.05        |\n",
      "|    mean_step_reward   | 0.4036023   |\n",
      "|    n_updates          | 22816       |\n",
      "|    policyGradLoss     | -0.00836    |\n",
      "|    value_loss         | 1.76        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 46743552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014802862 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.916       |\n",
      "|    mean_step_reward   | 0.43062004  |\n",
      "|    n_updates          | 22820       |\n",
      "|    policyGradLoss     | -0.00765    |\n",
      "|    value_loss         | 1.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 46751744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014281839 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.19        |\n",
      "|    mean_step_reward   | 0.45518535  |\n",
      "|    n_updates          | 22824       |\n",
      "|    policyGradLoss     | -0.00668    |\n",
      "|    value_loss         | 1.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 46759936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009813888 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.852       |\n",
      "|    mean_step_reward   | 0.4091485   |\n",
      "|    n_updates          | 22828       |\n",
      "|    policyGradLoss     | -0.00542    |\n",
      "|    value_loss         | 1.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 46768128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019270202 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.271       |\n",
      "|    mean_step_reward   | 0.44357198  |\n",
      "|    n_updates          | 22832       |\n",
      "|    policyGradLoss     | -0.00962    |\n",
      "|    value_loss         | 1.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 46776320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012462341 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.535       |\n",
      "|    mean_step_reward   | 0.4383223   |\n",
      "|    n_updates          | 22836       |\n",
      "|    policyGradLoss     | -0.00633    |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 46784512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012242891 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.268       |\n",
      "|    mean_step_reward   | 0.38474554  |\n",
      "|    n_updates          | 22840       |\n",
      "|    policyGradLoss     | -0.00577    |\n",
      "|    value_loss         | 1.64        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 46792704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014634103 |\n",
      "|    entropy_loss       | -1.57       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.318       |\n",
      "|    mean_step_reward   | 0.47439486  |\n",
      "|    n_updates          | 22844       |\n",
      "|    policyGradLoss     | -0.00633    |\n",
      "|    value_loss         | 1.55        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 46800896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011967093 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.763       |\n",
      "|    mean_step_reward   | 0.4181775   |\n",
      "|    n_updates          | 22848       |\n",
      "|    policyGradLoss     | -0.00596    |\n",
      "|    value_loss         | 1.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 46809088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012268926 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.28        |\n",
      "|    mean_step_reward   | 0.47492027  |\n",
      "|    n_updates          | 22852       |\n",
      "|    policyGradLoss     | -0.00487    |\n",
      "|    value_loss         | 1.44        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 783          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 198          |\n",
      "|    total_timesteps    | 46817280     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0141334245 |\n",
      "|    entropy_loss       | -1.62        |\n",
      "|    explained_variance | 0.989        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.591        |\n",
      "|    mean_step_reward   | 0.46334705   |\n",
      "|    n_updates          | 22856        |\n",
      "|    policyGradLoss     | -0.00571     |\n",
      "|    value_loss         | 2.09         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 784        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 208        |\n",
      "|    total_timesteps    | 46825472   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01656685 |\n",
      "|    entropy_loss       | -1.61      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.607      |\n",
      "|    mean_step_reward   | 0.4298577  |\n",
      "|    n_updates          | 22860      |\n",
      "|    policyGradLoss     | -0.00514   |\n",
      "|    value_loss         | 1.82       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 46833664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014986221 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.808       |\n",
      "|    mean_step_reward   | 0.40047067  |\n",
      "|    n_updates          | 22864       |\n",
      "|    policyGradLoss     | -0.00282    |\n",
      "|    value_loss         | 1.89        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 784        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 229        |\n",
      "|    total_timesteps    | 46841856   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01886807 |\n",
      "|    entropy_loss       | -1.62      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.992      |\n",
      "|    mean_step_reward   | 0.39212364 |\n",
      "|    n_updates          | 22868      |\n",
      "|    policyGradLoss     | -0.00617   |\n",
      "|    value_loss         | 1.78       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 784        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 240        |\n",
      "|    total_timesteps    | 46850048   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01729175 |\n",
      "|    entropy_loss       | -1.58      |\n",
      "|    explained_variance | 0.992      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.438      |\n",
      "|    mean_step_reward   | 0.4250783  |\n",
      "|    n_updates          | 22872      |\n",
      "|    policyGradLoss     | -0.00941   |\n",
      "|    value_loss         | 1.29       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 250         |\n",
      "|    total_timesteps    | 46858240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016994178 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.777       |\n",
      "|    mean_step_reward   | 0.45587432  |\n",
      "|    n_updates          | 22876       |\n",
      "|    policyGradLoss     | -0.00591    |\n",
      "|    value_loss         | 1.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 46866432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016549222 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.21        |\n",
      "|    mean_step_reward   | 0.43510717  |\n",
      "|    n_updates          | 22880       |\n",
      "|    policyGradLoss     | -0.00319    |\n",
      "|    value_loss         | 1.92        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 46874624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015172257 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.409       |\n",
      "|    mean_step_reward   | 0.40694028  |\n",
      "|    n_updates          | 22884       |\n",
      "|    policyGradLoss     | -0.00262    |\n",
      "|    value_loss         | 1.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 46882816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016586976 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.139       |\n",
      "|    mean_step_reward   | 0.4041816   |\n",
      "|    n_updates          | 22888       |\n",
      "|    policyGradLoss     | -0.00808    |\n",
      "|    value_loss         | 1.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 46891008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017932825 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.892       |\n",
      "|    mean_step_reward   | 0.4830182   |\n",
      "|    n_updates          | 22892       |\n",
      "|    policyGradLoss     | -0.00539    |\n",
      "|    value_loss         | 1.81        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 303         |\n",
      "|    total_timesteps    | 46899200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014736079 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.84        |\n",
      "|    mean_step_reward   | 0.4063413   |\n",
      "|    n_updates          | 22896       |\n",
      "|    policyGradLoss     | -0.00413    |\n",
      "|    value_loss         | 1.64        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 314         |\n",
      "|    total_timesteps    | 46907392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013924539 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.89        |\n",
      "|    mean_step_reward   | 0.44075125  |\n",
      "|    n_updates          | 22900       |\n",
      "|    policyGradLoss     | -0.00211    |\n",
      "|    value_loss         | 4.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 46915584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014162136 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.436       |\n",
      "|    mean_step_reward   | 0.4278215   |\n",
      "|    n_updates          | 22904       |\n",
      "|    policyGradLoss     | -0.00264    |\n",
      "|    value_loss         | 1.5         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 335         |\n",
      "|    total_timesteps    | 46923776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012258219 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.188       |\n",
      "|    mean_step_reward   | 0.44993982  |\n",
      "|    n_updates          | 22908       |\n",
      "|    policyGradLoss     | -0.00241    |\n",
      "|    value_loss         | 1.82        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_178.zip\n",
      "[EVAL] Mean Return: 543.260, Best Return: 549.927\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_178_543.26.mp4\n",
      "\n",
      "=== Round 180 | Learn 262144 steps (Total trained: 46923776) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1179     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 46931968 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 939         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 46940160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014438041 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.652       |\n",
      "|    mean_step_reward   | 0.40736997  |\n",
      "|    n_updates          | 22916       |\n",
      "|    policyGradLoss     | -0.00715    |\n",
      "|    value_loss         | 1.61        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 878         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 46948352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017363321 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.741       |\n",
      "|    mean_step_reward   | 0.43903196  |\n",
      "|    n_updates          | 22920       |\n",
      "|    policyGradLoss     | -0.00539    |\n",
      "|    value_loss         | 1.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 852         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 46956544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014725075 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.373       |\n",
      "|    mean_step_reward   | 0.40195626  |\n",
      "|    n_updates          | 22924       |\n",
      "|    policyGradLoss     | -0.00525    |\n",
      "|    value_loss         | 1.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 835         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 46964736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025657646 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.489       |\n",
      "|    mean_step_reward   | 0.41382888  |\n",
      "|    n_updates          | 22928       |\n",
      "|    policyGradLoss     | -0.00894    |\n",
      "|    value_loss         | 1.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 46972928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015034262 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.755       |\n",
      "|    mean_step_reward   | 0.4404586   |\n",
      "|    n_updates          | 22932       |\n",
      "|    policyGradLoss     | -0.00351    |\n",
      "|    value_loss         | 1.59        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 819        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 69         |\n",
      "|    total_timesteps    | 46981120   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01302868 |\n",
      "|    entropy_loss       | -1.59      |\n",
      "|    explained_variance | 0.96       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.686      |\n",
      "|    mean_step_reward   | 0.45433512 |\n",
      "|    n_updates          | 22936      |\n",
      "|    policyGradLoss     | 4.61e-05   |\n",
      "|    value_loss         | 3.4        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 80          |\n",
      "|    total_timesteps    | 46989312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011071597 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.809       |\n",
      "|    mean_step_reward   | 0.45337313  |\n",
      "|    n_updates          | 22940       |\n",
      "|    policyGradLoss     | -0.00582    |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 46997504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012661338 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.743       |\n",
      "|    mean_step_reward   | 0.4299425   |\n",
      "|    n_updates          | 22944       |\n",
      "|    policyGradLoss     | -0.00524    |\n",
      "|    value_loss         | 1.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 100         |\n",
      "|    total_timesteps    | 47005696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014906099 |\n",
      "|    entropy_loss       | -1.62       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0693      |\n",
      "|    mean_step_reward   | 0.40415567  |\n",
      "|    n_updates          | 22948       |\n",
      "|    policyGradLoss     | -0.00443    |\n",
      "|    value_loss         | 1.56        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 811        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 111        |\n",
      "|    total_timesteps    | 47013888   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01779081 |\n",
      "|    entropy_loss       | -1.59      |\n",
      "|    explained_variance | 0.986      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.965      |\n",
      "|    mean_step_reward   | 0.43231568 |\n",
      "|    n_updates          | 22952      |\n",
      "|    policyGradLoss     | -0.00446   |\n",
      "|    value_loss         | 1.98       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 121         |\n",
      "|    total_timesteps    | 47022080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015167613 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.372       |\n",
      "|    mean_step_reward   | 0.4049205   |\n",
      "|    n_updates          | 22956       |\n",
      "|    policyGradLoss     | -0.00578    |\n",
      "|    value_loss         | 1.64        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 131         |\n",
      "|    total_timesteps    | 47030272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011353919 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.542       |\n",
      "|    mean_step_reward   | 0.4130305   |\n",
      "|    n_updates          | 22960       |\n",
      "|    policyGradLoss     | -0.00594    |\n",
      "|    value_loss         | 1.74        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 47038464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011465335 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.262       |\n",
      "|    mean_step_reward   | 0.44543236  |\n",
      "|    n_updates          | 22964       |\n",
      "|    policyGradLoss     | -0.00566    |\n",
      "|    value_loss         | 1.19        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 801        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 153        |\n",
      "|    total_timesteps    | 47046656   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01503313 |\n",
      "|    entropy_loss       | -1.61      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.426      |\n",
      "|    mean_step_reward   | 0.42845744 |\n",
      "|    n_updates          | 22968      |\n",
      "|    policyGradLoss     | -0.00714   |\n",
      "|    value_loss         | 1.72       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 163         |\n",
      "|    total_timesteps    | 47054848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019980777 |\n",
      "|    entropy_loss       | -1.57       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.733       |\n",
      "|    mean_step_reward   | 0.38178134  |\n",
      "|    n_updates          | 22972       |\n",
      "|    policyGradLoss     | -0.01       |\n",
      "|    value_loss         | 1.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 174         |\n",
      "|    total_timesteps    | 47063040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018584885 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.506       |\n",
      "|    mean_step_reward   | 0.4016546   |\n",
      "|    n_updates          | 22976       |\n",
      "|    policyGradLoss     | 0.00287     |\n",
      "|    value_loss         | 1.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 184         |\n",
      "|    total_timesteps    | 47071232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016387578 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.373       |\n",
      "|    mean_step_reward   | 0.3880527   |\n",
      "|    n_updates          | 22980       |\n",
      "|    policyGradLoss     | -0.00806    |\n",
      "|    value_loss         | 1.81        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 195         |\n",
      "|    total_timesteps    | 47079424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014933493 |\n",
      "|    entropy_loss       | -1.56       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.306       |\n",
      "|    mean_step_reward   | 0.43627423  |\n",
      "|    n_updates          | 22984       |\n",
      "|    policyGradLoss     | -0.0076     |\n",
      "|    value_loss         | 1.11        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 205         |\n",
      "|    total_timesteps    | 47087616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016606223 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.783       |\n",
      "|    mean_step_reward   | 0.3759768   |\n",
      "|    n_updates          | 22988       |\n",
      "|    policyGradLoss     | -0.00638    |\n",
      "|    value_loss         | 1.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 216         |\n",
      "|    total_timesteps    | 47095808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018550923 |\n",
      "|    entropy_loss       | -1.58       |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.155       |\n",
      "|    mean_step_reward   | 0.42888305  |\n",
      "|    n_updates          | 22992       |\n",
      "|    policyGradLoss     | -0.00946    |\n",
      "|    value_loss         | 0.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 226         |\n",
      "|    total_timesteps    | 47104000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020577982 |\n",
      "|    entropy_loss       | -1.6        |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.868       |\n",
      "|    mean_step_reward   | 0.43350792  |\n",
      "|    n_updates          | 22996       |\n",
      "|    policyGradLoss     | -0.00277    |\n",
      "|    value_loss         | 1.54        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 794        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 237        |\n",
      "|    total_timesteps    | 47112192   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01039928 |\n",
      "|    entropy_loss       | -1.57      |\n",
      "|    explained_variance | 0.993      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0327     |\n",
      "|    mean_step_reward   | 0.4850877  |\n",
      "|    n_updates          | 23000      |\n",
      "|    policyGradLoss     | -0.00326   |\n",
      "|    value_loss         | 1.2        |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 793          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 247          |\n",
      "|    total_timesteps    | 47120384     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0118742455 |\n",
      "|    entropy_loss       | -1.63        |\n",
      "|    explained_variance | 0.993        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.603        |\n",
      "|    mean_step_reward   | 0.41270012   |\n",
      "|    n_updates          | 23004        |\n",
      "|    policyGradLoss     | -0.00583     |\n",
      "|    value_loss         | 1.47         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 258         |\n",
      "|    total_timesteps    | 47128576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012524276 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.398       |\n",
      "|    mean_step_reward   | 0.42631915  |\n",
      "|    n_updates          | 23008       |\n",
      "|    policyGradLoss     | -0.00311    |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 269         |\n",
      "|    total_timesteps    | 47136768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016674193 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.783       |\n",
      "|    mean_step_reward   | 0.4770748   |\n",
      "|    n_updates          | 23012       |\n",
      "|    policyGradLoss     | -0.00761    |\n",
      "|    value_loss         | 1.53        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 279         |\n",
      "|    total_timesteps    | 47144960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014237885 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.71        |\n",
      "|    mean_step_reward   | 0.37040544  |\n",
      "|    n_updates          | 23016       |\n",
      "|    policyGradLoss     | -0.00682    |\n",
      "|    value_loss         | 2           |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 290         |\n",
      "|    total_timesteps    | 47153152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021371542 |\n",
      "|    entropy_loss       | -1.55       |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.513       |\n",
      "|    mean_step_reward   | 0.50000286  |\n",
      "|    n_updates          | 23020       |\n",
      "|    policyGradLoss     | -0.00706    |\n",
      "|    value_loss         | 0.873       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 300         |\n",
      "|    total_timesteps    | 47161344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012594251 |\n",
      "|    entropy_loss       | -1.61       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.429       |\n",
      "|    mean_step_reward   | 0.3819329   |\n",
      "|    n_updates          | 23024       |\n",
      "|    policyGradLoss     | -0.00545    |\n",
      "|    value_loss         | 2.03        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 789        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 311        |\n",
      "|    total_timesteps    | 47169536   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01419063 |\n",
      "|    entropy_loss       | -1.58      |\n",
      "|    explained_variance | 0.992      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.319      |\n",
      "|    mean_step_reward   | 0.49442387 |\n",
      "|    n_updates          | 23028      |\n",
      "|    policyGradLoss     | -0.00362   |\n",
      "|    value_loss         | 1.45       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 321         |\n",
      "|    total_timesteps    | 47177728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012523051 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.24        |\n",
      "|    mean_step_reward   | 0.40719706  |\n",
      "|    n_updates          | 23032       |\n",
      "|    policyGradLoss     | -0.00552    |\n",
      "|    value_loss         | 2.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 332         |\n",
      "|    total_timesteps    | 47185920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017834917 |\n",
      "|    entropy_loss       | -1.59       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.376       |\n",
      "|    mean_step_reward   | 0.42317954  |\n",
      "|    n_updates          | 23036       |\n",
      "|    policyGradLoss     | -0.0058     |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_179.zip\n",
      "[EVAL] Mean Return: 543.359, Best Return: 550.025\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_179_543.36.mp4\n",
      "\n",
      "=== Round 181 | Learn 262144 steps (Total trained: 47185920) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1154     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 47194112 |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 934       |\n",
      "|    iterations         | 2         |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 47202304  |\n",
      "| train/                |           |\n",
      "|    approx_kl          | 0.0122112 |\n",
      "|    entropy_loss       | -1.64     |\n",
      "|    explained_variance | 0.967     |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    loss               | 0.306     |\n",
      "|    mean_step_reward   | 0.3493291 |\n",
      "|    n_updates          | 23044     |\n",
      "|    policyGradLoss     | -0.000362 |\n",
      "|    value_loss         | 2.83      |\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    while trained < TOTAL_STEPS:\n",
    "        round_idx += 1\n",
    "        chunk = min(TRAIN_CHUNK, TOTAL_STEPS - trained)\n",
    "        # chunk = 2000\n",
    "        label = \"Enc5\"\n",
    "        tagged_label = f\"{label}_{int(trained/TRAIN_CHUNK)}\"\n",
    "\n",
    "        print(f\"\\n=== Round {round_idx} | Learn {chunk} steps (Total trained: {trained}) ===\")\n",
    "        \n",
    "        # --- Train ---\n",
    "        model.learn(total_timesteps=chunk, reset_num_timesteps=False, tb_log_name=label)\n",
    "        trained += chunk\n",
    "\n",
    "        # --- Save Checkpoint ---\n",
    "        ckpt_path = os.path.join(CKPT_DIR, f\"{tagged_label}.zip\")\n",
    "        model.save(ckpt_path)\n",
    "        print(f\"Saved checkpoint: {ckpt_path}\")\n",
    "\n",
    "        # --- Evaluate ---\n",
    "        mean_ret, best_ret = evaluate_policy(\n",
    "            model,\n",
    "            GAME,\n",
    "            STATE,\n",
    "            n_episodes=EVAL_EPISODES,\n",
    "            max_steps=EVAL_MAX_STEPS,\n",
    "        )\n",
    "        print(f\"[EVAL] Mean Return: {mean_ret:.3f}, Best Return: {best_ret:.3f}\")\n",
    "\n",
    "        # --- Save Best Model ---\n",
    "        # if mean_ret > best_mean:\n",
    "        #     best_mean = mean_ret\n",
    "        #     best_path = os.path.join(LOG_DIR, \"best_model.zip\")\n",
    "        #     model.save(best_path)\n",
    "        #     print(f\"New best record. Saved to {best_path}\")\n",
    "\n",
    "        # --- Record Video ---\n",
    "        out_path = os.path.join(VIDEO_DIR, label)\n",
    "        os.makedirs(out_path,  exist_ok=True)\n",
    "        record_video(\n",
    "            model,\n",
    "            GAME,\n",
    "            STATE,\n",
    "            VIDEO_DIR,\n",
    "            video_len=RECORD_STEPS,\n",
    "            prefix=f\"{label}/{tagged_label}_{mean_ret:.2f}\",\n",
    "        )\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nTraining interrupted manually.\")\n",
    "\n",
    "finally:\n",
    "    train_env.close()\n",
    "    print(\"Training finished. Environment closed.\")\n",
    "    \n",
    "\"\"\"\n",
    "tensorboard --logdir=./runs_smw/tb\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f088b0b3-2418-4866-b332-0312c9f6467f",
   "metadata": {},
   "source": [
    "## Display Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73191bb-e875-4939-b04c-a4670abd9612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "import glob\n",
    "# label = \"Dec22A\"\n",
    "\n",
    "# list_of_files = glob.glob(os.path.join(VIDEO_DIR, label, '*.mp4')) \n",
    "# if list_of_files:\n",
    "#     latest_file = max(list_of_files, key=os.path.getctime)\n",
    "#     print(f\"Playing: {latest_file}\")\n",
    "#     latest_file = \"runs_smw/videos/Dec22A/Dec22A_73_596.54.mp4\"\n",
    "#     print(f\"Playing: {latest_file}\")\n",
    "#     display(Video(latest_file, embed=True, width=768))\n",
    "# else:\n",
    "#     print(\"No videos found yet.\")\n",
    "    \n",
    "video = \"./runs_smw/videos/Dec22A/Dec22A_73_596.54.mp4\"\n",
    "# display(Video(video, embed=True, width=768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942adf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(\"runs_smw/videos/test_16.mp4\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    cv2.imshow(\"Frame-by-Frame\", frame)\n",
    "\n",
    "    # 關鍵：這裡等待按鍵。按 'n' 鍵跳到下一幀，按 'q' 離開\n",
    "    key = cv2.waitKey(0) \n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('n'):\n",
    "        continue\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lab8 (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
