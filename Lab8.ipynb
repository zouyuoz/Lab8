{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dceedafe-2782-41a1-8119-50ee3d6c21fd",
   "metadata": {},
   "source": [
    "# 2025 DL Lab8: RL Assignment_Super Mario World"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fa555a-e61c-4fb3-b5d0-289b66570139",
   "metadata": {},
   "source": [
    "**Your Answer:**    \n",
    "Hi I'm XXX, XXXXXXXXXX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5b0974-9605-488a-9fd5-00816e7832cc",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This project implements a **Deep Reinforcement Learning** pipeline to train an autonomous agent for Super Mario World. Leveraging the **Proximal Policy Optimization (PPO)** algorithm, the system interacts with the **stable-retro** environment to master the YoshiIsland1 level. Key components include a custom Vision Backbone for extracting features from raw pixel data and a suite of Environment Wrappers that handle frame preprocessing, action discretization, and reward shaping to facilitate efficient learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02696447",
   "metadata": {},
   "source": [
    "Reward function implement  \n",
    "should do something in the beginning (monster attack)  \n",
    "Custom PPO implement  \n",
    "pre train weight 差不多，主要是 reward function  \n",
    "model weight capacity 1GB  \n",
    "class name 不要動 (可以新增，但是原本有的不要動)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8a0ab9-f86d-4038-833d-761ec81fc4f2",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00b10def-362c-4910-9ed0-f3d0904343ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import retro\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "\n",
    "from eval import evaluate_policy, record_video\n",
    "from custom_policy import VisionBackbonePolicy, CustomPPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10361fd-f291-4d93-b50d-cc749a3af588",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b4f6a25-738c-49dd-8e66-ae164b74a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game Settings\n",
    "GAME = \"SuperMarioWorld-Snes\"\n",
    "STATE = \"YoshiIsland1\"\n",
    "\n",
    "# Training Settings\n",
    "# TOTAL_STEPS = 0x1400000 # 20,971,520\n",
    "# TOTAL_STEPS = 0x0A00000 # 10,485,760\n",
    "TOTAL_STEPS = 0x1900000\n",
    "TRAIN_CHUNK = 0x0040000 #    262,144\n",
    "N_ENVS = 16\n",
    "\n",
    "# Evaluation & Recording Settings\n",
    "EVAL_EPISODES = 3\n",
    "EVAL_MAX_STEPS = 18000\n",
    "RECORD_STEPS = 1800\n",
    "\n",
    "# Directories\n",
    "LOG_DIR = \"./runs_smw\"\n",
    "VIDEO_DIR       = os.path.join(LOG_DIR, \"videos\")\n",
    "CKPT_DIR        = os.path.join(LOG_DIR, \"checkpoints\")\n",
    "TENSORBOARD_LOG = os.path.join(LOG_DIR, \"tb\")\n",
    "\n",
    "os.makedirs(LOG_DIR,   exist_ok=True)\n",
    "os.makedirs(CKPT_DIR,  exist_ok=True)\n",
    "os.makedirs(VIDEO_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a34b783-0273-4835-ad2e-f9186064f76f",
   "metadata": {},
   "source": [
    "## Environment Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c34213d-2c7c-42b8-922d-bafa285d1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrappers import make_base_env\n",
    "def _make_env_thunk(game: str, state: str):\n",
    "    \"\"\"Return a function that creates an environment (for multiprocessing).\"\"\"\n",
    "    def _thunk():\n",
    "        return make_base_env(game, state)\n",
    "    return _thunk\n",
    "\n",
    "def make_vec_env(game: str, state: str, n_envs: int, use_subproc: bool = True):\n",
    "    \"\"\"Create a vectorized environment (multiple envs running in parallel).\"\"\"\n",
    "    env_fns = [_make_env_thunk(game, state) for _ in range(n_envs)]\n",
    "    \n",
    "    if use_subproc and n_envs > 1:\n",
    "        vec_env = SubprocVecEnv(env_fns)\n",
    "    else:\n",
    "        vec_env = DummyVecEnv(env_fns)\n",
    "\n",
    "    return vec_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dff476-ea2e-4262-8780-afb32ef1b233",
   "metadata": {},
   "source": [
    "## Initialize Env & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c7c5fe-6421-4dbc-9bd8-822d61769c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment created: SuperMarioWorld-Snes - YoshiIsland1 with 16 parallel envs.\n",
      "[Fail] Can't load None. Will use new model\n",
      "Using cuda:0 device\n"
     ]
    }
   ],
   "source": [
    "# 1. Create Training Environment\n",
    "train_env = make_vec_env(GAME, STATE, n_envs=N_ENVS)\n",
    "# train_env = VecNormalize(train_env, norm_obs=True, norm_reward=True, clip_obs=10., clip_reward=10.)\n",
    "print(f\"Environment created: {GAME} - {STATE} with {N_ENVS} parallel envs.\")\n",
    "\n",
    "checkpoint_path = \"None\" # 6225920 (19) 有破壞\n",
    "# checkpoint_path = \"runs_smw/checkpoints/Enc5_45.zip\"\n",
    "\n",
    "best_mean = -1e18\n",
    "trained = 0\n",
    "round_idx = 0\n",
    "\n",
    "# 2. Initialize Model\n",
    "if os.path.exists(checkpoint_path):\n",
    "    # 讀取現有模型\n",
    "    model = CustomPPO.load(\n",
    "        checkpoint_path, \n",
    "        env=train_env,\n",
    "        device=\"cuda:0\" # 確保使用 GPU\n",
    "    )\n",
    "    trained = model.num_timesteps\n",
    "    round_idx = int(trained / TRAIN_CHUNK)\n",
    "    print(f\"[Sucess] Loaded model from {checkpoint_path}\")\n",
    "    print(f\"trained: {trained}, round_index: {round_idx}\")\n",
    "else:\n",
    "    print(f\"[Fail] Can't load {checkpoint_path}. Will use new model\")\n",
    "    model = CustomPPO(\n",
    "        VisionBackbonePolicy,\n",
    "        train_env,\n",
    "        policy_kwargs   = dict(normalize_images=False),\n",
    "        n_epochs        = 4,\n",
    "        n_steps         = 512,\n",
    "        batch_size      = 512,\n",
    "        learning_rate   = 1e-4,\n",
    "        verbose         = 1,\n",
    "        gamma           = 0.96875,\n",
    "        kl_coef         = 1,\n",
    "        clip_range      = 0.125,\n",
    "        ent_coef        = 0.0375,\n",
    "        tensorboard_log = TENSORBOARD_LOG,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cb3d0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"policy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eb7a896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "準備測試以下 Checkpoints: [59, 63, 67]\n",
      "\n",
      "[59] 正在載入模型: ./runs_smw/checkpoints/Enc5_59.zip ...\n",
      "[59] 正在錄影 (長度 1800 steps)...\n",
      "Saved video to ./runs_smw/videos/test_59.mp4\n",
      "✅ 完成！影片已儲存為 test_59.mp4\n",
      "\n",
      "[63] 正在載入模型: ./runs_smw/checkpoints/Enc5_63.zip ...\n",
      "[63] 正在錄影 (長度 1800 steps)...\n",
      "Saved video to ./runs_smw/videos/test_63.mp4\n",
      "✅ 完成！影片已儲存為 test_63.mp4\n",
      "\n",
      "[67] 正在載入模型: ./runs_smw/checkpoints/Enc5_67.zip ...\n",
      "[67] 正在錄影 (長度 1800 steps)...\n",
      "Saved video to ./runs_smw/videos/test_67.mp4\n",
      "✅ 完成！影片已儲存為 test_67.mp4\n",
      "\n",
      "所有測試結束。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from custom_policy import CustomPPO\n",
    "from eval import record_video  # 確保 eval.py 在同一目錄下\n",
    "\n",
    "# ================= 設定區 =================\n",
    "target_numbers = [59, 63, 67]\n",
    "\n",
    "# ================= 執行迴圈 =================\n",
    "print(f\"準備測試以下 Checkpoints: {target_numbers}\")\n",
    "\n",
    "for num in target_numbers:\n",
    "    model_path = os.path.join(CKPT_DIR, f\"Enc5_{num}.zip\")\n",
    "    \n",
    "    # 檢查檔案是否存在\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"⚠️ 找不到檔案: {model_path}，跳過。\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n[{num}] 正在載入模型: {model_path} ...\")\n",
    "    \n",
    "    try:\n",
    "        # 1. 載入模型 (不需要 env 參數也能載入權重)\n",
    "        # 如果你有改過 CustomPPO 的參數，load 會自動讀取 zip 裡的設定\n",
    "        model = CustomPPO.load(model_path, device=\"auto\") # device=\"auto\" 會自動用 GPU\n",
    "        \n",
    "        # 2. 錄製影片\n",
    "        prefix_name = f\"test_{num}\"\n",
    "        print(f\"[{num}] 正在錄影 (長度 {RECORD_STEPS} steps)...\")\n",
    "        \n",
    "        record_video(\n",
    "            model=model,\n",
    "            game=GAME,\n",
    "            state=STATE,\n",
    "            out_dir=VIDEO_DIR,\n",
    "            video_len=RECORD_STEPS,\n",
    "            prefix=prefix_name\n",
    "        )\n",
    "        print(f\"✅ 完成！影片已儲存為 {prefix_name}.mp4\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 發生錯誤 (Model: {num}): {e}\")\n",
    "\n",
    "print(\"\\n所有測試結束。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f594e443-843f-42c1-9fc6-3fbc82962021",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af4932-c531-4113-a33a-defc6fb5858e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Round 47 | Learn 262144 steps (Total trained: 12058624) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1104     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 12066816 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 870        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 12075008   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0114237  |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.88       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.213      |\n",
      "|    mean_step_reward   | 0.21493906 |\n",
      "|    n_updates          | 5892       |\n",
      "|    policyGradLoss     | 0.00225    |\n",
      "|    value_loss         | 1.18       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 12083200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020529095 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.677       |\n",
      "|    mean_step_reward   | 0.42075995  |\n",
      "|    n_updates          | 5896        |\n",
      "|    policyGradLoss     | 0.0137      |\n",
      "|    value_loss         | 3.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 12091392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010121493 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.638       |\n",
      "|    mean_step_reward   | 0.21442944  |\n",
      "|    n_updates          | 5900        |\n",
      "|    policyGradLoss     | 0.00292     |\n",
      "|    value_loss         | 2.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 12099584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008283007 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.465       |\n",
      "|    mean_step_reward   | 0.28377455  |\n",
      "|    n_updates          | 5904        |\n",
      "|    policyGradLoss     | -0.00225    |\n",
      "|    value_loss         | 2.29        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 787          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 62           |\n",
      "|    total_timesteps    | 12107776     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0082301535 |\n",
      "|    entropy_loss       | -1.75        |\n",
      "|    explained_variance | 0.967        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.304        |\n",
      "|    mean_step_reward   | 0.31520486   |\n",
      "|    n_updates          | 5908         |\n",
      "|    policyGradLoss     | -0.00574     |\n",
      "|    value_loss         | 1.81         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 73          |\n",
      "|    total_timesteps    | 12115968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008515691 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.369       |\n",
      "|    mean_step_reward   | 0.27310708  |\n",
      "|    n_updates          | 5912        |\n",
      "|    policyGradLoss     | -0.00528    |\n",
      "|    value_loss         | 1.81        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 773          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 84           |\n",
      "|    total_timesteps    | 12124160     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0105555635 |\n",
      "|    entropy_loss       | -1.77        |\n",
      "|    explained_variance | 0.925        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.02         |\n",
      "|    mean_step_reward   | 0.26086283   |\n",
      "|    n_updates          | 5916         |\n",
      "|    policyGradLoss     | -0.00108     |\n",
      "|    value_loss         | 3.25         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 96          |\n",
      "|    total_timesteps    | 12132352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009720324 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.14        |\n",
      "|    mean_step_reward   | 0.23404771  |\n",
      "|    n_updates          | 5920        |\n",
      "|    policyGradLoss     | -0.00527    |\n",
      "|    value_loss         | 1.46        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 12140544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008659767 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.2         |\n",
      "|    mean_step_reward   | 0.30134147  |\n",
      "|    n_updates          | 5924        |\n",
      "|    policyGradLoss     | -0.00553    |\n",
      "|    value_loss         | 1.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 117         |\n",
      "|    total_timesteps    | 12148736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009820309 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.892       |\n",
      "|    mean_step_reward   | 0.3117708   |\n",
      "|    n_updates          | 5928        |\n",
      "|    policyGradLoss     | 0.000674    |\n",
      "|    value_loss         | 4.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 128         |\n",
      "|    total_timesteps    | 12156928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008193584 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.209       |\n",
      "|    mean_step_reward   | 0.24509963  |\n",
      "|    n_updates          | 5932        |\n",
      "|    policyGradLoss     | -0.00462    |\n",
      "|    value_loss         | 1.69        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 763        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 139        |\n",
      "|    total_timesteps    | 12165120   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00920159 |\n",
      "|    entropy_loss       | -1.74      |\n",
      "|    explained_variance | 0.976      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.3        |\n",
      "|    mean_step_reward   | 0.35728043 |\n",
      "|    n_updates          | 5936       |\n",
      "|    policyGradLoss     | -0.00372   |\n",
      "|    value_loss         | 2.39       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 761        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 150        |\n",
      "|    total_timesteps    | 12173312   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01074196 |\n",
      "|    entropy_loss       | -1.72      |\n",
      "|    explained_variance | 0.941      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.671      |\n",
      "|    mean_step_reward   | 0.32339197 |\n",
      "|    n_updates          | 5940       |\n",
      "|    policyGradLoss     | 0.000935   |\n",
      "|    value_loss         | 3.38       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 161         |\n",
      "|    total_timesteps    | 12181504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009525852 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.882       |\n",
      "|    mean_step_reward   | 0.3178274   |\n",
      "|    n_updates          | 5944        |\n",
      "|    policyGradLoss     | -0.00079    |\n",
      "|    value_loss         | 2.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 172         |\n",
      "|    total_timesteps    | 12189696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008217361 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.893       |\n",
      "|    mean_step_reward   | 0.35292912  |\n",
      "|    n_updates          | 5948        |\n",
      "|    policyGradLoss     | -0.000949   |\n",
      "|    value_loss         | 3.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 183         |\n",
      "|    total_timesteps    | 12197888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009552049 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.383       |\n",
      "|    mean_step_reward   | 0.33500174  |\n",
      "|    n_updates          | 5952        |\n",
      "|    policyGradLoss     | -0.00273    |\n",
      "|    value_loss         | 2.76        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 193         |\n",
      "|    total_timesteps    | 12206080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009397231 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.456       |\n",
      "|    mean_step_reward   | 0.26663607  |\n",
      "|    n_updates          | 5956        |\n",
      "|    policyGradLoss     | -0.00381    |\n",
      "|    value_loss         | 1.99        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 204         |\n",
      "|    total_timesteps    | 12214272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009546277 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.48        |\n",
      "|    mean_step_reward   | 0.3703891   |\n",
      "|    n_updates          | 5960        |\n",
      "|    policyGradLoss     | -0.00144    |\n",
      "|    value_loss         | 2.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 216         |\n",
      "|    total_timesteps    | 12222464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007440051 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.311       |\n",
      "|    mean_step_reward   | 0.2652311   |\n",
      "|    n_updates          | 5964        |\n",
      "|    policyGradLoss     | -0.00405    |\n",
      "|    value_loss         | 1.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 227         |\n",
      "|    total_timesteps    | 12230656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009215887 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.256       |\n",
      "|    mean_step_reward   | 0.30895737  |\n",
      "|    n_updates          | 5968        |\n",
      "|    policyGradLoss     | -0.00368    |\n",
      "|    value_loss         | 1.97        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 758          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 237          |\n",
      "|    total_timesteps    | 12238848     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0075459504 |\n",
      "|    entropy_loss       | -1.69        |\n",
      "|    explained_variance | 0.983        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.447        |\n",
      "|    mean_step_reward   | 0.3547837    |\n",
      "|    n_updates          | 5972         |\n",
      "|    policyGradLoss     | -0.00655     |\n",
      "|    value_loss         | 1.51         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 246         |\n",
      "|    total_timesteps    | 12247040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007921739 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.274       |\n",
      "|    mean_step_reward   | 0.3549565   |\n",
      "|    n_updates          | 5976        |\n",
      "|    policyGradLoss     | -0.00723    |\n",
      "|    value_loss         | 1.45        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 12255232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010379796 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.31        |\n",
      "|    mean_step_reward   | 0.34902832  |\n",
      "|    n_updates          | 5980        |\n",
      "|    policyGradLoss     | -0.00334    |\n",
      "|    value_loss         | 2.25        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 771        |\n",
      "|    iterations         | 25         |\n",
      "|    time_elapsed       | 265        |\n",
      "|    total_timesteps    | 12263424   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01162022 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.984      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.223      |\n",
      "|    mean_step_reward   | 0.3463133  |\n",
      "|    n_updates          | 5984       |\n",
      "|    policyGradLoss     | -0.00597   |\n",
      "|    value_loss         | 1.05       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 770        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 276        |\n",
      "|    total_timesteps    | 12271616   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0106066  |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.98       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.29       |\n",
      "|    mean_step_reward   | 0.36401647 |\n",
      "|    n_updates          | 5988       |\n",
      "|    policyGradLoss     | -0.0031    |\n",
      "|    value_loss         | 2.35       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 287         |\n",
      "|    total_timesteps    | 12279808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010675494 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.621       |\n",
      "|    mean_step_reward   | 0.37552068  |\n",
      "|    n_updates          | 5992        |\n",
      "|    policyGradLoss     | -0.00416    |\n",
      "|    value_loss         | 2.17        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 768          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 298          |\n",
      "|    total_timesteps    | 12288000     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0074261143 |\n",
      "|    entropy_loss       | -1.71        |\n",
      "|    explained_variance | 0.984        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.616        |\n",
      "|    mean_step_reward   | 0.36606547   |\n",
      "|    n_updates          | 5996         |\n",
      "|    policyGradLoss     | -0.00547     |\n",
      "|    value_loss         | 2.21         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 310         |\n",
      "|    total_timesteps    | 12296192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008390855 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.239       |\n",
      "|    mean_step_reward   | 0.26720417  |\n",
      "|    n_updates          | 6000        |\n",
      "|    policyGradLoss     | -0.00504    |\n",
      "|    value_loss         | 1.61        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 320         |\n",
      "|    total_timesteps    | 12304384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010938364 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.392       |\n",
      "|    mean_step_reward   | 0.35911322  |\n",
      "|    n_updates          | 6004        |\n",
      "|    policyGradLoss     | -0.000704   |\n",
      "|    value_loss         | 1.81        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 764        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 331        |\n",
      "|    total_timesteps    | 12312576   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01273482 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.978      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.516      |\n",
      "|    mean_step_reward   | 0.2896475  |\n",
      "|    n_updates          | 6008       |\n",
      "|    policyGradLoss     | -0.00932   |\n",
      "|    value_loss         | 1.33       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 342         |\n",
      "|    total_timesteps    | 12320768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010428189 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.649       |\n",
      "|    mean_step_reward   | 0.33966517  |\n",
      "|    n_updates          | 6012        |\n",
      "|    policyGradLoss     | -0.00253    |\n",
      "|    value_loss         | 1.91        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_46.zip\n",
      "[EVAL] Mean Return: 29.241, Best Return: 29.907\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_46_29.24.mp4\n",
      "\n",
      "=== Round 48 | Learn 262144 steps (Total trained: 12320768) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1167     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 12328960 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 904         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 12337152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010246567 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.874       |\n",
      "|    mean_step_reward   | 0.3046252   |\n",
      "|    n_updates          | 6020        |\n",
      "|    policyGradLoss     | -0.00241    |\n",
      "|    value_loss         | 2.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 844         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 12345344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009686993 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.44        |\n",
      "|    mean_step_reward   | 0.2805956   |\n",
      "|    n_updates          | 6024        |\n",
      "|    policyGradLoss     | -0.00195    |\n",
      "|    value_loss         | 1.96        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 12353536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011090893 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.903       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.595       |\n",
      "|    mean_step_reward   | 0.28832078  |\n",
      "|    n_updates          | 6028        |\n",
      "|    policyGradLoss     | 0.00121     |\n",
      "|    value_loss         | 3.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 12361728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011274101 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.396       |\n",
      "|    mean_step_reward   | 0.3070492   |\n",
      "|    n_updates          | 6032        |\n",
      "|    policyGradLoss     | -0.00126    |\n",
      "|    value_loss         | 2.61        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 12369920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008886028 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.711       |\n",
      "|    mean_step_reward   | 0.2996293   |\n",
      "|    n_updates          | 6036        |\n",
      "|    policyGradLoss     | -0.00452    |\n",
      "|    value_loss         | 2.35        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 788          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 72           |\n",
      "|    total_timesteps    | 12378112     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0096180625 |\n",
      "|    entropy_loss       | -1.72        |\n",
      "|    explained_variance | 0.977        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.399        |\n",
      "|    mean_step_reward   | 0.34526002   |\n",
      "|    n_updates          | 6040         |\n",
      "|    policyGradLoss     | -0.00522     |\n",
      "|    value_loss         | 1.66         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 12386304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009935821 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.502       |\n",
      "|    mean_step_reward   | 0.32632762  |\n",
      "|    n_updates          | 6044        |\n",
      "|    policyGradLoss     | -0.00207    |\n",
      "|    value_loss         | 2.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 94          |\n",
      "|    total_timesteps    | 12394496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011763902 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.02        |\n",
      "|    mean_step_reward   | 0.33805954  |\n",
      "|    n_updates          | 6048        |\n",
      "|    policyGradLoss     | 0.00364     |\n",
      "|    value_loss         | 3.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 12402688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009278078 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.735       |\n",
      "|    mean_step_reward   | 0.35621646  |\n",
      "|    n_updates          | 6052        |\n",
      "|    policyGradLoss     | -0.00266    |\n",
      "|    value_loss         | 2.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 116         |\n",
      "|    total_timesteps    | 12410880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016836656 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.443       |\n",
      "|    mean_step_reward   | 0.26071513  |\n",
      "|    n_updates          | 6056        |\n",
      "|    policyGradLoss     | 0.00157     |\n",
      "|    value_loss         | 3.59        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 127         |\n",
      "|    total_timesteps    | 12419072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012946421 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.43        |\n",
      "|    mean_step_reward   | 0.35665488  |\n",
      "|    n_updates          | 6060        |\n",
      "|    policyGradLoss     | 0.00269     |\n",
      "|    value_loss         | 3.86        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 12427264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008104082 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.662       |\n",
      "|    mean_step_reward   | 0.38265184  |\n",
      "|    n_updates          | 6064        |\n",
      "|    policyGradLoss     | -0.00246    |\n",
      "|    value_loss         | 2.64        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 776        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 147        |\n",
      "|    total_timesteps    | 12435456   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01085194 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.974      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.245      |\n",
      "|    mean_step_reward   | 0.33419335 |\n",
      "|    n_updates          | 6068       |\n",
      "|    policyGradLoss     | -0.0056    |\n",
      "|    value_loss         | 1.62       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 12443648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008131942 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.3         |\n",
      "|    mean_step_reward   | 0.3233144   |\n",
      "|    n_updates          | 6072        |\n",
      "|    policyGradLoss     | -0.00206    |\n",
      "|    value_loss         | 1.95        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 779          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 168          |\n",
      "|    total_timesteps    | 12451840     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0087760985 |\n",
      "|    entropy_loss       | -1.72        |\n",
      "|    explained_variance | 0.958        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.761        |\n",
      "|    mean_step_reward   | 0.3237047    |\n",
      "|    n_updates          | 6076         |\n",
      "|    policyGradLoss     | -0.000582    |\n",
      "|    value_loss         | 2.69         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 12460032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010970412 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.478       |\n",
      "|    mean_step_reward   | 0.32397887  |\n",
      "|    n_updates          | 6080        |\n",
      "|    policyGradLoss     | -0.00418    |\n",
      "|    value_loss         | 1.88        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 12468224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008076963 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.11        |\n",
      "|    mean_step_reward   | 0.2903378   |\n",
      "|    n_updates          | 6084        |\n",
      "|    policyGradLoss     | -0.00429    |\n",
      "|    value_loss         | 2.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 12476416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009869993 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.53        |\n",
      "|    mean_step_reward   | 0.30392867  |\n",
      "|    n_updates          | 6088        |\n",
      "|    policyGradLoss     | 0.000777    |\n",
      "|    value_loss         | 2.48        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 770        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 212        |\n",
      "|    total_timesteps    | 12484608   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00889682 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.966      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.562      |\n",
      "|    mean_step_reward   | 0.26308185 |\n",
      "|    n_updates          | 6092       |\n",
      "|    policyGradLoss     | -0.0052    |\n",
      "|    value_loss         | 2.18       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 223         |\n",
      "|    total_timesteps    | 12492800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009066241 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.49        |\n",
      "|    mean_step_reward   | 0.27147698  |\n",
      "|    n_updates          | 6096        |\n",
      "|    policyGradLoss     | -0.00267    |\n",
      "|    value_loss         | 2.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 234         |\n",
      "|    total_timesteps    | 12500992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015764305 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.821       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.51        |\n",
      "|    mean_step_reward   | 0.32336402  |\n",
      "|    n_updates          | 6100        |\n",
      "|    policyGradLoss     | 0.00784     |\n",
      "|    value_loss         | 8.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 246         |\n",
      "|    total_timesteps    | 12509184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008223765 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.502       |\n",
      "|    mean_step_reward   | 0.32878453  |\n",
      "|    n_updates          | 6104        |\n",
      "|    policyGradLoss     | -0.0034     |\n",
      "|    value_loss         | 2.64        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 256         |\n",
      "|    total_timesteps    | 12517376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011003513 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.05        |\n",
      "|    mean_step_reward   | 0.38462472  |\n",
      "|    n_updates          | 6108        |\n",
      "|    policyGradLoss     | 0.000971    |\n",
      "|    value_loss         | 4.8         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 268         |\n",
      "|    total_timesteps    | 12525568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009159162 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.587       |\n",
      "|    mean_step_reward   | 0.33038044  |\n",
      "|    n_updates          | 6112        |\n",
      "|    policyGradLoss     | -0.00143    |\n",
      "|    value_loss         | 2.34        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 279         |\n",
      "|    total_timesteps    | 12533760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009355428 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.243       |\n",
      "|    mean_step_reward   | 0.35793686  |\n",
      "|    n_updates          | 6116        |\n",
      "|    policyGradLoss     | -0.00246    |\n",
      "|    value_loss         | 2.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 289         |\n",
      "|    total_timesteps    | 12541952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011071821 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.876       |\n",
      "|    mean_step_reward   | 0.33960548  |\n",
      "|    n_updates          | 6120        |\n",
      "|    policyGradLoss     | 0.00455     |\n",
      "|    value_loss         | 2.45        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 300         |\n",
      "|    total_timesteps    | 12550144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009122002 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.51        |\n",
      "|    mean_step_reward   | 0.34693366  |\n",
      "|    n_updates          | 6124        |\n",
      "|    policyGradLoss     | -0.00386    |\n",
      "|    value_loss         | 2.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 312         |\n",
      "|    total_timesteps    | 12558336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009832546 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.303       |\n",
      "|    mean_step_reward   | 0.37855703  |\n",
      "|    n_updates          | 6128        |\n",
      "|    policyGradLoss     | -0.00478    |\n",
      "|    value_loss         | 1.78        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 759        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 323        |\n",
      "|    total_timesteps    | 12566528   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00878058 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.962      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.638      |\n",
      "|    mean_step_reward   | 0.24163027 |\n",
      "|    n_updates          | 6132       |\n",
      "|    policyGradLoss     | -0.00222   |\n",
      "|    value_loss         | 2.22       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 334         |\n",
      "|    total_timesteps    | 12574720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011875889 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.559       |\n",
      "|    mean_step_reward   | 0.32226217  |\n",
      "|    n_updates          | 6136        |\n",
      "|    policyGradLoss     | 0.000854    |\n",
      "|    value_loss         | 2.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 345         |\n",
      "|    total_timesteps    | 12582912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011211334 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.482       |\n",
      "|    mean_step_reward   | 0.29572886  |\n",
      "|    n_updates          | 6140        |\n",
      "|    policyGradLoss     | -0.000174   |\n",
      "|    value_loss         | 2.22        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_47.zip\n",
      "[EVAL] Mean Return: 338.340, Best Return: 344.340\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_47_338.34.mp4\n",
      "\n",
      "=== Round 49 | Learn 262144 steps (Total trained: 12582912) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1086     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 12591104 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 938         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 12599296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011333286 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.568       |\n",
      "|    mean_step_reward   | 0.23187353  |\n",
      "|    n_updates          | 6148        |\n",
      "|    policyGradLoss     | -0.00281    |\n",
      "|    value_loss         | 2.53        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 937          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 26           |\n",
      "|    total_timesteps    | 12607488     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0129181035 |\n",
      "|    entropy_loss       | -1.72        |\n",
      "|    explained_variance | 0.965        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.408        |\n",
      "|    mean_step_reward   | 0.32878467   |\n",
      "|    n_updates          | 6152         |\n",
      "|    policyGradLoss     | -0.00502     |\n",
      "|    value_loss         | 1.78         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 926         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 35          |\n",
      "|    total_timesteps    | 12615680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008542373 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.791       |\n",
      "|    mean_step_reward   | 0.29536113  |\n",
      "|    n_updates          | 6156        |\n",
      "|    policyGradLoss     | -0.00538    |\n",
      "|    value_loss         | 2.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 915         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 44          |\n",
      "|    total_timesteps    | 12623872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008624802 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.741       |\n",
      "|    mean_step_reward   | 0.30729198  |\n",
      "|    n_updates          | 6160        |\n",
      "|    policyGradLoss     | -0.00982    |\n",
      "|    value_loss         | 1.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 878         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 55          |\n",
      "|    total_timesteps    | 12632064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010063903 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.427       |\n",
      "|    mean_step_reward   | 0.36644518  |\n",
      "|    n_updates          | 6164        |\n",
      "|    policyGradLoss     | -0.00327    |\n",
      "|    value_loss         | 2.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 856         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 66          |\n",
      "|    total_timesteps    | 12640256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009717528 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.342       |\n",
      "|    mean_step_reward   | 0.3263315   |\n",
      "|    n_updates          | 6168        |\n",
      "|    policyGradLoss     | -0.00447    |\n",
      "|    value_loss         | 1.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 842         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 77          |\n",
      "|    total_timesteps    | 12648448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010915587 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.533       |\n",
      "|    mean_step_reward   | 0.34211263  |\n",
      "|    n_updates          | 6172        |\n",
      "|    policyGradLoss     | -0.00592    |\n",
      "|    value_loss         | 1.8         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 830         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 88          |\n",
      "|    total_timesteps    | 12656640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009043714 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.623       |\n",
      "|    mean_step_reward   | 0.37098902  |\n",
      "|    n_updates          | 6176        |\n",
      "|    policyGradLoss     | -0.00423    |\n",
      "|    value_loss         | 2.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 827         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 12664832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009128298 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.305       |\n",
      "|    mean_step_reward   | 0.33927792  |\n",
      "|    n_updates          | 6180        |\n",
      "|    policyGradLoss     | -0.0052     |\n",
      "|    value_loss         | 1.45        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 815          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 110          |\n",
      "|    total_timesteps    | 12673024     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0075731548 |\n",
      "|    entropy_loss       | -1.71        |\n",
      "|    explained_variance | 0.969        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.898        |\n",
      "|    mean_step_reward   | 0.34077603   |\n",
      "|    n_updates          | 6184         |\n",
      "|    policyGradLoss     | -0.00342     |\n",
      "|    value_loss         | 2.67         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 812          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 120          |\n",
      "|    total_timesteps    | 12681216     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0077645574 |\n",
      "|    entropy_loss       | -1.69        |\n",
      "|    explained_variance | 0.978        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.15         |\n",
      "|    mean_step_reward   | 0.38820535   |\n",
      "|    n_updates          | 6188         |\n",
      "|    policyGradLoss     | -0.00461     |\n",
      "|    value_loss         | 2.27         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 805          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 132          |\n",
      "|    total_timesteps    | 12689408     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0081838025 |\n",
      "|    entropy_loss       | -1.73        |\n",
      "|    explained_variance | 0.978        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.75         |\n",
      "|    mean_step_reward   | 0.3406579    |\n",
      "|    n_updates          | 6192         |\n",
      "|    policyGradLoss     | -0.00497     |\n",
      "|    value_loss         | 2.4          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 143         |\n",
      "|    total_timesteps    | 12697600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011349113 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.543       |\n",
      "|    mean_step_reward   | 0.37106937  |\n",
      "|    n_updates          | 6196        |\n",
      "|    policyGradLoss     | -0.00344    |\n",
      "|    value_loss         | 1.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 12705792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011642802 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.895       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.17        |\n",
      "|    mean_step_reward   | 0.3206373   |\n",
      "|    n_updates          | 6200        |\n",
      "|    policyGradLoss     | 0.00109     |\n",
      "|    value_loss         | 4.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 12713984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009594193 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.367       |\n",
      "|    mean_step_reward   | 0.31638038  |\n",
      "|    n_updates          | 6204        |\n",
      "|    policyGradLoss     | -0.00349    |\n",
      "|    value_loss         | 1.59        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 12722176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012808211 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.426       |\n",
      "|    mean_step_reward   | 0.33256525  |\n",
      "|    n_updates          | 6208        |\n",
      "|    policyGradLoss     | -0.000964   |\n",
      "|    value_loss         | 2.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 12730368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012192953 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.921       |\n",
      "|    mean_step_reward   | 0.3069445   |\n",
      "|    n_updates          | 6212        |\n",
      "|    policyGradLoss     | -0.00112    |\n",
      "|    value_loss         | 2.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 12738560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015628545 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.622       |\n",
      "|    mean_step_reward   | 0.24652378  |\n",
      "|    n_updates          | 6216        |\n",
      "|    policyGradLoss     | 0.00221     |\n",
      "|    value_loss         | 2.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 12746752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011212366 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.525       |\n",
      "|    mean_step_reward   | 0.24083023  |\n",
      "|    n_updates          | 6220        |\n",
      "|    policyGradLoss     | -0.000312   |\n",
      "|    value_loss         | 1.85        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 777          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 221          |\n",
      "|    total_timesteps    | 12754944     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0077845864 |\n",
      "|    entropy_loss       | -1.78        |\n",
      "|    explained_variance | 0.966        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.24         |\n",
      "|    mean_step_reward   | 0.24940512   |\n",
      "|    n_updates          | 6224         |\n",
      "|    policyGradLoss     | -0.00259     |\n",
      "|    value_loss         | 1.72         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 12763136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018255293 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.901       |\n",
      "|    mean_step_reward   | 0.40066683  |\n",
      "|    n_updates          | 6228        |\n",
      "|    policyGradLoss     | 0.00733     |\n",
      "|    value_loss         | 4.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 12771328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012794793 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.759       |\n",
      "|    mean_step_reward   | 0.21949697  |\n",
      "|    n_updates          | 6232        |\n",
      "|    policyGradLoss     | 0.00147     |\n",
      "|    value_loss         | 1.68        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 773          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 254          |\n",
      "|    total_timesteps    | 12779520     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0131434705 |\n",
      "|    entropy_loss       | -1.66        |\n",
      "|    explained_variance | 0.967        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.609        |\n",
      "|    mean_step_reward   | 0.39353076   |\n",
      "|    n_updates          | 6236         |\n",
      "|    policyGradLoss     | 0.00141      |\n",
      "|    value_loss         | 2.54         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 265         |\n",
      "|    total_timesteps    | 12787712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011037194 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.719       |\n",
      "|    mean_step_reward   | 0.33311874  |\n",
      "|    n_updates          | 6240        |\n",
      "|    policyGradLoss     | -0.00392    |\n",
      "|    value_loss         | 1.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 276         |\n",
      "|    total_timesteps    | 12795904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009183561 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.415       |\n",
      "|    mean_step_reward   | 0.3547449   |\n",
      "|    n_updates          | 6244        |\n",
      "|    policyGradLoss     | -0.00198    |\n",
      "|    value_loss         | 2.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 287         |\n",
      "|    total_timesteps    | 12804096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011557657 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.446       |\n",
      "|    mean_step_reward   | 0.35019094  |\n",
      "|    n_updates          | 6248        |\n",
      "|    policyGradLoss     | -0.00446    |\n",
      "|    value_loss         | 2.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 297         |\n",
      "|    total_timesteps    | 12812288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009826193 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.405       |\n",
      "|    mean_step_reward   | 0.3216282   |\n",
      "|    n_updates          | 6252        |\n",
      "|    policyGradLoss     | -0.00311    |\n",
      "|    value_loss         | 2.04        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 774        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 306        |\n",
      "|    total_timesteps    | 12820480   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01249286 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.96       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.506      |\n",
      "|    mean_step_reward   | 0.3367795  |\n",
      "|    n_updates          | 6256       |\n",
      "|    policyGradLoss     | -0.00326   |\n",
      "|    value_loss         | 2.36       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 777          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 316          |\n",
      "|    total_timesteps    | 12828672     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0126868505 |\n",
      "|    entropy_loss       | -1.76        |\n",
      "|    explained_variance | 0.808        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.683        |\n",
      "|    mean_step_reward   | 0.2803209    |\n",
      "|    n_updates          | 6260         |\n",
      "|    policyGradLoss     | 0.00107      |\n",
      "|    value_loss         | 5.4          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 12836864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010546688 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.672       |\n",
      "|    mean_step_reward   | 0.3327353   |\n",
      "|    n_updates          | 6264        |\n",
      "|    policyGradLoss     | 0.002       |\n",
      "|    value_loss         | 2.93        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 12845056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012390871 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.509       |\n",
      "|    mean_step_reward   | 0.24258411  |\n",
      "|    n_updates          | 6268        |\n",
      "|    policyGradLoss     | -0.0029     |\n",
      "|    value_loss         | 2.63        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_48.zip\n",
      "[EVAL] Mean Return: 199.683, Best Return: 203.683\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_48_199.68.mp4\n",
      "\n",
      "=== Round 50 | Learn 262144 steps (Total trained: 12845056) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1179     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 12853248 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 903        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 12861440   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00966896 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.942      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.38       |\n",
      "|    mean_step_reward   | 0.25334728 |\n",
      "|    n_updates          | 6276       |\n",
      "|    policyGradLoss     | -0.00132   |\n",
      "|    value_loss         | 2.98       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 840          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 29           |\n",
      "|    total_timesteps    | 12869632     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0076531293 |\n",
      "|    entropy_loss       | -1.78        |\n",
      "|    explained_variance | 0.965        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.445        |\n",
      "|    mean_step_reward   | 0.2953133    |\n",
      "|    n_updates          | 6280         |\n",
      "|    policyGradLoss     | -0.0047      |\n",
      "|    value_loss         | 2.02         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 12877824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010870965 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.551       |\n",
      "|    mean_step_reward   | 0.3237031   |\n",
      "|    n_updates          | 6284        |\n",
      "|    policyGradLoss     | -0.00212    |\n",
      "|    value_loss         | 2.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 12886016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007523296 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.579       |\n",
      "|    mean_step_reward   | 0.28286237  |\n",
      "|    n_updates          | 6288        |\n",
      "|    policyGradLoss     | -0.00437    |\n",
      "|    value_loss         | 2.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 62          |\n",
      "|    total_timesteps    | 12894208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010623064 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.374       |\n",
      "|    mean_step_reward   | 0.39859015  |\n",
      "|    n_updates          | 6292        |\n",
      "|    policyGradLoss     | -0.00181    |\n",
      "|    value_loss         | 2.71        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 12902400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010786403 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.08        |\n",
      "|    mean_step_reward   | 0.2857933   |\n",
      "|    n_updates          | 6296        |\n",
      "|    policyGradLoss     | -0.00122    |\n",
      "|    value_loss         | 4.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 84          |\n",
      "|    total_timesteps    | 12910592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010501021 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.673       |\n",
      "|    mean_step_reward   | 0.3477292   |\n",
      "|    n_updates          | 6300        |\n",
      "|    policyGradLoss     | 0.000444    |\n",
      "|    value_loss         | 2.53        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 95          |\n",
      "|    total_timesteps    | 12918784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007904085 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.685       |\n",
      "|    mean_step_reward   | 0.28796878  |\n",
      "|    n_updates          | 6304        |\n",
      "|    policyGradLoss     | -0.00389    |\n",
      "|    value_loss         | 2.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 12926976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008222289 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.337       |\n",
      "|    mean_step_reward   | 0.3138486   |\n",
      "|    n_updates          | 6308        |\n",
      "|    policyGradLoss     | -0.00621    |\n",
      "|    value_loss         | 2.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 116         |\n",
      "|    total_timesteps    | 12935168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008534495 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.1         |\n",
      "|    mean_step_reward   | 0.3864804   |\n",
      "|    n_updates          | 6312        |\n",
      "|    policyGradLoss     | -0.002      |\n",
      "|    value_loss         | 3.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 128         |\n",
      "|    total_timesteps    | 12943360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010954443 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.355       |\n",
      "|    mean_step_reward   | 0.2836032   |\n",
      "|    n_updates          | 6316        |\n",
      "|    policyGradLoss     | 0.00253     |\n",
      "|    value_loss         | 3.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 137         |\n",
      "|    total_timesteps    | 12951552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011739946 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.533       |\n",
      "|    mean_step_reward   | 0.33504423  |\n",
      "|    n_updates          | 6320        |\n",
      "|    policyGradLoss     | -0.000378   |\n",
      "|    value_loss         | 3.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 12959744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011611585 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.341       |\n",
      "|    mean_step_reward   | 0.28792143  |\n",
      "|    n_updates          | 6324        |\n",
      "|    policyGradLoss     | 0.00143     |\n",
      "|    value_loss         | 2.44        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 789          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 155          |\n",
      "|    total_timesteps    | 12967936     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0090858005 |\n",
      "|    entropy_loss       | -1.79        |\n",
      "|    explained_variance | 0.962        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.264        |\n",
      "|    mean_step_reward   | 0.28732646   |\n",
      "|    n_updates          | 6328         |\n",
      "|    policyGradLoss     | -0.00356     |\n",
      "|    value_loss         | 2.1          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 12976128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012234407 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.958       |\n",
      "|    mean_step_reward   | 0.35947952  |\n",
      "|    n_updates          | 6332        |\n",
      "|    policyGradLoss     | 0.00293     |\n",
      "|    value_loss         | 4.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 12984320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012464567 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.865       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.401       |\n",
      "|    mean_step_reward   | 0.2635246   |\n",
      "|    n_updates          | 6336        |\n",
      "|    policyGradLoss     | 0.000932    |\n",
      "|    value_loss         | 3.43        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 12992512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010911912 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.27        |\n",
      "|    mean_step_reward   | 0.35189885  |\n",
      "|    n_updates          | 6340        |\n",
      "|    policyGradLoss     | 0.00428     |\n",
      "|    value_loss         | 5.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 13000704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011466684 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.06        |\n",
      "|    mean_step_reward   | 0.28485447  |\n",
      "|    n_updates          | 6344        |\n",
      "|    policyGradLoss     | -0.00113    |\n",
      "|    value_loss         | 1.95        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 776        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 210        |\n",
      "|    total_timesteps    | 13008896   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01204038 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.909      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.11       |\n",
      "|    mean_step_reward   | 0.3361865  |\n",
      "|    n_updates          | 6348       |\n",
      "|    policyGradLoss     | 0.00469    |\n",
      "|    value_loss         | 6.04       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 13017088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010603175 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.642       |\n",
      "|    mean_step_reward   | 0.29710403  |\n",
      "|    n_updates          | 6352        |\n",
      "|    policyGradLoss     | -0.00275    |\n",
      "|    value_loss         | 3.46        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 13025280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010444559 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.901       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.716       |\n",
      "|    mean_step_reward   | 0.31739783  |\n",
      "|    n_updates          | 6356        |\n",
      "|    policyGradLoss     | 0.0032      |\n",
      "|    value_loss         | 4.5         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 771        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 244        |\n",
      "|    total_timesteps    | 13033472   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00862055 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.958      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.692      |\n",
      "|    mean_step_reward   | 0.33073163 |\n",
      "|    n_updates          | 6360       |\n",
      "|    policyGradLoss     | -0.0022    |\n",
      "|    value_loss         | 2.41       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 13041664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007394956 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.422       |\n",
      "|    mean_step_reward   | 0.3186046   |\n",
      "|    n_updates          | 6364        |\n",
      "|    policyGradLoss     | -0.00274    |\n",
      "|    value_loss         | 2.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 266         |\n",
      "|    total_timesteps    | 13049856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007291518 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.783       |\n",
      "|    mean_step_reward   | 0.28300864  |\n",
      "|    n_updates          | 6368        |\n",
      "|    policyGradLoss     | -0.00207    |\n",
      "|    value_loss         | 2.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 277         |\n",
      "|    total_timesteps    | 13058048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014540955 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.907       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.442       |\n",
      "|    mean_step_reward   | 0.25938344  |\n",
      "|    n_updates          | 6372        |\n",
      "|    policyGradLoss     | 0.00222     |\n",
      "|    value_loss         | 3.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 288         |\n",
      "|    total_timesteps    | 13066240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009777459 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.317       |\n",
      "|    mean_step_reward   | 0.2573046   |\n",
      "|    n_updates          | 6376        |\n",
      "|    policyGradLoss     | -0.000439   |\n",
      "|    value_loss         | 2.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 299         |\n",
      "|    total_timesteps    | 13074432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009837298 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.633       |\n",
      "|    mean_step_reward   | 0.32266164  |\n",
      "|    n_updates          | 6380        |\n",
      "|    policyGradLoss     | -0.00344    |\n",
      "|    value_loss         | 2.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 309         |\n",
      "|    total_timesteps    | 13082624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009020507 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.54        |\n",
      "|    mean_step_reward   | 0.32105452  |\n",
      "|    n_updates          | 6384        |\n",
      "|    policyGradLoss     | -0.00206    |\n",
      "|    value_loss         | 2.74        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 321         |\n",
      "|    total_timesteps    | 13090816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010112658 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.379       |\n",
      "|    mean_step_reward   | 0.35180634  |\n",
      "|    n_updates          | 6388        |\n",
      "|    policyGradLoss     | -0.000997   |\n",
      "|    value_loss         | 2.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 332         |\n",
      "|    total_timesteps    | 13099008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008298508 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.752       |\n",
      "|    mean_step_reward   | 0.2598931   |\n",
      "|    n_updates          | 6392        |\n",
      "|    policyGradLoss     | -0.00526    |\n",
      "|    value_loss         | 1.84        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 343         |\n",
      "|    total_timesteps    | 13107200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009044666 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.507       |\n",
      "|    mean_step_reward   | 0.30916876  |\n",
      "|    n_updates          | 6396        |\n",
      "|    policyGradLoss     | -0.00405    |\n",
      "|    value_loss         | 2.49        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_49.zip\n",
      "[EVAL] Mean Return: 527.630, Best Return: 533.630\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_49_527.63.mp4\n",
      "\n",
      "=== Round 51 | Learn 262144 steps (Total trained: 13107200) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1230     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 13115392 |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 999          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 16           |\n",
      "|    total_timesteps    | 13123584     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0108092185 |\n",
      "|    entropy_loss       | -1.8         |\n",
      "|    explained_variance | 0.908        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.798        |\n",
      "|    mean_step_reward   | 0.29980993   |\n",
      "|    n_updates          | 6404         |\n",
      "|    policyGradLoss     | 0.00272      |\n",
      "|    value_loss         | 3.96         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 955         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 13131776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012888843 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.861       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.641       |\n",
      "|    mean_step_reward   | 0.27630004  |\n",
      "|    n_updates          | 6408        |\n",
      "|    policyGradLoss     | 0.0021      |\n",
      "|    value_loss         | 4.74        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 929         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 35          |\n",
      "|    total_timesteps    | 13139968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009964573 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.752       |\n",
      "|    mean_step_reward   | 0.2752123   |\n",
      "|    n_updates          | 6412        |\n",
      "|    policyGradLoss     | -0.00178    |\n",
      "|    value_loss         | 2.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 886         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 46          |\n",
      "|    total_timesteps    | 13148160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008764774 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.463       |\n",
      "|    mean_step_reward   | 0.36296207  |\n",
      "|    n_updates          | 6416        |\n",
      "|    policyGradLoss     | -1.49e-05   |\n",
      "|    value_loss         | 3.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 858         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 57          |\n",
      "|    total_timesteps    | 13156352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011413848 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.22        |\n",
      "|    mean_step_reward   | 0.32172132  |\n",
      "|    n_updates          | 6420        |\n",
      "|    policyGradLoss     | -0.00182    |\n",
      "|    value_loss         | 1.61        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 853         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 67          |\n",
      "|    total_timesteps    | 13164544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009021757 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.307       |\n",
      "|    mean_step_reward   | 0.33902892  |\n",
      "|    n_updates          | 6424        |\n",
      "|    policyGradLoss     | -0.000315   |\n",
      "|    value_loss         | 2.62        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 831        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 78         |\n",
      "|    total_timesteps    | 13172736   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01119634 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.941      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.325      |\n",
      "|    mean_step_reward   | 0.33181506 |\n",
      "|    n_updates          | 6428       |\n",
      "|    policyGradLoss     | -0.000108  |\n",
      "|    value_loss         | 2.46       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 830         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 88          |\n",
      "|    total_timesteps    | 13180928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009348749 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.314       |\n",
      "|    mean_step_reward   | 0.31637943  |\n",
      "|    n_updates          | 6432        |\n",
      "|    policyGradLoss     | -0.000727   |\n",
      "|    value_loss         | 2.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 99          |\n",
      "|    total_timesteps    | 13189120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010650784 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.898       |\n",
      "|    mean_step_reward   | 0.3866635   |\n",
      "|    n_updates          | 6436        |\n",
      "|    policyGradLoss     | -0.00144    |\n",
      "|    value_loss         | 4.94        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 111         |\n",
      "|    total_timesteps    | 13197312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010339251 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.57        |\n",
      "|    mean_step_reward   | 0.27823523  |\n",
      "|    n_updates          | 6440        |\n",
      "|    policyGradLoss     | -0.0019     |\n",
      "|    value_loss         | 2.93        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 122         |\n",
      "|    total_timesteps    | 13205504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010478733 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.451       |\n",
      "|    mean_step_reward   | 0.35975537  |\n",
      "|    n_updates          | 6444        |\n",
      "|    policyGradLoss     | 0.00034     |\n",
      "|    value_loss         | 2.93        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 133         |\n",
      "|    total_timesteps    | 13213696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012505265 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.295       |\n",
      "|    mean_step_reward   | 0.3300266   |\n",
      "|    n_updates          | 6448        |\n",
      "|    policyGradLoss     | -0.00473    |\n",
      "|    value_loss         | 1.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 13221888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009306705 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.471       |\n",
      "|    mean_step_reward   | 0.35950208  |\n",
      "|    n_updates          | 6452        |\n",
      "|    policyGradLoss     | -0.00145    |\n",
      "|    value_loss         | 2.04        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 790        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 155        |\n",
      "|    total_timesteps    | 13230080   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01169999 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.944      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.637      |\n",
      "|    mean_step_reward   | 0.34943184 |\n",
      "|    n_updates          | 6456       |\n",
      "|    policyGradLoss     | -0.000814  |\n",
      "|    value_loss         | 3.47       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 13238272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008721916 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.571       |\n",
      "|    mean_step_reward   | 0.2875065   |\n",
      "|    n_updates          | 6460        |\n",
      "|    policyGradLoss     | -0.00472    |\n",
      "|    value_loss         | 2.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 13246464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009976363 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.288       |\n",
      "|    mean_step_reward   | 0.30449995  |\n",
      "|    n_updates          | 6464        |\n",
      "|    policyGradLoss     | 0.00173     |\n",
      "|    value_loss         | 2.46        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 13254656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012380058 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.824       |\n",
      "|    mean_step_reward   | 0.28166115  |\n",
      "|    n_updates          | 6468        |\n",
      "|    policyGradLoss     | 0.000209    |\n",
      "|    value_loss         | 2.5         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 13262848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013320433 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.901       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.554       |\n",
      "|    mean_step_reward   | 0.3145518   |\n",
      "|    n_updates          | 6472        |\n",
      "|    policyGradLoss     | 2.42e-05    |\n",
      "|    value_loss         | 4.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 13271040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011668313 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.41        |\n",
      "|    mean_step_reward   | 0.3526783   |\n",
      "|    n_updates          | 6476        |\n",
      "|    policyGradLoss     | -0.00131    |\n",
      "|    value_loss         | 3.55        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 774        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 222        |\n",
      "|    total_timesteps    | 13279232   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01075241 |\n",
      "|    entropy_loss       | -1.71      |\n",
      "|    explained_variance | 0.977      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.508      |\n",
      "|    mean_step_reward   | 0.3552739  |\n",
      "|    n_updates          | 6480       |\n",
      "|    policyGradLoss     | -0.00449   |\n",
      "|    value_loss         | 1.76       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 13287424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008269567 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.86        |\n",
      "|    mean_step_reward   | 0.40319544  |\n",
      "|    n_updates          | 6484        |\n",
      "|    policyGradLoss     | -0.000247   |\n",
      "|    value_loss         | 2.61        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 769          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 244          |\n",
      "|    total_timesteps    | 13295616     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0108282585 |\n",
      "|    entropy_loss       | -1.73        |\n",
      "|    explained_variance | 0.917        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.12         |\n",
      "|    mean_step_reward   | 0.31491894   |\n",
      "|    n_updates          | 6488         |\n",
      "|    policyGradLoss     | 0.00306      |\n",
      "|    value_loss         | 4.57         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 256         |\n",
      "|    total_timesteps    | 13303808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012840988 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.783       |\n",
      "|    mean_step_reward   | 0.3217836   |\n",
      "|    n_updates          | 6492        |\n",
      "|    policyGradLoss     | 0.0028      |\n",
      "|    value_loss         | 4.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 267         |\n",
      "|    total_timesteps    | 13312000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011951093 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.89        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.594       |\n",
      "|    mean_step_reward   | 0.35262278  |\n",
      "|    n_updates          | 6496        |\n",
      "|    policyGradLoss     | 0.00265     |\n",
      "|    value_loss         | 3.72        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 766        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 277        |\n",
      "|    total_timesteps    | 13320192   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01284338 |\n",
      "|    entropy_loss       | -1.72      |\n",
      "|    explained_variance | 0.909      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.576      |\n",
      "|    mean_step_reward   | 0.3187675  |\n",
      "|    n_updates          | 6500       |\n",
      "|    policyGradLoss     | 0.00618    |\n",
      "|    value_loss         | 5.12       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 768          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 287          |\n",
      "|    total_timesteps    | 13328384     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0117193805 |\n",
      "|    entropy_loss       | -1.73        |\n",
      "|    explained_variance | 0.948        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.507        |\n",
      "|    mean_step_reward   | 0.32382092   |\n",
      "|    n_updates          | 6504         |\n",
      "|    policyGradLoss     | 0.00011      |\n",
      "|    value_loss         | 2.87         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 297         |\n",
      "|    total_timesteps    | 13336576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014850466 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.909       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.696       |\n",
      "|    mean_step_reward   | 0.25159153  |\n",
      "|    n_updates          | 6508        |\n",
      "|    policyGradLoss     | 0.00209     |\n",
      "|    value_loss         | 3.94        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 775        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 306        |\n",
      "|    total_timesteps    | 13344768   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01266593 |\n",
      "|    entropy_loss       | -1.76      |\n",
      "|    explained_variance | 0.904      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.846      |\n",
      "|    mean_step_reward   | 0.29650244 |\n",
      "|    n_updates          | 6512       |\n",
      "|    policyGradLoss     | 0.000608   |\n",
      "|    value_loss         | 6.66       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 13352960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009588793 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.786       |\n",
      "|    mean_step_reward   | 0.31888235  |\n",
      "|    n_updates          | 6516        |\n",
      "|    policyGradLoss     | 0.00149     |\n",
      "|    value_loss         | 3.07        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 13361152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014296421 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.825       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.35        |\n",
      "|    mean_step_reward   | 0.27912825  |\n",
      "|    n_updates          | 6520        |\n",
      "|    policyGradLoss     | 0.00686     |\n",
      "|    value_loss         | 7.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 13369344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011825815 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.448       |\n",
      "|    mean_step_reward   | 0.2897454   |\n",
      "|    n_updates          | 6524        |\n",
      "|    policyGradLoss     | -0.000495   |\n",
      "|    value_loss         | 2.36        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_50.zip\n",
      "[EVAL] Mean Return: 29.231, Best Return: 29.898\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_50_29.23.mp4\n",
      "\n",
      "=== Round 52 | Learn 262144 steps (Total trained: 13369344) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1172     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 13377536 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 907         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 13385728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010046504 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.362       |\n",
      "|    mean_step_reward   | 0.25519148  |\n",
      "|    n_updates          | 6532        |\n",
      "|    policyGradLoss     | -0.00445    |\n",
      "|    value_loss         | 1.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 847         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 13393920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013509665 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.32        |\n",
      "|    mean_step_reward   | 0.39256305  |\n",
      "|    n_updates          | 6536        |\n",
      "|    policyGradLoss     | 0.00336     |\n",
      "|    value_loss         | 2.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 13402112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011419094 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.511       |\n",
      "|    mean_step_reward   | 0.28800792  |\n",
      "|    n_updates          | 6540        |\n",
      "|    policyGradLoss     | -0.00433    |\n",
      "|    value_loss         | 1.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 13410304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012079571 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.495       |\n",
      "|    mean_step_reward   | 0.3468029   |\n",
      "|    n_updates          | 6544        |\n",
      "|    policyGradLoss     | -0.00223    |\n",
      "|    value_loss         | 2.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 62          |\n",
      "|    total_timesteps    | 13418496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008444041 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.989       |\n",
      "|    mean_step_reward   | 0.38115826  |\n",
      "|    n_updates          | 6548        |\n",
      "|    policyGradLoss     | -5.04e-05   |\n",
      "|    value_loss         | 4.11        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 782          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 73           |\n",
      "|    total_timesteps    | 13426688     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0105730975 |\n",
      "|    entropy_loss       | -1.78        |\n",
      "|    explained_variance | 0.933        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.526        |\n",
      "|    mean_step_reward   | 0.23884945   |\n",
      "|    n_updates          | 6552         |\n",
      "|    policyGradLoss     | -0.000517    |\n",
      "|    value_loss         | 2.16         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 84          |\n",
      "|    total_timesteps    | 13434880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009107887 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.433       |\n",
      "|    mean_step_reward   | 0.35546762  |\n",
      "|    n_updates          | 6556        |\n",
      "|    policyGradLoss     | -0.0045     |\n",
      "|    value_loss         | 2.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 95          |\n",
      "|    total_timesteps    | 13443072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012447289 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.866       |\n",
      "|    mean_step_reward   | 0.27985924  |\n",
      "|    n_updates          | 6560        |\n",
      "|    policyGradLoss     | -0.000578   |\n",
      "|    value_loss         | 2.43        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 106         |\n",
      "|    total_timesteps    | 13451264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011099508 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.787       |\n",
      "|    mean_step_reward   | 0.345689    |\n",
      "|    n_updates          | 6564        |\n",
      "|    policyGradLoss     | -0.000991   |\n",
      "|    value_loss         | 2.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 118         |\n",
      "|    total_timesteps    | 13459456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009045998 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.297       |\n",
      "|    mean_step_reward   | 0.33028686  |\n",
      "|    n_updates          | 6568        |\n",
      "|    policyGradLoss     | -0.00245    |\n",
      "|    value_loss         | 2.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 128         |\n",
      "|    total_timesteps    | 13467648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013652736 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.627       |\n",
      "|    mean_step_reward   | 0.42698276  |\n",
      "|    n_updates          | 6572        |\n",
      "|    policyGradLoss     | 0.00219     |\n",
      "|    value_loss         | 4.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 140         |\n",
      "|    total_timesteps    | 13475840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009749654 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.882       |\n",
      "|    mean_step_reward   | 0.30898678  |\n",
      "|    n_updates          | 6576        |\n",
      "|    policyGradLoss     | -0.00181    |\n",
      "|    value_loss         | 2.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 150         |\n",
      "|    total_timesteps    | 13484032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010538965 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.483       |\n",
      "|    mean_step_reward   | 0.35262147  |\n",
      "|    n_updates          | 6580        |\n",
      "|    policyGradLoss     | -0.00099    |\n",
      "|    value_loss         | 2.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 161         |\n",
      "|    total_timesteps    | 13492224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010103763 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.861       |\n",
      "|    mean_step_reward   | 0.38845032  |\n",
      "|    n_updates          | 6584        |\n",
      "|    policyGradLoss     | 0.00205     |\n",
      "|    value_loss         | 3.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 172         |\n",
      "|    total_timesteps    | 13500416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008174004 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.243       |\n",
      "|    mean_step_reward   | 0.3236705   |\n",
      "|    n_updates          | 6588        |\n",
      "|    policyGradLoss     | -0.00184    |\n",
      "|    value_loss         | 2.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 183         |\n",
      "|    total_timesteps    | 13508608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010977002 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.509       |\n",
      "|    mean_step_reward   | 0.34364235  |\n",
      "|    n_updates          | 6592        |\n",
      "|    policyGradLoss     | -0.0031     |\n",
      "|    value_loss         | 2.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 192         |\n",
      "|    total_timesteps    | 13516800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008911207 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.392       |\n",
      "|    mean_step_reward   | 0.4041537   |\n",
      "|    n_updates          | 6596        |\n",
      "|    policyGradLoss     | -0.00514    |\n",
      "|    value_loss         | 1.75        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 13524992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009464701 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.06        |\n",
      "|    mean_step_reward   | 0.33902335  |\n",
      "|    n_updates          | 6600        |\n",
      "|    policyGradLoss     | -0.00129    |\n",
      "|    value_loss         | 3.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 13533184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014972042 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.503       |\n",
      "|    mean_step_reward   | 0.32845592  |\n",
      "|    n_updates          | 6604        |\n",
      "|    policyGradLoss     | -0.00723    |\n",
      "|    value_loss         | 1.86        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 781        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 220        |\n",
      "|    total_timesteps    | 13541376   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01121779 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.975      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.333      |\n",
      "|    mean_step_reward   | 0.32120413 |\n",
      "|    n_updates          | 6608       |\n",
      "|    policyGradLoss     | -0.00652   |\n",
      "|    value_loss         | 1.71       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 13549568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015689548 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.364       |\n",
      "|    mean_step_reward   | 0.318078    |\n",
      "|    n_updates          | 6612        |\n",
      "|    policyGradLoss     | 0.00615     |\n",
      "|    value_loss         | 3.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 13557760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011186114 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.509       |\n",
      "|    mean_step_reward   | 0.3294054   |\n",
      "|    n_updates          | 6616        |\n",
      "|    policyGradLoss     | -0.000858   |\n",
      "|    value_loss         | 2.79        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 778          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 252          |\n",
      "|    total_timesteps    | 13565952     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0109371785 |\n",
      "|    entropy_loss       | -1.71        |\n",
      "|    explained_variance | 0.958        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.279        |\n",
      "|    mean_step_reward   | 0.31086195   |\n",
      "|    n_updates          | 6620         |\n",
      "|    policyGradLoss     | -0.00204     |\n",
      "|    value_loss         | 1.9          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 13574144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009927897 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.505       |\n",
      "|    mean_step_reward   | 0.38432673  |\n",
      "|    n_updates          | 6624        |\n",
      "|    policyGradLoss     | -0.00459    |\n",
      "|    value_loss         | 2.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 13582336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008523889 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.659       |\n",
      "|    mean_step_reward   | 0.28038162  |\n",
      "|    n_updates          | 6628        |\n",
      "|    policyGradLoss     | -0.00367    |\n",
      "|    value_loss         | 3.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 286         |\n",
      "|    total_timesteps    | 13590528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010543814 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.524       |\n",
      "|    mean_step_reward   | 0.32214543  |\n",
      "|    n_updates          | 6632        |\n",
      "|    policyGradLoss     | 0.00361     |\n",
      "|    value_loss         | 2.83        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 13598720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009326022 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.399       |\n",
      "|    mean_step_reward   | 0.29242775  |\n",
      "|    n_updates          | 6636        |\n",
      "|    policyGradLoss     | -0.00287    |\n",
      "|    value_loss         | 2.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 308         |\n",
      "|    total_timesteps    | 13606912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008838693 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.665       |\n",
      "|    mean_step_reward   | 0.3786664   |\n",
      "|    n_updates          | 6640        |\n",
      "|    policyGradLoss     | -0.00298    |\n",
      "|    value_loss         | 2.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 319         |\n",
      "|    total_timesteps    | 13615104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010330588 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.539       |\n",
      "|    mean_step_reward   | 0.33648717  |\n",
      "|    n_updates          | 6644        |\n",
      "|    policyGradLoss     | -0.0072     |\n",
      "|    value_loss         | 2.09        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 13623296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010675384 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.958       |\n",
      "|    mean_step_reward   | 0.31658012  |\n",
      "|    n_updates          | 6648        |\n",
      "|    policyGradLoss     | -0.000848   |\n",
      "|    value_loss         | 2.86        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 341         |\n",
      "|    total_timesteps    | 13631488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008892091 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.179       |\n",
      "|    mean_step_reward   | 0.27427948  |\n",
      "|    n_updates          | 6652        |\n",
      "|    policyGradLoss     | -0.00734    |\n",
      "|    value_loss         | 1.32        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_51.zip\n",
      "[EVAL] Mean Return: 513.145, Best Return: 521.145\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_51_513.15.mp4\n",
      "\n",
      "=== Round 53 | Learn 262144 steps (Total trained: 13631488) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1130     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 13639680 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 890         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 13647872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008682724 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.424       |\n",
      "|    mean_step_reward   | 0.32139802  |\n",
      "|    n_updates          | 6660        |\n",
      "|    policyGradLoss     | -0.002      |\n",
      "|    value_loss         | 2.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 13656064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011056861 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.253       |\n",
      "|    mean_step_reward   | 0.40554085  |\n",
      "|    n_updates          | 6664        |\n",
      "|    policyGradLoss     | -0.00474    |\n",
      "|    value_loss         | 1.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 13664256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010183617 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.708       |\n",
      "|    mean_step_reward   | 0.35117084  |\n",
      "|    n_updates          | 6668        |\n",
      "|    policyGradLoss     | -0.00218    |\n",
      "|    value_loss         | 2.71        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 795          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 51           |\n",
      "|    total_timesteps    | 13672448     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0126944855 |\n",
      "|    entropy_loss       | -1.71        |\n",
      "|    explained_variance | 0.955        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.683        |\n",
      "|    mean_step_reward   | 0.34414074   |\n",
      "|    n_updates          | 6672         |\n",
      "|    policyGradLoss     | -0.00147     |\n",
      "|    value_loss         | 2.97         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 62          |\n",
      "|    total_timesteps    | 13680640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010673761 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.723       |\n",
      "|    mean_step_reward   | 0.42980865  |\n",
      "|    n_updates          | 6676        |\n",
      "|    policyGradLoss     | 0.000129    |\n",
      "|    value_loss         | 3.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 73          |\n",
      "|    total_timesteps    | 13688832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009555837 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.514       |\n",
      "|    mean_step_reward   | 0.41231477  |\n",
      "|    n_updates          | 6680        |\n",
      "|    policyGradLoss     | -0.00305    |\n",
      "|    value_loss         | 2.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 13697024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010889969 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.01        |\n",
      "|    mean_step_reward   | 0.35084772  |\n",
      "|    n_updates          | 6684        |\n",
      "|    policyGradLoss     | -0.00336    |\n",
      "|    value_loss         | 3.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 13705216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014119276 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.791       |\n",
      "|    mean_step_reward   | 0.39458433  |\n",
      "|    n_updates          | 6688        |\n",
      "|    policyGradLoss     | 0.000665    |\n",
      "|    value_loss         | 3.43        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 13713408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010067824 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.596       |\n",
      "|    mean_step_reward   | 0.2958776   |\n",
      "|    n_updates          | 6692        |\n",
      "|    policyGradLoss     | -0.00692    |\n",
      "|    value_loss         | 1.65        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 795        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 113        |\n",
      "|    total_timesteps    | 13721600   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01089273 |\n",
      "|    entropy_loss       | -1.7       |\n",
      "|    explained_variance | 0.952      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.859      |\n",
      "|    mean_step_reward   | 0.32020456 |\n",
      "|    n_updates          | 6696       |\n",
      "|    policyGradLoss     | -0.000179  |\n",
      "|    value_loss         | 2.18       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 13729792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011444235 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.22        |\n",
      "|    mean_step_reward   | 0.37818068  |\n",
      "|    n_updates          | 6700        |\n",
      "|    policyGradLoss     | -6.86e-05   |\n",
      "|    value_loss         | 2.96        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 789          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 134          |\n",
      "|    total_timesteps    | 13737984     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0071946396 |\n",
      "|    entropy_loss       | -1.73        |\n",
      "|    explained_variance | 0.984        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.596        |\n",
      "|    mean_step_reward   | 0.28421286   |\n",
      "|    n_updates          | 6704         |\n",
      "|    policyGradLoss     | -0.0041      |\n",
      "|    value_loss         | 1.54         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 13746176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011261721 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.439       |\n",
      "|    mean_step_reward   | 0.43556446  |\n",
      "|    n_updates          | 6708        |\n",
      "|    policyGradLoss     | -0.000247   |\n",
      "|    value_loss         | 2.29        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 781       |\n",
      "|    iterations         | 15        |\n",
      "|    time_elapsed       | 157       |\n",
      "|    total_timesteps    | 13754368  |\n",
      "| train/                |           |\n",
      "|    approx_kl          | 0.0104446 |\n",
      "|    entropy_loss       | -1.74     |\n",
      "|    explained_variance | 0.952     |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    loss               | 0.645     |\n",
      "|    mean_step_reward   | 0.2927885 |\n",
      "|    n_updates          | 6712      |\n",
      "|    policyGradLoss     | -0.00216  |\n",
      "|    value_loss         | 3.07      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 13762560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012123743 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.556       |\n",
      "|    mean_step_reward   | 0.33043402  |\n",
      "|    n_updates          | 6716        |\n",
      "|    policyGradLoss     | -0.00335    |\n",
      "|    value_loss         | 2.82        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 13770752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013664719 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.377       |\n",
      "|    mean_step_reward   | 0.31816217  |\n",
      "|    n_updates          | 6720        |\n",
      "|    policyGradLoss     | 0.00121     |\n",
      "|    value_loss         | 1.89        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 13778944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011389185 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.912       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.634       |\n",
      "|    mean_step_reward   | 0.22885242  |\n",
      "|    n_updates          | 6724        |\n",
      "|    policyGradLoss     | 0.00218     |\n",
      "|    value_loss         | 3.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 13787136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010935268 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.34        |\n",
      "|    mean_step_reward   | 0.3076207   |\n",
      "|    n_updates          | 6728        |\n",
      "|    policyGradLoss     | -0.00663    |\n",
      "|    value_loss         | 1.75        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 212         |\n",
      "|    total_timesteps    | 13795328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011075793 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.546       |\n",
      "|    mean_step_reward   | 0.32239115  |\n",
      "|    n_updates          | 6732        |\n",
      "|    policyGradLoss     | -0.000425   |\n",
      "|    value_loss         | 2.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 223         |\n",
      "|    total_timesteps    | 13803520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010954316 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.426       |\n",
      "|    mean_step_reward   | 0.35821664  |\n",
      "|    n_updates          | 6736        |\n",
      "|    policyGradLoss     | -0.00436    |\n",
      "|    value_loss         | 2.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 234         |\n",
      "|    total_timesteps    | 13811712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010378946 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.701       |\n",
      "|    mean_step_reward   | 0.32757187  |\n",
      "|    n_updates          | 6740        |\n",
      "|    policyGradLoss     | -0.00735    |\n",
      "|    value_loss         | 1.55        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 245         |\n",
      "|    total_timesteps    | 13819904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011345491 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.808       |\n",
      "|    mean_step_reward   | 0.31828752  |\n",
      "|    n_updates          | 6744        |\n",
      "|    policyGradLoss     | -0.00296    |\n",
      "|    value_loss         | 2.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 256         |\n",
      "|    total_timesteps    | 13828096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011254553 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.975       |\n",
      "|    mean_step_reward   | 0.2862634   |\n",
      "|    n_updates          | 6748        |\n",
      "|    policyGradLoss     | -0.00101    |\n",
      "|    value_loss         | 2.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 267         |\n",
      "|    total_timesteps    | 13836288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010554043 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.469       |\n",
      "|    mean_step_reward   | 0.31530434  |\n",
      "|    n_updates          | 6752        |\n",
      "|    policyGradLoss     | -0.00437    |\n",
      "|    value_loss         | 2.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 279         |\n",
      "|    total_timesteps    | 13844480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010445168 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.632       |\n",
      "|    mean_step_reward   | 0.3309434   |\n",
      "|    n_updates          | 6756        |\n",
      "|    policyGradLoss     | 0.000744    |\n",
      "|    value_loss         | 3.6         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 765        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 289        |\n",
      "|    total_timesteps    | 13852672   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00993322 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.96       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.524      |\n",
      "|    mean_step_reward   | 0.33097136 |\n",
      "|    n_updates          | 6760       |\n",
      "|    policyGradLoss     | -0.000681  |\n",
      "|    value_loss         | 2.91       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 300         |\n",
      "|    total_timesteps    | 13860864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010767267 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.36        |\n",
      "|    mean_step_reward   | 0.33165342  |\n",
      "|    n_updates          | 6764        |\n",
      "|    policyGradLoss     | -0.00567    |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 311         |\n",
      "|    total_timesteps    | 13869056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009097702 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.584       |\n",
      "|    mean_step_reward   | 0.31433052  |\n",
      "|    n_updates          | 6768        |\n",
      "|    policyGradLoss     | -0.00475    |\n",
      "|    value_loss         | 2.35        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 763          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 321          |\n",
      "|    total_timesteps    | 13877248     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0093659535 |\n",
      "|    entropy_loss       | -1.7         |\n",
      "|    explained_variance | 0.972        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.863        |\n",
      "|    mean_step_reward   | 0.42382532   |\n",
      "|    n_updates          | 6772         |\n",
      "|    policyGradLoss     | -0.00219     |\n",
      "|    value_loss         | 2.87         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 13885440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009692001 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.739       |\n",
      "|    mean_step_reward   | 0.33679855  |\n",
      "|    n_updates          | 6776        |\n",
      "|    policyGradLoss     | -0.0048     |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 344         |\n",
      "|    total_timesteps    | 13893632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009135637 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.328       |\n",
      "|    mean_step_reward   | 0.32596236  |\n",
      "|    n_updates          | 6780        |\n",
      "|    policyGradLoss     | -0.0049     |\n",
      "|    value_loss         | 2.33        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_52.zip\n",
      "[EVAL] Mean Return: 549.683, Best Return: 557.683\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_52_549.68.mp4\n",
      "\n",
      "=== Round 54 | Learn 262144 steps (Total trained: 13893632) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1193     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 13901824 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 891         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 13910016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009621594 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.78        |\n",
      "|    mean_step_reward   | 0.40247545  |\n",
      "|    n_updates          | 6788        |\n",
      "|    policyGradLoss     | -0.00286    |\n",
      "|    value_loss         | 2.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 839         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 13918208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009306856 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.583       |\n",
      "|    mean_step_reward   | 0.3242752   |\n",
      "|    n_updates          | 6792        |\n",
      "|    policyGradLoss     | -0.00438    |\n",
      "|    value_loss         | 1.76        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 13926400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011755861 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.399       |\n",
      "|    mean_step_reward   | 0.36779183  |\n",
      "|    n_updates          | 6796        |\n",
      "|    policyGradLoss     | -0.0041     |\n",
      "|    value_loss         | 1.95        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 13934592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014601286 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.174       |\n",
      "|    mean_step_reward   | 0.3229664   |\n",
      "|    n_updates          | 6800        |\n",
      "|    policyGradLoss     | -0.00682    |\n",
      "|    value_loss         | 1.09        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 62          |\n",
      "|    total_timesteps    | 13942784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018337656 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.912       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.62        |\n",
      "|    mean_step_reward   | 0.34665468  |\n",
      "|    n_updates          | 6804        |\n",
      "|    policyGradLoss     | 0.00537     |\n",
      "|    value_loss         | 5.84        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 73          |\n",
      "|    total_timesteps    | 13950976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013939165 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.502       |\n",
      "|    mean_step_reward   | 0.3475711   |\n",
      "|    n_updates          | 6808        |\n",
      "|    policyGradLoss     | 0.00328     |\n",
      "|    value_loss         | 4.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 84          |\n",
      "|    total_timesteps    | 13959168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010531788 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.24        |\n",
      "|    mean_step_reward   | 0.3404475   |\n",
      "|    n_updates          | 6812        |\n",
      "|    policyGradLoss     | -0.000986   |\n",
      "|    value_loss         | 5.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 95          |\n",
      "|    total_timesteps    | 13967360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014057498 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.354       |\n",
      "|    mean_step_reward   | 0.3689009   |\n",
      "|    n_updates          | 6816        |\n",
      "|    policyGradLoss     | -0.00302    |\n",
      "|    value_loss         | 2.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 13975552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008934977 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.662       |\n",
      "|    mean_step_reward   | 0.3672836   |\n",
      "|    n_updates          | 6820        |\n",
      "|    policyGradLoss     | -0.00521    |\n",
      "|    value_loss         | 2.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 116         |\n",
      "|    total_timesteps    | 13983744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013695268 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.363       |\n",
      "|    mean_step_reward   | 0.31561115  |\n",
      "|    n_updates          | 6824        |\n",
      "|    policyGradLoss     | 0.00123     |\n",
      "|    value_loss         | 3.65        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 127         |\n",
      "|    total_timesteps    | 13991936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010068534 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.585       |\n",
      "|    mean_step_reward   | 0.34696186  |\n",
      "|    n_updates          | 6828        |\n",
      "|    policyGradLoss     | -0.00531    |\n",
      "|    value_loss         | 2.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 14000128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009252513 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.933       |\n",
      "|    mean_step_reward   | 0.33894637  |\n",
      "|    n_updates          | 6832        |\n",
      "|    policyGradLoss     | -0.00399    |\n",
      "|    value_loss         | 2.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 149         |\n",
      "|    total_timesteps    | 14008320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010584165 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.286       |\n",
      "|    mean_step_reward   | 0.28830588  |\n",
      "|    n_updates          | 6836        |\n",
      "|    policyGradLoss     | -0.00424    |\n",
      "|    value_loss         | 1.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 159         |\n",
      "|    total_timesteps    | 14016512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013239273 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.803       |\n",
      "|    mean_step_reward   | 0.3941334   |\n",
      "|    n_updates          | 6840        |\n",
      "|    policyGradLoss     | 0.0021      |\n",
      "|    value_loss         | 3.17        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 763          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 171          |\n",
      "|    total_timesteps    | 14024704     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0101106195 |\n",
      "|    entropy_loss       | -1.74        |\n",
      "|    explained_variance | 0.98         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.667        |\n",
      "|    mean_step_reward   | 0.3609077    |\n",
      "|    n_updates          | 6844         |\n",
      "|    policyGradLoss     | -0.00513     |\n",
      "|    value_loss         | 2.16         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 182         |\n",
      "|    total_timesteps    | 14032896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008774115 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.412       |\n",
      "|    mean_step_reward   | 0.3406771   |\n",
      "|    n_updates          | 6848        |\n",
      "|    policyGradLoss     | -0.00583    |\n",
      "|    value_loss         | 2.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 193         |\n",
      "|    total_timesteps    | 14041088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011744451 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.826       |\n",
      "|    mean_step_reward   | 0.36334437  |\n",
      "|    n_updates          | 6852        |\n",
      "|    policyGradLoss     | -0.00221    |\n",
      "|    value_loss         | 2.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 204         |\n",
      "|    total_timesteps    | 14049280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010184862 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.335       |\n",
      "|    mean_step_reward   | 0.32432222  |\n",
      "|    n_updates          | 6856        |\n",
      "|    policyGradLoss     | -0.00539    |\n",
      "|    value_loss         | 1.99        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 215         |\n",
      "|    total_timesteps    | 14057472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014517121 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.1         |\n",
      "|    mean_step_reward   | 0.37171414  |\n",
      "|    n_updates          | 6860        |\n",
      "|    policyGradLoss     | -0.000812   |\n",
      "|    value_loss         | 4.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 226         |\n",
      "|    total_timesteps    | 14065664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011426928 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.378       |\n",
      "|    mean_step_reward   | 0.33758664  |\n",
      "|    n_updates          | 6864        |\n",
      "|    policyGradLoss     | -0.00241    |\n",
      "|    value_loss         | 2.85        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 759        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 237        |\n",
      "|    total_timesteps    | 14073856   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01171351 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.974      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.744      |\n",
      "|    mean_step_reward   | 0.3797922  |\n",
      "|    n_updates          | 6868       |\n",
      "|    policyGradLoss     | -0.00261   |\n",
      "|    value_loss         | 2.3        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 246         |\n",
      "|    total_timesteps    | 14082048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010356119 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.228       |\n",
      "|    mean_step_reward   | 0.33414063  |\n",
      "|    n_updates          | 6872        |\n",
      "|    policyGradLoss     | -0.0054     |\n",
      "|    value_loss         | 0.928       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 14090240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012829805 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.309       |\n",
      "|    mean_step_reward   | 0.3555507   |\n",
      "|    n_updates          | 6876        |\n",
      "|    policyGradLoss     | -0.00147    |\n",
      "|    value_loss         | 2.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 14098432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013678893 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.754       |\n",
      "|    mean_step_reward   | 0.39639175  |\n",
      "|    n_updates          | 6880        |\n",
      "|    policyGradLoss     | -0.00216    |\n",
      "|    value_loss         | 4.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 14106624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007583818 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.35        |\n",
      "|    mean_step_reward   | 0.3129254   |\n",
      "|    n_updates          | 6884        |\n",
      "|    policyGradLoss     | -0.002      |\n",
      "|    value_loss         | 2.46        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 14114816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010701456 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.377       |\n",
      "|    mean_step_reward   | 0.31743172  |\n",
      "|    n_updates          | 6888        |\n",
      "|    policyGradLoss     | -0.00614    |\n",
      "|    value_loss         | 1.46        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 14123008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010809521 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.279       |\n",
      "|    mean_step_reward   | 0.36686438  |\n",
      "|    n_updates          | 6892        |\n",
      "|    policyGradLoss     | -0.00416    |\n",
      "|    value_loss         | 1.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 307         |\n",
      "|    total_timesteps    | 14131200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008716868 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.33        |\n",
      "|    mean_step_reward   | 0.34243244  |\n",
      "|    n_updates          | 6896        |\n",
      "|    policyGradLoss     | -0.00217    |\n",
      "|    value_loss         | 2.74        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 770        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 318        |\n",
      "|    total_timesteps    | 14139392   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01199057 |\n",
      "|    entropy_loss       | -1.7       |\n",
      "|    explained_variance | 0.948      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.848      |\n",
      "|    mean_step_reward   | 0.43545252 |\n",
      "|    n_updates          | 6900       |\n",
      "|    policyGradLoss     | 0.000895   |\n",
      "|    value_loss         | 4.57       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 329         |\n",
      "|    total_timesteps    | 14147584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011580719 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.57        |\n",
      "|    mean_step_reward   | 0.33263022  |\n",
      "|    n_updates          | 6904        |\n",
      "|    policyGradLoss     | -0.00161    |\n",
      "|    value_loss         | 1.99        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 770          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 340          |\n",
      "|    total_timesteps    | 14155776     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0106968405 |\n",
      "|    entropy_loss       | -1.73        |\n",
      "|    explained_variance | 0.989        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.316        |\n",
      "|    mean_step_reward   | 0.3213222    |\n",
      "|    n_updates          | 6908         |\n",
      "|    policyGradLoss     | -0.0096      |\n",
      "|    value_loss         | 0.984        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_53.zip\n",
      "[EVAL] Mean Return: 63.026, Best Return: 64.359\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_53_63.03.mp4\n",
      "\n",
      "=== Round 55 | Learn 262144 steps (Total trained: 14155776) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1193     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 14163968 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 915         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 14172160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011224224 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.606       |\n",
      "|    mean_step_reward   | 0.29815504  |\n",
      "|    n_updates          | 6916        |\n",
      "|    policyGradLoss     | -0.0017     |\n",
      "|    value_loss         | 2.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 850         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 14180352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010737885 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.606       |\n",
      "|    mean_step_reward   | 0.3764292   |\n",
      "|    n_updates          | 6920        |\n",
      "|    policyGradLoss     | -0.00164    |\n",
      "|    value_loss         | 1.92        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 817          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 40           |\n",
      "|    total_timesteps    | 14188544     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0100211175 |\n",
      "|    entropy_loss       | -1.72        |\n",
      "|    explained_variance | 0.978        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.439        |\n",
      "|    mean_step_reward   | 0.35407162   |\n",
      "|    n_updates          | 6924         |\n",
      "|    policyGradLoss     | -0.00567     |\n",
      "|    value_loss         | 2.02         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 14196736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010930728 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.05        |\n",
      "|    mean_step_reward   | 0.37599695  |\n",
      "|    n_updates          | 6928        |\n",
      "|    policyGradLoss     | -0.00102    |\n",
      "|    value_loss         | 2.76        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 14204928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010945134 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.726       |\n",
      "|    mean_step_reward   | 0.32217556  |\n",
      "|    n_updates          | 6932        |\n",
      "|    policyGradLoss     | 0.000292    |\n",
      "|    value_loss         | 4           |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 73          |\n",
      "|    total_timesteps    | 14213120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011797013 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.683       |\n",
      "|    mean_step_reward   | 0.31856126  |\n",
      "|    n_updates          | 6936        |\n",
      "|    policyGradLoss     | 0.00134     |\n",
      "|    value_loss         | 3.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 14221312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009873725 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.408       |\n",
      "|    mean_step_reward   | 0.32427478  |\n",
      "|    n_updates          | 6940        |\n",
      "|    policyGradLoss     | -0.000696   |\n",
      "|    value_loss         | 2           |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 793        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 92         |\n",
      "|    total_timesteps    | 14229504   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0097619  |\n",
      "|    entropy_loss       | -1.76      |\n",
      "|    explained_variance | 0.96       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.425      |\n",
      "|    mean_step_reward   | 0.31927562 |\n",
      "|    n_updates          | 6944       |\n",
      "|    policyGradLoss     | -0.00115   |\n",
      "|    value_loss         | 2.37       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 14237696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010895422 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.494       |\n",
      "|    mean_step_reward   | 0.3872869   |\n",
      "|    n_updates          | 6948        |\n",
      "|    policyGradLoss     | 0.00241     |\n",
      "|    value_loss         | 3.39        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 793          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 113          |\n",
      "|    total_timesteps    | 14245888     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0078085163 |\n",
      "|    entropy_loss       | -1.78        |\n",
      "|    explained_variance | 0.968        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.244        |\n",
      "|    mean_step_reward   | 0.3544582    |\n",
      "|    n_updates          | 6952         |\n",
      "|    policyGradLoss     | -0.00188     |\n",
      "|    value_loss         | 2.45         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 14254080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012701696 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.598       |\n",
      "|    mean_step_reward   | 0.32843533  |\n",
      "|    n_updates          | 6956        |\n",
      "|    policyGradLoss     | -0.0052     |\n",
      "|    value_loss         | 1.45        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 14262272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015536447 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.664       |\n",
      "|    mean_step_reward   | 0.34495318  |\n",
      "|    n_updates          | 6960        |\n",
      "|    policyGradLoss     | -0.00153    |\n",
      "|    value_loss         | 2.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 14270464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010180686 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.826       |\n",
      "|    mean_step_reward   | 0.36214423  |\n",
      "|    n_updates          | 6964        |\n",
      "|    policyGradLoss     | -0.00683    |\n",
      "|    value_loss         | 1.83        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 14278656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010967322 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.256       |\n",
      "|    mean_step_reward   | 0.31671965  |\n",
      "|    n_updates          | 6968        |\n",
      "|    policyGradLoss     | -0.0066     |\n",
      "|    value_loss         | 1.8         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 14286848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011224087 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.356       |\n",
      "|    mean_step_reward   | 0.38199767  |\n",
      "|    n_updates          | 6972        |\n",
      "|    policyGradLoss     | -0.00633    |\n",
      "|    value_loss         | 1.53        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 14295040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010043202 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.708       |\n",
      "|    mean_step_reward   | 0.35867006  |\n",
      "|    n_updates          | 6976        |\n",
      "|    policyGradLoss     | -0.00379    |\n",
      "|    value_loss         | 2.45        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 14303232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010826107 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.286       |\n",
      "|    mean_step_reward   | 0.302191    |\n",
      "|    n_updates          | 6980        |\n",
      "|    policyGradLoss     | -0.00491    |\n",
      "|    value_loss         | 1.71        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 14311424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012658415 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.871       |\n",
      "|    mean_step_reward   | 0.36724088  |\n",
      "|    n_updates          | 6984        |\n",
      "|    policyGradLoss     | -0.00115    |\n",
      "|    value_loss         | 1.74        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 212         |\n",
      "|    total_timesteps    | 14319616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014023408 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.441       |\n",
      "|    mean_step_reward   | 0.25019187  |\n",
      "|    n_updates          | 6988        |\n",
      "|    policyGradLoss     | -0.00272    |\n",
      "|    value_loss         | 1.92        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 223         |\n",
      "|    total_timesteps    | 14327808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013283026 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.753       |\n",
      "|    mean_step_reward   | 0.39596635  |\n",
      "|    n_updates          | 6992        |\n",
      "|    policyGradLoss     | 0.000961    |\n",
      "|    value_loss         | 2.43        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 234         |\n",
      "|    total_timesteps    | 14336000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008834784 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.308       |\n",
      "|    mean_step_reward   | 0.2755392   |\n",
      "|    n_updates          | 6996        |\n",
      "|    policyGradLoss     | -0.00551    |\n",
      "|    value_loss         | 1.66        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 766          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 245          |\n",
      "|    total_timesteps    | 14344192     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0140021555 |\n",
      "|    entropy_loss       | -1.64        |\n",
      "|    explained_variance | 0.952        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.43         |\n",
      "|    mean_step_reward   | 0.37484115   |\n",
      "|    n_updates          | 7000         |\n",
      "|    policyGradLoss     | 8.67e-05     |\n",
      "|    value_loss         | 3.49         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 256         |\n",
      "|    total_timesteps    | 14352384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011162095 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.912       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.755       |\n",
      "|    mean_step_reward   | 0.26658085  |\n",
      "|    n_updates          | 7004        |\n",
      "|    policyGradLoss     | 0.000167    |\n",
      "|    value_loss         | 4.09        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 268         |\n",
      "|    total_timesteps    | 14360576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009763636 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.642       |\n",
      "|    mean_step_reward   | 0.37382415  |\n",
      "|    n_updates          | 7008        |\n",
      "|    policyGradLoss     | -0.000866   |\n",
      "|    value_loss         | 2.43        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 278         |\n",
      "|    total_timesteps    | 14368768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008243489 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.714       |\n",
      "|    mean_step_reward   | 0.3489614   |\n",
      "|    n_updates          | 7012        |\n",
      "|    policyGradLoss     | -0.00145    |\n",
      "|    value_loss         | 2.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 289         |\n",
      "|    total_timesteps    | 14376960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008485738 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.592       |\n",
      "|    mean_step_reward   | 0.33584508  |\n",
      "|    n_updates          | 7016        |\n",
      "|    policyGradLoss     | -0.00521    |\n",
      "|    value_loss         | 1.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 300         |\n",
      "|    total_timesteps    | 14385152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010763762 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.33        |\n",
      "|    mean_step_reward   | 0.41665524  |\n",
      "|    n_updates          | 7020        |\n",
      "|    policyGradLoss     | -0.00231    |\n",
      "|    value_loss         | 3.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 311         |\n",
      "|    total_timesteps    | 14393344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011684844 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.446       |\n",
      "|    mean_step_reward   | 0.3309446   |\n",
      "|    n_updates          | 7024        |\n",
      "|    policyGradLoss     | -0.00599    |\n",
      "|    value_loss         | 2.07        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 322         |\n",
      "|    total_timesteps    | 14401536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015927304 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.591       |\n",
      "|    mean_step_reward   | 0.3148916   |\n",
      "|    n_updates          | 7028        |\n",
      "|    policyGradLoss     | 0.00189     |\n",
      "|    value_loss         | 3.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 14409728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017678129 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.396       |\n",
      "|    mean_step_reward   | 0.34488812  |\n",
      "|    n_updates          | 7032        |\n",
      "|    policyGradLoss     | 0.00365     |\n",
      "|    value_loss         | 2.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 345         |\n",
      "|    total_timesteps    | 14417920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011183595 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.824       |\n",
      "|    mean_step_reward   | 0.34465575  |\n",
      "|    n_updates          | 7036        |\n",
      "|    policyGradLoss     | -0.00321    |\n",
      "|    value_loss         | 1.92        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_54.zip\n",
      "[EVAL] Mean Return: 547.941, Best Return: 554.607\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_54_547.94.mp4\n",
      "\n",
      "=== Round 56 | Learn 262144 steps (Total trained: 14417920) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1169     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 14426112 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 937         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 14434304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013505393 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.27        |\n",
      "|    mean_step_reward   | 0.2931766   |\n",
      "|    n_updates          | 7044        |\n",
      "|    policyGradLoss     | 0.00133     |\n",
      "|    value_loss         | 4.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 847         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 14442496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013285498 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.27        |\n",
      "|    mean_step_reward   | 0.36255136  |\n",
      "|    n_updates          | 7048        |\n",
      "|    policyGradLoss     | 0.00406     |\n",
      "|    value_loss         | 3.82        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 828         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 14450688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013004785 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.723       |\n",
      "|    mean_step_reward   | 0.3147891   |\n",
      "|    n_updates          | 7052        |\n",
      "|    policyGradLoss     | -0.000473   |\n",
      "|    value_loss         | 1.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 14458880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014964912 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.318       |\n",
      "|    mean_step_reward   | 0.31229863  |\n",
      "|    n_updates          | 7056        |\n",
      "|    policyGradLoss     | 0.000719    |\n",
      "|    value_loss         | 2.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 14467072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013388218 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.177       |\n",
      "|    mean_step_reward   | 0.27781132  |\n",
      "|    n_updates          | 7060        |\n",
      "|    policyGradLoss     | -0.00662    |\n",
      "|    value_loss         | 1.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 14475264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011911057 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.478       |\n",
      "|    mean_step_reward   | 0.32048368  |\n",
      "|    n_updates          | 7064        |\n",
      "|    policyGradLoss     | -0.00385    |\n",
      "|    value_loss         | 1.52        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 14483456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011569095 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.338       |\n",
      "|    mean_step_reward   | 0.3570291   |\n",
      "|    n_updates          | 7068        |\n",
      "|    policyGradLoss     | -0.0046     |\n",
      "|    value_loss         | 2.04        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 94          |\n",
      "|    total_timesteps    | 14491648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011778017 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.506       |\n",
      "|    mean_step_reward   | 0.23561707  |\n",
      "|    n_updates          | 7072        |\n",
      "|    policyGradLoss     | -0.00566    |\n",
      "|    value_loss         | 1.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 14499840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013064317 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.319       |\n",
      "|    mean_step_reward   | 0.29616338  |\n",
      "|    n_updates          | 7076        |\n",
      "|    policyGradLoss     | -0.00157    |\n",
      "|    value_loss         | 1.95        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 116         |\n",
      "|    total_timesteps    | 14508032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008945172 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.503       |\n",
      "|    mean_step_reward   | 0.2798343   |\n",
      "|    n_updates          | 7080        |\n",
      "|    policyGradLoss     | -0.00394    |\n",
      "|    value_loss         | 1.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 127         |\n",
      "|    total_timesteps    | 14516224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018306931 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.966       |\n",
      "|    mean_step_reward   | 0.3791241   |\n",
      "|    n_updates          | 7084        |\n",
      "|    policyGradLoss     | 0.00166     |\n",
      "|    value_loss         | 4.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 14524416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010858862 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.833       |\n",
      "|    mean_step_reward   | 0.28574014  |\n",
      "|    n_updates          | 7088        |\n",
      "|    policyGradLoss     | -0.00298    |\n",
      "|    value_loss         | 1.94        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 149         |\n",
      "|    total_timesteps    | 14532608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013017429 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.302       |\n",
      "|    mean_step_reward   | 0.31459513  |\n",
      "|    n_updates          | 7092        |\n",
      "|    policyGradLoss     | -0.00357    |\n",
      "|    value_loss         | 1.94        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 161         |\n",
      "|    total_timesteps    | 14540800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012358886 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.23        |\n",
      "|    mean_step_reward   | 0.33904618  |\n",
      "|    n_updates          | 7096        |\n",
      "|    policyGradLoss     | -0.00585    |\n",
      "|    value_loss         | 1.9         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 171         |\n",
      "|    total_timesteps    | 14548992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012593401 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.413       |\n",
      "|    mean_step_reward   | 0.20717362  |\n",
      "|    n_updates          | 7100        |\n",
      "|    policyGradLoss     | -0.0033     |\n",
      "|    value_loss         | 1.89        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 183         |\n",
      "|    total_timesteps    | 14557184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013343858 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.157       |\n",
      "|    mean_step_reward   | 0.3191393   |\n",
      "|    n_updates          | 7104        |\n",
      "|    policyGradLoss     | -0.00312    |\n",
      "|    value_loss         | 1.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 193         |\n",
      "|    total_timesteps    | 14565376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011989098 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.9         |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.561       |\n",
      "|    mean_step_reward   | 0.25184745  |\n",
      "|    n_updates          | 7108        |\n",
      "|    policyGradLoss     | 0.002       |\n",
      "|    value_loss         | 3.98        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 204         |\n",
      "|    total_timesteps    | 14573568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015580369 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.89        |\n",
      "|    mean_step_reward   | 0.3165264   |\n",
      "|    n_updates          | 7112        |\n",
      "|    policyGradLoss     | -0.00223    |\n",
      "|    value_loss         | 2.76        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 759        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 215        |\n",
      "|    total_timesteps    | 14581760   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01244039 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.945      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.209      |\n",
      "|    mean_step_reward   | 0.31488106 |\n",
      "|    n_updates          | 7116       |\n",
      "|    policyGradLoss     | 0.00144    |\n",
      "|    value_loss         | 2.49       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 226         |\n",
      "|    total_timesteps    | 14589952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011205621 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.01        |\n",
      "|    mean_step_reward   | 0.3778715   |\n",
      "|    n_updates          | 7120        |\n",
      "|    policyGradLoss     | -0.00212    |\n",
      "|    value_loss         | 2.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 237         |\n",
      "|    total_timesteps    | 14598144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013566413 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.941       |\n",
      "|    mean_step_reward   | 0.36023802  |\n",
      "|    n_updates          | 7124        |\n",
      "|    policyGradLoss     | -0.00298    |\n",
      "|    value_loss         | 2.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 248         |\n",
      "|    total_timesteps    | 14606336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011423696 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.919       |\n",
      "|    mean_step_reward   | 0.30630857  |\n",
      "|    n_updates          | 7128        |\n",
      "|    policyGradLoss     | 0.000297    |\n",
      "|    value_loss         | 4.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 257         |\n",
      "|    total_timesteps    | 14614528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011123192 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.542       |\n",
      "|    mean_step_reward   | 0.34148538  |\n",
      "|    n_updates          | 7132        |\n",
      "|    policyGradLoss     | -0.00128    |\n",
      "|    value_loss         | 2.93        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 266         |\n",
      "|    total_timesteps    | 14622720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012449456 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.48        |\n",
      "|    mean_step_reward   | 0.37612444  |\n",
      "|    n_updates          | 7136        |\n",
      "|    policyGradLoss     | 0.00316     |\n",
      "|    value_loss         | 5.07        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 275         |\n",
      "|    total_timesteps    | 14630912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012600066 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.716       |\n",
      "|    mean_step_reward   | 0.30098444  |\n",
      "|    n_updates          | 7140        |\n",
      "|    policyGradLoss     | 0.0013      |\n",
      "|    value_loss         | 1.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 286         |\n",
      "|    total_timesteps    | 14639104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012057157 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.511       |\n",
      "|    mean_step_reward   | 0.413907    |\n",
      "|    n_updates          | 7144        |\n",
      "|    policyGradLoss     | -0.00425    |\n",
      "|    value_loss         | 2.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 14647296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009028494 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.817       |\n",
      "|    mean_step_reward   | 0.30438167  |\n",
      "|    n_updates          | 7148        |\n",
      "|    policyGradLoss     | -0.00608    |\n",
      "|    value_loss         | 1.66        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 770        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 308        |\n",
      "|    total_timesteps    | 14655488   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01447439 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.928      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.576      |\n",
      "|    mean_step_reward   | 0.38075644 |\n",
      "|    n_updates          | 7152       |\n",
      "|    policyGradLoss     | 0.00173    |\n",
      "|    value_loss         | 3.24       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 14663680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013591202 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.642       |\n",
      "|    mean_step_reward   | 0.3119936   |\n",
      "|    n_updates          | 7156        |\n",
      "|    policyGradLoss     | -3.34e-05   |\n",
      "|    value_loss         | 4.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 14671872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012792616 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.489       |\n",
      "|    mean_step_reward   | 0.3856184   |\n",
      "|    n_updates          | 7160        |\n",
      "|    policyGradLoss     | -0.00198    |\n",
      "|    value_loss         | 2.65        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 341         |\n",
      "|    total_timesteps    | 14680064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010386062 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.862       |\n",
      "|    mean_step_reward   | 0.36206302  |\n",
      "|    n_updates          | 7164        |\n",
      "|    policyGradLoss     | -0.000893   |\n",
      "|    value_loss         | 2.21        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_55.zip\n",
      "[EVAL] Mean Return: 60.896, Best Return: 62.230\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_55_60.90.mp4\n",
      "\n",
      "=== Round 57 | Learn 262144 steps (Total trained: 14680064) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1142     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 14688256 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 892         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 14696448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011356058 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.517       |\n",
      "|    mean_step_reward   | 0.36744702  |\n",
      "|    n_updates          | 7172        |\n",
      "|    policyGradLoss     | 0.000269    |\n",
      "|    value_loss         | 4.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 835         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 14704640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010715153 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.774       |\n",
      "|    mean_step_reward   | 0.33349997  |\n",
      "|    n_updates          | 7176        |\n",
      "|    policyGradLoss     | -0.00147    |\n",
      "|    value_loss         | 2.66        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 14712832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013675586 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.229       |\n",
      "|    mean_step_reward   | 0.33766443  |\n",
      "|    n_updates          | 7180        |\n",
      "|    policyGradLoss     | -0.00151    |\n",
      "|    value_loss         | 1.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 14721024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008821892 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.661       |\n",
      "|    mean_step_reward   | 0.32501003  |\n",
      "|    n_updates          | 7184        |\n",
      "|    policyGradLoss     | -0.00287    |\n",
      "|    value_loss         | 2.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 14729216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011901377 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.782       |\n",
      "|    mean_step_reward   | 0.28452206  |\n",
      "|    n_updates          | 7188        |\n",
      "|    policyGradLoss     | -0.00873    |\n",
      "|    value_loss         | 1.99        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 73         |\n",
      "|    total_timesteps    | 14737408   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01100909 |\n",
      "|    entropy_loss       | -1.68      |\n",
      "|    explained_variance | 0.964      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.457      |\n",
      "|    mean_step_reward   | 0.3720271  |\n",
      "|    n_updates          | 7192       |\n",
      "|    policyGradLoss     | -0.00169   |\n",
      "|    value_loss         | 2.41       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 14745600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012462897 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.6         |\n",
      "|    mean_step_reward   | 0.35578573  |\n",
      "|    n_updates          | 7196        |\n",
      "|    policyGradLoss     | -0.00559    |\n",
      "|    value_loss         | 1.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 95          |\n",
      "|    total_timesteps    | 14753792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009319709 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.27        |\n",
      "|    mean_step_reward   | 0.35946897  |\n",
      "|    n_updates          | 7200        |\n",
      "|    policyGradLoss     | -0.00491    |\n",
      "|    value_loss         | 2.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 14761984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012416691 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.198       |\n",
      "|    mean_step_reward   | 0.29384503  |\n",
      "|    n_updates          | 7204        |\n",
      "|    policyGradLoss     | -0.00433    |\n",
      "|    value_loss         | 1.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 14770176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012320979 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.559       |\n",
      "|    mean_step_reward   | 0.4050636   |\n",
      "|    n_updates          | 7208        |\n",
      "|    policyGradLoss     | 5.85e-05    |\n",
      "|    value_loss         | 3.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 122         |\n",
      "|    total_timesteps    | 14778368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010687163 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.503       |\n",
      "|    mean_step_reward   | 0.3070781   |\n",
      "|    n_updates          | 7212        |\n",
      "|    policyGradLoss     | -0.00162    |\n",
      "|    value_loss         | 3.53        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 14786560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011093621 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.521       |\n",
      "|    mean_step_reward   | 0.33182755  |\n",
      "|    n_updates          | 7216        |\n",
      "|    policyGradLoss     | -0.00152    |\n",
      "|    value_loss         | 2.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 14794752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018577743 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.809       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.77        |\n",
      "|    mean_step_reward   | 0.3025397   |\n",
      "|    n_updates          | 7220        |\n",
      "|    policyGradLoss     | 0.0107      |\n",
      "|    value_loss         | 7.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 14802944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010893929 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.02        |\n",
      "|    mean_step_reward   | 0.38418847  |\n",
      "|    n_updates          | 7224        |\n",
      "|    policyGradLoss     | 0.00249     |\n",
      "|    value_loss         | 2.97        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 786        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 166        |\n",
      "|    total_timesteps    | 14811136   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00965346 |\n",
      "|    entropy_loss       | -1.76      |\n",
      "|    explained_variance | 0.971      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.779      |\n",
      "|    mean_step_reward   | 0.32916    |\n",
      "|    n_updates          | 7228       |\n",
      "|    policyGradLoss     | 0.00196    |\n",
      "|    value_loss         | 2.27       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 783        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 177        |\n",
      "|    total_timesteps    | 14819328   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01276477 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.939      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.828      |\n",
      "|    mean_step_reward   | 0.30122966 |\n",
      "|    n_updates          | 7232       |\n",
      "|    policyGradLoss     | 3.14e-05   |\n",
      "|    value_loss         | 3.46       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 189        |\n",
      "|    total_timesteps    | 14827520   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01760527 |\n",
      "|    entropy_loss       | -1.76      |\n",
      "|    explained_variance | 0.912      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.768      |\n",
      "|    mean_step_reward   | 0.32923028 |\n",
      "|    n_updates          | 7236       |\n",
      "|    policyGradLoss     | 0.000856   |\n",
      "|    value_loss         | 5.45       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 779       |\n",
      "|    iterations         | 19        |\n",
      "|    time_elapsed       | 199       |\n",
      "|    total_timesteps    | 14835712  |\n",
      "| train/                |           |\n",
      "|    approx_kl          | 0.0167825 |\n",
      "|    entropy_loss       | -1.78     |\n",
      "|    explained_variance | 0.966     |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    loss               | 0.126     |\n",
      "|    mean_step_reward   | 0.2678643 |\n",
      "|    n_updates          | 7240      |\n",
      "|    policyGradLoss     | -0.00518  |\n",
      "|    value_loss         | 1.39      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 14843904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010559709 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.871       |\n",
      "|    mean_step_reward   | 0.32441524  |\n",
      "|    n_updates          | 7244        |\n",
      "|    policyGradLoss     | 0.000291    |\n",
      "|    value_loss         | 5.41        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 776          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 221          |\n",
      "|    total_timesteps    | 14852096     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0107951425 |\n",
      "|    entropy_loss       | -1.79        |\n",
      "|    explained_variance | 0.895        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.584        |\n",
      "|    mean_step_reward   | 0.25867084   |\n",
      "|    n_updates          | 7248         |\n",
      "|    policyGradLoss     | -0.00297     |\n",
      "|    value_loss         | 4.53         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 14860288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014348115 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.993       |\n",
      "|    mean_step_reward   | 0.38340688  |\n",
      "|    n_updates          | 7252        |\n",
      "|    policyGradLoss     | 0.00441     |\n",
      "|    value_loss         | 5.86        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 14868480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009627966 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.536       |\n",
      "|    mean_step_reward   | 0.34471142  |\n",
      "|    n_updates          | 7256        |\n",
      "|    policyGradLoss     | -0.00262    |\n",
      "|    value_loss         | 2.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 14876672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010167228 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.529       |\n",
      "|    mean_step_reward   | 0.29116642  |\n",
      "|    n_updates          | 7260        |\n",
      "|    policyGradLoss     | -0.00421    |\n",
      "|    value_loss         | 2.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 265         |\n",
      "|    total_timesteps    | 14884864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013217339 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.537       |\n",
      "|    mean_step_reward   | 0.31110114  |\n",
      "|    n_updates          | 7264        |\n",
      "|    policyGradLoss     | 0.00219     |\n",
      "|    value_loss         | 3.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 276         |\n",
      "|    total_timesteps    | 14893056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012115708 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.9         |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.373       |\n",
      "|    mean_step_reward   | 0.24085316  |\n",
      "|    n_updates          | 7268        |\n",
      "|    policyGradLoss     | 0.000225    |\n",
      "|    value_loss         | 3.5         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 287         |\n",
      "|    total_timesteps    | 14901248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009614052 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.309       |\n",
      "|    mean_step_reward   | 0.32797313  |\n",
      "|    n_updates          | 7272        |\n",
      "|    policyGradLoss     | -0.00385    |\n",
      "|    value_loss         | 1.64        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 298         |\n",
      "|    total_timesteps    | 14909440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014760877 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.747       |\n",
      "|    mean_step_reward   | 0.31335822  |\n",
      "|    n_updates          | 7276        |\n",
      "|    policyGradLoss     | -0.00123    |\n",
      "|    value_loss         | 2.75        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 309         |\n",
      "|    total_timesteps    | 14917632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011106728 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.46        |\n",
      "|    mean_step_reward   | 0.27993482  |\n",
      "|    n_updates          | 7280        |\n",
      "|    policyGradLoss     | -0.00579    |\n",
      "|    value_loss         | 2.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 320         |\n",
      "|    total_timesteps    | 14925824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010529586 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.865       |\n",
      "|    mean_step_reward   | 0.36933276  |\n",
      "|    n_updates          | 7284        |\n",
      "|    policyGradLoss     | -0.0032     |\n",
      "|    value_loss         | 1.9         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 331         |\n",
      "|    total_timesteps    | 14934016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011627956 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.03        |\n",
      "|    mean_step_reward   | 0.3538165   |\n",
      "|    n_updates          | 7288        |\n",
      "|    policyGradLoss     | -0.00198    |\n",
      "|    value_loss         | 3.93        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 342         |\n",
      "|    total_timesteps    | 14942208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014920587 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.183       |\n",
      "|    mean_step_reward   | 0.36398718  |\n",
      "|    n_updates          | 7292        |\n",
      "|    policyGradLoss     | -0.00379    |\n",
      "|    value_loss         | 1.35        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_56.zip\n",
      "[EVAL] Mean Return: 548.582, Best Return: 554.582\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_56_548.58.mp4\n",
      "\n",
      "=== Round 58 | Learn 262144 steps (Total trained: 14942208) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1445     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 14950400 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 977         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 16          |\n",
      "|    total_timesteps    | 14958592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008800048 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.645       |\n",
      "|    mean_step_reward   | 0.3356478   |\n",
      "|    n_updates          | 7300        |\n",
      "|    policyGradLoss     | -0.00221    |\n",
      "|    value_loss         | 2.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 886         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 14966784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008375216 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.79        |\n",
      "|    mean_step_reward   | 0.41732374  |\n",
      "|    n_updates          | 7304        |\n",
      "|    policyGradLoss     | -0.00356    |\n",
      "|    value_loss         | 1.89        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 840         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 14974976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007771257 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.356       |\n",
      "|    mean_step_reward   | 0.30210763  |\n",
      "|    n_updates          | 7308        |\n",
      "|    policyGradLoss     | -0.00441    |\n",
      "|    value_loss         | 2.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 14983168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013508348 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.33        |\n",
      "|    mean_step_reward   | 0.368256    |\n",
      "|    n_updates          | 7312        |\n",
      "|    policyGradLoss     | -0.000872   |\n",
      "|    value_loss         | 3.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 14991360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011514796 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1           |\n",
      "|    mean_step_reward   | 0.38702905  |\n",
      "|    n_updates          | 7316        |\n",
      "|    policyGradLoss     | -0.000548   |\n",
      "|    value_loss         | 2.74        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 791        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 72         |\n",
      "|    total_timesteps    | 14999552   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00795236 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.976      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.385      |\n",
      "|    mean_step_reward   | 0.2842329  |\n",
      "|    n_updates          | 7320       |\n",
      "|    policyGradLoss     | -0.00537   |\n",
      "|    value_loss         | 1.94       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 788          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 83           |\n",
      "|    total_timesteps    | 15007744     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0111651365 |\n",
      "|    entropy_loss       | -1.73        |\n",
      "|    explained_variance | 0.964        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.424        |\n",
      "|    mean_step_reward   | 0.3330623    |\n",
      "|    n_updates          | 7324         |\n",
      "|    policyGradLoss     | -0.000466    |\n",
      "|    value_loss         | 2.52         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 94          |\n",
      "|    total_timesteps    | 15015936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013846293 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.841       |\n",
      "|    mean_step_reward   | 0.26501328  |\n",
      "|    n_updates          | 7328        |\n",
      "|    policyGradLoss     | 0.00081     |\n",
      "|    value_loss         | 2.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 15024128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009765545 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.35        |\n",
      "|    mean_step_reward   | 0.40103114  |\n",
      "|    n_updates          | 7332        |\n",
      "|    policyGradLoss     | -0.00258    |\n",
      "|    value_loss         | 1.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 116         |\n",
      "|    total_timesteps    | 15032320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012725119 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.5         |\n",
      "|    mean_step_reward   | 0.31673074  |\n",
      "|    n_updates          | 7336        |\n",
      "|    policyGradLoss     | -0.000575   |\n",
      "|    value_loss         | 3.94        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 127         |\n",
      "|    total_timesteps    | 15040512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009289093 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.61        |\n",
      "|    mean_step_reward   | 0.33018297  |\n",
      "|    n_updates          | 7340        |\n",
      "|    policyGradLoss     | -0.00736    |\n",
      "|    value_loss         | 1.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 139         |\n",
      "|    total_timesteps    | 15048704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011201477 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.666       |\n",
      "|    mean_step_reward   | 0.34546983  |\n",
      "|    n_updates          | 7344        |\n",
      "|    policyGradLoss     | -0.00618    |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 761        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 150        |\n",
      "|    total_timesteps    | 15056896   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01759287 |\n",
      "|    entropy_loss       | -1.7       |\n",
      "|    explained_variance | 0.958      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.797      |\n",
      "|    mean_step_reward   | 0.35933504 |\n",
      "|    n_updates          | 7348       |\n",
      "|    policyGradLoss     | -0.00436   |\n",
      "|    value_loss         | 2.7        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 161         |\n",
      "|    total_timesteps    | 15065088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014191804 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.902       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.608       |\n",
      "|    mean_step_reward   | 0.3108675   |\n",
      "|    n_updates          | 7352        |\n",
      "|    policyGradLoss     | 0.00347     |\n",
      "|    value_loss         | 4.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 172         |\n",
      "|    total_timesteps    | 15073280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011762229 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.281       |\n",
      "|    mean_step_reward   | 0.3108495   |\n",
      "|    n_updates          | 7356        |\n",
      "|    policyGradLoss     | -0.00327    |\n",
      "|    value_loss         | 1.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 183         |\n",
      "|    total_timesteps    | 15081472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015113924 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.765       |\n",
      "|    mean_step_reward   | 0.3379527   |\n",
      "|    n_updates          | 7360        |\n",
      "|    policyGradLoss     | 0.00391     |\n",
      "|    value_loss         | 3.95        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 194         |\n",
      "|    total_timesteps    | 15089664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011956811 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.502       |\n",
      "|    mean_step_reward   | 0.36273628  |\n",
      "|    n_updates          | 7364        |\n",
      "|    policyGradLoss     | -0.00416    |\n",
      "|    value_loss         | 1.88        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 205         |\n",
      "|    total_timesteps    | 15097856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011753984 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.81        |\n",
      "|    mean_step_reward   | 0.318569    |\n",
      "|    n_updates          | 7368        |\n",
      "|    policyGradLoss     | -0.000727   |\n",
      "|    value_loss         | 4.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 216         |\n",
      "|    total_timesteps    | 15106048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010945978 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.618       |\n",
      "|    mean_step_reward   | 0.3693639   |\n",
      "|    n_updates          | 7372        |\n",
      "|    policyGradLoss     | 0.00268     |\n",
      "|    value_loss         | 2.04        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 227         |\n",
      "|    total_timesteps    | 15114240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008690978 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.732       |\n",
      "|    mean_step_reward   | 0.34923875  |\n",
      "|    n_updates          | 7376        |\n",
      "|    policyGradLoss     | -0.00234    |\n",
      "|    value_loss         | 1.86        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 238         |\n",
      "|    total_timesteps    | 15122432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015917715 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.445       |\n",
      "|    mean_step_reward   | 0.37098205  |\n",
      "|    n_updates          | 7380        |\n",
      "|    policyGradLoss     | -0.00115    |\n",
      "|    value_loss         | 2.98        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 249         |\n",
      "|    total_timesteps    | 15130624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012694185 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.792       |\n",
      "|    mean_step_reward   | 0.33706754  |\n",
      "|    n_updates          | 7384        |\n",
      "|    policyGradLoss     | 0.000848    |\n",
      "|    value_loss         | 4.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 260         |\n",
      "|    total_timesteps    | 15138816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007877449 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.516       |\n",
      "|    mean_step_reward   | 0.34088483  |\n",
      "|    n_updates          | 7388        |\n",
      "|    policyGradLoss     | -0.00528    |\n",
      "|    value_loss         | 1.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 269         |\n",
      "|    total_timesteps    | 15147008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012478361 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.488       |\n",
      "|    mean_step_reward   | 0.3986156   |\n",
      "|    n_updates          | 7392        |\n",
      "|    policyGradLoss     | -0.00113    |\n",
      "|    value_loss         | 1.81        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 277         |\n",
      "|    total_timesteps    | 15155200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011773836 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.562       |\n",
      "|    mean_step_reward   | 0.31754962  |\n",
      "|    n_updates          | 7396        |\n",
      "|    policyGradLoss     | -0.00498    |\n",
      "|    value_loss         | 1.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 287         |\n",
      "|    total_timesteps    | 15163392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011795358 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.296       |\n",
      "|    mean_step_reward   | 0.3726482   |\n",
      "|    n_updates          | 7400        |\n",
      "|    policyGradLoss     | -0.00738    |\n",
      "|    value_loss         | 1.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 15171584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007949096 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.977       |\n",
      "|    mean_step_reward   | 0.37427974  |\n",
      "|    n_updates          | 7404        |\n",
      "|    policyGradLoss     | -0.00451    |\n",
      "|    value_loss         | 2.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 307         |\n",
      "|    total_timesteps    | 15179776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010813738 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.17        |\n",
      "|    mean_step_reward   | 0.41120368  |\n",
      "|    n_updates          | 7408        |\n",
      "|    policyGradLoss     | 0.00277     |\n",
      "|    value_loss         | 4.65        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 773        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 317        |\n",
      "|    total_timesteps    | 15187968   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01123907 |\n",
      "|    entropy_loss       | -1.71      |\n",
      "|    explained_variance | 0.98       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.344      |\n",
      "|    mean_step_reward   | 0.3618342  |\n",
      "|    n_updates          | 7412       |\n",
      "|    policyGradLoss     | -0.00514   |\n",
      "|    value_loss         | 1.89       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 329         |\n",
      "|    total_timesteps    | 15196160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008440449 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.569       |\n",
      "|    mean_step_reward   | 0.3610498   |\n",
      "|    n_updates          | 7416        |\n",
      "|    policyGradLoss     | -0.0034     |\n",
      "|    value_loss         | 2.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 15204352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016222414 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.53        |\n",
      "|    mean_step_reward   | 0.35341308  |\n",
      "|    n_updates          | 7420        |\n",
      "|    policyGradLoss     | 0.00743     |\n",
      "|    value_loss         | 4.37        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_57.zip\n",
      "[EVAL] Mean Return: 508.520, Best Return: 515.186\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_57_508.52.mp4\n",
      "\n",
      "=== Round 59 | Learn 262144 steps (Total trained: 15204352) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1111     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 15212544 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 909         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 15220736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009445814 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.293       |\n",
      "|    mean_step_reward   | 0.42398632  |\n",
      "|    n_updates          | 7428        |\n",
      "|    policyGradLoss     | 0.000183    |\n",
      "|    value_loss         | 1.53        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 831        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 29         |\n",
      "|    total_timesteps    | 15228928   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00994504 |\n",
      "|    entropy_loss       | -1.72      |\n",
      "|    explained_variance | 0.977      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.643      |\n",
      "|    mean_step_reward   | 0.29709494 |\n",
      "|    n_updates          | 7432       |\n",
      "|    policyGradLoss     | -0.000631  |\n",
      "|    value_loss         | 1.59       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 15237120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009568945 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.208       |\n",
      "|    mean_step_reward   | 0.3586248   |\n",
      "|    n_updates          | 7436        |\n",
      "|    policyGradLoss     | -0.00417    |\n",
      "|    value_loss         | 1.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 15245312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011930728 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.563       |\n",
      "|    mean_step_reward   | 0.31221446  |\n",
      "|    n_updates          | 7440        |\n",
      "|    policyGradLoss     | 0.00391     |\n",
      "|    value_loss         | 2.98        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 62          |\n",
      "|    total_timesteps    | 15253504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013823945 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.356       |\n",
      "|    mean_step_reward   | 0.33576334  |\n",
      "|    n_updates          | 7444        |\n",
      "|    policyGradLoss     | -0.00251    |\n",
      "|    value_loss         | 2.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 73          |\n",
      "|    total_timesteps    | 15261696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012530793 |\n",
      "|    entropy_loss       | -1.63       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.387       |\n",
      "|    mean_step_reward   | 0.4222196   |\n",
      "|    n_updates          | 7448        |\n",
      "|    policyGradLoss     | -0.00202    |\n",
      "|    value_loss         | 2.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 15269888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010334365 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.67        |\n",
      "|    mean_step_reward   | 0.38074124  |\n",
      "|    n_updates          | 7452        |\n",
      "|    policyGradLoss     | 0.000683    |\n",
      "|    value_loss         | 3.04        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 96          |\n",
      "|    total_timesteps    | 15278080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012512108 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.653       |\n",
      "|    mean_step_reward   | 0.37303165  |\n",
      "|    n_updates          | 7456        |\n",
      "|    policyGradLoss     | 0.000369    |\n",
      "|    value_loss         | 2.02        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 760        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 107        |\n",
      "|    total_timesteps    | 15286272   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01355236 |\n",
      "|    entropy_loss       | -1.7       |\n",
      "|    explained_variance | 0.966      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.527      |\n",
      "|    mean_step_reward   | 0.32001963 |\n",
      "|    n_updates          | 7460       |\n",
      "|    policyGradLoss     | 0.00168    |\n",
      "|    value_loss         | 2.48       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 118         |\n",
      "|    total_timesteps    | 15294464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009537573 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.648       |\n",
      "|    mean_step_reward   | 0.3504884   |\n",
      "|    n_updates          | 7464        |\n",
      "|    policyGradLoss     | -0.00223    |\n",
      "|    value_loss         | 1.88        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 129         |\n",
      "|    total_timesteps    | 15302656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011404119 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.61        |\n",
      "|    mean_step_reward   | 0.3540973   |\n",
      "|    n_updates          | 7468        |\n",
      "|    policyGradLoss     | 0.000168    |\n",
      "|    value_loss         | 2.75        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 140         |\n",
      "|    total_timesteps    | 15310848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010543836 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.542       |\n",
      "|    mean_step_reward   | 0.34658754  |\n",
      "|    n_updates          | 7472        |\n",
      "|    policyGradLoss     | -0.0049     |\n",
      "|    value_loss         | 2.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 151         |\n",
      "|    total_timesteps    | 15319040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019228978 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.434       |\n",
      "|    mean_step_reward   | 0.35720277  |\n",
      "|    n_updates          | 7476        |\n",
      "|    policyGradLoss     | 0.00887     |\n",
      "|    value_loss         | 4.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 161         |\n",
      "|    total_timesteps    | 15327232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010088304 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.97        |\n",
      "|    mean_step_reward   | 0.34216946  |\n",
      "|    n_updates          | 7480        |\n",
      "|    policyGradLoss     | -0.00153    |\n",
      "|    value_loss         | 2.95        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 171         |\n",
      "|    total_timesteps    | 15335424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009518087 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.456       |\n",
      "|    mean_step_reward   | 0.4164068   |\n",
      "|    n_updates          | 7484        |\n",
      "|    policyGradLoss     | -0.00293    |\n",
      "|    value_loss         | 2.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 15343616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010648378 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.776       |\n",
      "|    mean_step_reward   | 0.3162199   |\n",
      "|    n_updates          | 7488        |\n",
      "|    policyGradLoss     | 7.79e-05    |\n",
      "|    value_loss         | 2.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 15351808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010075995 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.52        |\n",
      "|    mean_step_reward   | 0.38739038  |\n",
      "|    n_updates          | 7492        |\n",
      "|    policyGradLoss     | -0.00219    |\n",
      "|    value_loss         | 2.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 203         |\n",
      "|    total_timesteps    | 15360000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008952873 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.37        |\n",
      "|    mean_step_reward   | 0.36365804  |\n",
      "|    n_updates          | 7496        |\n",
      "|    policyGradLoss     | -0.00567    |\n",
      "|    value_loss         | 2           |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 214         |\n",
      "|    total_timesteps    | 15368192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009258686 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.928       |\n",
      "|    mean_step_reward   | 0.32336086  |\n",
      "|    n_updates          | 7500        |\n",
      "|    policyGradLoss     | 0.00042     |\n",
      "|    value_loss         | 3.93        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 225         |\n",
      "|    total_timesteps    | 15376384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012099638 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.394       |\n",
      "|    mean_step_reward   | 0.37147185  |\n",
      "|    n_updates          | 7504        |\n",
      "|    policyGradLoss     | -0.00126    |\n",
      "|    value_loss         | 2.93        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 235         |\n",
      "|    total_timesteps    | 15384576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012366295 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.463       |\n",
      "|    mean_step_reward   | 0.33475077  |\n",
      "|    n_updates          | 7508        |\n",
      "|    policyGradLoss     | -0.00134    |\n",
      "|    value_loss         | 1.64        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 247         |\n",
      "|    total_timesteps    | 15392768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009940589 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.587       |\n",
      "|    mean_step_reward   | 0.3950422   |\n",
      "|    n_updates          | 7512        |\n",
      "|    policyGradLoss     | -0.00372    |\n",
      "|    value_loss         | 2.3         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 761          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 258          |\n",
      "|    total_timesteps    | 15400960     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0074433475 |\n",
      "|    entropy_loss       | -1.73        |\n",
      "|    explained_variance | 0.978        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.696        |\n",
      "|    mean_step_reward   | 0.37145534   |\n",
      "|    n_updates          | 7516         |\n",
      "|    policyGradLoss     | -0.00262     |\n",
      "|    value_loss         | 2.32         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 269         |\n",
      "|    total_timesteps    | 15409152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009175925 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.321       |\n",
      "|    mean_step_reward   | 0.3564492   |\n",
      "|    n_updates          | 7520        |\n",
      "|    policyGradLoss     | -0.00572    |\n",
      "|    value_loss         | 1.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 280         |\n",
      "|    total_timesteps    | 15417344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012393866 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.707       |\n",
      "|    mean_step_reward   | 0.36776572  |\n",
      "|    n_updates          | 7524        |\n",
      "|    policyGradLoss     | 0.000295    |\n",
      "|    value_loss         | 2.77        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 291         |\n",
      "|    total_timesteps    | 15425536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010029848 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.312       |\n",
      "|    mean_step_reward   | 0.3847309   |\n",
      "|    n_updates          | 7528        |\n",
      "|    policyGradLoss     | -0.00365    |\n",
      "|    value_loss         | 2.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 302         |\n",
      "|    total_timesteps    | 15433728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010791677 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.526       |\n",
      "|    mean_step_reward   | 0.40864116  |\n",
      "|    n_updates          | 7532        |\n",
      "|    policyGradLoss     | -0.00116    |\n",
      "|    value_loss         | 2.9         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 757         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 313         |\n",
      "|    total_timesteps    | 15441920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011731393 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.498       |\n",
      "|    mean_step_reward   | 0.36151505  |\n",
      "|    n_updates          | 7536        |\n",
      "|    policyGradLoss     | -0.00383    |\n",
      "|    value_loss         | 3.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 15450112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010782535 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.673       |\n",
      "|    mean_step_reward   | 0.34834635  |\n",
      "|    n_updates          | 7540        |\n",
      "|    policyGradLoss     | -0.00367    |\n",
      "|    value_loss         | 2.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 15458304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009558525 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.633       |\n",
      "|    mean_step_reward   | 0.36899874  |\n",
      "|    n_updates          | 7544        |\n",
      "|    policyGradLoss     | -0.00485    |\n",
      "|    value_loss         | 2.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 754         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 347         |\n",
      "|    total_timesteps    | 15466496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012403395 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.289       |\n",
      "|    mean_step_reward   | 0.2843032   |\n",
      "|    n_updates          | 7548        |\n",
      "|    policyGradLoss     | 0.00151     |\n",
      "|    value_loss         | 3.18        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_58.zip\n",
      "[EVAL] Mean Return: 40.885, Best Return: 41.552\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_58_40.89.mp4\n",
      "\n",
      "=== Round 60 | Learn 262144 steps (Total trained: 15466496) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1141     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 15474688 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 877        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 15482880   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00992932 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.976      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.329      |\n",
      "|    mean_step_reward   | 0.35201624 |\n",
      "|    n_updates          | 7556       |\n",
      "|    policyGradLoss     | -0.00105   |\n",
      "|    value_loss         | 1.85       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 829          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 29           |\n",
      "|    total_timesteps    | 15491072     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0109540215 |\n",
      "|    entropy_loss       | -1.7         |\n",
      "|    explained_variance | 0.924        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.748        |\n",
      "|    mean_step_reward   | 0.35157362   |\n",
      "|    n_updates          | 7560         |\n",
      "|    policyGradLoss     | -0.0019      |\n",
      "|    value_loss         | 4.89         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 15499264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013696807 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0974      |\n",
      "|    mean_step_reward   | 0.41569424  |\n",
      "|    n_updates          | 7564        |\n",
      "|    policyGradLoss     | -0.00499    |\n",
      "|    value_loss         | 1.15        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 797        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 51         |\n",
      "|    total_timesteps    | 15507456   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01270891 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.943      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.515      |\n",
      "|    mean_step_reward   | 0.3703668  |\n",
      "|    n_updates          | 7568       |\n",
      "|    policyGradLoss     | -0.000533  |\n",
      "|    value_loss         | 4.73       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 15515648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015591258 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.468       |\n",
      "|    mean_step_reward   | 0.32729667  |\n",
      "|    n_updates          | 7572        |\n",
      "|    policyGradLoss     | -0.0012     |\n",
      "|    value_loss         | 1.96        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 830         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 69          |\n",
      "|    total_timesteps    | 15523840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010550765 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.865       |\n",
      "|    mean_step_reward   | 0.36575177  |\n",
      "|    n_updates          | 7576        |\n",
      "|    policyGradLoss     | -0.00411    |\n",
      "|    value_loss         | 2.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 15532032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013353136 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.539       |\n",
      "|    mean_step_reward   | 0.35678697  |\n",
      "|    n_updates          | 7580        |\n",
      "|    policyGradLoss     | -0.00451    |\n",
      "|    value_loss         | 1.98        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 88          |\n",
      "|    total_timesteps    | 15540224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013025644 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.517       |\n",
      "|    mean_step_reward   | 0.36478743  |\n",
      "|    n_updates          | 7584        |\n",
      "|    policyGradLoss     | -0.00162    |\n",
      "|    value_loss         | 3.11        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 827         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 15548416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009966215 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.469       |\n",
      "|    mean_step_reward   | 0.317936    |\n",
      "|    n_updates          | 7588        |\n",
      "|    policyGradLoss     | -0.00442    |\n",
      "|    value_loss         | 1.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 110         |\n",
      "|    total_timesteps    | 15556608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015473358 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.832       |\n",
      "|    mean_step_reward   | 0.42303938  |\n",
      "|    n_updates          | 7592        |\n",
      "|    policyGradLoss     | -0.000676   |\n",
      "|    value_loss         | 4.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 15564800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009911358 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.797       |\n",
      "|    mean_step_reward   | 0.37082255  |\n",
      "|    n_updates          | 7596        |\n",
      "|    policyGradLoss     | -0.000738   |\n",
      "|    value_loss         | 3.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 132         |\n",
      "|    total_timesteps    | 15572992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010408468 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.339       |\n",
      "|    mean_step_reward   | 0.30674613  |\n",
      "|    n_updates          | 7600        |\n",
      "|    policyGradLoss     | -0.00382    |\n",
      "|    value_loss         | 1.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 143         |\n",
      "|    total_timesteps    | 15581184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013862308 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.703       |\n",
      "|    mean_step_reward   | 0.42116344  |\n",
      "|    n_updates          | 7604        |\n",
      "|    policyGradLoss     | -0.000145   |\n",
      "|    value_loss         | 2.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 15589376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009242703 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.43        |\n",
      "|    mean_step_reward   | 0.26805413  |\n",
      "|    n_updates          | 7608        |\n",
      "|    policyGradLoss     | -0.00175    |\n",
      "|    value_loss         | 2.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 15597568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015220234 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.01        |\n",
      "|    mean_step_reward   | 0.3383975   |\n",
      "|    n_updates          | 7612        |\n",
      "|    policyGradLoss     | 0.00545     |\n",
      "|    value_loss         | 4.88        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 791        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 175        |\n",
      "|    total_timesteps    | 15605760   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01685647 |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.893      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.338      |\n",
      "|    mean_step_reward   | 0.2973364  |\n",
      "|    n_updates          | 7616       |\n",
      "|    policyGradLoss     | 0.007      |\n",
      "|    value_loss         | 4.66       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 15613952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011147289 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.561       |\n",
      "|    mean_step_reward   | 0.32967466  |\n",
      "|    n_updates          | 7620        |\n",
      "|    policyGradLoss     | 0.000155    |\n",
      "|    value_loss         | 3.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 197         |\n",
      "|    total_timesteps    | 15622144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008517591 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.57        |\n",
      "|    mean_step_reward   | 0.3420701   |\n",
      "|    n_updates          | 7624        |\n",
      "|    policyGradLoss     | -0.00404    |\n",
      "|    value_loss         | 2.36        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 782        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 209        |\n",
      "|    total_timesteps    | 15630336   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00905671 |\n",
      "|    entropy_loss       | -1.76      |\n",
      "|    explained_variance | 0.973      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.793      |\n",
      "|    mean_step_reward   | 0.3017993  |\n",
      "|    n_updates          | 7628       |\n",
      "|    policyGradLoss     | -0.00558   |\n",
      "|    value_loss         | 1.97       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 15638528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008305328 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.546       |\n",
      "|    mean_step_reward   | 0.3382492   |\n",
      "|    n_updates          | 7632        |\n",
      "|    policyGradLoss     | -0.00588    |\n",
      "|    value_loss         | 1.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 15646720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010510573 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.402       |\n",
      "|    mean_step_reward   | 0.36378178  |\n",
      "|    n_updates          | 7636        |\n",
      "|    policyGradLoss     | -0.00556    |\n",
      "|    value_loss         | 2.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 15654912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009596218 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.246       |\n",
      "|    mean_step_reward   | 0.3209509   |\n",
      "|    n_updates          | 7640        |\n",
      "|    policyGradLoss     | -0.00757    |\n",
      "|    value_loss         | 1.33        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 775        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 253        |\n",
      "|    total_timesteps    | 15663104   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01712279 |\n",
      "|    entropy_loss       | -1.71      |\n",
      "|    explained_variance | 0.955      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.757      |\n",
      "|    mean_step_reward   | 0.34700447 |\n",
      "|    n_updates          | 7644       |\n",
      "|    policyGradLoss     | 0.00164    |\n",
      "|    value_loss         | 2.97       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 15671296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011171534 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.629       |\n",
      "|    mean_step_reward   | 0.37120748  |\n",
      "|    n_updates          | 7648        |\n",
      "|    policyGradLoss     | -0.00648    |\n",
      "|    value_loss         | 1.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 15679488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009291062 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.04        |\n",
      "|    mean_step_reward   | 0.32112885  |\n",
      "|    n_updates          | 7652        |\n",
      "|    policyGradLoss     | -0.00302    |\n",
      "|    value_loss         | 2.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 286         |\n",
      "|    total_timesteps    | 15687680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010946272 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.515       |\n",
      "|    mean_step_reward   | 0.34352845  |\n",
      "|    n_updates          | 7656        |\n",
      "|    policyGradLoss     | -0.00214    |\n",
      "|    value_loss         | 2.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 297         |\n",
      "|    total_timesteps    | 15695872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012225037 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.352       |\n",
      "|    mean_step_reward   | 0.38520592  |\n",
      "|    n_updates          | 7660        |\n",
      "|    policyGradLoss     | -0.00173    |\n",
      "|    value_loss         | 1.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 308         |\n",
      "|    total_timesteps    | 15704064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009764053 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.425       |\n",
      "|    mean_step_reward   | 0.33201677  |\n",
      "|    n_updates          | 7664        |\n",
      "|    policyGradLoss     | -0.00439    |\n",
      "|    value_loss         | 1.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 319         |\n",
      "|    total_timesteps    | 15712256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011977614 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.647       |\n",
      "|    mean_step_reward   | 0.36504924  |\n",
      "|    n_updates          | 7668        |\n",
      "|    policyGradLoss     | -0.00155    |\n",
      "|    value_loss         | 3.86        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 768         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 15720448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017574035 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.907       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.961       |\n",
      "|    mean_step_reward   | 0.35994643  |\n",
      "|    n_updates          | 7672        |\n",
      "|    policyGradLoss     | 0.00518     |\n",
      "|    value_loss         | 4.92        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 340         |\n",
      "|    total_timesteps    | 15728640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009288389 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.232       |\n",
      "|    mean_step_reward   | 0.3325066   |\n",
      "|    n_updates          | 7676        |\n",
      "|    policyGradLoss     | -0.00309    |\n",
      "|    value_loss         | 2.22        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_59.zip\n",
      "[EVAL] Mean Return: 558.763, Best Return: 564.097\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_59_558.76.mp4\n",
      "\n",
      "=== Round 61 | Learn 262144 steps (Total trained: 15728640) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1079     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 15736832 |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 873          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 15745024     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0091503905 |\n",
      "|    entropy_loss       | -1.7         |\n",
      "|    explained_variance | 0.962        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.61         |\n",
      "|    mean_step_reward   | 0.38593906   |\n",
      "|    n_updates          | 7684         |\n",
      "|    policyGradLoss     | 0.000403     |\n",
      "|    value_loss         | 4.37         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 15753216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008396184 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.301       |\n",
      "|    mean_step_reward   | 0.33637697  |\n",
      "|    n_updates          | 7688        |\n",
      "|    policyGradLoss     | -0.00253    |\n",
      "|    value_loss         | 2.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 15761408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010875984 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.879       |\n",
      "|    mean_step_reward   | 0.29547092  |\n",
      "|    n_updates          | 7692        |\n",
      "|    policyGradLoss     | -0.00173    |\n",
      "|    value_loss         | 4.94        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 793        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 51         |\n",
      "|    total_timesteps    | 15769600   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01051589 |\n",
      "|    entropy_loss       | -1.7       |\n",
      "|    explained_variance | 0.976      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.869      |\n",
      "|    mean_step_reward   | 0.38732263 |\n",
      "|    n_updates          | 7696       |\n",
      "|    policyGradLoss     | -0.00301   |\n",
      "|    value_loss         | 2.34       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 781          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 62           |\n",
      "|    total_timesteps    | 15777792     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0090845125 |\n",
      "|    entropy_loss       | -1.69        |\n",
      "|    explained_variance | 0.967        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.503        |\n",
      "|    mean_step_reward   | 0.37884176   |\n",
      "|    n_updates          | 7700         |\n",
      "|    policyGradLoss     | -0.00207     |\n",
      "|    value_loss         | 2.82         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 73          |\n",
      "|    total_timesteps    | 15785984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010484964 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.567       |\n",
      "|    mean_step_reward   | 0.411438    |\n",
      "|    n_updates          | 7704        |\n",
      "|    policyGradLoss     | -0.0035     |\n",
      "|    value_loss         | 2.71        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 15794176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007865586 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.579       |\n",
      "|    mean_step_reward   | 0.38408256  |\n",
      "|    n_updates          | 7708        |\n",
      "|    policyGradLoss     | -0.00618    |\n",
      "|    value_loss         | 1.89        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 95          |\n",
      "|    total_timesteps    | 15802368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012640914 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.806       |\n",
      "|    mean_step_reward   | 0.33808768  |\n",
      "|    n_updates          | 7712        |\n",
      "|    policyGradLoss     | 0.00147     |\n",
      "|    value_loss         | 5.58        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 764       |\n",
      "|    iterations         | 10        |\n",
      "|    time_elapsed       | 107       |\n",
      "|    total_timesteps    | 15810560  |\n",
      "| train/                |           |\n",
      "|    approx_kl          | 0.0140872 |\n",
      "|    entropy_loss       | -1.68     |\n",
      "|    explained_variance | 0.922     |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    loss               | 0.805     |\n",
      "|    mean_step_reward   | 0.3516265 |\n",
      "|    n_updates          | 7716      |\n",
      "|    policyGradLoss     | 0.000168  |\n",
      "|    value_loss         | 3.12      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 117         |\n",
      "|    total_timesteps    | 15818752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009644328 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.503       |\n",
      "|    mean_step_reward   | 0.3413189   |\n",
      "|    n_updates          | 7720        |\n",
      "|    policyGradLoss     | -0.00553    |\n",
      "|    value_loss         | 1.85        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 128         |\n",
      "|    total_timesteps    | 15826944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009327458 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.02        |\n",
      "|    mean_step_reward   | 0.39691535  |\n",
      "|    n_updates          | 7724        |\n",
      "|    policyGradLoss     | -0.00756    |\n",
      "|    value_loss         | 1.55        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 139         |\n",
      "|    total_timesteps    | 15835136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010177961 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.47        |\n",
      "|    mean_step_reward   | 0.36927772  |\n",
      "|    n_updates          | 7728        |\n",
      "|    policyGradLoss     | -0.00478    |\n",
      "|    value_loss         | 1.96        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 151         |\n",
      "|    total_timesteps    | 15843328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011087156 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.58        |\n",
      "|    mean_step_reward   | 0.3827505   |\n",
      "|    n_updates          | 7732        |\n",
      "|    policyGradLoss     | -0.00107    |\n",
      "|    value_loss         | 3.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 162         |\n",
      "|    total_timesteps    | 15851520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010383738 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.971       |\n",
      "|    mean_step_reward   | 0.29338035  |\n",
      "|    n_updates          | 7736        |\n",
      "|    policyGradLoss     | -0.00382    |\n",
      "|    value_loss         | 2.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 172         |\n",
      "|    total_timesteps    | 15859712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011541573 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.47        |\n",
      "|    mean_step_reward   | 0.35682118  |\n",
      "|    n_updates          | 7740        |\n",
      "|    policyGradLoss     | -0.00302    |\n",
      "|    value_loss         | 4.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 183         |\n",
      "|    total_timesteps    | 15867904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011371571 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.866       |\n",
      "|    mean_step_reward   | 0.32646775  |\n",
      "|    n_updates          | 7744        |\n",
      "|    policyGradLoss     | -0.00129    |\n",
      "|    value_loss         | 2.92        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 756         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 194         |\n",
      "|    total_timesteps    | 15876096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018664056 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.903       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.843       |\n",
      "|    mean_step_reward   | 0.2891593   |\n",
      "|    n_updates          | 7748        |\n",
      "|    policyGradLoss     | 0.00441     |\n",
      "|    value_loss         | 3.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 755         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 205         |\n",
      "|    total_timesteps    | 15884288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016280508 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.889       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.709       |\n",
      "|    mean_step_reward   | 0.31132373  |\n",
      "|    n_updates          | 7752        |\n",
      "|    policyGradLoss     | 0.00558     |\n",
      "|    value_loss         | 5.89        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 217         |\n",
      "|    total_timesteps    | 15892480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013289139 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.273       |\n",
      "|    mean_step_reward   | 0.3597668   |\n",
      "|    n_updates          | 7756        |\n",
      "|    policyGradLoss     | 0.0035      |\n",
      "|    value_loss         | 2.24        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 753          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 228          |\n",
      "|    total_timesteps    | 15900672     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0134537015 |\n",
      "|    entropy_loss       | -1.7         |\n",
      "|    explained_variance | 0.969        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.364        |\n",
      "|    mean_step_reward   | 0.33980197   |\n",
      "|    n_updates          | 7760         |\n",
      "|    policyGradLoss     | 0.00324      |\n",
      "|    value_loss         | 2.05         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 237         |\n",
      "|    total_timesteps    | 15908864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014739526 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.893       |\n",
      "|    mean_step_reward   | 0.4201053   |\n",
      "|    n_updates          | 7764        |\n",
      "|    policyGradLoss     | 0.00332     |\n",
      "|    value_loss         | 4.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 246         |\n",
      "|    total_timesteps    | 15917056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007984729 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.676       |\n",
      "|    mean_step_reward   | 0.34968758  |\n",
      "|    n_updates          | 7768        |\n",
      "|    policyGradLoss     | -0.0017     |\n",
      "|    value_loss         | 1.96        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 766         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 256         |\n",
      "|    total_timesteps    | 15925248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010225393 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.718       |\n",
      "|    mean_step_reward   | 0.4008093   |\n",
      "|    n_updates          | 7772        |\n",
      "|    policyGradLoss     | 0.00187     |\n",
      "|    value_loss         | 2.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 267         |\n",
      "|    total_timesteps    | 15933440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007295044 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.801       |\n",
      "|    mean_step_reward   | 0.33905572  |\n",
      "|    n_updates          | 7776        |\n",
      "|    policyGradLoss     | -0.00108    |\n",
      "|    value_loss         | 2.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 278         |\n",
      "|    total_timesteps    | 15941632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009779336 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.98        |\n",
      "|    mean_step_reward   | 0.37242994  |\n",
      "|    n_updates          | 7780        |\n",
      "|    policyGradLoss     | -0.00407    |\n",
      "|    value_loss         | 3.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 764         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 289         |\n",
      "|    total_timesteps    | 15949824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008780645 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.939       |\n",
      "|    mean_step_reward   | 0.36855605  |\n",
      "|    n_updates          | 7784        |\n",
      "|    policyGradLoss     | -0.00229    |\n",
      "|    value_loss         | 2.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 300         |\n",
      "|    total_timesteps    | 15958016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010676314 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.538       |\n",
      "|    mean_step_reward   | 0.3920927   |\n",
      "|    n_updates          | 7788        |\n",
      "|    policyGradLoss     | -0.00238    |\n",
      "|    value_loss         | 2.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 311         |\n",
      "|    total_timesteps    | 15966208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009937525 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.509       |\n",
      "|    mean_step_reward   | 0.38271928  |\n",
      "|    n_updates          | 7792        |\n",
      "|    policyGradLoss     | -0.00582    |\n",
      "|    value_loss         | 1.43        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 322         |\n",
      "|    total_timesteps    | 15974400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013342336 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.245       |\n",
      "|    mean_step_reward   | 0.36051375  |\n",
      "|    n_updates          | 7796        |\n",
      "|    policyGradLoss     | -0.00862    |\n",
      "|    value_loss         | 0.988       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 15982592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013386637 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.26        |\n",
      "|    mean_step_reward   | 0.34945986  |\n",
      "|    n_updates          | 7800        |\n",
      "|    policyGradLoss     | 0.000287    |\n",
      "|    value_loss         | 3.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 345         |\n",
      "|    total_timesteps    | 15990784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012490954 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.293       |\n",
      "|    mean_step_reward   | 0.26621667  |\n",
      "|    n_updates          | 7804        |\n",
      "|    policyGradLoss     | 0.00455     |\n",
      "|    value_loss         | 1.84        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_60.zip\n",
      "[EVAL] Mean Return: 73.438, Best Return: 73.438\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_60_73.44.mp4\n",
      "\n",
      "=== Round 62 | Learn 262144 steps (Total trained: 15990784) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1272     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 15998976 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 921         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 16007168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008927664 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.44        |\n",
      "|    mean_step_reward   | 0.2923189   |\n",
      "|    n_updates          | 7812        |\n",
      "|    policyGradLoss     | 0.0018      |\n",
      "|    value_loss         | 2.5         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 851         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 16015360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013146695 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.724       |\n",
      "|    mean_step_reward   | 0.35298502  |\n",
      "|    n_updates          | 7816        |\n",
      "|    policyGradLoss     | -0.00427    |\n",
      "|    value_loss         | 1.92        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 843         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 16023552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013818276 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.582       |\n",
      "|    mean_step_reward   | 0.37850553  |\n",
      "|    n_updates          | 7820        |\n",
      "|    policyGradLoss     | -0.00353    |\n",
      "|    value_loss         | 1.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 16031744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010960987 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.06        |\n",
      "|    mean_step_reward   | 0.276439    |\n",
      "|    n_updates          | 7824        |\n",
      "|    policyGradLoss     | -0.00146    |\n",
      "|    value_loss         | 2.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 16039936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017071811 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.308       |\n",
      "|    mean_step_reward   | 0.34914976  |\n",
      "|    n_updates          | 7828        |\n",
      "|    policyGradLoss     | -0.00347    |\n",
      "|    value_loss         | 1.86        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 69          |\n",
      "|    total_timesteps    | 16048128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013550989 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.697       |\n",
      "|    mean_step_reward   | 0.29844588  |\n",
      "|    n_updates          | 7832        |\n",
      "|    policyGradLoss     | -0.00711    |\n",
      "|    value_loss         | 1.23        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 831        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 78         |\n",
      "|    total_timesteps    | 16056320   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01715555 |\n",
      "|    entropy_loss       | -1.68      |\n",
      "|    explained_variance | 0.956      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.878      |\n",
      "|    mean_step_reward   | 0.37107152 |\n",
      "|    n_updates          | 7836       |\n",
      "|    policyGradLoss     | -0.000757  |\n",
      "|    value_loss         | 2.32       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 88          |\n",
      "|    total_timesteps    | 16064512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011665287 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.752       |\n",
      "|    mean_step_reward   | 0.4310797   |\n",
      "|    n_updates          | 7840        |\n",
      "|    policyGradLoss     | -0.00697    |\n",
      "|    value_loss         | 1.19        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 831        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 98         |\n",
      "|    total_timesteps    | 16072704   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01097665 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.982      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 1.18       |\n",
      "|    mean_step_reward   | 0.31680194 |\n",
      "|    n_updates          | 7844       |\n",
      "|    policyGradLoss     | -0.00395   |\n",
      "|    value_loss         | 1.9        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 16080896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010598831 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.566       |\n",
      "|    mean_step_reward   | 0.38810694  |\n",
      "|    n_updates          | 7848        |\n",
      "|    policyGradLoss     | -0.00276    |\n",
      "|    value_loss         | 2.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 16089088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011137303 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.233       |\n",
      "|    mean_step_reward   | 0.41052794  |\n",
      "|    n_updates          | 7852        |\n",
      "|    policyGradLoss     | -0.00465    |\n",
      "|    value_loss         | 2.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 131         |\n",
      "|    total_timesteps    | 16097280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011174215 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.452       |\n",
      "|    mean_step_reward   | 0.35996187  |\n",
      "|    n_updates          | 7856        |\n",
      "|    policyGradLoss     | -0.00333    |\n",
      "|    value_loss         | 1.98        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 16105472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012262059 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.54        |\n",
      "|    mean_step_reward   | 0.383655    |\n",
      "|    n_updates          | 7860        |\n",
      "|    policyGradLoss     | -0.00627    |\n",
      "|    value_loss         | 1.75        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 152         |\n",
      "|    total_timesteps    | 16113664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009248239 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.659       |\n",
      "|    mean_step_reward   | 0.4157776   |\n",
      "|    n_updates          | 7864        |\n",
      "|    policyGradLoss     | -0.00332    |\n",
      "|    value_loss         | 1.99        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 163         |\n",
      "|    total_timesteps    | 16121856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008749891 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.95        |\n",
      "|    mean_step_reward   | 0.363593    |\n",
      "|    n_updates          | 7868        |\n",
      "|    policyGradLoss     | -0.00493    |\n",
      "|    value_loss         | 1.94        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 798          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 174          |\n",
      "|    total_timesteps    | 16130048     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0116275195 |\n",
      "|    entropy_loss       | -1.65        |\n",
      "|    explained_variance | 0.974        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.935        |\n",
      "|    mean_step_reward   | 0.4035534    |\n",
      "|    n_updates          | 7872         |\n",
      "|    policyGradLoss     | -0.00232     |\n",
      "|    value_loss         | 3.04         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 794          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 185          |\n",
      "|    total_timesteps    | 16138240     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0090601435 |\n",
      "|    entropy_loss       | -1.69        |\n",
      "|    explained_variance | 0.972        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.549        |\n",
      "|    mean_step_reward   | 0.38009018   |\n",
      "|    n_updates          | 7876         |\n",
      "|    policyGradLoss     | -0.00234     |\n",
      "|    value_loss         | 2.16         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 197         |\n",
      "|    total_timesteps    | 16146432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009452006 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.473       |\n",
      "|    mean_step_reward   | 0.37002292  |\n",
      "|    n_updates          | 7880        |\n",
      "|    policyGradLoss     | -0.00533    |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 787          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 207          |\n",
      "|    total_timesteps    | 16154624     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0097852135 |\n",
      "|    entropy_loss       | -1.69        |\n",
      "|    explained_variance | 0.962        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.509        |\n",
      "|    mean_step_reward   | 0.3605762    |\n",
      "|    n_updates          | 7884         |\n",
      "|    policyGradLoss     | 0.000873     |\n",
      "|    value_loss         | 2.64         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 784          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 219          |\n",
      "|    total_timesteps    | 16162816     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0116466675 |\n",
      "|    entropy_loss       | -1.73        |\n",
      "|    explained_variance | 0.968        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.334        |\n",
      "|    mean_step_reward   | 0.38338387   |\n",
      "|    n_updates          | 7888         |\n",
      "|    policyGradLoss     | -0.00424     |\n",
      "|    value_loss         | 2.76         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 16171008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012546787 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.292       |\n",
      "|    mean_step_reward   | 0.33970657  |\n",
      "|    n_updates          | 7892        |\n",
      "|    policyGradLoss     | -0.00484    |\n",
      "|    value_loss         | 1.88        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 16179200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015996857 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.535       |\n",
      "|    mean_step_reward   | 0.33852005  |\n",
      "|    n_updates          | 7896        |\n",
      "|    policyGradLoss     | -0.00169    |\n",
      "|    value_loss         | 2.5         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 16187392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013960352 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.915       |\n",
      "|    mean_step_reward   | 0.40311164  |\n",
      "|    n_updates          | 7900        |\n",
      "|    policyGradLoss     | 0.00554     |\n",
      "|    value_loss         | 3.45        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 16195584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009949606 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.07        |\n",
      "|    mean_step_reward   | 0.41244084  |\n",
      "|    n_updates          | 7904        |\n",
      "|    policyGradLoss     | -0.00234    |\n",
      "|    value_loss         | 2.53        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 16203776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012119776 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.738       |\n",
      "|    mean_step_reward   | 0.40852118  |\n",
      "|    n_updates          | 7908        |\n",
      "|    policyGradLoss     | -0.00602    |\n",
      "|    value_loss         | 2.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 16211968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010601339 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.909       |\n",
      "|    mean_step_reward   | 0.3073104   |\n",
      "|    n_updates          | 7912        |\n",
      "|    policyGradLoss     | -0.00618    |\n",
      "|    value_loss         | 2.11        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 16220160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012688693 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.33        |\n",
      "|    mean_step_reward   | 0.32174408  |\n",
      "|    n_updates          | 7916        |\n",
      "|    policyGradLoss     | 0.00136     |\n",
      "|    value_loss         | 4.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 307         |\n",
      "|    total_timesteps    | 16228352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009743665 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.586       |\n",
      "|    mean_step_reward   | 0.34702966  |\n",
      "|    n_updates          | 7920        |\n",
      "|    policyGradLoss     | -0.00177    |\n",
      "|    value_loss         | 2.04        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 16236544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012375735 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.789       |\n",
      "|    mean_step_reward   | 0.40524226  |\n",
      "|    n_updates          | 7924        |\n",
      "|    policyGradLoss     | -7.93e-05   |\n",
      "|    value_loss         | 4.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 329         |\n",
      "|    total_timesteps    | 16244736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009438936 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.215       |\n",
      "|    mean_step_reward   | 0.38577244  |\n",
      "|    n_updates          | 7928        |\n",
      "|    policyGradLoss     | -0.00514    |\n",
      "|    value_loss         | 2.64        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 340         |\n",
      "|    total_timesteps    | 16252928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011060345 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.62        |\n",
      "|    mean_step_reward   | 0.3954357   |\n",
      "|    n_updates          | 7932        |\n",
      "|    policyGradLoss     | -0.00681    |\n",
      "|    value_loss         | 1.64        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_61.zip\n",
      "[EVAL] Mean Return: 95.840, Best Return: 96.507\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_61_95.84.mp4\n",
      "\n",
      "=== Round 63 | Learn 262144 steps (Total trained: 16252928) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1097     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 16261120 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 947         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 16269312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010022578 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.716       |\n",
      "|    mean_step_reward   | 0.3390557   |\n",
      "|    n_updates          | 7940        |\n",
      "|    policyGradLoss     | -0.00504    |\n",
      "|    value_loss         | 2.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 864         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 16277504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014376765 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.249       |\n",
      "|    mean_step_reward   | 0.44601053  |\n",
      "|    n_updates          | 7944        |\n",
      "|    policyGradLoss     | -0.00154    |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 16285696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010771099 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.754       |\n",
      "|    mean_step_reward   | 0.36242408  |\n",
      "|    n_updates          | 7948        |\n",
      "|    policyGradLoss     | -0.00215    |\n",
      "|    value_loss         | 2.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 16293888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013492869 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.742       |\n",
      "|    mean_step_reward   | 0.41243362  |\n",
      "|    n_updates          | 7952        |\n",
      "|    policyGradLoss     | 0.00182     |\n",
      "|    value_loss         | 2.81        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 62          |\n",
      "|    total_timesteps    | 16302080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014013146 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.326       |\n",
      "|    mean_step_reward   | 0.31301686  |\n",
      "|    n_updates          | 7956        |\n",
      "|    policyGradLoss     | -0.00316    |\n",
      "|    value_loss         | 1.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 16310272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011667141 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.418       |\n",
      "|    mean_step_reward   | 0.45199442  |\n",
      "|    n_updates          | 7960        |\n",
      "|    policyGradLoss     | -0.000215   |\n",
      "|    value_loss         | 1.59        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 16318464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010568241 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.626       |\n",
      "|    mean_step_reward   | 0.37600505  |\n",
      "|    n_updates          | 7964        |\n",
      "|    policyGradLoss     | -0.00676    |\n",
      "|    value_loss         | 1.34        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 16326656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010835466 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.22        |\n",
      "|    mean_step_reward   | 0.3335004   |\n",
      "|    n_updates          | 7968        |\n",
      "|    policyGradLoss     | 0.0101      |\n",
      "|    value_loss         | 3.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 16334848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013800731 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.731       |\n",
      "|    mean_step_reward   | 0.39214447  |\n",
      "|    n_updates          | 7972        |\n",
      "|    policyGradLoss     | 0.00199     |\n",
      "|    value_loss         | 4.74        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 16343040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013239687 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.24        |\n",
      "|    mean_step_reward   | 0.29149053  |\n",
      "|    n_updates          | 7976        |\n",
      "|    policyGradLoss     | -0.00298    |\n",
      "|    value_loss         | 2.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 126         |\n",
      "|    total_timesteps    | 16351232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014416686 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.3         |\n",
      "|    mean_step_reward   | 0.40280598  |\n",
      "|    n_updates          | 7980        |\n",
      "|    policyGradLoss     | -0.00217    |\n",
      "|    value_loss         | 1.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 137         |\n",
      "|    total_timesteps    | 16359424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008760204 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.407       |\n",
      "|    mean_step_reward   | 0.33035785  |\n",
      "|    n_updates          | 7984        |\n",
      "|    policyGradLoss     | -0.00302    |\n",
      "|    value_loss         | 2.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 16367616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011638185 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.488       |\n",
      "|    mean_step_reward   | 0.4427238   |\n",
      "|    n_updates          | 7988        |\n",
      "|    policyGradLoss     | -0.0031     |\n",
      "|    value_loss         | 2.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 159         |\n",
      "|    total_timesteps    | 16375808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011654569 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.816       |\n",
      "|    mean_step_reward   | 0.30475077  |\n",
      "|    n_updates          | 7992        |\n",
      "|    policyGradLoss     | -0.00316    |\n",
      "|    value_loss         | 1.65        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 16384000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011174076 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.523       |\n",
      "|    mean_step_reward   | 0.3617422   |\n",
      "|    n_updates          | 7996        |\n",
      "|    policyGradLoss     | -0.00662    |\n",
      "|    value_loss         | 1.65        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 767          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 181          |\n",
      "|    total_timesteps    | 16392192     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0149959475 |\n",
      "|    entropy_loss       | -1.74        |\n",
      "|    explained_variance | 0.944        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 1.05         |\n",
      "|    mean_step_reward   | 0.37891513   |\n",
      "|    n_updates          | 8000         |\n",
      "|    policyGradLoss     | -1.09e-05    |\n",
      "|    value_loss         | 4.13         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 16400384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010959117 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.407       |\n",
      "|    mean_step_reward   | 0.3146009   |\n",
      "|    n_updates          | 8004        |\n",
      "|    policyGradLoss     | 0.000525    |\n",
      "|    value_loss         | 1.61        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 16408576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015753366 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.898       |\n",
      "|    mean_step_reward   | 0.4028936   |\n",
      "|    n_updates          | 8008        |\n",
      "|    policyGradLoss     | 0.00401     |\n",
      "|    value_loss         | 2.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 16416768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009877339 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.321       |\n",
      "|    mean_step_reward   | 0.3310011   |\n",
      "|    n_updates          | 8012        |\n",
      "|    policyGradLoss     | -0.00528    |\n",
      "|    value_loss         | 1.8         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 218         |\n",
      "|    total_timesteps    | 16424960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014794897 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.588       |\n",
      "|    mean_step_reward   | 0.3039948   |\n",
      "|    n_updates          | 8016        |\n",
      "|    policyGradLoss     | -0.003      |\n",
      "|    value_loss         | 3.31        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 783        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 229        |\n",
      "|    total_timesteps    | 16433152   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00949149 |\n",
      "|    entropy_loss       | -1.67      |\n",
      "|    explained_variance | 0.98       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.319      |\n",
      "|    mean_step_reward   | 0.35383764 |\n",
      "|    n_updates          | 8020       |\n",
      "|    policyGradLoss     | -0.00672   |\n",
      "|    value_loss         | 1.33       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 16441344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011385132 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.633       |\n",
      "|    mean_step_reward   | 0.3683405   |\n",
      "|    n_updates          | 8024        |\n",
      "|    policyGradLoss     | -0.0051     |\n",
      "|    value_loss         | 1.93        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 252        |\n",
      "|    total_timesteps    | 16449536   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00962819 |\n",
      "|    entropy_loss       | -1.71      |\n",
      "|    explained_variance | 0.978      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.826      |\n",
      "|    mean_step_reward   | 0.33861285 |\n",
      "|    n_updates          | 8028       |\n",
      "|    policyGradLoss     | -0.0052    |\n",
      "|    value_loss         | 1.74       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 16457728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008425925 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.769       |\n",
      "|    mean_step_reward   | 0.4294029   |\n",
      "|    n_updates          | 8032        |\n",
      "|    policyGradLoss     | -0.00336    |\n",
      "|    value_loss         | 1.78        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 777          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 274          |\n",
      "|    total_timesteps    | 16465920     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0109188445 |\n",
      "|    entropy_loss       | -1.75        |\n",
      "|    explained_variance | 0.959        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 2.24         |\n",
      "|    mean_step_reward   | 0.35894197   |\n",
      "|    n_updates          | 8036         |\n",
      "|    policyGradLoss     | -0.000283    |\n",
      "|    value_loss         | 3.6          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 16474112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016193483 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.894       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.533       |\n",
      "|    mean_step_reward   | 0.3635846   |\n",
      "|    n_updates          | 8040        |\n",
      "|    policyGradLoss     | 0.0113      |\n",
      "|    value_loss         | 4.58        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 774          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 296          |\n",
      "|    total_timesteps    | 16482304     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0129270945 |\n",
      "|    entropy_loss       | -1.68        |\n",
      "|    explained_variance | 0.979        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.661        |\n",
      "|    mean_step_reward   | 0.4376011    |\n",
      "|    n_updates          | 8044         |\n",
      "|    policyGradLoss     | -0.00354     |\n",
      "|    value_loss         | 1.89         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 772          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 307          |\n",
      "|    total_timesteps    | 16490496     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0077986745 |\n",
      "|    entropy_loss       | -1.76        |\n",
      "|    explained_variance | 0.977        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.66         |\n",
      "|    mean_step_reward   | 0.3375318    |\n",
      "|    n_updates          | 8048         |\n",
      "|    policyGradLoss     | -0.00478     |\n",
      "|    value_loss         | 2.37         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 16498688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015809812 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.469       |\n",
      "|    mean_step_reward   | 0.3465641   |\n",
      "|    n_updates          | 8052        |\n",
      "|    policyGradLoss     | -0.0075     |\n",
      "|    value_loss         | 1.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 329         |\n",
      "|    total_timesteps    | 16506880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011625698 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.316       |\n",
      "|    mean_step_reward   | 0.3721205   |\n",
      "|    n_updates          | 8056        |\n",
      "|    policyGradLoss     | -0.0048     |\n",
      "|    value_loss         | 1.87        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 340         |\n",
      "|    total_timesteps    | 16515072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011337635 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.841       |\n",
      "|    mean_step_reward   | 0.37764174  |\n",
      "|    n_updates          | 8060        |\n",
      "|    policyGradLoss     | -0.00177    |\n",
      "|    value_loss         | 2.46        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_62.zip\n",
      "[EVAL] Mean Return: 49.019, Best Return: 49.686\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_62_49.02.mp4\n",
      "\n",
      "=== Round 64 | Learn 262144 steps (Total trained: 16515072) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1105     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 16523264 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 903         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 16531456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011155065 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.372       |\n",
      "|    mean_step_reward   | 0.42140394  |\n",
      "|    n_updates          | 8068        |\n",
      "|    policyGradLoss     | -0.00542    |\n",
      "|    value_loss         | 1.74        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 827         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 16539648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010413304 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.43        |\n",
      "|    mean_step_reward   | 0.3561759   |\n",
      "|    n_updates          | 8072        |\n",
      "|    policyGradLoss     | -0.00859    |\n",
      "|    value_loss         | 1.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 832         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 16547840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015189804 |\n",
      "|    entropy_loss       | -1.64       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.228       |\n",
      "|    mean_step_reward   | 0.4343801   |\n",
      "|    n_updates          | 8076        |\n",
      "|    policyGradLoss     | -0.00638    |\n",
      "|    value_loss         | 1.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 16556032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013680715 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.383       |\n",
      "|    mean_step_reward   | 0.3227182   |\n",
      "|    n_updates          | 8080        |\n",
      "|    policyGradLoss     | 0.000755    |\n",
      "|    value_loss         | 2.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 16564224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011745045 |\n",
      "|    entropy_loss       | -1.66       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.636       |\n",
      "|    mean_step_reward   | 0.39421952  |\n",
      "|    n_updates          | 8084        |\n",
      "|    policyGradLoss     | -0.00174    |\n",
      "|    value_loss         | 2.53        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 16572416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013520799 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.525       |\n",
      "|    mean_step_reward   | 0.34727854  |\n",
      "|    n_updates          | 8088        |\n",
      "|    policyGradLoss     | -4.58e-05   |\n",
      "|    value_loss         | 1.96        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 16580608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011811441 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.388       |\n",
      "|    mean_step_reward   | 0.34279844  |\n",
      "|    n_updates          | 8092        |\n",
      "|    policyGradLoss     | -0.000695   |\n",
      "|    value_loss         | 2.04        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 94          |\n",
      "|    total_timesteps    | 16588800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014525075 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.849       |\n",
      "|    mean_step_reward   | 0.4310521   |\n",
      "|    n_updates          | 8096        |\n",
      "|    policyGradLoss     | 0.006       |\n",
      "|    value_loss         | 6.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 16596992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009748979 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.636       |\n",
      "|    mean_step_reward   | 0.3606771   |\n",
      "|    n_updates          | 8100        |\n",
      "|    policyGradLoss     | -0.00414    |\n",
      "|    value_loss         | 2.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 16605184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012548594 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.737       |\n",
      "|    mean_step_reward   | 0.3340628   |\n",
      "|    n_updates          | 8104        |\n",
      "|    policyGradLoss     | -0.00148    |\n",
      "|    value_loss         | 2.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 16613376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013572857 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.339       |\n",
      "|    mean_step_reward   | 0.32034737  |\n",
      "|    n_updates          | 8108        |\n",
      "|    policyGradLoss     | -0.00904    |\n",
      "|    value_loss         | 1.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 16621568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014094019 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.138       |\n",
      "|    mean_step_reward   | 0.2731855   |\n",
      "|    n_updates          | 8112        |\n",
      "|    policyGradLoss     | -0.005      |\n",
      "|    value_loss         | 1.47        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 783          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 146          |\n",
      "|    total_timesteps    | 16629760     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0151657285 |\n",
      "|    entropy_loss       | -1.73        |\n",
      "|    explained_variance | 0.923        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.57         |\n",
      "|    mean_step_reward   | 0.39163643   |\n",
      "|    n_updates          | 8116         |\n",
      "|    policyGradLoss     | 0.00542      |\n",
      "|    value_loss         | 7.73         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 781        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 157        |\n",
      "|    total_timesteps    | 16637952   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01416165 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.92       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.566      |\n",
      "|    mean_step_reward   | 0.24484222 |\n",
      "|    n_updates          | 8120       |\n",
      "|    policyGradLoss     | 0.00426    |\n",
      "|    value_loss         | 2.13       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 16646144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018204505 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.916       |\n",
      "|    mean_step_reward   | 0.38247675  |\n",
      "|    n_updates          | 8124        |\n",
      "|    policyGradLoss     | 0.00787     |\n",
      "|    value_loss         | 4.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 16654336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014023582 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.529       |\n",
      "|    mean_step_reward   | 0.30861694  |\n",
      "|    n_updates          | 8128        |\n",
      "|    policyGradLoss     | -0.00433    |\n",
      "|    value_loss         | 1.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 16662528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011731588 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.79        |\n",
      "|    mean_step_reward   | 0.35325694  |\n",
      "|    n_updates          | 8132        |\n",
      "|    policyGradLoss     | -0.0047     |\n",
      "|    value_loss         | 2.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 16670720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009729808 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.364       |\n",
      "|    mean_step_reward   | 0.43981344  |\n",
      "|    n_updates          | 8136        |\n",
      "|    policyGradLoss     | -0.00526    |\n",
      "|    value_loss         | 1.88        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 770         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 212         |\n",
      "|    total_timesteps    | 16678912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007536593 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.899       |\n",
      "|    mean_step_reward   | 0.3787325   |\n",
      "|    n_updates          | 8140        |\n",
      "|    policyGradLoss     | -0.00539    |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 224         |\n",
      "|    total_timesteps    | 16687104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009208977 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1           |\n",
      "|    mean_step_reward   | 0.406736    |\n",
      "|    n_updates          | 8144        |\n",
      "|    policyGradLoss     | -0.00571    |\n",
      "|    value_loss         | 2.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 765         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 235         |\n",
      "|    total_timesteps    | 16695296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007457896 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.898       |\n",
      "|    mean_step_reward   | 0.3935299   |\n",
      "|    n_updates          | 8148        |\n",
      "|    policyGradLoss     | -0.00389    |\n",
      "|    value_loss         | 2.46        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 246         |\n",
      "|    total_timesteps    | 16703488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008477556 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.585       |\n",
      "|    mean_step_reward   | 0.33026472  |\n",
      "|    n_updates          | 8152        |\n",
      "|    policyGradLoss     | -0.00649    |\n",
      "|    value_loss         | 2.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 257         |\n",
      "|    total_timesteps    | 16711680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011310177 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.468       |\n",
      "|    mean_step_reward   | 0.4010917   |\n",
      "|    n_updates          | 8156        |\n",
      "|    policyGradLoss     | 0.000173    |\n",
      "|    value_loss         | 2.86        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 763         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 268         |\n",
      "|    total_timesteps    | 16719872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008596646 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.876       |\n",
      "|    mean_step_reward   | 0.3164003   |\n",
      "|    n_updates          | 8160        |\n",
      "|    policyGradLoss     | -0.00166    |\n",
      "|    value_loss         | 2.56        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 762         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 279         |\n",
      "|    total_timesteps    | 16728064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014389174 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.397       |\n",
      "|    mean_step_reward   | 0.3098831   |\n",
      "|    n_updates          | 8164        |\n",
      "|    policyGradLoss     | 0.000644    |\n",
      "|    value_loss         | 1.84        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 761         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 290         |\n",
      "|    total_timesteps    | 16736256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010423013 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.467       |\n",
      "|    mean_step_reward   | 0.27691424  |\n",
      "|    n_updates          | 8168        |\n",
      "|    policyGradLoss     | -0.00411    |\n",
      "|    value_loss         | 1.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 301         |\n",
      "|    total_timesteps    | 16744448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009248663 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.799       |\n",
      "|    mean_step_reward   | 0.3006941   |\n",
      "|    n_updates          | 8172        |\n",
      "|    policyGradLoss     | -0.00591    |\n",
      "|    value_loss         | 2.12        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 760        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 312        |\n",
      "|    total_timesteps    | 16752640   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00970855 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.374      |\n",
      "|    mean_step_reward   | 0.3669746  |\n",
      "|    n_updates          | 8176       |\n",
      "|    policyGradLoss     | -0.00452   |\n",
      "|    value_loss         | 1.56       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 759          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 323          |\n",
      "|    total_timesteps    | 16760832     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0116827395 |\n",
      "|    entropy_loss       | -1.79        |\n",
      "|    explained_variance | 0.98         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.542        |\n",
      "|    mean_step_reward   | 0.2929896    |\n",
      "|    n_updates          | 8180         |\n",
      "|    policyGradLoss     | -0.00835     |\n",
      "|    value_loss         | 1.41         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 334         |\n",
      "|    total_timesteps    | 16769024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011560127 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.51        |\n",
      "|    mean_step_reward   | 0.37243783  |\n",
      "|    n_updates          | 8184        |\n",
      "|    policyGradLoss     | -0.0038     |\n",
      "|    value_loss         | 2.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 345         |\n",
      "|    total_timesteps    | 16777216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014590574 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.868       |\n",
      "|    mean_step_reward   | 0.39241335  |\n",
      "|    n_updates          | 8188        |\n",
      "|    policyGradLoss     | 0.0016      |\n",
      "|    value_loss         | 1.99        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Enc5_63.zip\n",
      "[EVAL] Mean Return: 554.997, Best Return: 562.997\n",
      "Saved video to ./runs_smw/videos/Enc5/Enc5_63_555.00.mp4\n",
      "\n",
      "=== Round 65 | Learn 262144 steps (Total trained: 16777216) ===\n",
      "Logging to ./runs_smw/tb/Enc5_0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    while trained < TOTAL_STEPS:\n",
    "        round_idx += 1\n",
    "        chunk = min(TRAIN_CHUNK, TOTAL_STEPS - trained)\n",
    "        # chunk = 2000\n",
    "        label = \"Enc5\"\n",
    "        tagged_label = f\"{label}_{int(trained/TRAIN_CHUNK)}\"\n",
    "\n",
    "        print(f\"\\n=== Round {round_idx} | Learn {chunk} steps (Total trained: {trained}) ===\")\n",
    "        \n",
    "        # --- Train ---\n",
    "        model.learn(total_timesteps=chunk, reset_num_timesteps=False, tb_log_name=label)\n",
    "        trained += chunk\n",
    "\n",
    "        # --- Save Checkpoint ---\n",
    "        ckpt_path = os.path.join(CKPT_DIR, f\"{tagged_label}.zip\")\n",
    "        model.save(ckpt_path)\n",
    "        print(f\"Saved checkpoint: {ckpt_path}\")\n",
    "\n",
    "        # --- Evaluate ---\n",
    "        mean_ret, best_ret = evaluate_policy(\n",
    "            model,\n",
    "            GAME,\n",
    "            STATE,\n",
    "            n_episodes=EVAL_EPISODES,\n",
    "            max_steps=EVAL_MAX_STEPS,\n",
    "        )\n",
    "        print(f\"[EVAL] Mean Return: {mean_ret:.3f}, Best Return: {best_ret:.3f}\")\n",
    "\n",
    "        # --- Save Best Model ---\n",
    "        # if mean_ret > best_mean:\n",
    "        #     best_mean = mean_ret\n",
    "        #     best_path = os.path.join(LOG_DIR, \"best_model.zip\")\n",
    "        #     model.save(best_path)\n",
    "        #     print(f\"New best record. Saved to {best_path}\")\n",
    "\n",
    "        # --- Record Video ---\n",
    "        out_path = os.path.join(VIDEO_DIR, label)\n",
    "        os.makedirs(out_path,  exist_ok=True)\n",
    "        record_video(\n",
    "            model,\n",
    "            GAME,\n",
    "            STATE,\n",
    "            VIDEO_DIR,\n",
    "            video_len=RECORD_STEPS,\n",
    "            prefix=f\"{label}/{tagged_label}_{mean_ret:.2f}\",\n",
    "        )\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nTraining interrupted manually.\")\n",
    "\n",
    "finally:\n",
    "    train_env.close()\n",
    "    print(\"Training finished. Environment closed.\")\n",
    "    \n",
    "\"\"\"\n",
    "tensorboard --logdir=./runs_smw/tb\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f088b0b3-2418-4866-b332-0312c9f6467f",
   "metadata": {},
   "source": [
    "## Display Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a73191bb-e875-4939-b04c-a4670abd9612",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mglob\u001b[39;00m\n\u001b[32m      3\u001b[39m label = \u001b[33m\"\u001b[39m\u001b[33mDec22A\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m list_of_files = glob.glob(\u001b[43mos\u001b[49m.path.join(VIDEO_DIR, label, \u001b[33m'\u001b[39m\u001b[33m*.mp4\u001b[39m\u001b[33m'\u001b[39m)) \n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m list_of_files:\n\u001b[32m      7\u001b[39m     latest_file = \u001b[38;5;28mmax\u001b[39m(list_of_files, key=os.path.getctime)\n",
      "\u001b[31mNameError\u001b[39m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "import glob\n",
    "label = \"Dec22A\"\n",
    "\n",
    "list_of_files = glob.glob(os.path.join(VIDEO_DIR, label, '*.mp4')) \n",
    "if list_of_files:\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    print(f\"Playing: {latest_file}\")\n",
    "    latest_file = \"runs_smw/videos/Dec22A/Dec22A_73_596.54.mp4\"\n",
    "    print(f\"Playing: {latest_file}\")\n",
    "    display(Video(latest_file, embed=True, width=768))\n",
    "else:\n",
    "    print(\"No videos found yet.\")\n",
    "    \n",
    "video = \"./runs_smw/videos/Dec22A/Dec22A_73_596.54.mp4\"\n",
    "# display(Video(video, embed=True, width=768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942adf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(\"runs_smw/videos/test_16.mp4\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    cv2.imshow(\"Frame-by-Frame\", frame)\n",
    "\n",
    "    # 關鍵：這裡等待按鍵。按 'n' 鍵跳到下一幀，按 'q' 離開\n",
    "    key = cv2.waitKey(0) \n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('n'):\n",
    "        continue\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lab8 (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
