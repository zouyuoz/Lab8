{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dceedafe-2782-41a1-8119-50ee3d6c21fd",
   "metadata": {},
   "source": [
    "# 2025 DL Lab8: RL Assignment_Super Mario World"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fa555a-e61c-4fb3-b5d0-289b66570139",
   "metadata": {},
   "source": [
    "**Your Answer:**    \n",
    "Hi I'm XXX, XXXXXXXXXX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5b0974-9605-488a-9fd5-00816e7832cc",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This project implements a **Deep Reinforcement Learning** pipeline to train an autonomous agent for Super Mario World. Leveraging the **Proximal Policy Optimization (PPO)** algorithm, the system interacts with the **stable-retro** environment to master the YoshiIsland1 level. Key components include a custom Vision Backbone for extracting features from raw pixel data and a suite of Environment Wrappers that handle frame preprocessing, action discretization, and reward shaping to facilitate efficient learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02696447",
   "metadata": {},
   "source": [
    "Reward function implement  \n",
    "should do something in the beginning (monster attack)  \n",
    "Custom PPO implement  \n",
    "pre train weight 差不多，主要是 reward function  \n",
    "model weight capacity 1GB  \n",
    "class name 不要動 (可以新增，但是原本有的不要動)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8a0ab9-f86d-4038-833d-761ec81fc4f2",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00b10def-362c-4910-9ed0-f3d0904343ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import retro\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "\n",
    "from eval import evaluate_policy, record_video\n",
    "from custom_policy import VisionBackbonePolicy, CustomPPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10361fd-f291-4d93-b50d-cc749a3af588",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b4f6a25-738c-49dd-8e66-ae164b74a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game Settings\n",
    "GAME = \"SuperMarioWorld-Snes\"\n",
    "STATE = \"YoshiIsland1\"\n",
    "\n",
    "# Training Settings\n",
    "BASE_CHUNK  = 8192\n",
    "TRAIN_CHUNK = BASE_CHUNK * 32\n",
    "TOTAL_STEPS = TRAIN_CHUNK * 160\n",
    "N_ENVS = 16\n",
    "\n",
    "# Evaluation & Recording Settingsc\n",
    "EVAL_EPISODES = 3\n",
    "EVAL_MAX_STEPS = 18000\n",
    "RECORD_STEPS = 1200\n",
    "\n",
    "# Directories\n",
    "LOG_DIR = \"./runs_smw\"\n",
    "VIDEO_DIR       = os.path.join(LOG_DIR, \"videos\")\n",
    "CKPT_DIR        = os.path.join(LOG_DIR, \"checkpoints\")\n",
    "TENSORBOARD_LOG = os.path.join(LOG_DIR, \"tb\")\n",
    "\n",
    "os.makedirs(LOG_DIR,   exist_ok=True)\n",
    "os.makedirs(CKPT_DIR,  exist_ok=True)\n",
    "os.makedirs(VIDEO_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a34b783-0273-4835-ad2e-f9186064f76f",
   "metadata": {},
   "source": [
    "## Environment Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c34213d-2c7c-42b8-922d-bafa285d1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrappers import make_base_env\n",
    "def _make_env_thunk(game: str, state: str):\n",
    "    \"\"\"Return a function that creates an environment (for multiprocessing).\"\"\"\n",
    "    def _thunk():\n",
    "        return make_base_env(game, state)\n",
    "    return _thunk\n",
    "\n",
    "def make_vec_env(game: str, state: str, n_envs: int, use_subproc: bool = True):\n",
    "    \"\"\"Create a vectorized environment (multiple envs running in parallel).\"\"\"\n",
    "    env_fns = [_make_env_thunk(game, state) for _ in range(n_envs)]\n",
    "    \n",
    "    if use_subproc and n_envs > 1:\n",
    "        vec_env = SubprocVecEnv(env_fns)\n",
    "    else:\n",
    "        vec_env = DummyVecEnv(env_fns)\n",
    "\n",
    "    return vec_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dff476-ea2e-4262-8780-afb32ef1b233",
   "metadata": {},
   "source": [
    "## Initialize Env & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c7c5fe-6421-4dbc-9bd8-822d61769c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment created: SuperMarioWorld-Snes - YoshiIsland1 with 16 parallel envs.\n",
      "[Sucess] Loaded model from runs_smw/checkpoints/Run_107.zip\n",
      "trained: 28311552, round_index: 108\n"
     ]
    }
   ],
   "source": [
    "# 1. Create Training Environment\n",
    "train_env = make_vec_env(GAME, STATE, n_envs=N_ENVS)\n",
    "# train_env = VecNormalize(train_env, norm_obs=True, norm_reward=True, clip_obs=10., clip_reward=10.)\n",
    "print(f\"Environment created: {GAME} - {STATE} with {N_ENVS} parallel envs.\")\n",
    "\n",
    "checkpoint_path = \"None\"\n",
    "checkpoint_path = \"runs_smw/checkpoints/Run_107.zip\"\n",
    "\n",
    "best_mean = -1e18\n",
    "trained = 0\n",
    "round_idx = 0\n",
    "\n",
    "# 2. Initialize Model\n",
    "if os.path.exists(checkpoint_path):\n",
    "    # 讀取現有模型\n",
    "    model = CustomPPO.load(\n",
    "        checkpoint_path, \n",
    "        env=train_env,\n",
    "        device=\"cuda:0\" # 確保使用 GPU\n",
    "    )\n",
    "    trained = model.num_timesteps\n",
    "    round_idx = int(trained / TRAIN_CHUNK)\n",
    "    print(f\"[Sucess] Loaded model from {checkpoint_path}\")\n",
    "    print(f\"trained: {trained}, round_index: {round_idx}\")\n",
    "else:\n",
    "    print(f\"[Fail] Can't load {checkpoint_path}. Will use new model\")\n",
    "    model = CustomPPO(\n",
    "        VisionBackbonePolicy,\n",
    "        train_env,\n",
    "        policy_kwargs   = dict(normalize_images=False),\n",
    "        n_epochs        = 4,\n",
    "        n_steps         = 512,\n",
    "        batch_size      = 512,\n",
    "        learning_rate   = 1e-4,\n",
    "        verbose         = 1,\n",
    "        gamma           = 0.96875,\n",
    "        kl_coef         = 1,\n",
    "        clip_range      = 0.125,\n",
    "        ent_coef        = 0.0375,\n",
    "        tensorboard_log = TENSORBOARD_LOG,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eb7a896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from custom_policy import CustomPPO\n",
    "# from wrappers import make_base_env  # [新增] 必須引入這行來建立環境\n",
    "\n",
    "# # ================= 設定區 =================\n",
    "# # 請確保這些變數有被定義 (這裡沿用你原本的變數名稱)\n",
    "# # GAME = \"SuperMarioWorld-Snes\"\n",
    "# # STATE = \"Level1\" \n",
    "# # CKPT_DIR = \"./\"\n",
    "# # RECORD_STEPS = 2000\n",
    "# PSVD_DIR = \"./runs_smw/preserved/\"\n",
    "\n",
    "# target_numbers = list(range(70, 128))\n",
    "# # target_numbers = [124, 137, 147, 151, 179]\n",
    "\n",
    "# # ================= 執行迴圈 =================\n",
    "# for num in target_numbers:\n",
    "#     model_path = os.path.join(CKPT_DIR, f\"S2K_{num}.zip\")\n",
    "    \n",
    "#     if not os.path.exists(model_path):\n",
    "#         # print(f\"⚠️ 找不到檔案: {model_path}，跳過。\")\n",
    "#         continue\n",
    "    \n",
    "#     # print(f\"\\n[{num}] 正在載入模型: {model_path} ...\")\n",
    "    \n",
    "#     env = None\n",
    "#     try:\n",
    "#         model = CustomPPO.load(model_path, device=\"auto\")\n",
    "#         env = make_base_env(game=GAME, state=STATE)\n",
    "        \n",
    "#         obs, info = env.reset()\n",
    "#         final_score = 0\n",
    "#         final_coins = 0 # [新增] 初始化金幣紀錄\n",
    "        \n",
    "#         for step in range(RECORD_STEPS):\n",
    "#             action, _ = model.predict(obs, deterministic=True)\n",
    "#             obs, reward, terminated, truncated, info = env.step(action)\n",
    "            \n",
    "#             # 從 info 中讀取當前數值 \n",
    "#             final_score = info.get(\"score\", final_score)\n",
    "#             final_coins = info.get(\"coins\", final_coins)\n",
    "            \n",
    "#             if terminated or truncated:\n",
    "#                 break\n",
    "        \n",
    "#         # 修改後的印出格式\n",
    "#         print(f\"[{num}] coins: {final_coins} | score: {final_score}\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"❌ 發生錯誤 (Model: {num}): {e}\")\n",
    "#     finally:\n",
    "#         if env is not None:\n",
    "#             env.close()\n",
    "\n",
    "# print(\"\\n所有測試結束。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdfff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "# from custom_policy import CustomPPO\n",
    "# from eval import record_video  # 確保 eval.py 在同一目錄下\n",
    "# PSVD_DIR = \"./runs_smw/preserved/\"\n",
    "# CKPT_DIR\n",
    "# # ================= 設定區 =================\n",
    "# # target_numbers = list(range(38, 40))\n",
    "# target_numbers = [126]\n",
    "\n",
    "# # ================= 執行迴圈 =================\n",
    "# print(f\"準備測試以下 Checkpoints: {target_numbers}\")\n",
    "\n",
    "# for num in target_numbers:\n",
    "#     model_path = os.path.join(PSVD_DIR, f\"S2K_{num}.zip\")\n",
    "    \n",
    "#     # 檢查檔案是否存在\n",
    "#     if not os.path.exists(model_path):\n",
    "#         print(f\"⚠️ 找不到檔案: {model_path}，跳過。\")\n",
    "#         continue\n",
    "    \n",
    "#     print(f\"\\n[{num}] 正在載入模型: {model_path} ...\")\n",
    "    \n",
    "#     try:\n",
    "#         # 1. 載入模型 (不需要 env 參數也能載入權重)\n",
    "#         # 如果你有改過 CustomPPO 的參數，load 會自動讀取 zip 裡的設定\n",
    "#         model = CustomPPO.load(model_path, device=\"auto\") # device=\"auto\" 會自動用 GPU\n",
    "        \n",
    "#         # 2. 錄製影片\n",
    "#         prefix_name = f\"test_{num}\"\n",
    "#         print(f\"[{num}] 正在錄影 (長度 {RECORD_STEPS} steps)...\")\n",
    "        \n",
    "#         record_video(\n",
    "#             model=model,\n",
    "#             game=GAME,\n",
    "#             state=STATE,\n",
    "#             out_dir=VIDEO_DIR,\n",
    "#             video_len=RECORD_STEPS,\n",
    "#             prefix=prefix_name\n",
    "#         )\n",
    "#         print(f\"✅ 完成！影片已儲存為 {prefix_name}.mp4\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"❌ 發生錯誤 (Model: {num}): {e}\")\n",
    "\n",
    "# print(\"\\n所有測試結束。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f594e443-843f-42c1-9fc6-3fbc82962021",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3af4932-c531-4113-a33a-defc6fb5858e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Round 109 | Learn 262144 steps (Total trained: 28311552) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1117     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 28319744 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 904         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 28327936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030534374 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0219     |\n",
      "|    mean_step_reward   | 0.1256311   |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.295       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 852         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 28336128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021539118 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0844      |\n",
      "|    mean_step_reward   | 0.12389018  |\n",
      "|    n_updates          | 8/128)      |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 28344320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026853837 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0423      |\n",
      "|    mean_step_reward   | 0.10326065  |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.212       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 28352512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028236758 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0676     |\n",
      "|    mean_step_reward   | 0.14974518  |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.013      |\n",
      "|    value_loss         | 0.141       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 28360704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023441344 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0444     |\n",
      "|    mean_step_reward   | 0.11278565  |\n",
      "|    n_updates          | 20/128)     |\n",
      "|    policyGradLoss     | -0.0128     |\n",
      "|    value_loss         | 0.154       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 28368896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025686717 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0333     |\n",
      "|    mean_step_reward   | 0.14889781  |\n",
      "|    n_updates          | 24/128)     |\n",
      "|    policyGradLoss     | -0.0129     |\n",
      "|    value_loss         | 0.204       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 28377088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030551802 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0469     |\n",
      "|    mean_step_reward   | 0.11055823  |\n",
      "|    n_updates          | 28/128)     |\n",
      "|    policyGradLoss     | -0.0221     |\n",
      "|    value_loss         | 0.127       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 28385280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.037623502 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0681     |\n",
      "|    mean_step_reward   | 0.16162358  |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.122       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 28393472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024168354 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.042      |\n",
      "|    mean_step_reward   | 0.10200134  |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.0135     |\n",
      "|    value_loss         | 0.203       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 28401664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021237899 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0139     |\n",
      "|    mean_step_reward   | 0.14900589  |\n",
      "|    n_updates          | 40/128)     |\n",
      "|    policyGradLoss     | -0.0139     |\n",
      "|    value_loss         | 0.251       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 28409856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017167361 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0415      |\n",
      "|    mean_step_reward   | 0.10513812  |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0127     |\n",
      "|    value_loss         | 0.226       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 28418048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032002598 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0165      |\n",
      "|    mean_step_reward   | 0.1534621   |\n",
      "|    n_updates          | 48/128)     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.361       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 28426240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021065913 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0168     |\n",
      "|    mean_step_reward   | 0.106939934 |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.0133     |\n",
      "|    value_loss         | 0.216       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 28434432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.037298817 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0294     |\n",
      "|    mean_step_reward   | 0.15606046  |\n",
      "|    n_updates          | 56/128)     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.158       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 28442624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030360617 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0313     |\n",
      "|    mean_step_reward   | 0.111749545 |\n",
      "|    n_updates          | 60/128)     |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.177       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 781        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 178        |\n",
      "|    total_timesteps    | 28450816   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03295137 |\n",
      "|    entropy_loss       | -1.71      |\n",
      "|    explained_variance | 0.975      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0132    |\n",
      "|    mean_step_reward   | 0.15187871 |\n",
      "|    n_updates          | 64/128)    |\n",
      "|    policyGradLoss     | -0.0191    |\n",
      "|    value_loss         | 0.209      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 28459008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026524533 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0159     |\n",
      "|    mean_step_reward   | 0.099739075 |\n",
      "|    n_updates          | 68/128)     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.288       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 28467200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032435823 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0473     |\n",
      "|    mean_step_reward   | 0.1334751   |\n",
      "|    n_updates          | 72/128)     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.227       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 28475392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031502012 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00818    |\n",
      "|    mean_step_reward   | 0.10159829  |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.269       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 28483584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031184081 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0514     |\n",
      "|    mean_step_reward   | 0.138713    |\n",
      "|    n_updates          | 80/128)     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.209       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 28491776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019487184 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0216      |\n",
      "|    mean_step_reward   | 0.103948146 |\n",
      "|    n_updates          | 84/128)     |\n",
      "|    policyGradLoss     | -0.0141     |\n",
      "|    value_loss         | 0.297       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 28499968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026752312 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0605      |\n",
      "|    mean_step_reward   | 0.14317726  |\n",
      "|    n_updates          | 88/128)     |\n",
      "|    policyGradLoss     | -0.0222     |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 28508160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019791467 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0328     |\n",
      "|    mean_step_reward   | 0.10922056  |\n",
      "|    n_updates          | 92/128)     |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.207       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 28516352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032304395 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0655     |\n",
      "|    mean_step_reward   | 0.14050029  |\n",
      "|    n_updates          | 96/128)     |\n",
      "|    policyGradLoss     | -0.0224     |\n",
      "|    value_loss         | 0.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 28524544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031447887 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0674     |\n",
      "|    mean_step_reward   | 0.12420718  |\n",
      "|    n_updates          | 100/128)    |\n",
      "|    policyGradLoss     | -0.0217     |\n",
      "|    value_loss         | 0.151       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 28532736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026273187 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0341      |\n",
      "|    mean_step_reward   | 0.1263783   |\n",
      "|    n_updates          | 104/128)    |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.299       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 28540928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029131193 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0113     |\n",
      "|    mean_step_reward   | 0.12803474  |\n",
      "|    n_updates          | 108/128)    |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.216       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 28549120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030375432 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.056      |\n",
      "|    mean_step_reward   | 0.13017192  |\n",
      "|    n_updates          | 112/128)    |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.193       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 28557312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029435398 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0311     |\n",
      "|    mean_step_reward   | 0.13567275  |\n",
      "|    n_updates          | 116/128)    |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.192       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 28565504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026935244 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0388     |\n",
      "|    mean_step_reward   | 0.10319333  |\n",
      "|    n_updates          | 120/128)    |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 28573696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030257275 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0648     |\n",
      "|    mean_step_reward   | 0.13452253  |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.0214     |\n",
      "|    value_loss         | 0.152       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_108.zip\n",
      "[EVAL] Mean Return: 156.551, Best Return: 163.218\n",
      "Saved video to ./runs_smw/videos/Run/Run_108_156.55.mp4\n",
      "\n",
      "=== Round 110 | Learn 262144 steps (Total trained: 28573696) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1157     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 28581888 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 921         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 28590080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027509006 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0323     |\n",
      "|    mean_step_reward   | 0.12230079  |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.239       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 857        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 28598272   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01766138 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.962      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0316     |\n",
      "|    mean_step_reward   | 0.11944996 |\n",
      "|    n_updates          | 8/128)     |\n",
      "|    policyGradLoss     | -0.0149    |\n",
      "|    value_loss         | 0.332      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 836         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 28606464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029929154 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0501     |\n",
      "|    mean_step_reward   | 0.13956381  |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.174       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 28614656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027398761 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0373     |\n",
      "|    mean_step_reward   | 0.11022097  |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.204       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 811        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 28622848   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02282754 |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.948      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0195    |\n",
      "|    mean_step_reward   | 0.13613564 |\n",
      "|    n_updates          | 20/128)    |\n",
      "|    policyGradLoss     | -0.0154    |\n",
      "|    value_loss         | 0.308      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 807        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 71         |\n",
      "|    total_timesteps    | 28631040   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02969395 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.974      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0491    |\n",
      "|    mean_step_reward   | 0.11033063 |\n",
      "|    n_updates          | 24/128)    |\n",
      "|    policyGradLoss     | -0.0204    |\n",
      "|    value_loss         | 0.178      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 803        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 81         |\n",
      "|    total_timesteps    | 28639232   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02491625 |\n",
      "|    entropy_loss       | -1.74      |\n",
      "|    explained_variance | 0.962      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.035     |\n",
      "|    mean_step_reward   | 0.14949803 |\n",
      "|    n_updates          | 28/128)    |\n",
      "|    policyGradLoss     | -0.0156    |\n",
      "|    value_loss         | 0.198      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 28647424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030317785 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0452     |\n",
      "|    mean_step_reward   | 0.12158144  |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.0211     |\n",
      "|    value_loss         | 0.122       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 28655616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018235896 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0249     |\n",
      "|    mean_step_reward   | 0.14020938  |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.308       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 28663808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030130483 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0637     |\n",
      "|    mean_step_reward   | 0.122679666 |\n",
      "|    n_updates          | 40/128)     |\n",
      "|    policyGradLoss     | -0.0218     |\n",
      "|    value_loss         | 0.127       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 28672000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029534958 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0663     |\n",
      "|    mean_step_reward   | 0.1431084   |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.024      |\n",
      "|    value_loss         | 0.103       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 28680192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024891406 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0273     |\n",
      "|    mean_step_reward   | 0.1247741   |\n",
      "|    n_updates          | 48/128)     |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.243       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 28688384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031774104 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.078      |\n",
      "|    mean_step_reward   | 0.12936395  |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.0239     |\n",
      "|    value_loss         | 0.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 28696576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024565544 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0252      |\n",
      "|    mean_step_reward   | 0.11280712  |\n",
      "|    n_updates          | 56/128)     |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.301       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 28704768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028871179 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.000764   |\n",
      "|    mean_step_reward   | 0.12978037  |\n",
      "|    n_updates          | 60/128)     |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.174       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 28712960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020926282 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0419     |\n",
      "|    mean_step_reward   | 0.12114404  |\n",
      "|    n_updates          | 64/128)     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 28721152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022435544 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0442     |\n",
      "|    mean_step_reward   | 0.12702572  |\n",
      "|    n_updates          | 68/128)     |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.219       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 28729344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021385502 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0319     |\n",
      "|    mean_step_reward   | 0.13114923  |\n",
      "|    n_updates          | 72/128)     |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.258       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 28737536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022100855 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0411     |\n",
      "|    mean_step_reward   | 0.11261307  |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.255       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 28745728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015498262 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0343     |\n",
      "|    mean_step_reward   | 0.13249524  |\n",
      "|    n_updates          | 80/128)     |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.282       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 28753920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020789478 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0146     |\n",
      "|    mean_step_reward   | 0.118111275 |\n",
      "|    n_updates          | 84/128)     |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.244       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 28762112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027230375 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0403     |\n",
      "|    mean_step_reward   | 0.13576177  |\n",
      "|    n_updates          | 88/128)     |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.211       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 28770304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026539776 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0177     |\n",
      "|    mean_step_reward   | 0.1098483   |\n",
      "|    n_updates          | 92/128)     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.257       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 28778496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019269535 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0264     |\n",
      "|    mean_step_reward   | 0.12433024  |\n",
      "|    n_updates          | 96/128)     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.245       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 28786688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030323138 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0566     |\n",
      "|    mean_step_reward   | 0.11481267  |\n",
      "|    n_updates          | 100/128)    |\n",
      "|    policyGradLoss     | -0.0209     |\n",
      "|    value_loss         | 0.165       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 28794880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023691364 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0476     |\n",
      "|    mean_step_reward   | 0.12071454  |\n",
      "|    n_updates          | 104/128)    |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.225       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 28803072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018936034 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0305      |\n",
      "|    mean_step_reward   | 0.11726421  |\n",
      "|    n_updates          | 108/128)    |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.239       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 28811264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017556574 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0041      |\n",
      "|    mean_step_reward   | 0.13826704  |\n",
      "|    n_updates          | 112/128)    |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.271       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 314         |\n",
      "|    total_timesteps    | 28819456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022290094 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00465     |\n",
      "|    mean_step_reward   | 0.11639536  |\n",
      "|    n_updates          | 116/128)    |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.268       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 325        |\n",
      "|    total_timesteps    | 28827648   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03210932 |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.982      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0609    |\n",
      "|    mean_step_reward   | 0.13851577 |\n",
      "|    n_updates          | 120/128)   |\n",
      "|    policyGradLoss     | -0.0194    |\n",
      "|    value_loss         | 0.143      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 28835840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034784764 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0406     |\n",
      "|    mean_step_reward   | 0.122723915 |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.023      |\n",
      "|    value_loss         | 0.164       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_109.zip\n",
      "[EVAL] Mean Return: 153.810, Best Return: 160.810\n",
      "Saved video to ./runs_smw/videos/Run/Run_109_153.81.mp4\n",
      "\n",
      "=== Round 111 | Learn 262144 steps (Total trained: 28835840) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1134     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 28844032 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 901         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 28852224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033149663 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0376     |\n",
      "|    mean_step_reward   | 0.11772146  |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.182       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 844         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 28860416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018674511 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0313     |\n",
      "|    mean_step_reward   | 0.14350238  |\n",
      "|    n_updates          | 8/128)      |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.199       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 822        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 39         |\n",
      "|    total_timesteps    | 28868608   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03453031 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.974      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0332    |\n",
      "|    mean_step_reward   | 0.12804058 |\n",
      "|    n_updates          | 12/128)    |\n",
      "|    policyGradLoss     | -0.022     |\n",
      "|    value_loss         | 0.133      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 28876800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026094407 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0682     |\n",
      "|    mean_step_reward   | 0.13490519  |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.021      |\n",
      "|    value_loss         | 0.145       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 28884992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019056085 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.027      |\n",
      "|    mean_step_reward   | 0.11960526  |\n",
      "|    n_updates          | 20/128)     |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.246       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 28893184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031306285 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0645     |\n",
      "|    mean_step_reward   | 0.1404765   |\n",
      "|    n_updates          | 24/128)     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.146       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 794        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 82         |\n",
      "|    total_timesteps    | 28901376   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03516847 |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.969      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0386    |\n",
      "|    mean_step_reward   | 0.12707388 |\n",
      "|    n_updates          | 28/128)    |\n",
      "|    policyGradLoss     | -0.0226    |\n",
      "|    value_loss         | 0.202      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 28909568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023016866 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0272      |\n",
      "|    mean_step_reward   | 0.11018732  |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.402       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 28917760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029466853 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.018      |\n",
      "|    mean_step_reward   | 0.1290702   |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.232       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 789        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 114        |\n",
      "|    total_timesteps    | 28925952   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03277742 |\n",
      "|    entropy_loss       | -1.76      |\n",
      "|    explained_variance | 0.967      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0385    |\n",
      "|    mean_step_reward   | 0.1343332  |\n",
      "|    n_updates          | 40/128)    |\n",
      "|    policyGradLoss     | -0.0207    |\n",
      "|    value_loss         | 0.207      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 28934144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030943815 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0174     |\n",
      "|    mean_step_reward   | 0.119945236 |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.216       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 28942336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028692413 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0285     |\n",
      "|    mean_step_reward   | 0.1351955   |\n",
      "|    n_updates          | 48/128)     |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.218       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 28950528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015534273 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00199    |\n",
      "|    mean_step_reward   | 0.10797498  |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.294       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 28958720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.035087742 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0382     |\n",
      "|    mean_step_reward   | 0.13738461  |\n",
      "|    n_updates          | 56/128)     |\n",
      "|    policyGradLoss     | -0.0216     |\n",
      "|    value_loss         | 0.188       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 28966912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.03240769  |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0139      |\n",
      "|    mean_step_reward   | 0.105909765 |\n",
      "|    n_updates          | 60/128)     |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.265       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 782        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 177        |\n",
      "|    total_timesteps    | 28975104   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01833519 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.968      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0275     |\n",
      "|    mean_step_reward   | 0.14466466 |\n",
      "|    n_updates          | 64/128)    |\n",
      "|    policyGradLoss     | -0.0107    |\n",
      "|    value_loss         | 0.312      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 28983296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028276626 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0216     |\n",
      "|    mean_step_reward   | 0.115621075 |\n",
      "|    n_updates          | 68/128)     |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.263       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 28991488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031892594 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0632     |\n",
      "|    mean_step_reward   | 0.13821343  |\n",
      "|    n_updates          | 72/128)     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 28999680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030848298 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0192     |\n",
      "|    mean_step_reward   | 0.12631565  |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.199       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 781        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 220        |\n",
      "|    total_timesteps    | 29007872   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03593272 |\n",
      "|    entropy_loss       | -1.74      |\n",
      "|    explained_variance | 0.972      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0292    |\n",
      "|    mean_step_reward   | 0.13502711 |\n",
      "|    n_updates          | 80/128)    |\n",
      "|    policyGradLoss     | -0.0184    |\n",
      "|    value_loss         | 0.209      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 29016064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029753733 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0647     |\n",
      "|    mean_step_reward   | 0.12599942  |\n",
      "|    n_updates          | 84/128)     |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.142       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 29024256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024238471 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0089     |\n",
      "|    mean_step_reward   | 0.13466842  |\n",
      "|    n_updates          | 88/128)     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.229       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 29032448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028438596 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0517     |\n",
      "|    mean_step_reward   | 0.14335771  |\n",
      "|    n_updates          | 92/128)     |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.119       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 29040640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024313457 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00502     |\n",
      "|    mean_step_reward   | 0.11567135  |\n",
      "|    n_updates          | 96/128)     |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.288       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 29048832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032978535 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0648     |\n",
      "|    mean_step_reward   | 0.14829862  |\n",
      "|    n_updates          | 100/128)    |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.141       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 284        |\n",
      "|    total_timesteps    | 29057024   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0255029  |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.97       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0277    |\n",
      "|    mean_step_reward   | 0.11932083 |\n",
      "|    n_updates          | 104/128)   |\n",
      "|    policyGradLoss     | -0.0129    |\n",
      "|    value_loss         | 0.16       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 29065216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022115216 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0115     |\n",
      "|    mean_step_reward   | 0.14819765  |\n",
      "|    n_updates          | 108/128)    |\n",
      "|    policyGradLoss     | -0.0112     |\n",
      "|    value_loss         | 0.258       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 29073408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.035231598 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.022      |\n",
      "|    mean_step_reward   | 0.11751268  |\n",
      "|    n_updates          | 112/128)    |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.218       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 29081600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024236975 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0551     |\n",
      "|    mean_step_reward   | 0.14346042  |\n",
      "|    n_updates          | 116/128)    |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 29089792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029858131 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0372     |\n",
      "|    mean_step_reward   | 0.11469693  |\n",
      "|    n_updates          | 120/128)    |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.176       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 29097984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028892254 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0409     |\n",
      "|    mean_step_reward   | 0.14875785  |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.125       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_110.zip\n",
      "[EVAL] Mean Return: 147.514, Best Return: 153.848\n",
      "Saved video to ./runs_smw/videos/Run/Run_110_147.51.mp4\n",
      "\n",
      "=== Round 112 | Learn 262144 steps (Total trained: 29097984) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1129     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 29106176 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 920         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 29114368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033192683 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0557     |\n",
      "|    mean_step_reward   | 0.1449064   |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.0222     |\n",
      "|    value_loss         | 0.133       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 865        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 29122560   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03222629 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.977      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0644    |\n",
      "|    mean_step_reward   | 0.1229174  |\n",
      "|    n_updates          | 8/128)     |\n",
      "|    policyGradLoss     | -0.0219    |\n",
      "|    value_loss         | 0.148      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 841         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 29130752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022377754 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0141      |\n",
      "|    mean_step_reward   | 0.12804037  |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.266       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 29138944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033461057 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0633     |\n",
      "|    mean_step_reward   | 0.12387919  |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.0209     |\n",
      "|    value_loss         | 0.159       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 29147136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027984053 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0551     |\n",
      "|    mean_step_reward   | 0.13293016  |\n",
      "|    n_updates          | 20/128)     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.182       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 29155328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029699948 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0561     |\n",
      "|    mean_step_reward   | 0.12503597  |\n",
      "|    n_updates          | 24/128)     |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.171       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 29163520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026573233 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.057      |\n",
      "|    mean_step_reward   | 0.12784554  |\n",
      "|    n_updates          | 28/128)     |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.169       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 29171712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029575918 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0707     |\n",
      "|    mean_step_reward   | 0.14601924  |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.143       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 29179904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030691393 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0635     |\n",
      "|    mean_step_reward   | 0.12830853  |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.168       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 29188096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024475131 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0477     |\n",
      "|    mean_step_reward   | 0.12156094  |\n",
      "|    n_updates          | 40/128)     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.229       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 29196288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031890154 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0479     |\n",
      "|    mean_step_reward   | 0.12143746  |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.241       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 29204480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029706087 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0132     |\n",
      "|    mean_step_reward   | 0.13465598  |\n",
      "|    n_updates          | 48/128)     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 29212672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017302047 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0558     |\n",
      "|    mean_step_reward   | 0.1316998   |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.159       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 29220864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015429264 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0956      |\n",
      "|    mean_step_reward   | 0.110104844 |\n",
      "|    n_updates          | 56/128)     |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.359       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 29229056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020932913 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00143     |\n",
      "|    mean_step_reward   | 0.1371145   |\n",
      "|    n_updates          | 60/128)     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.223       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 784        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 177        |\n",
      "|    total_timesteps    | 29237248   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03257271 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.97       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0337    |\n",
      "|    mean_step_reward   | 0.11518304 |\n",
      "|    n_updates          | 64/128)    |\n",
      "|    policyGradLoss     | -0.0162    |\n",
      "|    value_loss         | 0.223      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 29245440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034467883 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0445     |\n",
      "|    mean_step_reward   | 0.13707992  |\n",
      "|    n_updates          | 68/128)     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 29253632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028733697 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0308     |\n",
      "|    mean_step_reward   | 0.12569343  |\n",
      "|    n_updates          | 72/128)     |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.193       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 29261824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025850998 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00807    |\n",
      "|    mean_step_reward   | 0.12547718  |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.295       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 29270016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032188244 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0331     |\n",
      "|    mean_step_reward   | 0.12664472  |\n",
      "|    n_updates          | 80/128)     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.199       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 29278208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027486863 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0511     |\n",
      "|    mean_step_reward   | 0.12986344  |\n",
      "|    n_updates          | 84/128)     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 29286400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022673316 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0231     |\n",
      "|    mean_step_reward   | 0.11389668  |\n",
      "|    n_updates          | 88/128)     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.281       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 252        |\n",
      "|    total_timesteps    | 29294592   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02508873 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.97       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.05      |\n",
      "|    mean_step_reward   | 0.13080537 |\n",
      "|    n_updates          | 92/128)    |\n",
      "|    policyGradLoss     | -0.0176    |\n",
      "|    value_loss         | 0.161      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 29302784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030885298 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0525     |\n",
      "|    mean_step_reward   | 0.12721395  |\n",
      "|    n_updates          | 96/128)     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.171       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 29310976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029794455 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0086     |\n",
      "|    mean_step_reward   | 0.13498226  |\n",
      "|    n_updates          | 100/128)    |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.282       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 29319168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026450794 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0312      |\n",
      "|    mean_step_reward   | 0.108962044 |\n",
      "|    n_updates          | 104/128)    |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.328       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 29327360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031069351 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0615     |\n",
      "|    mean_step_reward   | 0.14167018  |\n",
      "|    n_updates          | 108/128)    |\n",
      "|    policyGradLoss     | -0.0212     |\n",
      "|    value_loss         | 0.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 29335552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027733997 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0347     |\n",
      "|    mean_step_reward   | 0.1210266   |\n",
      "|    n_updates          | 112/128)    |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.217       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 29343744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027833007 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00825    |\n",
      "|    mean_step_reward   | 0.144131    |\n",
      "|    n_updates          | 116/128)    |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.206       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 776        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 327        |\n",
      "|    total_timesteps    | 29351936   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02812719 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.971      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0366    |\n",
      "|    mean_step_reward   | 0.1297012  |\n",
      "|    n_updates          | 120/128)   |\n",
      "|    policyGradLoss     | -0.0201    |\n",
      "|    value_loss         | 0.176      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 29360128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021888088 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.000168   |\n",
      "|    mean_step_reward   | 0.12748116  |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.339       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_111.zip\n",
      "[EVAL] Mean Return: 99.471, Best Return: 102.804\n",
      "Saved video to ./runs_smw/videos/Run/Run_111_99.47.mp4\n",
      "\n",
      "=== Round 113 | Learn 262144 steps (Total trained: 29360128) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1147     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 29368320 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 925         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 29376512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024489276 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0258     |\n",
      "|    mean_step_reward   | 0.13558659  |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.178       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 871        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 29384704   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02947624 |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.977      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0624    |\n",
      "|    mean_step_reward   | 0.1319401  |\n",
      "|    n_updates          | 8/128)     |\n",
      "|    policyGradLoss     | -0.0214    |\n",
      "|    value_loss         | 0.15       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 848         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 29392896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019695483 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0258      |\n",
      "|    mean_step_reward   | 0.13161597  |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 830         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 29401088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017400127 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.01       |\n",
      "|    mean_step_reward   | 0.12340221  |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.214       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 820        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 59         |\n",
      "|    total_timesteps    | 29409280   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02018512 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.952      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.023     |\n",
      "|    mean_step_reward   | 0.12604536 |\n",
      "|    n_updates          | 20/128)    |\n",
      "|    policyGradLoss     | -0.0178    |\n",
      "|    value_loss         | 0.27       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 29417472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017730754 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.042      |\n",
      "|    mean_step_reward   | 0.13306952  |\n",
      "|    n_updates          | 24/128)     |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.182       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 29425664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026715524 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0137     |\n",
      "|    mean_step_reward   | 0.13491082  |\n",
      "|    n_updates          | 28/128)     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.238       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 29433856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019676693 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0293     |\n",
      "|    mean_step_reward   | 0.11794931  |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.175       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 29442048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018208053 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0113      |\n",
      "|    mean_step_reward   | 0.13239023  |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.348       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 796        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 113        |\n",
      "|    total_timesteps    | 29450240   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03363253 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.976      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0734    |\n",
      "|    mean_step_reward   | 0.1350702  |\n",
      "|    n_updates          | 40/128)    |\n",
      "|    policyGradLoss     | -0.0218    |\n",
      "|    value_loss         | 0.135      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 29458432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024332006 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0687      |\n",
      "|    mean_step_reward   | 0.1168772   |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.264       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 789        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 134        |\n",
      "|    total_timesteps    | 29466624   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03268565 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.982      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0555     |\n",
      "|    mean_step_reward   | 0.14531311 |\n",
      "|    n_updates          | 48/128)    |\n",
      "|    policyGradLoss     | -0.0206    |\n",
      "|    value_loss         | 0.155      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 788        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 145        |\n",
      "|    total_timesteps    | 29474816   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02780208 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.975      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0618    |\n",
      "|    mean_step_reward   | 0.12231506 |\n",
      "|    n_updates          | 52/128)    |\n",
      "|    policyGradLoss     | -0.0183    |\n",
      "|    value_loss         | 0.127      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 29483008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026580859 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0589     |\n",
      "|    mean_step_reward   | 0.122324646 |\n",
      "|    n_updates          | 56/128)     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.214       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 29491200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027720958 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0533     |\n",
      "|    mean_step_reward   | 0.13012111  |\n",
      "|    n_updates          | 60/128)     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.181       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 29499392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027702874 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.000721    |\n",
      "|    mean_step_reward   | 0.12902823  |\n",
      "|    n_updates          | 64/128)     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.248       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 784        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 188        |\n",
      "|    total_timesteps    | 29507584   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02940057 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.963      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0527    |\n",
      "|    mean_step_reward   | 0.12015176 |\n",
      "|    n_updates          | 68/128)    |\n",
      "|    policyGradLoss     | -0.0198    |\n",
      "|    value_loss         | 0.24       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 29515776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032654725 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0728     |\n",
      "|    mean_step_reward   | 0.13669488  |\n",
      "|    n_updates          | 72/128)     |\n",
      "|    policyGradLoss     | -0.0232     |\n",
      "|    value_loss         | 0.117       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 783        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 209        |\n",
      "|    total_timesteps    | 29523968   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02889784 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.963      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0422    |\n",
      "|    mean_step_reward   | 0.12213511 |\n",
      "|    n_updates          | 76/128)    |\n",
      "|    policyGradLoss     | -0.0221    |\n",
      "|    value_loss         | 0.244      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 29532160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026705705 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00976     |\n",
      "|    mean_step_reward   | 0.11622462  |\n",
      "|    n_updates          | 80/128)     |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.249       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 29540352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024047062 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00824    |\n",
      "|    mean_step_reward   | 0.12693256  |\n",
      "|    n_updates          | 84/128)     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.255       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 29548544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028289855 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0219     |\n",
      "|    mean_step_reward   | 0.11703588  |\n",
      "|    n_updates          | 88/128)     |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.243       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 29556736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021760404 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.000772    |\n",
      "|    mean_step_reward   | 0.13580802  |\n",
      "|    n_updates          | 92/128)     |\n",
      "|    policyGradLoss     | -0.012      |\n",
      "|    value_loss         | 0.271       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 29564928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020515535 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0121      |\n",
      "|    mean_step_reward   | 0.12499207  |\n",
      "|    n_updates          | 96/128)     |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.234       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 29573120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018999234 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00814    |\n",
      "|    mean_step_reward   | 0.113983065 |\n",
      "|    n_updates          | 100/128)    |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.298       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 29581312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027459718 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0439     |\n",
      "|    mean_step_reward   | 0.120956    |\n",
      "|    n_updates          | 104/128)    |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.22        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 294        |\n",
      "|    total_timesteps    | 29589504   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03017294 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.96       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0481    |\n",
      "|    mean_step_reward   | 0.11618883 |\n",
      "|    n_updates          | 108/128)   |\n",
      "|    policyGradLoss     | -0.0191    |\n",
      "|    value_loss         | 0.289      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 29597696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034785803 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0573     |\n",
      "|    mean_step_reward   | 0.13751459  |\n",
      "|    n_updates          | 112/128)    |\n",
      "|    policyGradLoss     | -0.0242     |\n",
      "|    value_loss         | 0.152       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 29605888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029674992 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0149      |\n",
      "|    mean_step_reward   | 0.1102649   |\n",
      "|    n_updates          | 116/128)    |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 29614080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025201619 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0018     |\n",
      "|    mean_step_reward   | 0.14762746  |\n",
      "|    n_updates          | 120/128)    |\n",
      "|    policyGradLoss     | -0.0148     |\n",
      "|    value_loss         | 0.226       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 29622272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027871959 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0624     |\n",
      "|    mean_step_reward   | 0.11017276  |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.142       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_112.zip\n",
      "[EVAL] Mean Return: 155.014, Best Return: 162.014\n",
      "Saved video to ./runs_smw/videos/Run/Run_112_155.01.mp4\n",
      "\n",
      "=== Round 114 | Learn 262144 steps (Total trained: 29622272) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1240     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 29630464 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 963         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 29638656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028970234 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0565     |\n",
      "|    mean_step_reward   | 0.113157764 |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.0213     |\n",
      "|    value_loss         | 0.178       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 881         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 29646848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016650701 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0616      |\n",
      "|    mean_step_reward   | 0.12136604  |\n",
      "|    n_updates          | 8/128)      |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.312       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 853         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 29655040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027687808 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.049      |\n",
      "|    mean_step_reward   | 0.13313077  |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.021      |\n",
      "|    value_loss         | 0.175       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 835         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 29663232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027299028 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0155     |\n",
      "|    mean_step_reward   | 0.12673242  |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.189       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 29671424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019958511 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.053       |\n",
      "|    mean_step_reward   | 0.12775788  |\n",
      "|    n_updates          | 20/128)     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.225       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 810        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 70         |\n",
      "|    total_timesteps    | 29679616   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03469701 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.986      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0646    |\n",
      "|    mean_step_reward   | 0.13648158 |\n",
      "|    n_updates          | 24/128)    |\n",
      "|    policyGradLoss     | -0.023     |\n",
      "|    value_loss         | 0.117      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 29687808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032374848 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00118    |\n",
      "|    mean_step_reward   | 0.122392796 |\n",
      "|    n_updates          | 28/128)     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.302       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 800        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 92         |\n",
      "|    total_timesteps    | 29696000   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03694319 |\n",
      "|    entropy_loss       | -1.74      |\n",
      "|    explained_variance | 0.986      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0724    |\n",
      "|    mean_step_reward   | 0.14034192 |\n",
      "|    n_updates          | 32/128)    |\n",
      "|    policyGradLoss     | -0.0232    |\n",
      "|    value_loss         | 0.0964     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 29704192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028406575 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0327     |\n",
      "|    mean_step_reward   | 0.12776473  |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.177       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 29712384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034861196 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0656     |\n",
      "|    mean_step_reward   | 0.13277696  |\n",
      "|    n_updates          | 40/128)     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.193       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 29720576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026753655 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0159     |\n",
      "|    mean_step_reward   | 0.13152313  |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.195       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 29728768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032399468 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0686     |\n",
      "|    mean_step_reward   | 0.12913266  |\n",
      "|    n_updates          | 48/128)     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.233       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 29736960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028912988 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.044      |\n",
      "|    mean_step_reward   | 0.12288007  |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.192       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 29745152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019330313 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0349      |\n",
      "|    mean_step_reward   | 0.12116432  |\n",
      "|    n_updates          | 56/128)     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.357       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 29753344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024157014 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.042      |\n",
      "|    mean_step_reward   | 0.14125909  |\n",
      "|    n_updates          | 60/128)     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.178       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 29761536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032575898 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0784     |\n",
      "|    mean_step_reward   | 0.123440936 |\n",
      "|    n_updates          | 64/128)     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.116       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 786        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 187        |\n",
      "|    total_timesteps    | 29769728   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03144625 |\n",
      "|    entropy_loss       | -1.72      |\n",
      "|    explained_variance | 0.969      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0237     |\n",
      "|    mean_step_reward   | 0.13350928 |\n",
      "|    n_updates          | 68/128)    |\n",
      "|    policyGradLoss     | -0.0174    |\n",
      "|    value_loss         | 0.223      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 29777920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015637914 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0488      |\n",
      "|    mean_step_reward   | 0.10387588  |\n",
      "|    n_updates          | 72/128)     |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.359       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 29786112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023474902 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0223     |\n",
      "|    mean_step_reward   | 0.14035404  |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.263       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 783        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 219        |\n",
      "|    total_timesteps    | 29794304   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03277176 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.969      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0283    |\n",
      "|    mean_step_reward   | 0.10809548 |\n",
      "|    n_updates          | 80/128)    |\n",
      "|    policyGradLoss     | -0.0203    |\n",
      "|    value_loss         | 0.164      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 29802496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028369086 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0732     |\n",
      "|    mean_step_reward   | 0.15213913  |\n",
      "|    n_updates          | 84/128)     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.163       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 29810688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027050974 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0117      |\n",
      "|    mean_step_reward   | 0.10117002  |\n",
      "|    n_updates          | 88/128)     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.324       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 29818880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025432061 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.049      |\n",
      "|    mean_step_reward   | 0.14502764  |\n",
      "|    n_updates          | 92/128)     |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.211       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 29827072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024709951 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00363     |\n",
      "|    mean_step_reward   | 0.11548937  |\n",
      "|    n_updates          | 96/128)     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.237       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 29835264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027886366 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.048      |\n",
      "|    mean_step_reward   | 0.14109218  |\n",
      "|    n_updates          | 100/128)    |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.199       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 780        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 283        |\n",
      "|    total_timesteps    | 29843456   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02767503 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.966      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0318    |\n",
      "|    mean_step_reward   | 0.12658346 |\n",
      "|    n_updates          | 104/128)   |\n",
      "|    policyGradLoss     | -0.0194    |\n",
      "|    value_loss         | 0.178      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 29851648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022182707 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0863      |\n",
      "|    mean_step_reward   | 0.10732121  |\n",
      "|    n_updates          | 108/128)    |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.353       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 29859840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021362612 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0445     |\n",
      "|    mean_step_reward   | 0.13458613  |\n",
      "|    n_updates          | 112/128)    |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.182       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 29868032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031937964 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0611     |\n",
      "|    mean_step_reward   | 0.11985568  |\n",
      "|    n_updates          | 116/128)    |\n",
      "|    policyGradLoss     | -0.0237     |\n",
      "|    value_loss         | 0.166       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 29876224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019994931 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0208      |\n",
      "|    mean_step_reward   | 0.12696011  |\n",
      "|    n_updates          | 120/128)    |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.282       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 29884416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026250854 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0651     |\n",
      "|    mean_step_reward   | 0.12486586  |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.0221     |\n",
      "|    value_loss         | 0.186       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_113.zip\n",
      "[EVAL] Mean Return: 141.885, Best Return: 148.885\n",
      "Saved video to ./runs_smw/videos/Run/Run_113_141.89.mp4\n",
      "\n",
      "=== Round 115 | Learn 262144 steps (Total trained: 29884416) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1148     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 29892608 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 920         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 29900800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025913639 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0108     |\n",
      "|    mean_step_reward   | 0.10197947  |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.316       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 867        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 29908992   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03879699 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.961      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0461    |\n",
      "|    mean_step_reward   | 0.12636885 |\n",
      "|    n_updates          | 8/128)     |\n",
      "|    policyGradLoss     | -0.0178    |\n",
      "|    value_loss         | 0.26       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 847         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 29917184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019748826 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.047      |\n",
      "|    mean_step_reward   | 0.1212708   |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.195       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 828         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 29925376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.035187304 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0637     |\n",
      "|    mean_step_reward   | 0.13688883  |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.124       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 818        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 29933568   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03620609 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.977      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0572    |\n",
      "|    mean_step_reward   | 0.12525058 |\n",
      "|    n_updates          | 20/128)    |\n",
      "|    policyGradLoss     | -0.0191    |\n",
      "|    value_loss         | 0.14       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 29941760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024870763 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0513     |\n",
      "|    mean_step_reward   | 0.13775888  |\n",
      "|    n_updates          | 24/128)     |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.194       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 806        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 81         |\n",
      "|    total_timesteps    | 29949952   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.033849   |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.982      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0712    |\n",
      "|    mean_step_reward   | 0.13358554 |\n",
      "|    n_updates          | 28/128)    |\n",
      "|    policyGradLoss     | -0.0206    |\n",
      "|    value_loss         | 0.128      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 29958144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031566687 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0466     |\n",
      "|    mean_step_reward   | 0.13276838  |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.166       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 29966336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023972873 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00362    |\n",
      "|    mean_step_reward   | 0.117876336 |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.235       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 29974528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021364365 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0592     |\n",
      "|    mean_step_reward   | 0.1410938   |\n",
      "|    n_updates          | 40/128)     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.127       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 29982720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031859428 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0567     |\n",
      "|    mean_step_reward   | 0.13805972  |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.135       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 29990912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025913008 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0359     |\n",
      "|    mean_step_reward   | 0.13431998  |\n",
      "|    n_updates          | 48/128)     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.178       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 29999104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.036409106 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0679     |\n",
      "|    mean_step_reward   | 0.13992995  |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.115       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 30007296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032279164 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0522     |\n",
      "|    mean_step_reward   | 0.13320032  |\n",
      "|    n_updates          | 56/128)     |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.176       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 30015488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033658363 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0458     |\n",
      "|    mean_step_reward   | 0.12865944  |\n",
      "|    n_updates          | 60/128)     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.158       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 30023680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025178056 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0249     |\n",
      "|    mean_step_reward   | 0.123575225 |\n",
      "|    n_updates          | 64/128)     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.291       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 789        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 186        |\n",
      "|    total_timesteps    | 30031872   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02637951 |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.954      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0238    |\n",
      "|    mean_step_reward   | 0.1142039  |\n",
      "|    n_updates          | 68/128)    |\n",
      "|    policyGradLoss     | -0.0182    |\n",
      "|    value_loss         | 0.292      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 197         |\n",
      "|    total_timesteps    | 30040064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024651533 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0345     |\n",
      "|    mean_step_reward   | 0.13251448  |\n",
      "|    n_updates          | 72/128)     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.158       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 30048256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033835836 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0621     |\n",
      "|    mean_step_reward   | 0.12429617  |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.185       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 217         |\n",
      "|    total_timesteps    | 30056448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034845777 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0717     |\n",
      "|    mean_step_reward   | 0.1450882   |\n",
      "|    n_updates          | 80/128)     |\n",
      "|    policyGradLoss     | -0.0228     |\n",
      "|    value_loss         | 0.127       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 226         |\n",
      "|    total_timesteps    | 30064640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02221096  |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0329      |\n",
      "|    mean_step_reward   | 0.123145126 |\n",
      "|    n_updates          | 84/128)     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.124       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 235         |\n",
      "|    total_timesteps    | 30072832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.039835453 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0411     |\n",
      "|    mean_step_reward   | 0.14320475  |\n",
      "|    n_updates          | 88/128)     |\n",
      "|    policyGradLoss     | -0.0212     |\n",
      "|    value_loss         | 0.154       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 245         |\n",
      "|    total_timesteps    | 30081024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023840386 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0495     |\n",
      "|    mean_step_reward   | 0.1265701   |\n",
      "|    n_updates          | 92/128)     |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.148       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 256         |\n",
      "|    total_timesteps    | 30089216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033208366 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0159      |\n",
      "|    mean_step_reward   | 0.13797936  |\n",
      "|    n_updates          | 96/128)     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.179       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 267         |\n",
      "|    total_timesteps    | 30097408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.041743368 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0511     |\n",
      "|    mean_step_reward   | 0.13894583  |\n",
      "|    n_updates          | 100/128)    |\n",
      "|    policyGradLoss     | -0.0219     |\n",
      "|    value_loss         | 0.11        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 278         |\n",
      "|    total_timesteps    | 30105600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031442963 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0513     |\n",
      "|    mean_step_reward   | 0.11965714  |\n",
      "|    n_updates          | 104/128)    |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.133       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 288         |\n",
      "|    total_timesteps    | 30113792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024770848 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00248    |\n",
      "|    mean_step_reward   | 0.1453664   |\n",
      "|    n_updates          | 108/128)    |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.233       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 299         |\n",
      "|    total_timesteps    | 30121984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030544989 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0501     |\n",
      "|    mean_step_reward   | 0.1258085   |\n",
      "|    n_updates          | 112/128)    |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.109       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 310         |\n",
      "|    total_timesteps    | 30130176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031557318 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0713     |\n",
      "|    mean_step_reward   | 0.14966959  |\n",
      "|    n_updates          | 116/128)    |\n",
      "|    policyGradLoss     | -0.022      |\n",
      "|    value_loss         | 0.115       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 791        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 320        |\n",
      "|    total_timesteps    | 30138368   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02617281 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.963      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0332    |\n",
      "|    mean_step_reward   | 0.11071323 |\n",
      "|    n_updates          | 120/128)   |\n",
      "|    policyGradLoss     | -0.0192    |\n",
      "|    value_loss         | 0.253      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 331         |\n",
      "|    total_timesteps    | 30146560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026172101 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0249      |\n",
      "|    mean_step_reward   | 0.13116191  |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.244       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_114.zip\n",
      "[EVAL] Mean Return: 148.648, Best Return: 150.648\n",
      "Saved video to ./runs_smw/videos/Run/Run_114_148.65.mp4\n",
      "\n",
      "=== Round 116 | Learn 262144 steps (Total trained: 30146560) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1115     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 30154752 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 918        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 30162944   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02956019 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.975      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0256     |\n",
      "|    mean_step_reward   | 0.14850517 |\n",
      "|    n_updates          | 4/128)     |\n",
      "|    policyGradLoss     | -0.017     |\n",
      "|    value_loss         | 0.188      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 863         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 30171136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029936843 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0333     |\n",
      "|    mean_step_reward   | 0.116329946 |\n",
      "|    n_updates          | 8/128)      |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.157       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 30179328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029091058 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0489     |\n",
      "|    mean_step_reward   | 0.14517403  |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.181       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 30187520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022229766 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0476     |\n",
      "|    mean_step_reward   | 0.11427279  |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.181       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 30195712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033875156 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0569     |\n",
      "|    mean_step_reward   | 0.14709128  |\n",
      "|    n_updates          | 20/128)     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 30203904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028583793 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.057      |\n",
      "|    mean_step_reward   | 0.11765322  |\n",
      "|    n_updates          | 24/128)     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.139       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 30212096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025382858 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00457     |\n",
      "|    mean_step_reward   | 0.12326144  |\n",
      "|    n_updates          | 28/128)     |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.298       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 30220288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01890078  |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00369    |\n",
      "|    mean_step_reward   | 0.124980345 |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.267       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 30228480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030695695 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0271     |\n",
      "|    mean_step_reward   | 0.12958328  |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.214       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 30236672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025045492 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00902    |\n",
      "|    mean_step_reward   | 0.121765286 |\n",
      "|    n_updates          | 40/128)     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.234       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 30244864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023924686 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.051      |\n",
      "|    mean_step_reward   | 0.13068455  |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.194       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 795        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 133        |\n",
      "|    total_timesteps    | 30253056   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03038283 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.972      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0386    |\n",
      "|    mean_step_reward   | 0.13276535 |\n",
      "|    n_updates          | 48/128)    |\n",
      "|    policyGradLoss     | -0.0177    |\n",
      "|    value_loss         | 0.162      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 30261248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029100463 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0617     |\n",
      "|    mean_step_reward   | 0.13349818  |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.203       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 792        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 155        |\n",
      "|    total_timesteps    | 30269440   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03079538 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.971      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0499    |\n",
      "|    mean_step_reward   | 0.12811548 |\n",
      "|    n_updates          | 56/128)    |\n",
      "|    policyGradLoss     | -0.0193    |\n",
      "|    value_loss         | 0.166      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 791        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 165        |\n",
      "|    total_timesteps    | 30277632   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03482187 |\n",
      "|    entropy_loss       | -1.76      |\n",
      "|    explained_variance | 0.979      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0612    |\n",
      "|    mean_step_reward   | 0.1332142  |\n",
      "|    n_updates          | 60/128)    |\n",
      "|    policyGradLoss     | -0.0229    |\n",
      "|    value_loss         | 0.142      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 30285824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023530299 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0165     |\n",
      "|    mean_step_reward   | 0.11300912  |\n",
      "|    n_updates          | 64/128)     |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.218       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 789        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 186        |\n",
      "|    total_timesteps    | 30294016   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02739447 |\n",
      "|    entropy_loss       | -1.72      |\n",
      "|    explained_variance | 0.98       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0373    |\n",
      "|    mean_step_reward   | 0.1460568  |\n",
      "|    n_updates          | 68/128)    |\n",
      "|    policyGradLoss     | -0.0159    |\n",
      "|    value_loss         | 0.162      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 789        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 197        |\n",
      "|    total_timesteps    | 30302208   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03178342 |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.928      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0224    |\n",
      "|    mean_step_reward   | 0.12093119 |\n",
      "|    n_updates          | 72/128)    |\n",
      "|    policyGradLoss     | -0.0144    |\n",
      "|    value_loss         | 0.227      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 207         |\n",
      "|    total_timesteps    | 30310400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029174678 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0449     |\n",
      "|    mean_step_reward   | 0.14415824  |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0129     |\n",
      "|    value_loss         | 0.221       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 218         |\n",
      "|    total_timesteps    | 30318592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031227998 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0531     |\n",
      "|    mean_step_reward   | 0.113669254 |\n",
      "|    n_updates          | 80/128)     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.162       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 30326784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033230565 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0759     |\n",
      "|    mean_step_reward   | 0.1505776   |\n",
      "|    n_updates          | 84/128)     |\n",
      "|    policyGradLoss     | -0.022      |\n",
      "|    value_loss         | 0.0945      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 239         |\n",
      "|    total_timesteps    | 30334976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029782252 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0548     |\n",
      "|    mean_step_reward   | 0.11204099  |\n",
      "|    n_updates          | 88/128)     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.149       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 785        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 250        |\n",
      "|    total_timesteps    | 30343168   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02559305 |\n",
      "|    entropy_loss       | -1.72      |\n",
      "|    explained_variance | 0.961      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0112     |\n",
      "|    mean_step_reward   | 0.15068878 |\n",
      "|    n_updates          | 92/128)    |\n",
      "|    policyGradLoss     | -0.0178    |\n",
      "|    value_loss         | 0.255      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 260         |\n",
      "|    total_timesteps    | 30351360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029799232 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0037     |\n",
      "|    mean_step_reward   | 0.094272286 |\n",
      "|    n_updates          | 96/128)     |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.318       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 30359552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022879496 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0445     |\n",
      "|    mean_step_reward   | 0.14081214  |\n",
      "|    n_updates          | 100/128)    |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.208       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 281         |\n",
      "|    total_timesteps    | 30367744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024405431 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0367     |\n",
      "|    mean_step_reward   | 0.11446354  |\n",
      "|    n_updates          | 104/128)    |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.241       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 30375936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021773692 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00834    |\n",
      "|    mean_step_reward   | 0.12042387  |\n",
      "|    n_updates          | 108/128)    |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.237       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 303         |\n",
      "|    total_timesteps    | 30384128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017037079 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0222     |\n",
      "|    mean_step_reward   | 0.121430434 |\n",
      "|    n_updates          | 112/128)    |\n",
      "|    policyGradLoss     | -0.0122     |\n",
      "|    value_loss         | 0.245       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 313         |\n",
      "|    total_timesteps    | 30392320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027089646 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0476     |\n",
      "|    mean_step_reward   | 0.12850021  |\n",
      "|    n_updates          | 116/128)    |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.266       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 321         |\n",
      "|    total_timesteps    | 30400512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020216255 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0386     |\n",
      "|    mean_step_reward   | 0.122093454 |\n",
      "|    n_updates          | 120/128)    |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.199       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 30408704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019216016 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0642     |\n",
      "|    mean_step_reward   | 0.124299474 |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.19        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_115.zip\n",
      "[EVAL] Mean Return: 157.340, Best Return: 164.340\n",
      "Saved video to ./runs_smw/videos/Run/Run_115_157.34.mp4\n",
      "\n",
      "=== Round 117 | Learn 262144 steps (Total trained: 30408704) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1559     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 30416896 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1013        |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 16          |\n",
      "|    total_timesteps    | 30425088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025446584 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0109      |\n",
      "|    mean_step_reward   | 0.119474925 |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.367       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 915        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 26         |\n",
      "|    total_timesteps    | 30433280   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03447687 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.972      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0453    |\n",
      "|    mean_step_reward   | 0.12851569 |\n",
      "|    n_updates          | 8/128)     |\n",
      "|    policyGradLoss     | -0.0176    |\n",
      "|    value_loss         | 0.167      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 877        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 37         |\n",
      "|    total_timesteps    | 30441472   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0297082  |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.961      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0732    |\n",
      "|    mean_step_reward   | 0.12867713 |\n",
      "|    n_updates          | 12/128)    |\n",
      "|    policyGradLoss     | -0.0198    |\n",
      "|    value_loss         | 0.192      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 853         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 47          |\n",
      "|    total_timesteps    | 30449664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031582404 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0603     |\n",
      "|    mean_step_reward   | 0.1313993   |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.136       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 842        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 58         |\n",
      "|    total_timesteps    | 30457856   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02661929 |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.973      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.062     |\n",
      "|    mean_step_reward   | 0.13691798 |\n",
      "|    n_updates          | 20/128)    |\n",
      "|    policyGradLoss     | -0.0202    |\n",
      "|    value_loss         | 0.144      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 829        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 69         |\n",
      "|    total_timesteps    | 30466048   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02626668 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.962      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0417    |\n",
      "|    mean_step_reward   | 0.11698042 |\n",
      "|    n_updates          | 24/128)    |\n",
      "|    policyGradLoss     | -0.0149    |\n",
      "|    value_loss         | 0.207      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 819        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 79         |\n",
      "|    total_timesteps    | 30474240   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.04631549 |\n",
      "|    entropy_loss       | -1.76      |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0648    |\n",
      "|    mean_step_reward   | 0.14232391 |\n",
      "|    n_updates          | 28/128)    |\n",
      "|    policyGradLoss     | -0.0218    |\n",
      "|    value_loss         | 0.117      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 90          |\n",
      "|    total_timesteps    | 30482432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030457748 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0314     |\n",
      "|    mean_step_reward   | 0.12470682  |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.0224     |\n",
      "|    value_loss         | 0.166       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 101         |\n",
      "|    total_timesteps    | 30490624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024901412 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0398     |\n",
      "|    mean_step_reward   | 0.13006882  |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.229       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 112         |\n",
      "|    total_timesteps    | 30498816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027016941 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0412     |\n",
      "|    mean_step_reward   | 0.11716539  |\n",
      "|    n_updates          | 40/128)     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.281       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 122         |\n",
      "|    total_timesteps    | 30507008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026583506 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0599     |\n",
      "|    mean_step_reward   | 0.12761778  |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.189       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 133         |\n",
      "|    total_timesteps    | 30515200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024621606 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0257     |\n",
      "|    mean_step_reward   | 0.1263546   |\n",
      "|    n_updates          | 48/128)     |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.232       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 30523392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020428382 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.048      |\n",
      "|    mean_step_reward   | 0.11824297  |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.233       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 30531584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018058129 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0419      |\n",
      "|    mean_step_reward   | 0.10633343  |\n",
      "|    n_updates          | 56/128)     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.362       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 30539776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024851762 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0316      |\n",
      "|    mean_step_reward   | 0.12774394  |\n",
      "|    n_updates          | 60/128)     |\n",
      "|    policyGradLoss     | -0.0213     |\n",
      "|    value_loss         | 0.214       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 30547968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028866291 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0207     |\n",
      "|    mean_step_reward   | 0.12340188  |\n",
      "|    n_updates          | 64/128)     |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.179       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 787        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 187        |\n",
      "|    total_timesteps    | 30556160   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03079551 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.958      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0548    |\n",
      "|    mean_step_reward   | 0.12494512 |\n",
      "|    n_updates          | 68/128)    |\n",
      "|    policyGradLoss     | -0.017     |\n",
      "|    value_loss         | 0.217      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 197         |\n",
      "|    total_timesteps    | 30564352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02792918  |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0417     |\n",
      "|    mean_step_reward   | 0.122416124 |\n",
      "|    n_updates          | 72/128)     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 207         |\n",
      "|    total_timesteps    | 30572544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016765596 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0344      |\n",
      "|    mean_step_reward   | 0.13412419  |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0132     |\n",
      "|    value_loss         | 0.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 218         |\n",
      "|    total_timesteps    | 30580736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025913723 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0152     |\n",
      "|    mean_step_reward   | 0.13228536  |\n",
      "|    n_updates          | 80/128)     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.203       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 30588928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019234784 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0232     |\n",
      "|    mean_step_reward   | 0.12094012  |\n",
      "|    n_updates          | 84/128)     |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.234       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 30597120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022812411 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0603     |\n",
      "|    mean_step_reward   | 0.11683203  |\n",
      "|    n_updates          | 88/128)     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.229       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 30605312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023616452 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0392     |\n",
      "|    mean_step_reward   | 0.13301602  |\n",
      "|    n_updates          | 92/128)     |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.261       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 30613504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023727644 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0319     |\n",
      "|    mean_step_reward   | 0.10989759  |\n",
      "|    n_updates          | 96/128)     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.261       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 30621696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022581086 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00288     |\n",
      "|    mean_step_reward   | 0.13093273  |\n",
      "|    n_updates          | 100/128)    |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.374       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 30629888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02755227  |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.047      |\n",
      "|    mean_step_reward   | 0.121499754 |\n",
      "|    n_updates          | 104/128)    |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.141       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 30638080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022182116 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0125      |\n",
      "|    mean_step_reward   | 0.12651211  |\n",
      "|    n_updates          | 108/128)    |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.294       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 30646272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026294023 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0474     |\n",
      "|    mean_step_reward   | 0.11403078  |\n",
      "|    n_updates          | 112/128)    |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 315        |\n",
      "|    total_timesteps    | 30654464   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01870189 |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.965      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0492     |\n",
      "|    mean_step_reward   | 0.11983788 |\n",
      "|    n_updates          | 116/128)   |\n",
      "|    policyGradLoss     | -0.0168    |\n",
      "|    value_loss         | 0.322      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 30662656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033302676 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0584     |\n",
      "|    mean_step_reward   | 0.12986411  |\n",
      "|    n_updates          | 120/128)    |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 30670848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028639793 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0245      |\n",
      "|    mean_step_reward   | 0.11323489  |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.239       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_116.zip\n",
      "[EVAL] Mean Return: 155.796, Best Return: 162.463\n",
      "Saved video to ./runs_smw/videos/Run/Run_116_155.80.mp4\n",
      "\n",
      "=== Round 118 | Learn 262144 steps (Total trained: 30670848) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1128     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 30679040 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 905         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 30687232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032410376 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0624     |\n",
      "|    mean_step_reward   | 0.116913274 |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.023      |\n",
      "|    value_loss         | 0.125       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 856         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 30695424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023821456 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0486     |\n",
      "|    mean_step_reward   | 0.13489878  |\n",
      "|    n_updates          | 8/128)      |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.188       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 833         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 30703616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023904819 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0467     |\n",
      "|    mean_step_reward   | 0.118472    |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.201       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 30711808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026958698 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0108      |\n",
      "|    mean_step_reward   | 0.13871717  |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.255       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 30720000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020559873 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0258     |\n",
      "|    mean_step_reward   | 0.11817868  |\n",
      "|    n_updates          | 20/128)     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.26        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 801        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 71         |\n",
      "|    total_timesteps    | 30728192   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02276253 |\n",
      "|    entropy_loss       | -1.76      |\n",
      "|    explained_variance | 0.964      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0121     |\n",
      "|    mean_step_reward   | 0.12989944 |\n",
      "|    n_updates          | 24/128)    |\n",
      "|    policyGradLoss     | -0.0172    |\n",
      "|    value_loss         | 0.263      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 30736384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019165447 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0119      |\n",
      "|    mean_step_reward   | 0.11834175  |\n",
      "|    n_updates          | 28/128)     |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.317       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 30744576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024051964 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0256      |\n",
      "|    mean_step_reward   | 0.13064122  |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.0139     |\n",
      "|    value_loss         | 0.311       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 30752768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026345026 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.072      |\n",
      "|    mean_step_reward   | 0.13560654  |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 30760960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028647091 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0365     |\n",
      "|    mean_step_reward   | 0.12477816  |\n",
      "|    n_updates          | 40/128)     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.226       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 30769152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026077464 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0427     |\n",
      "|    mean_step_reward   | 0.13672872  |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 30777344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021039762 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00892    |\n",
      "|    mean_step_reward   | 0.11257694  |\n",
      "|    n_updates          | 48/128)     |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.253       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 30785536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027673764 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0546     |\n",
      "|    mean_step_reward   | 0.14572838  |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.152       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 30793728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023961116 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0169     |\n",
      "|    mean_step_reward   | 0.12271419  |\n",
      "|    n_updates          | 56/128)     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.214       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 30801920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021016665 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0999      |\n",
      "|    mean_step_reward   | 0.13255511  |\n",
      "|    n_updates          | 60/128)     |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.259       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 30810112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013967562 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0225     |\n",
      "|    mean_step_reward   | 0.12576278  |\n",
      "|    n_updates          | 64/128)     |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.244       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 30818304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023672307 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0194     |\n",
      "|    mean_step_reward   | 0.13215339  |\n",
      "|    n_updates          | 68/128)     |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.235       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 30826496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027635368 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0319     |\n",
      "|    mean_step_reward   | 0.12694556  |\n",
      "|    n_updates          | 72/128)     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.245       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 30834688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022881117 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0076     |\n",
      "|    mean_step_reward   | 0.10338779  |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.408       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 30842880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027416877 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0708     |\n",
      "|    mean_step_reward   | 0.1500304   |\n",
      "|    n_updates          | 80/128)     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.173       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 231        |\n",
      "|    total_timesteps    | 30851072   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02762482 |\n",
      "|    entropy_loss       | -1.86      |\n",
      "|    explained_variance | 0.962      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0444    |\n",
      "|    mean_step_reward   | 0.10817535 |\n",
      "|    n_updates          | 84/128)    |\n",
      "|    policyGradLoss     | -0.0179    |\n",
      "|    value_loss         | 0.242      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 30859264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019753143 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0184     |\n",
      "|    mean_step_reward   | 0.14085945  |\n",
      "|    n_updates          | 88/128)     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 30867456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020220436 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0433      |\n",
      "|    mean_step_reward   | 0.10189652  |\n",
      "|    n_updates          | 92/128)     |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.403       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 30875648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020028498 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.000355   |\n",
      "|    mean_step_reward   | 0.14641061  |\n",
      "|    n_updates          | 96/128)     |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.263       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 30883840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027136553 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0639     |\n",
      "|    mean_step_reward   | 0.12426259  |\n",
      "|    n_updates          | 100/128)    |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.117       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 284        |\n",
      "|    total_timesteps    | 30892032   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02504743 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.971      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0428    |\n",
      "|    mean_step_reward   | 0.13735482 |\n",
      "|    n_updates          | 104/128)   |\n",
      "|    policyGradLoss     | -0.0176    |\n",
      "|    value_loss         | 0.198      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 30900224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026500434 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0592      |\n",
      "|    mean_step_reward   | 0.109538466 |\n",
      "|    n_updates          | 108/128)    |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.242       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 30908416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024640935 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.026      |\n",
      "|    mean_step_reward   | 0.14881521  |\n",
      "|    n_updates          | 112/128)    |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.188       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 30916608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030905169 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0337     |\n",
      "|    mean_step_reward   | 0.11352241  |\n",
      "|    n_updates          | 116/128)    |\n",
      "|    policyGradLoss     | -0.0231     |\n",
      "|    value_loss         | 0.179       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 30924800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019591257 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00929    |\n",
      "|    mean_step_reward   | 0.13255703  |\n",
      "|    n_updates          | 120/128)    |\n",
      "|    policyGradLoss     | -0.0148     |\n",
      "|    value_loss         | 0.304       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 30932992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020286506 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 7.62e-05    |\n",
      "|    mean_step_reward   | 0.11216068  |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.353       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_117.zip\n",
      "[EVAL] Mean Return: 153.361, Best Return: 160.194\n",
      "Saved video to ./runs_smw/videos/Run/Run_117_153.36.mp4\n",
      "\n",
      "=== Round 119 | Learn 262144 steps (Total trained: 30932992) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1116     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 30941184 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 899         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 30949376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025275424 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0695     |\n",
      "|    mean_step_reward   | 0.106309816 |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.232       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 852         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 30957568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029154252 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0681     |\n",
      "|    mean_step_reward   | 0.15070572  |\n",
      "|    n_updates          | 8/128)      |\n",
      "|    policyGradLoss     | -0.0211     |\n",
      "|    value_loss         | 0.172       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 832         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 30965760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025542494 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0852     |\n",
      "|    mean_step_reward   | 0.12960012  |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.107       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 30973952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029290248 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0445     |\n",
      "|    mean_step_reward   | 0.1433492   |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.151       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 30982144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026976138 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0382     |\n",
      "|    mean_step_reward   | 0.12518454  |\n",
      "|    n_updates          | 20/128)     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.193       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 30990336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021436248 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00472    |\n",
      "|    mean_step_reward   | 0.12623453  |\n",
      "|    n_updates          | 24/128)     |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.229       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 30998528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019405589 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0473     |\n",
      "|    mean_step_reward   | 0.12911698  |\n",
      "|    n_updates          | 28/128)     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 31006720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025904182 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0216      |\n",
      "|    mean_step_reward   | 0.12352781  |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.258       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 31014912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026614515 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0922      |\n",
      "|    mean_step_reward   | 0.13886878  |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.217       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 795        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 113        |\n",
      "|    total_timesteps    | 31023104   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03505682 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.978      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0534    |\n",
      "|    mean_step_reward   | 0.1273329  |\n",
      "|    n_updates          | 40/128)    |\n",
      "|    policyGradLoss     | -0.0196    |\n",
      "|    value_loss         | 0.146      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 31031296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028993335 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0654     |\n",
      "|    mean_step_reward   | 0.12787108  |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.156       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 792        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 134        |\n",
      "|    total_timesteps    | 31039488   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03030179 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.962      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0952     |\n",
      "|    mean_step_reward   | 0.11094247 |\n",
      "|    n_updates          | 48/128)    |\n",
      "|    policyGradLoss     | -0.0163    |\n",
      "|    value_loss         | 0.283      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 31047680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029770859 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0625     |\n",
      "|    mean_step_reward   | 0.13739145  |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.179       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 788        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 155        |\n",
      "|    total_timesteps    | 31055872   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03257292 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.964      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0508    |\n",
      "|    mean_step_reward   | 0.11186294 |\n",
      "|    n_updates          | 56/128)    |\n",
      "|    policyGradLoss     | -0.0192    |\n",
      "|    value_loss         | 0.178      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 31064064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028723458 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.042      |\n",
      "|    mean_step_reward   | 0.13671696  |\n",
      "|    n_updates          | 60/128)     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.179       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 31072256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029802082 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0607     |\n",
      "|    mean_step_reward   | 0.13107058  |\n",
      "|    n_updates          | 64/128)     |\n",
      "|    policyGradLoss     | -0.0213     |\n",
      "|    value_loss         | 0.118       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 31080448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029461056 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0513     |\n",
      "|    mean_step_reward   | 0.13484457  |\n",
      "|    n_updates          | 68/128)     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.199       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 785        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 198        |\n",
      "|    total_timesteps    | 31088640   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02078459 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.974      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00681   |\n",
      "|    mean_step_reward   | 0.13794012 |\n",
      "|    n_updates          | 72/128)    |\n",
      "|    policyGradLoss     | -0.0167    |\n",
      "|    value_loss         | 0.2        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 31096832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026261594 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0101      |\n",
      "|    mean_step_reward   | 0.12521729  |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 31105024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02927145  |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0602     |\n",
      "|    mean_step_reward   | 0.121146165 |\n",
      "|    n_updates          | 80/128)     |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.223       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 31113216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014564959 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0238      |\n",
      "|    mean_step_reward   | 0.13146205  |\n",
      "|    n_updates          | 84/128)     |\n",
      "|    policyGradLoss     | -0.0114     |\n",
      "|    value_loss         | 0.302       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 788        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 239        |\n",
      "|    total_timesteps    | 31121408   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01758676 |\n",
      "|    entropy_loss       | -1.76      |\n",
      "|    explained_variance | 0.969      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0112    |\n",
      "|    mean_step_reward   | 0.12890303 |\n",
      "|    n_updates          | 88/128)    |\n",
      "|    policyGradLoss     | -0.0168    |\n",
      "|    value_loss         | 0.211      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 249         |\n",
      "|    total_timesteps    | 31129600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026948307 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0584     |\n",
      "|    mean_step_reward   | 0.12471248  |\n",
      "|    n_updates          | 92/128)     |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 260         |\n",
      "|    total_timesteps    | 31137792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018153913 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.025       |\n",
      "|    mean_step_reward   | 0.12161256  |\n",
      "|    n_updates          | 96/128)     |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.348       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 31145984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01760288  |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0262     |\n",
      "|    mean_step_reward   | 0.124343075 |\n",
      "|    n_updates          | 100/128)    |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.226       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 281         |\n",
      "|    total_timesteps    | 31154176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027359232 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0547     |\n",
      "|    mean_step_reward   | 0.12243997  |\n",
      "|    n_updates          | 104/128)    |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.297       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 31162368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.075194    |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00729    |\n",
      "|    mean_step_reward   | 0.123821825 |\n",
      "|    n_updates          | 108/128)    |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.216       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 783        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 303        |\n",
      "|    total_timesteps    | 31170560   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03266993 |\n",
      "|    entropy_loss       | -1.74      |\n",
      "|    explained_variance | 0.965      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00281   |\n",
      "|    mean_step_reward   | 0.13654383 |\n",
      "|    n_updates          | 112/128)   |\n",
      "|    policyGradLoss     | -0.0184    |\n",
      "|    value_loss         | 0.246      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 313         |\n",
      "|    total_timesteps    | 31178752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032903347 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0419      |\n",
      "|    mean_step_reward   | 0.13451754  |\n",
      "|    n_updates          | 116/128)    |\n",
      "|    policyGradLoss     | -0.0211     |\n",
      "|    value_loss         | 0.14        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 782        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 324        |\n",
      "|    total_timesteps    | 31186944   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03044971 |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.971      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0496    |\n",
      "|    mean_step_reward   | 0.12271219 |\n",
      "|    n_updates          | 120/128)   |\n",
      "|    policyGradLoss     | -0.0211    |\n",
      "|    value_loss         | 0.2        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 334         |\n",
      "|    total_timesteps    | 31195136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028458858 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.039      |\n",
      "|    mean_step_reward   | 0.13418181  |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.174       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_118.zip\n",
      "[EVAL] Mean Return: 152.646, Best Return: 159.979\n",
      "Saved video to ./runs_smw/videos/Run/Run_118_152.65.mp4\n",
      "\n",
      "=== Round 120 | Learn 262144 steps (Total trained: 31195136) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1127     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 31203328 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 917         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 31211520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030815192 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00623    |\n",
      "|    mean_step_reward   | 0.13153856  |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.252       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 864        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 31219712   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03191393 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.965      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0154    |\n",
      "|    mean_step_reward   | 0.10871345 |\n",
      "|    n_updates          | 8/128)     |\n",
      "|    policyGradLoss     | -0.0158    |\n",
      "|    value_loss         | 0.262      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 833         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 31227904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029695932 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0694     |\n",
      "|    mean_step_reward   | 0.13854548  |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.127       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 31236096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029608544 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0304     |\n",
      "|    mean_step_reward   | 0.12548637  |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.185       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 809        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 31244288   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02485755 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.97       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0121    |\n",
      "|    mean_step_reward   | 0.13075843 |\n",
      "|    n_updates          | 20/128)    |\n",
      "|    policyGradLoss     | -0.0149    |\n",
      "|    value_loss         | 0.264      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 31252480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029558962 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0452     |\n",
      "|    mean_step_reward   | 0.12476151  |\n",
      "|    n_updates          | 24/128)     |\n",
      "|    policyGradLoss     | -0.0209     |\n",
      "|    value_loss         | 0.201       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 31260672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023786228 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0245     |\n",
      "|    mean_step_reward   | 0.13586146  |\n",
      "|    n_updates          | 28/128)     |\n",
      "|    policyGradLoss     | -0.0132     |\n",
      "|    value_loss         | 0.162       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 31268864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024242371 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0196     |\n",
      "|    mean_step_reward   | 0.13690269  |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.254       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 31277056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028509164 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0485      |\n",
      "|    mean_step_reward   | 0.1332904   |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.158       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 31285248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024363175 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0413     |\n",
      "|    mean_step_reward   | 0.14086956  |\n",
      "|    n_updates          | 40/128)     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 31293440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026368558 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0388     |\n",
      "|    mean_step_reward   | 0.12583676  |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.174       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 31301632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034433603 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0543     |\n",
      "|    mean_step_reward   | 0.14282174  |\n",
      "|    n_updates          | 48/128)     |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.162       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 31309824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017850865 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0365      |\n",
      "|    mean_step_reward   | 0.120279595 |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.247       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 788        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 155        |\n",
      "|    total_timesteps    | 31318016   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02478094 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.98       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.063     |\n",
      "|    mean_step_reward   | 0.13893558 |\n",
      "|    n_updates          | 56/128)    |\n",
      "|    policyGradLoss     | -0.0194    |\n",
      "|    value_loss         | 0.136      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 31326208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.03000744  |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.045      |\n",
      "|    mean_step_reward   | 0.113875166 |\n",
      "|    n_updates          | 60/128)     |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.209       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 786        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 177        |\n",
      "|    total_timesteps    | 31334400   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02507805 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.972      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0335    |\n",
      "|    mean_step_reward   | 0.15128069 |\n",
      "|    n_updates          | 64/128)    |\n",
      "|    policyGradLoss     | -0.0167    |\n",
      "|    value_loss         | 0.205      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 784        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 188        |\n",
      "|    total_timesteps    | 31342592   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02537729 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.966      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0427    |\n",
      "|    mean_step_reward   | 0.11741071 |\n",
      "|    n_updates          | 68/128)    |\n",
      "|    policyGradLoss     | -0.0184    |\n",
      "|    value_loss         | 0.182      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 31350784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029942583 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0468     |\n",
      "|    mean_step_reward   | 0.14717677  |\n",
      "|    n_updates          | 72/128)     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.157       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 31358976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025619341 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0502     |\n",
      "|    mean_step_reward   | 0.104089275 |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.153       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 31367168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029960241 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0433     |\n",
      "|    mean_step_reward   | 0.12616563  |\n",
      "|    n_updates          | 80/128)     |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.206       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 31375360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018789597 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0192      |\n",
      "|    mean_step_reward   | 0.116869174 |\n",
      "|    n_updates          | 84/128)     |\n",
      "|    policyGradLoss     | -0.0133     |\n",
      "|    value_loss         | 0.247       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 31383552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026263053 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0385     |\n",
      "|    mean_step_reward   | 0.15617621  |\n",
      "|    n_updates          | 88/128)     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.194       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 31391744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028678428 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0551     |\n",
      "|    mean_step_reward   | 0.12277682  |\n",
      "|    n_updates          | 92/128)     |\n",
      "|    policyGradLoss     | -0.021      |\n",
      "|    value_loss         | 0.11        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 781        |\n",
      "|    iterations         | 25         |\n",
      "|    time_elapsed       | 261        |\n",
      "|    total_timesteps    | 31399936   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0183925  |\n",
      "|    entropy_loss       | -1.72      |\n",
      "|    explained_variance | 0.976      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0338    |\n",
      "|    mean_step_reward   | 0.15023333 |\n",
      "|    n_updates          | 96/128)    |\n",
      "|    policyGradLoss     | -0.0168    |\n",
      "|    value_loss         | 0.205      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 31408128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024533674 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0488     |\n",
      "|    mean_step_reward   | 0.11177701  |\n",
      "|    n_updates          | 100/128)    |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.212       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 31416320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028302625 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0418     |\n",
      "|    mean_step_reward   | 0.14064243  |\n",
      "|    n_updates          | 104/128)    |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.186       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 294        |\n",
      "|    total_timesteps    | 31424512   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02424382 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.973      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0294    |\n",
      "|    mean_step_reward   | 0.12483912 |\n",
      "|    n_updates          | 108/128)   |\n",
      "|    policyGradLoss     | -0.0175    |\n",
      "|    value_loss         | 0.174      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 31432704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026438262 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0703     |\n",
      "|    mean_step_reward   | 0.13353328  |\n",
      "|    n_updates          | 112/128)    |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 31440896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016641283 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0286     |\n",
      "|    mean_step_reward   | 0.13058001  |\n",
      "|    n_updates          | 116/128)    |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.165       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 31449088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022744464 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0535     |\n",
      "|    mean_step_reward   | 0.11258438  |\n",
      "|    n_updates          | 120/128)    |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 31457280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018746976 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0277      |\n",
      "|    mean_step_reward   | 0.13555348  |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.0132     |\n",
      "|    value_loss         | 0.295       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_119.zip\n",
      "[EVAL] Mean Return: 104.782, Best Return: 108.782\n",
      "Saved video to ./runs_smw/videos/Run/Run_119_104.78.mp4\n",
      "\n",
      "=== Round 121 | Learn 262144 steps (Total trained: 31457280) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1149     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 31465472 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 932         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 31473664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030813208 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0715     |\n",
      "|    mean_step_reward   | 0.13640255  |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.136       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 872         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 31481856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031223206 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0216     |\n",
      "|    mean_step_reward   | 0.13372996  |\n",
      "|    n_updates          | 8/128)      |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.251       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 847         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 31490048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024017097 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0311     |\n",
      "|    mean_step_reward   | 0.1346355   |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 833        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 49         |\n",
      "|    total_timesteps    | 31498240   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03504628 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.977      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0554    |\n",
      "|    mean_step_reward   | 0.1345781  |\n",
      "|    n_updates          | 16/128)    |\n",
      "|    policyGradLoss     | -0.0194    |\n",
      "|    value_loss         | 0.191      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 31506432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027062401 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0237      |\n",
      "|    mean_step_reward   | 0.12072446  |\n",
      "|    n_updates          | 20/128)     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.303       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 31514624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029738285 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0351      |\n",
      "|    mean_step_reward   | 0.14086674  |\n",
      "|    n_updates          | 24/128)     |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.288       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 80          |\n",
      "|    total_timesteps    | 31522816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029193271 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0584     |\n",
      "|    mean_step_reward   | 0.12733716  |\n",
      "|    n_updates          | 28/128)     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.139       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 807        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 91         |\n",
      "|    total_timesteps    | 31531008   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02890183 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.963      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0276     |\n",
      "|    mean_step_reward   | 0.12901923 |\n",
      "|    n_updates          | 32/128)    |\n",
      "|    policyGradLoss     | -0.0165    |\n",
      "|    value_loss         | 0.302      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 101         |\n",
      "|    total_timesteps    | 31539200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019854812 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.912       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0367     |\n",
      "|    mean_step_reward   | 0.13173059  |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.0106     |\n",
      "|    value_loss         | 0.289       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 803        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 112        |\n",
      "|    total_timesteps    | 31547392   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02020583 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0421    |\n",
      "|    mean_step_reward   | 0.1442485  |\n",
      "|    n_updates          | 40/128)    |\n",
      "|    policyGradLoss     | -0.0181    |\n",
      "|    value_loss         | 0.134      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 122         |\n",
      "|    total_timesteps    | 31555584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024638716 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0321     |\n",
      "|    mean_step_reward   | 0.11953491  |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.238       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 799        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 133        |\n",
      "|    total_timesteps    | 31563776   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02665955 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.967      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0109    |\n",
      "|    mean_step_reward   | 0.12485771 |\n",
      "|    n_updates          | 48/128)    |\n",
      "|    policyGradLoss     | -0.0182    |\n",
      "|    value_loss         | 0.225      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 143         |\n",
      "|    total_timesteps    | 31571968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026473824 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0384     |\n",
      "|    mean_step_reward   | 0.13148746  |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.2         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 795        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 154        |\n",
      "|    total_timesteps    | 31580160   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03033315 |\n",
      "|    entropy_loss       | -1.74      |\n",
      "|    explained_variance | 0.984      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0571    |\n",
      "|    mean_step_reward   | 0.14239979 |\n",
      "|    n_updates          | 56/128)    |\n",
      "|    policyGradLoss     | -0.0229    |\n",
      "|    value_loss         | 0.122      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 164         |\n",
      "|    total_timesteps    | 31588352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021410331 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0107     |\n",
      "|    mean_step_reward   | 0.13218778  |\n",
      "|    n_updates          | 60/128)     |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.205       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 175         |\n",
      "|    total_timesteps    | 31596544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026255097 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0695     |\n",
      "|    mean_step_reward   | 0.12994011  |\n",
      "|    n_updates          | 64/128)     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.178       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 186         |\n",
      "|    total_timesteps    | 31604736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024603277 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0206     |\n",
      "|    mean_step_reward   | 0.13522077  |\n",
      "|    n_updates          | 68/128)     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.201       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 196         |\n",
      "|    total_timesteps    | 31612928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015839085 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0194     |\n",
      "|    mean_step_reward   | 0.12442741  |\n",
      "|    n_updates          | 72/128)     |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.209       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 207         |\n",
      "|    total_timesteps    | 31621120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018924814 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.032      |\n",
      "|    mean_step_reward   | 0.14186674  |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.169       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 218         |\n",
      "|    total_timesteps    | 31629312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028725538 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0331     |\n",
      "|    mean_step_reward   | 0.11811967  |\n",
      "|    n_updates          | 80/128)     |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 228         |\n",
      "|    total_timesteps    | 31637504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028430298 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.034      |\n",
      "|    mean_step_reward   | 0.1306662   |\n",
      "|    n_updates          | 84/128)     |\n",
      "|    policyGradLoss     | -0.0208     |\n",
      "|    value_loss         | 0.169       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 239         |\n",
      "|    total_timesteps    | 31645696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021428363 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0411     |\n",
      "|    mean_step_reward   | 0.1138092   |\n",
      "|    n_updates          | 88/128)     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.229       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 250         |\n",
      "|    total_timesteps    | 31653888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027611561 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0133     |\n",
      "|    mean_step_reward   | 0.13878241  |\n",
      "|    n_updates          | 92/128)     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.225       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 260         |\n",
      "|    total_timesteps    | 31662080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020755848 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0683     |\n",
      "|    mean_step_reward   | 0.12722063  |\n",
      "|    n_updates          | 96/128)     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.138       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 31670272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030919127 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0419     |\n",
      "|    mean_step_reward   | 0.14632088  |\n",
      "|    n_updates          | 100/128)    |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.133       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 31678464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021713313 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0512      |\n",
      "|    mean_step_reward   | 0.12909693  |\n",
      "|    n_updates          | 104/128)    |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.218       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 783        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 292        |\n",
      "|    total_timesteps    | 31686656   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03233228 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.066     |\n",
      "|    mean_step_reward   | 0.13865997 |\n",
      "|    n_updates          | 108/128)   |\n",
      "|    policyGradLoss     | -0.0234    |\n",
      "|    value_loss         | 0.0997     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 783        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 303        |\n",
      "|    total_timesteps    | 31694848   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03100506 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0704    |\n",
      "|    mean_step_reward   | 0.13141544 |\n",
      "|    n_updates          | 112/128)   |\n",
      "|    policyGradLoss     | -0.0198    |\n",
      "|    value_loss         | 0.0983     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 313         |\n",
      "|    total_timesteps    | 31703040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026127841 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0339     |\n",
      "|    mean_step_reward   | 0.14704868  |\n",
      "|    n_updates          | 116/128)    |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.13        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 782        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 324        |\n",
      "|    total_timesteps    | 31711232   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03163957 |\n",
      "|    entropy_loss       | -1.71      |\n",
      "|    explained_variance | 0.979      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0487    |\n",
      "|    mean_step_reward   | 0.13249227 |\n",
      "|    n_updates          | 120/128)   |\n",
      "|    policyGradLoss     | -0.0188    |\n",
      "|    value_loss         | 0.158      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 335         |\n",
      "|    total_timesteps    | 31719424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026474547 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.031      |\n",
      "|    mean_step_reward   | 0.13149744  |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.189       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_120.zip\n",
      "[EVAL] Mean Return: 156.234, Best Return: 163.234\n",
      "Saved video to ./runs_smw/videos/Run/Run_120_156.23.mp4\n",
      "\n",
      "=== Round 122 | Learn 262144 steps (Total trained: 31719424) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1131     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 31727616 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 923         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 31735808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028358687 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0556     |\n",
      "|    mean_step_reward   | 0.13351932  |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.127       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 866         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 31744000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022119235 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0245     |\n",
      "|    mean_step_reward   | 0.1529944   |\n",
      "|    n_updates          | 8/128)      |\n",
      "|    policyGradLoss     | -0.0136     |\n",
      "|    value_loss         | 0.167       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 31752192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026079703 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0133     |\n",
      "|    mean_step_reward   | 0.1195482   |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.226       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 31760384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.035454508 |\n",
      "|    entropy_loss       | -1.65       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0521     |\n",
      "|    mean_step_reward   | 0.15967897  |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.123       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 31768576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030114295 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0183     |\n",
      "|    mean_step_reward   | 0.10660186  |\n",
      "|    n_updates          | 20/128)     |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.196       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 31776768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027637294 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.038      |\n",
      "|    mean_step_reward   | 0.15654263  |\n",
      "|    n_updates          | 24/128)     |\n",
      "|    policyGradLoss     | -0.0136     |\n",
      "|    value_loss         | 0.206       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 31784960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018620577 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00636    |\n",
      "|    mean_step_reward   | 0.10676742  |\n",
      "|    n_updates          | 28/128)     |\n",
      "|    policyGradLoss     | -0.0137     |\n",
      "|    value_loss         | 0.173       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 31793152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023364102 |\n",
      "|    entropy_loss       | -1.68       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.046      |\n",
      "|    mean_step_reward   | 0.15439105  |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.163       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 795        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 102        |\n",
      "|    total_timesteps    | 31801344   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02824742 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.959      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.107      |\n",
      "|    mean_step_reward   | 0.11063362 |\n",
      "|    n_updates          | 36/128)    |\n",
      "|    policyGradLoss     | -0.0167    |\n",
      "|    value_loss         | 0.292      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 31809536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024163399 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0222     |\n",
      "|    mean_step_reward   | 0.15842883  |\n",
      "|    n_updates          | 40/128)     |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.145       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 31817728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019605428 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0431      |\n",
      "|    mean_step_reward   | 0.1125572   |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.3         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 788        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 135        |\n",
      "|    total_timesteps    | 31825920   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02631789 |\n",
      "|    entropy_loss       | -1.71      |\n",
      "|    explained_variance | 0.957      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0592     |\n",
      "|    mean_step_reward   | 0.1351622  |\n",
      "|    n_updates          | 48/128)    |\n",
      "|    policyGradLoss     | -0.0172    |\n",
      "|    value_loss         | 0.291      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 31834112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026784722 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0271     |\n",
      "|    mean_step_reward   | 0.12507111  |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.204       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 787        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 155        |\n",
      "|    total_timesteps    | 31842304   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02690123 |\n",
      "|    entropy_loss       | -1.71      |\n",
      "|    explained_variance | 0.971      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.000795  |\n",
      "|    mean_step_reward   | 0.13423795 |\n",
      "|    n_updates          | 56/128)    |\n",
      "|    policyGradLoss     | -0.0171    |\n",
      "|    value_loss         | 0.233      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 785        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 166        |\n",
      "|    total_timesteps    | 31850496   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03125432 |\n",
      "|    entropy_loss       | -1.76      |\n",
      "|    explained_variance | 0.968      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0487    |\n",
      "|    mean_step_reward   | 0.12622622 |\n",
      "|    n_updates          | 60/128)    |\n",
      "|    policyGradLoss     | -0.0177    |\n",
      "|    value_loss         | 0.188      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 31858688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022821385 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00302     |\n",
      "|    mean_step_reward   | 0.12531926  |\n",
      "|    n_updates          | 64/128)     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.335       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 31866880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032517128 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0511     |\n",
      "|    mean_step_reward   | 0.14014769  |\n",
      "|    n_updates          | 68/128)     |\n",
      "|    policyGradLoss     | -0.0214     |\n",
      "|    value_loss         | 0.139       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 780        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 199        |\n",
      "|    total_timesteps    | 31875072   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02498959 |\n",
      "|    entropy_loss       | -1.76      |\n",
      "|    explained_variance | 0.967      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0297    |\n",
      "|    mean_step_reward   | 0.12777567 |\n",
      "|    n_updates          | 72/128)    |\n",
      "|    policyGradLoss     | -0.0179    |\n",
      "|    value_loss         | 0.2        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 31883264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027373694 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0204     |\n",
      "|    mean_step_reward   | 0.12823743  |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.262       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 31891456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021544741 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.000473    |\n",
      "|    mean_step_reward   | 0.119022496 |\n",
      "|    n_updates          | 80/128)     |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.317       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 31899648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022576276 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0384     |\n",
      "|    mean_step_reward   | 0.1327519   |\n",
      "|    n_updates          | 84/128)     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 31907840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021247853 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0472      |\n",
      "|    mean_step_reward   | 0.13579318  |\n",
      "|    n_updates          | 88/128)     |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.291       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 31916032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024626266 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0544     |\n",
      "|    mean_step_reward   | 0.13513574  |\n",
      "|    n_updates          | 92/128)     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 31924224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024515584 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0308     |\n",
      "|    mean_step_reward   | 0.13018638  |\n",
      "|    n_updates          | 96/128)     |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.27        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 273        |\n",
      "|    total_timesteps    | 31932416   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03428951 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.976      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0507    |\n",
      "|    mean_step_reward   | 0.1393733  |\n",
      "|    n_updates          | 100/128)   |\n",
      "|    policyGradLoss     | -0.0211    |\n",
      "|    value_loss         | 0.138      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 284        |\n",
      "|    total_timesteps    | 31940608   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0321816  |\n",
      "|    entropy_loss       | -1.76      |\n",
      "|    explained_variance | 0.969      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0528    |\n",
      "|    mean_step_reward   | 0.12944956 |\n",
      "|    n_updates          | 104/128)   |\n",
      "|    policyGradLoss     | -0.0191    |\n",
      "|    value_loss         | 0.164      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 31948800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026446093 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0508     |\n",
      "|    mean_step_reward   | 0.13403417  |\n",
      "|    n_updates          | 108/128)    |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.223       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 31956992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026004635 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0321      |\n",
      "|    mean_step_reward   | 0.119407296 |\n",
      "|    n_updates          | 112/128)    |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.252       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 31965184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018022517 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00954    |\n",
      "|    mean_step_reward   | 0.14506564  |\n",
      "|    n_updates          | 116/128)    |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.268       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 31973376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025048211 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00483    |\n",
      "|    mean_step_reward   | 0.12452249  |\n",
      "|    n_updates          | 120/128)    |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 31981568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032228827 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0655     |\n",
      "|    mean_step_reward   | 0.14972803  |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.112       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_121.zip\n",
      "[EVAL] Mean Return: 155.886, Best Return: 162.886\n",
      "Saved video to ./runs_smw/videos/Run/Run_121_155.89.mp4\n",
      "\n",
      "=== Round 123 | Learn 262144 steps (Total trained: 31981568) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1125     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 31989760 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 915         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 31997952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029759385 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0289     |\n",
      "|    mean_step_reward   | 0.13861832  |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.208       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 851         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 32006144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029570285 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0235     |\n",
      "|    mean_step_reward   | 0.12511873  |\n",
      "|    n_updates          | 8/128)      |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.219       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 835         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 32014336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.037397698 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00729    |\n",
      "|    mean_step_reward   | 0.13795422  |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.229       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 32022528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026750453 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0175      |\n",
      "|    mean_step_reward   | 0.122950934 |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.255       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 816        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 32030720   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02076361 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.969      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0213    |\n",
      "|    mean_step_reward   | 0.11616637 |\n",
      "|    n_updates          | 20/128)    |\n",
      "|    policyGradLoss     | -0.0155    |\n",
      "|    value_loss         | 0.27       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 812        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 70         |\n",
      "|    total_timesteps    | 32038912   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03419245 |\n",
      "|    entropy_loss       | -1.72      |\n",
      "|    explained_variance | 0.976      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0422    |\n",
      "|    mean_step_reward   | 0.14150855 |\n",
      "|    n_updates          | 24/128)    |\n",
      "|    policyGradLoss     | -0.02      |\n",
      "|    value_loss         | 0.176      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 808        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 81         |\n",
      "|    total_timesteps    | 32047104   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03406381 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.971      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0115    |\n",
      "|    mean_step_reward   | 0.12823758 |\n",
      "|    n_updates          | 28/128)    |\n",
      "|    policyGradLoss     | -0.0175    |\n",
      "|    value_loss         | 0.198      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 32055296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021014959 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0308     |\n",
      "|    mean_step_reward   | 0.13154373  |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.171       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 32063488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029880501 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0558     |\n",
      "|    mean_step_reward   | 0.106530935 |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 32071680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025243536 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0309     |\n",
      "|    mean_step_reward   | 0.116918124 |\n",
      "|    n_updates          | 40/128)     |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.212       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 32079872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022193782 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0627     |\n",
      "|    mean_step_reward   | 0.12783152  |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.158       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 32088064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033148315 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0195     |\n",
      "|    mean_step_reward   | 0.13532816  |\n",
      "|    n_updates          | 48/128)     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.277       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 787        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 145        |\n",
      "|    total_timesteps    | 32096256   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03563319 |\n",
      "|    entropy_loss       | -1.72      |\n",
      "|    explained_variance | 0.971      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0475    |\n",
      "|    mean_step_reward   | 0.1374659  |\n",
      "|    n_updates          | 52/128)    |\n",
      "|    policyGradLoss     | -0.0196    |\n",
      "|    value_loss         | 0.197      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 786        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 156        |\n",
      "|    total_timesteps    | 32104448   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02349802 |\n",
      "|    entropy_loss       | -1.76      |\n",
      "|    explained_variance | 0.946      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0974     |\n",
      "|    mean_step_reward   | 0.12456945 |\n",
      "|    n_updates          | 56/128)    |\n",
      "|    policyGradLoss     | -0.0125    |\n",
      "|    value_loss         | 0.401      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 784        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 167        |\n",
      "|    total_timesteps    | 32112640   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02973357 |\n",
      "|    entropy_loss       | -1.74      |\n",
      "|    explained_variance | 0.983      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0847    |\n",
      "|    mean_step_reward   | 0.14779052 |\n",
      "|    n_updates          | 60/128)    |\n",
      "|    policyGradLoss     | -0.0218    |\n",
      "|    value_loss         | 0.115      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 32120832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023146678 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0193      |\n",
      "|    mean_step_reward   | 0.1138054   |\n",
      "|    n_updates          | 64/128)     |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.256       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 32129024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031053541 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0232     |\n",
      "|    mean_step_reward   | 0.13243568  |\n",
      "|    n_updates          | 68/128)     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.216       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 32137216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020392846 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0312     |\n",
      "|    mean_step_reward   | 0.12973943  |\n",
      "|    n_updates          | 72/128)     |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.215       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 32145408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028768353 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.033      |\n",
      "|    mean_step_reward   | 0.13300525  |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.247       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 32153600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015155327 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0254      |\n",
      "|    mean_step_reward   | 0.11261914  |\n",
      "|    n_updates          | 80/128)     |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.303       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 231        |\n",
      "|    total_timesteps    | 32161792   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03682876 |\n",
      "|    entropy_loss       | -1.72      |\n",
      "|    explained_variance | 0.979      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0504    |\n",
      "|    mean_step_reward   | 0.13446175 |\n",
      "|    n_updates          | 84/128)    |\n",
      "|    policyGradLoss     | -0.0226    |\n",
      "|    value_loss         | 0.173      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 32169984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030077623 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0401     |\n",
      "|    mean_step_reward   | 0.12932914  |\n",
      "|    n_updates          | 88/128)     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.169       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 252        |\n",
      "|    total_timesteps    | 32178176   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02190676 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.97       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0169    |\n",
      "|    mean_step_reward   | 0.13823497 |\n",
      "|    n_updates          | 92/128)    |\n",
      "|    policyGradLoss     | -0.0158    |\n",
      "|    value_loss         | 0.237      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 32186368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032633044 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0662     |\n",
      "|    mean_step_reward   | 0.124161996 |\n",
      "|    n_updates          | 96/128)     |\n",
      "|    policyGradLoss     | -0.0218     |\n",
      "|    value_loss         | 0.108       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 32194560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028145738 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.044      |\n",
      "|    mean_step_reward   | 0.13482566  |\n",
      "|    n_updates          | 100/128)    |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.215       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 776        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 284        |\n",
      "|    total_timesteps    | 32202752   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01698761 |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.966      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0144    |\n",
      "|    mean_step_reward   | 0.12703578 |\n",
      "|    n_updates          | 104/128)   |\n",
      "|    policyGradLoss     | -0.0141    |\n",
      "|    value_loss         | 0.243      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 32210944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030216945 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0423     |\n",
      "|    mean_step_reward   | 0.14572376  |\n",
      "|    n_updates          | 108/128)    |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 32219136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030547928 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0317     |\n",
      "|    mean_step_reward   | 0.112482116 |\n",
      "|    n_updates          | 112/128)    |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.192       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 32227328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034711674 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00625    |\n",
      "|    mean_step_reward   | 0.13755521  |\n",
      "|    n_updates          | 116/128)    |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.272       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 32235520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024837121 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00338     |\n",
      "|    mean_step_reward   | 0.106164075 |\n",
      "|    n_updates          | 120/128)    |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.253       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 32243712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026708122 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0188     |\n",
      "|    mean_step_reward   | 0.16022074  |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.221       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_122.zip\n",
      "[EVAL] Mean Return: 147.316, Best Return: 153.649\n",
      "Saved video to ./runs_smw/videos/Run/Run_122_147.32.mp4\n",
      "\n",
      "=== Round 124 | Learn 262144 steps (Total trained: 32243712) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1134     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 32251904 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 921         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 32260096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023646055 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0292     |\n",
      "|    mean_step_reward   | 0.14722605  |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 863         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 32268288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.035019606 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0719     |\n",
      "|    mean_step_reward   | 0.11044277  |\n",
      "|    n_updates          | 8/128)      |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.128       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 836         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 32276480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027730625 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00356     |\n",
      "|    mean_step_reward   | 0.1405769   |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.326       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 823         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 32284672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02608563  |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0571     |\n",
      "|    mean_step_reward   | 0.124772035 |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.168       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 32292864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029219372 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0667     |\n",
      "|    mean_step_reward   | 0.112809435 |\n",
      "|    n_updates          | 20/128)     |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.193       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 32301056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015100808 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0262      |\n",
      "|    mean_step_reward   | 0.13054599  |\n",
      "|    n_updates          | 24/128)     |\n",
      "|    policyGradLoss     | -0.011      |\n",
      "|    value_loss         | 0.406       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 32309248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033260584 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0252     |\n",
      "|    mean_step_reward   | 0.12235326  |\n",
      "|    n_updates          | 28/128)     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.171       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 32317440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018796133 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0924      |\n",
      "|    mean_step_reward   | 0.13609946  |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.391       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 32325632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026825365 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0127     |\n",
      "|    mean_step_reward   | 0.12309716  |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.302       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 792        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 113        |\n",
      "|    total_timesteps    | 32333824   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03139581 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.966      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0264    |\n",
      "|    mean_step_reward   | 0.13511886 |\n",
      "|    n_updates          | 40/128)    |\n",
      "|    policyGradLoss     | -0.023     |\n",
      "|    value_loss         | 0.214      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 32342016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026679888 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0356     |\n",
      "|    mean_step_reward   | 0.1184858   |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.203       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 32350208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016748644 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00686    |\n",
      "|    mean_step_reward   | 0.13096662  |\n",
      "|    n_updates          | 48/128)     |\n",
      "|    policyGradLoss     | -0.0141     |\n",
      "|    value_loss         | 0.256       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 32358400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023980051 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0507     |\n",
      "|    mean_step_reward   | 0.11810997  |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.238       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 32366592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023224823 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0493     |\n",
      "|    mean_step_reward   | 0.14113882  |\n",
      "|    n_updates          | 56/128)     |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.214       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 32374784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028471965 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0561     |\n",
      "|    mean_step_reward   | 0.11705811  |\n",
      "|    n_updates          | 60/128)     |\n",
      "|    policyGradLoss     | -0.0225     |\n",
      "|    value_loss         | 0.218       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 782        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 177        |\n",
      "|    total_timesteps    | 32382976   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02373915 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.949      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.083      |\n",
      "|    mean_step_reward   | 0.11220936 |\n",
      "|    n_updates          | 64/128)    |\n",
      "|    policyGradLoss     | -0.0176    |\n",
      "|    value_loss         | 0.422      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 32391168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027769184 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0405     |\n",
      "|    mean_step_reward   | 0.1266674   |\n",
      "|    n_updates          | 68/128)     |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.224       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 780        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 199        |\n",
      "|    total_timesteps    | 32399360   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0207876  |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0367    |\n",
      "|    mean_step_reward   | 0.12634079 |\n",
      "|    n_updates          | 72/128)    |\n",
      "|    policyGradLoss     | -0.0175    |\n",
      "|    value_loss         | 0.191      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 32407552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026667707 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0175     |\n",
      "|    mean_step_reward   | 0.12784459  |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.263       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 32415744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027235184 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0305     |\n",
      "|    mean_step_reward   | 0.132281    |\n",
      "|    n_updates          | 80/128)     |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.161       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 32423936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020815436 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0442     |\n",
      "|    mean_step_reward   | 0.13462584  |\n",
      "|    n_updates          | 84/128)     |\n",
      "|    policyGradLoss     | -0.0208     |\n",
      "|    value_loss         | 0.178       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 32432128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021438265 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0486     |\n",
      "|    mean_step_reward   | 0.13058148  |\n",
      "|    n_updates          | 88/128)     |\n",
      "|    policyGradLoss     | -0.0209     |\n",
      "|    value_loss         | 0.195       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 252        |\n",
      "|    total_timesteps    | 32440320   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03264205 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.982      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0475    |\n",
      "|    mean_step_reward   | 0.13419181 |\n",
      "|    n_updates          | 92/128)    |\n",
      "|    policyGradLoss     | -0.0228    |\n",
      "|    value_loss         | 0.116      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 32448512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027388655 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0276     |\n",
      "|    mean_step_reward   | 0.12626928  |\n",
      "|    n_updates          | 96/128)     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.208       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 32456704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023958765 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0277      |\n",
      "|    mean_step_reward   | 0.12838073  |\n",
      "|    n_updates          | 100/128)    |\n",
      "|    policyGradLoss     | -0.0148     |\n",
      "|    value_loss         | 0.343       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 32464896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028988041 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.017       |\n",
      "|    mean_step_reward   | 0.1184056   |\n",
      "|    n_updates          | 104/128)    |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.302       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 32473088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019679528 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0496      |\n",
      "|    mean_step_reward   | 0.12903646  |\n",
      "|    n_updates          | 108/128)    |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.274       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 32481280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033561867 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00485    |\n",
      "|    mean_step_reward   | 0.12503827  |\n",
      "|    n_updates          | 112/128)    |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.261       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 32489472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032072216 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0197     |\n",
      "|    mean_step_reward   | 0.12848833  |\n",
      "|    n_updates          | 116/128)    |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.261       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 32497664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032399446 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0719     |\n",
      "|    mean_step_reward   | 0.14064963  |\n",
      "|    n_updates          | 120/128)    |\n",
      "|    policyGradLoss     | -0.0211     |\n",
      "|    value_loss         | 0.125       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 32505856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028173113 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0279     |\n",
      "|    mean_step_reward   | 0.12993996  |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.215       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_123.zip\n",
      "[EVAL] Mean Return: 155.131, Best Return: 162.131\n",
      "Saved video to ./runs_smw/videos/Run/Run_123_155.13.mp4\n",
      "\n",
      "=== Round 125 | Learn 262144 steps (Total trained: 32505856) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1166     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 32514048 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 926         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 32522240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024723988 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0646     |\n",
      "|    mean_step_reward   | 0.1261124   |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.155       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 869         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 32530432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023301765 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0345     |\n",
      "|    mean_step_reward   | 0.13527253  |\n",
      "|    n_updates          | 8/128)      |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.202       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 847         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 32538624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020823285 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0275     |\n",
      "|    mean_step_reward   | 0.113337874 |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.169       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 828         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 32546816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030314736 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0607     |\n",
      "|    mean_step_reward   | 0.14035006  |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.0229     |\n",
      "|    value_loss         | 0.154       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 32555008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027050328 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0397     |\n",
      "|    mean_step_reward   | 0.11422593  |\n",
      "|    n_updates          | 20/128)     |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.232       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 32563200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030266855 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0406     |\n",
      "|    mean_step_reward   | 0.1328006   |\n",
      "|    n_updates          | 24/128)     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.248       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 32571392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028723804 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0407     |\n",
      "|    mean_step_reward   | 0.12778406  |\n",
      "|    n_updates          | 28/128)     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.196       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 32579584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020656237 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0161     |\n",
      "|    mean_step_reward   | 0.12983188  |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 32587776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032547705 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0734     |\n",
      "|    mean_step_reward   | 0.13539362  |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.134       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 32595968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017703442 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00145     |\n",
      "|    mean_step_reward   | 0.12831941  |\n",
      "|    n_updates          | 40/128)     |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.303       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 32604160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021614542 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0379     |\n",
      "|    mean_step_reward   | 0.13144821  |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.183       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 791        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 134        |\n",
      "|    total_timesteps    | 32612352   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02718437 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.965      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0293    |\n",
      "|    mean_step_reward   | 0.13271771 |\n",
      "|    n_updates          | 48/128)    |\n",
      "|    policyGradLoss     | -0.017     |\n",
      "|    value_loss         | 0.225      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 32620544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027561156 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0394     |\n",
      "|    mean_step_reward   | 0.12696052  |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.242       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 32628736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028995734 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.056      |\n",
      "|    mean_step_reward   | 0.14282075  |\n",
      "|    n_updates          | 56/128)     |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 32636928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019661386 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0127     |\n",
      "|    mean_step_reward   | 0.118397586 |\n",
      "|    n_updates          | 60/128)     |\n",
      "|    policyGradLoss     | -0.0129     |\n",
      "|    value_loss         | 0.345       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 32645120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023056146 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0316     |\n",
      "|    mean_step_reward   | 0.12554444  |\n",
      "|    n_updates          | 64/128)     |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.304       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 32653312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01792334  |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00357    |\n",
      "|    mean_step_reward   | 0.112050414 |\n",
      "|    n_updates          | 68/128)     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.308       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 197         |\n",
      "|    total_timesteps    | 32661504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028139181 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0533     |\n",
      "|    mean_step_reward   | 0.12018407  |\n",
      "|    n_updates          | 72/128)     |\n",
      "|    policyGradLoss     | -0.0218     |\n",
      "|    value_loss         | 0.246       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 32669696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026648935 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00931    |\n",
      "|    mean_step_reward   | 0.10971073  |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0212     |\n",
      "|    value_loss         | 0.273       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 32677888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024164198 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0587     |\n",
      "|    mean_step_reward   | 0.119993344 |\n",
      "|    n_updates          | 80/128)     |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.232       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 784        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 229        |\n",
      "|    total_timesteps    | 32686080   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02402627 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.964      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.025     |\n",
      "|    mean_step_reward   | 0.1299353  |\n",
      "|    n_updates          | 84/128)    |\n",
      "|    policyGradLoss     | -0.0202    |\n",
      "|    value_loss         | 0.244      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 239         |\n",
      "|    total_timesteps    | 32694272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016324496 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00437    |\n",
      "|    mean_step_reward   | 0.13367328  |\n",
      "|    n_updates          | 88/128)     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.229       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 250         |\n",
      "|    total_timesteps    | 32702464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022513926 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0508     |\n",
      "|    mean_step_reward   | 0.13821217  |\n",
      "|    n_updates          | 92/128)     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.195       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 32710656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027380388 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0386     |\n",
      "|    mean_step_reward   | 0.12321078  |\n",
      "|    n_updates          | 96/128)     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.212       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 783        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 271        |\n",
      "|    total_timesteps    | 32718848   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03084319 |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.979      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0594    |\n",
      "|    mean_step_reward   | 0.1364798  |\n",
      "|    n_updates          | 100/128)   |\n",
      "|    policyGradLoss     | -0.0224    |\n",
      "|    value_loss         | 0.169      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 32727040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023751095 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00666    |\n",
      "|    mean_step_reward   | 0.1320746   |\n",
      "|    n_updates          | 104/128)    |\n",
      "|    policyGradLoss     | -0.0217     |\n",
      "|    value_loss         | 0.223       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 32735232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027316242 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0112     |\n",
      "|    mean_step_reward   | 0.11950603  |\n",
      "|    n_updates          | 108/128)    |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.285       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 303         |\n",
      "|    total_timesteps    | 32743424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030274224 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0478     |\n",
      "|    mean_step_reward   | 0.13497636  |\n",
      "|    n_updates          | 112/128)    |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.244       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 314         |\n",
      "|    total_timesteps    | 32751616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031575315 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0713     |\n",
      "|    mean_step_reward   | 0.11965141  |\n",
      "|    n_updates          | 116/128)    |\n",
      "|    policyGradLoss     | -0.0272     |\n",
      "|    value_loss         | 0.107       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 32759808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028689224 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0227     |\n",
      "|    mean_step_reward   | 0.116234146 |\n",
      "|    n_updates          | 120/128)    |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.271       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 335         |\n",
      "|    total_timesteps    | 32768000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028996956 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.068      |\n",
      "|    mean_step_reward   | 0.12583786  |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.0224     |\n",
      "|    value_loss         | 0.143       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_124.zip\n",
      "[EVAL] Mean Return: 156.038, Best Return: 163.038\n",
      "Saved video to ./runs_smw/videos/Run/Run_124_156.04.mp4\n",
      "\n",
      "=== Round 126 | Learn 262144 steps (Total trained: 32768000) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1164     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 32776192 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 926         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 32784384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017093852 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0321     |\n",
      "|    mean_step_reward   | 0.124652    |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.259       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 866         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 32792576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028347004 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0323     |\n",
      "|    mean_step_reward   | 0.12991416  |\n",
      "|    n_updates          | 8/128)      |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.207       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 841         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 32800768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.039108913 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00404     |\n",
      "|    mean_step_reward   | 0.1200902   |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.0238     |\n",
      "|    value_loss         | 0.216       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 32808960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028354285 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0503     |\n",
      "|    mean_step_reward   | 0.13690458  |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.187       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 816        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 32817152   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02799691 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.976      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0385    |\n",
      "|    mean_step_reward   | 0.13205302 |\n",
      "|    n_updates          | 20/128)    |\n",
      "|    policyGradLoss     | -0.0182    |\n",
      "|    value_loss         | 0.202      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 32825344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019142825 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0271     |\n",
      "|    mean_step_reward   | 0.13394259  |\n",
      "|    n_updates          | 24/128)     |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.263       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 32833536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030282987 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.016      |\n",
      "|    mean_step_reward   | 0.12871934  |\n",
      "|    n_updates          | 28/128)     |\n",
      "|    policyGradLoss     | -0.0222     |\n",
      "|    value_loss         | 0.183       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 32841728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023298467 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0278     |\n",
      "|    mean_step_reward   | 0.13050243  |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.202       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 795        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 103        |\n",
      "|    total_timesteps    | 32849920   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03632545 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.966      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0482    |\n",
      "|    mean_step_reward   | 0.13415757 |\n",
      "|    n_updates          | 36/128)    |\n",
      "|    policyGradLoss     | -0.0222    |\n",
      "|    value_loss         | 0.188      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 32858112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034867723 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0548     |\n",
      "|    mean_step_reward   | 0.1176652   |\n",
      "|    n_updates          | 40/128)     |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.194       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 32866304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025754841 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0487     |\n",
      "|    mean_step_reward   | 0.13167128  |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.256       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 32874496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021428283 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0162     |\n",
      "|    mean_step_reward   | 0.119851306 |\n",
      "|    n_updates          | 48/128)     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.167       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 32882688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027396135 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0326     |\n",
      "|    mean_step_reward   | 0.12751752  |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.278       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 32890880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028078618 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0203     |\n",
      "|    mean_step_reward   | 0.12726015  |\n",
      "|    n_updates          | 56/128)     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.186       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 32899072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021467865 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0525     |\n",
      "|    mean_step_reward   | 0.12521383  |\n",
      "|    n_updates          | 60/128)     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.209       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 32907264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026128106 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.000585    |\n",
      "|    mean_step_reward   | 0.12009325  |\n",
      "|    n_updates          | 64/128)     |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.219       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 32915456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031278346 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0166      |\n",
      "|    mean_step_reward   | 0.12757352  |\n",
      "|    n_updates          | 68/128)     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.226       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 783        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 198        |\n",
      "|    total_timesteps    | 32923648   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02945736 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.973      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0624    |\n",
      "|    mean_step_reward   | 0.12512404 |\n",
      "|    n_updates          | 72/128)    |\n",
      "|    policyGradLoss     | -0.0187    |\n",
      "|    value_loss         | 0.168      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 782        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 209        |\n",
      "|    total_timesteps    | 32931840   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0228069  |\n",
      "|    entropy_loss       | -1.71      |\n",
      "|    explained_variance | 0.98       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0291    |\n",
      "|    mean_step_reward   | 0.14417219 |\n",
      "|    n_updates          | 76/128)    |\n",
      "|    policyGradLoss     | -0.0184    |\n",
      "|    value_loss         | 0.167      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 32940032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028398357 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0504     |\n",
      "|    mean_step_reward   | 0.115621395 |\n",
      "|    n_updates          | 80/128)     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.174       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 32948224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032513782 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0564     |\n",
      "|    mean_step_reward   | 0.14132315  |\n",
      "|    n_updates          | 84/128)     |\n",
      "|    policyGradLoss     | -0.0208     |\n",
      "|    value_loss         | 0.149       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 32956416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024595646 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0743     |\n",
      "|    mean_step_reward   | 0.12862596  |\n",
      "|    n_updates          | 88/128)     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.142       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 32964608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032052677 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0532     |\n",
      "|    mean_step_reward   | 0.14282396  |\n",
      "|    n_updates          | 92/128)     |\n",
      "|    policyGradLoss     | -0.0209     |\n",
      "|    value_loss         | 0.125       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 32972800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024552997 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0193     |\n",
      "|    mean_step_reward   | 0.12379137  |\n",
      "|    n_updates          | 96/128)     |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.202       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 780        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 272        |\n",
      "|    total_timesteps    | 32980992   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02158833 |\n",
      "|    entropy_loss       | -1.7       |\n",
      "|    explained_variance | 0.983      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0469    |\n",
      "|    mean_step_reward   | 0.1541535  |\n",
      "|    n_updates          | 100/128)   |\n",
      "|    policyGradLoss     | -0.0167    |\n",
      "|    value_loss         | 0.152      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 283        |\n",
      "|    total_timesteps    | 32989184   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0300904  |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.979      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0533    |\n",
      "|    mean_step_reward   | 0.12051709 |\n",
      "|    n_updates          | 104/128)   |\n",
      "|    policyGradLoss     | -0.0216    |\n",
      "|    value_loss         | 0.114      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 32997376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030517165 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0563     |\n",
      "|    mean_step_reward   | 0.14653146  |\n",
      "|    n_updates          | 108/128)    |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.149       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 305        |\n",
      "|    total_timesteps    | 33005568   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03117806 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0442    |\n",
      "|    mean_step_reward   | 0.12869859 |\n",
      "|    n_updates          | 112/128)   |\n",
      "|    policyGradLoss     | -0.0179    |\n",
      "|    value_loss         | 0.133      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 315        |\n",
      "|    total_timesteps    | 33013760   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03314233 |\n",
      "|    entropy_loss       | -1.68      |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0657    |\n",
      "|    mean_step_reward   | 0.1538867  |\n",
      "|    n_updates          | 116/128)   |\n",
      "|    policyGradLoss     | -0.0183    |\n",
      "|    value_loss         | 0.122      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 33021952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026877796 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0637     |\n",
      "|    mean_step_reward   | 0.120377205 |\n",
      "|    n_updates          | 120/128)    |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.136       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 33030144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026937712 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0183     |\n",
      "|    mean_step_reward   | 0.13925055  |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.297       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_125.zip\n",
      "[EVAL] Mean Return: 132.109, Best Return: 138.442\n",
      "Saved video to ./runs_smw/videos/Run/Run_125_132.11.mp4\n",
      "\n",
      "=== Round 127 | Learn 262144 steps (Total trained: 33030144) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1118     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 33038336 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 922         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 33046528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026390199 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0399     |\n",
      "|    mean_step_reward   | 0.13867328  |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 868         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 33054720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030485809 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0732     |\n",
      "|    mean_step_reward   | 0.13220543  |\n",
      "|    n_updates          | 8/128)      |\n",
      "|    policyGradLoss     | -0.022      |\n",
      "|    value_loss         | 0.099       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 840         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 33062912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030409647 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0673     |\n",
      "|    mean_step_reward   | 0.14046785  |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.021      |\n",
      "|    value_loss         | 0.141       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 33071104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030279856 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0751     |\n",
      "|    mean_step_reward   | 0.13423586  |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.024      |\n",
      "|    value_loss         | 0.104       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 33079296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019324888 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00296    |\n",
      "|    mean_step_reward   | 0.13726023  |\n",
      "|    n_updates          | 20/128)     |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.235       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 33087488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024432143 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.042      |\n",
      "|    mean_step_reward   | 0.1291414   |\n",
      "|    n_updates          | 24/128)     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.176       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 33095680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.037119422 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.000937    |\n",
      "|    mean_step_reward   | 0.13700733  |\n",
      "|    n_updates          | 28/128)     |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.163       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 33103872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026297804 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0502     |\n",
      "|    mean_step_reward   | 0.13926572  |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.182       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 33112064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02981186  |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0565     |\n",
      "|    mean_step_reward   | 0.122398876 |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.229       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 33120256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030215472 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00131     |\n",
      "|    mean_step_reward   | 0.14358756  |\n",
      "|    n_updates          | 40/128)     |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.276       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 33128448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019454166 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.031      |\n",
      "|    mean_step_reward   | 0.11574405  |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0121     |\n",
      "|    value_loss         | 0.206       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 33136640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031855997 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.052      |\n",
      "|    mean_step_reward   | 0.1352326   |\n",
      "|    n_updates          | 48/128)     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.214       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 33144832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016733352 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0255     |\n",
      "|    mean_step_reward   | 0.112851635 |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.179       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 33153024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028226074 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0539     |\n",
      "|    mean_step_reward   | 0.1351119   |\n",
      "|    n_updates          | 56/128)     |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 33161216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028705318 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0587     |\n",
      "|    mean_step_reward   | 0.13229683  |\n",
      "|    n_updates          | 60/128)     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.145       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 781        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 178        |\n",
      "|    total_timesteps    | 33169408   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03263336 |\n",
      "|    entropy_loss       | -1.74      |\n",
      "|    explained_variance | 0.973      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0174    |\n",
      "|    mean_step_reward   | 0.1309672  |\n",
      "|    n_updates          | 64/128)    |\n",
      "|    policyGradLoss     | -0.0189    |\n",
      "|    value_loss         | 0.206      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 33177600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028253702 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0435     |\n",
      "|    mean_step_reward   | 0.13996717  |\n",
      "|    n_updates          | 68/128)     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.123       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 780        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 199        |\n",
      "|    total_timesteps    | 33185792   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03148002 |\n",
      "|    entropy_loss       | -1.74      |\n",
      "|    explained_variance | 0.982      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0571    |\n",
      "|    mean_step_reward   | 0.14078933 |\n",
      "|    n_updates          | 72/128)    |\n",
      "|    policyGradLoss     | -0.022     |\n",
      "|    value_loss         | 0.119      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 33193984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030506238 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0347     |\n",
      "|    mean_step_reward   | 0.114422426 |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.191       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 33202176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028667156 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0667     |\n",
      "|    mean_step_reward   | 0.14465341  |\n",
      "|    n_updates          | 80/128)     |\n",
      "|    policyGradLoss     | -0.0224     |\n",
      "|    value_loss         | 0.149       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 33210368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023219746 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0272      |\n",
      "|    mean_step_reward   | 0.1148657   |\n",
      "|    n_updates          | 84/128)     |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.323       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 33218560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027983429 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0436     |\n",
      "|    mean_step_reward   | 0.14774588  |\n",
      "|    n_updates          | 88/128)     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 252        |\n",
      "|    total_timesteps    | 33226752   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01893436 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.894      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0202    |\n",
      "|    mean_step_reward   | 0.10719485 |\n",
      "|    n_updates          | 92/128)    |\n",
      "|    policyGradLoss     | -0.0143    |\n",
      "|    value_loss         | 0.398      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 33234944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025426742 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00302    |\n",
      "|    mean_step_reward   | 0.14684024  |\n",
      "|    n_updates          | 96/128)     |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.281       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 33243136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028164286 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0438     |\n",
      "|    mean_step_reward   | 0.10845934  |\n",
      "|    n_updates          | 100/128)    |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.186       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 33251328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030808192 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0553     |\n",
      "|    mean_step_reward   | 0.15583786  |\n",
      "|    n_updates          | 104/128)    |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.149       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 294        |\n",
      "|    total_timesteps    | 33259520   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01778766 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.942      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0671     |\n",
      "|    mean_step_reward   | 0.11707138 |\n",
      "|    n_updates          | 108/128)   |\n",
      "|    policyGradLoss     | -0.0124    |\n",
      "|    value_loss         | 0.382      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 33267712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029220313 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0147     |\n",
      "|    mean_step_reward   | 0.1414811   |\n",
      "|    n_updates          | 112/128)    |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.302       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 33275904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025859047 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0543     |\n",
      "|    mean_step_reward   | 0.11429578  |\n",
      "|    n_updates          | 116/128)    |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.201       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 33284096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028064083 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0204     |\n",
      "|    mean_step_reward   | 0.13535246  |\n",
      "|    n_updates          | 120/128)    |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 33292288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028432459 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0598     |\n",
      "|    mean_step_reward   | 0.121926814 |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.0208     |\n",
      "|    value_loss         | 0.24        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_126.zip\n",
      "[EVAL] Mean Return: 142.043, Best Return: 148.709\n",
      "Saved video to ./runs_smw/videos/Run/Run_126_142.04.mp4\n",
      "\n",
      "=== Round 128 | Learn 262144 steps (Total trained: 33292288) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1111     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 33300480 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 912        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 33308672   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02314381 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.962      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0374    |\n",
      "|    mean_step_reward   | 0.12206964 |\n",
      "|    n_updates          | 4/128)     |\n",
      "|    policyGradLoss     | -0.0195    |\n",
      "|    value_loss         | 0.238      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 855         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 33316864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026524214 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0309     |\n",
      "|    mean_step_reward   | 0.12680937  |\n",
      "|    n_updates          | 8/128)      |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.275       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 830        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 39         |\n",
      "|    total_timesteps    | 33325056   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03264805 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.975      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.049     |\n",
      "|    mean_step_reward   | 0.14079694 |\n",
      "|    n_updates          | 12/128)    |\n",
      "|    policyGradLoss     | -0.022     |\n",
      "|    value_loss         | 0.17       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 33333248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026865711 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0103     |\n",
      "|    mean_step_reward   | 0.11583305  |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.269       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 33341440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027219463 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.000905    |\n",
      "|    mean_step_reward   | 0.13840313  |\n",
      "|    n_updates          | 20/128)     |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.216       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 33349632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027421717 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0278      |\n",
      "|    mean_step_reward   | 0.119138144 |\n",
      "|    n_updates          | 24/128)     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.363       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 33357824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024767406 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0401     |\n",
      "|    mean_step_reward   | 0.13297069  |\n",
      "|    n_updates          | 28/128)     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.273       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 33366016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025188696 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0379     |\n",
      "|    mean_step_reward   | 0.1185991   |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.0223     |\n",
      "|    value_loss         | 0.186       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 33374208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033906054 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0197     |\n",
      "|    mean_step_reward   | 0.12290494  |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.0208     |\n",
      "|    value_loss         | 0.217       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 33382400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025084307 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0304     |\n",
      "|    mean_step_reward   | 0.12942491  |\n",
      "|    n_updates          | 40/128)     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.216       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 33390592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021891464 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0229     |\n",
      "|    mean_step_reward   | 0.11460465  |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.285       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 33398784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024413094 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0167     |\n",
      "|    mean_step_reward   | 0.12206653  |\n",
      "|    n_updates          | 48/128)     |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.302       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 33406976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018164203 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0179      |\n",
      "|    mean_step_reward   | 0.12629274  |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.237       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 33415168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024024969 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0449     |\n",
      "|    mean_step_reward   | 0.13336542  |\n",
      "|    n_updates          | 56/128)     |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.242       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 33423360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022349427 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0391     |\n",
      "|    mean_step_reward   | 0.13111453  |\n",
      "|    n_updates          | 60/128)     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.176       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 33431552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024400083 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0389      |\n",
      "|    mean_step_reward   | 0.1246295   |\n",
      "|    n_updates          | 64/128)     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.316       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 33439744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034738377 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0538     |\n",
      "|    mean_step_reward   | 0.14095524  |\n",
      "|    n_updates          | 68/128)     |\n",
      "|    policyGradLoss     | -0.0253     |\n",
      "|    value_loss         | 0.116       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 33447936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031202728 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0277     |\n",
      "|    mean_step_reward   | 0.11984652  |\n",
      "|    n_updates          | 72/128)     |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.183       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 33456128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025373675 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0472     |\n",
      "|    mean_step_reward   | 0.14362183  |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 33464320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023332749 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0534     |\n",
      "|    mean_step_reward   | 0.1205387   |\n",
      "|    n_updates          | 80/128)     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.214       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 33472512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030419076 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0754     |\n",
      "|    mean_step_reward   | 0.14934099  |\n",
      "|    n_updates          | 84/128)     |\n",
      "|    policyGradLoss     | -0.0229     |\n",
      "|    value_loss         | 0.109       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 33480704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014670743 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0219      |\n",
      "|    mean_step_reward   | 0.109545164 |\n",
      "|    n_updates          | 88/128)     |\n",
      "|    policyGradLoss     | -0.0124     |\n",
      "|    value_loss         | 0.332       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 33488896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.037328586 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00539    |\n",
      "|    mean_step_reward   | 0.1474584   |\n",
      "|    n_updates          | 92/128)     |\n",
      "|    policyGradLoss     | -0.0235     |\n",
      "|    value_loss         | 0.126       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 33497088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02995488  |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0428     |\n",
      "|    mean_step_reward   | 0.117974274 |\n",
      "|    n_updates          | 96/128)     |\n",
      "|    policyGradLoss     | -0.0218     |\n",
      "|    value_loss         | 0.176       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 33505280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032326676 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0533     |\n",
      "|    mean_step_reward   | 0.13441427  |\n",
      "|    n_updates          | 100/128)    |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.247       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 33513472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022398831 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0474     |\n",
      "|    mean_step_reward   | 0.12072277  |\n",
      "|    n_updates          | 104/128)    |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.202       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 33521664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.037283324 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0208     |\n",
      "|    mean_step_reward   | 0.13648824  |\n",
      "|    n_updates          | 108/128)    |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.219       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 33529856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027496576 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0216     |\n",
      "|    mean_step_reward   | 0.11970323  |\n",
      "|    n_updates          | 112/128)    |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.224       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 33538048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026162611 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0361      |\n",
      "|    mean_step_reward   | 0.12156058  |\n",
      "|    n_updates          | 116/128)    |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.309       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 33546240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014058853 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0191     |\n",
      "|    mean_step_reward   | 0.12331517  |\n",
      "|    n_updates          | 120/128)    |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 32         |\n",
      "|    time_elapsed       | 336        |\n",
      "|    total_timesteps    | 33554432   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03223778 |\n",
      "|    entropy_loss       | -1.76      |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0717    |\n",
      "|    mean_step_reward   | 0.13563919 |\n",
      "|    n_updates          | 124/128)   |\n",
      "|    policyGradLoss     | -0.0233    |\n",
      "|    value_loss         | 0.151      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_127.zip\n",
      "[EVAL] Mean Return: 154.941, Best Return: 161.941\n",
      "Saved video to ./runs_smw/videos/Run/Run_127_154.94.mp4\n",
      "\n",
      "=== Round 129 | Learn 262144 steps (Total trained: 33554432) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1128     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 33562624 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 919         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 33570816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022323117 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.011      |\n",
      "|    mean_step_reward   | 0.13321546  |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.211       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 860         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 33579008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028232394 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0286     |\n",
      "|    mean_step_reward   | 0.13169885  |\n",
      "|    n_updates          | 8/128)      |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.178       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 33587200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023919553 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0511      |\n",
      "|    mean_step_reward   | 0.13314223  |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.304       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 33595392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032157235 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0592     |\n",
      "|    mean_step_reward   | 0.1418733   |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.197       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 821        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 59         |\n",
      "|    total_timesteps    | 33603584   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03905565 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.97       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0534    |\n",
      "|    mean_step_reward   | 0.1143552  |\n",
      "|    n_updates          | 20/128)    |\n",
      "|    policyGradLoss     | -0.0206    |\n",
      "|    value_loss         | 0.199      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 33611776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033530295 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0467     |\n",
      "|    mean_step_reward   | 0.1404087   |\n",
      "|    n_updates          | 24/128)     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 33619968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032646358 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0613     |\n",
      "|    mean_step_reward   | 0.1312877   |\n",
      "|    n_updates          | 28/128)     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.113       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 33628160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033208553 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0468     |\n",
      "|    mean_step_reward   | 0.13943036  |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.184       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 33636352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031103516 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0622     |\n",
      "|    mean_step_reward   | 0.12509805  |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.0235     |\n",
      "|    value_loss         | 0.155       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 33644544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.037051268 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0647     |\n",
      "|    mean_step_reward   | 0.11891691  |\n",
      "|    n_updates          | 40/128)     |\n",
      "|    policyGradLoss     | -0.0254     |\n",
      "|    value_loss         | 0.145       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 794         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 33652736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016814582 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0135      |\n",
      "|    mean_step_reward   | 0.12307006  |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.383       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 33660928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023912754 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0275     |\n",
      "|    mean_step_reward   | 0.13163997  |\n",
      "|    n_updates          | 48/128)     |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.228       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 33669120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033553127 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0534     |\n",
      "|    mean_step_reward   | 0.1274947   |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.187       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 33677312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031828377 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0609     |\n",
      "|    mean_step_reward   | 0.13835932  |\n",
      "|    n_updates          | 56/128)     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.209       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 33685504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030646458 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00337     |\n",
      "|    mean_step_reward   | 0.13037643  |\n",
      "|    n_updates          | 60/128)     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.174       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 789        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 176        |\n",
      "|    total_timesteps    | 33693696   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0248098  |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.958      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00273   |\n",
      "|    mean_step_reward   | 0.12500905 |\n",
      "|    n_updates          | 64/128)    |\n",
      "|    policyGradLoss     | -0.0155    |\n",
      "|    value_loss         | 0.261      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 186         |\n",
      "|    total_timesteps    | 33701888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026987977 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0483     |\n",
      "|    mean_step_reward   | 0.12761271  |\n",
      "|    n_updates          | 68/128)     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.272       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 197         |\n",
      "|    total_timesteps    | 33710080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022685776 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0448     |\n",
      "|    mean_step_reward   | 0.11781813  |\n",
      "|    n_updates          | 72/128)     |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.322       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 33718272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029913912 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0459      |\n",
      "|    mean_step_reward   | 0.1271098   |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.248       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 33726464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023032665 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.048      |\n",
      "|    mean_step_reward   | 0.12289144  |\n",
      "|    n_updates          | 80/128)     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.174       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 33734656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031819742 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0359     |\n",
      "|    mean_step_reward   | 0.13184391  |\n",
      "|    n_updates          | 84/128)     |\n",
      "|    policyGradLoss     | -0.021      |\n",
      "|    value_loss         | 0.204       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 33742848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027604394 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0229     |\n",
      "|    mean_step_reward   | 0.119407825 |\n",
      "|    n_updates          | 88/128)     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.225       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 250         |\n",
      "|    total_timesteps    | 33751040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029874535 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0177      |\n",
      "|    mean_step_reward   | 0.11589739  |\n",
      "|    n_updates          | 92/128)     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.313       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 33759232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021578074 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0245     |\n",
      "|    mean_step_reward   | 0.13205187  |\n",
      "|    n_updates          | 96/128)     |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.241       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 33767424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019321334 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0189     |\n",
      "|    mean_step_reward   | 0.119542085 |\n",
      "|    n_updates          | 100/128)    |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.236       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 33775616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027021375 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0348     |\n",
      "|    mean_step_reward   | 0.14391956  |\n",
      "|    n_updates          | 104/128)    |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.234       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 33783808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020042405 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0209     |\n",
      "|    mean_step_reward   | 0.1299474   |\n",
      "|    n_updates          | 108/128)    |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.236       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 782        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 303        |\n",
      "|    total_timesteps    | 33792000   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03244263 |\n",
      "|    entropy_loss       | -1.74      |\n",
      "|    explained_variance | 0.974      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0215     |\n",
      "|    mean_step_reward   | 0.12785807 |\n",
      "|    n_updates          | 112/128)   |\n",
      "|    policyGradLoss     | -0.0195    |\n",
      "|    value_loss         | 0.197      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 782        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 314        |\n",
      "|    total_timesteps    | 33800192   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03300522 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.95       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00167   |\n",
      "|    mean_step_reward   | 0.11776512 |\n",
      "|    n_updates          | 116/128)   |\n",
      "|    policyGradLoss     | -0.0178    |\n",
      "|    value_loss         | 0.379      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 781        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 324        |\n",
      "|    total_timesteps    | 33808384   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03282907 |\n",
      "|    entropy_loss       | -1.72      |\n",
      "|    explained_variance | 0.978      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0508    |\n",
      "|    mean_step_reward   | 0.13219807 |\n",
      "|    n_updates          | 120/128)   |\n",
      "|    policyGradLoss     | -0.0212    |\n",
      "|    value_loss         | 0.155      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 335         |\n",
      "|    total_timesteps    | 33816576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.039001346 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0489     |\n",
      "|    mean_step_reward   | 0.13004181  |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.0248     |\n",
      "|    value_loss         | 0.132       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_128.zip\n",
      "[EVAL] Mean Return: 156.466, Best Return: 163.466\n",
      "Saved video to ./runs_smw/videos/Run/Run_128_156.47.mp4\n",
      "\n",
      "=== Round 130 | Learn 262144 steps (Total trained: 33816576) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1095     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 33824768 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 919         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 33832960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.038302764 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0522     |\n",
      "|    mean_step_reward   | 0.13906077  |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.0235     |\n",
      "|    value_loss         | 0.134       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 862         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 33841152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.037288673 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0587     |\n",
      "|    mean_step_reward   | 0.1363526   |\n",
      "|    n_updates          | 8/128)      |\n",
      "|    policyGradLoss     | -0.0232     |\n",
      "|    value_loss         | 0.107       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 832         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 33849344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031318963 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0191     |\n",
      "|    mean_step_reward   | 0.12740026  |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.266       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 33857536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019324671 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0339     |\n",
      "|    mean_step_reward   | 0.13959683  |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.164       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 33865728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026092464 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0365     |\n",
      "|    mean_step_reward   | 0.12694165  |\n",
      "|    n_updates          | 20/128)     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.215       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 799         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 33873920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.048678696 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0352     |\n",
      "|    mean_step_reward   | 0.13327971  |\n",
      "|    n_updates          | 24/128)     |\n",
      "|    policyGradLoss     | -0.0219     |\n",
      "|    value_loss         | 0.167       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 33882112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020790607 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0204     |\n",
      "|    mean_step_reward   | 0.12298576  |\n",
      "|    n_updates          | 28/128)     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.274       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 33890304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031984672 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.044      |\n",
      "|    mean_step_reward   | 0.1461665   |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.174       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 33898496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033693068 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0434     |\n",
      "|    mean_step_reward   | 0.12939307  |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.16        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 786        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 114        |\n",
      "|    total_timesteps    | 33906688   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.04095283 |\n",
      "|    entropy_loss       | -1.71      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0534    |\n",
      "|    mean_step_reward   | 0.15130383 |\n",
      "|    n_updates          | 40/128)    |\n",
      "|    policyGradLoss     | -0.0215    |\n",
      "|    value_loss         | 0.0904     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 33914880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027444778 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0349     |\n",
      "|    mean_step_reward   | 0.11905907  |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 33923072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020387035 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0287      |\n",
      "|    mean_step_reward   | 0.12702939  |\n",
      "|    n_updates          | 48/128)     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.361       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 33931264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021944942 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00387    |\n",
      "|    mean_step_reward   | 0.12313691  |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.255       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 33939456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029188745 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0235     |\n",
      "|    mean_step_reward   | 0.1401012   |\n",
      "|    n_updates          | 56/128)     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.187       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 782        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 167        |\n",
      "|    total_timesteps    | 33947648   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03118742 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.967      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.038     |\n",
      "|    mean_step_reward   | 0.12565142 |\n",
      "|    n_updates          | 60/128)    |\n",
      "|    policyGradLoss     | -0.0205    |\n",
      "|    value_loss         | 0.212      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 33955840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016905807 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00695    |\n",
      "|    mean_step_reward   | 0.1296133   |\n",
      "|    n_updates          | 64/128)     |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.234       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 33964032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033459276 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.043      |\n",
      "|    mean_step_reward   | 0.14895687  |\n",
      "|    n_updates          | 68/128)     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 33972224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018779762 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.022      |\n",
      "|    mean_step_reward   | 0.10955627  |\n",
      "|    n_updates          | 72/128)     |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.243       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 210        |\n",
      "|    total_timesteps    | 33980416   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03422887 |\n",
      "|    entropy_loss       | -1.74      |\n",
      "|    explained_variance | 0.964      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0602    |\n",
      "|    mean_step_reward   | 0.13473025 |\n",
      "|    n_updates          | 76/128)    |\n",
      "|    policyGradLoss     | -0.0196    |\n",
      "|    value_loss         | 0.191      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 33988608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027271485 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0267      |\n",
      "|    mean_step_reward   | 0.09698823  |\n",
      "|    n_updates          | 80/128)     |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.235       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 33996800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030117586 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.041      |\n",
      "|    mean_step_reward   | 0.15149277  |\n",
      "|    n_updates          | 84/128)     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.163       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 242        |\n",
      "|    total_timesteps    | 34004992   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03119115 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.979      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0397    |\n",
      "|    mean_step_reward   | 0.11864188 |\n",
      "|    n_updates          | 88/128)    |\n",
      "|    policyGradLoss     | -0.0221    |\n",
      "|    value_loss         | 0.161      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 34013184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025084741 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0214     |\n",
      "|    mean_step_reward   | 0.14546435  |\n",
      "|    n_updates          | 92/128)     |\n",
      "|    policyGradLoss     | -0.0149     |\n",
      "|    value_loss         | 0.297       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 34021376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031055382 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00612    |\n",
      "|    mean_step_reward   | 0.12111591  |\n",
      "|    n_updates          | 96/128)     |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.165       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 34029568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026750904 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0183      |\n",
      "|    mean_step_reward   | 0.12915969  |\n",
      "|    n_updates          | 100/128)    |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.315       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 34037760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021940615 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0405     |\n",
      "|    mean_step_reward   | 0.12284579  |\n",
      "|    n_updates          | 104/128)    |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.184       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 776        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 295        |\n",
      "|    total_timesteps    | 34045952   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02815255 |\n",
      "|    entropy_loss       | -1.74      |\n",
      "|    explained_variance | 0.97       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0012    |\n",
      "|    mean_step_reward   | 0.1337319  |\n",
      "|    n_updates          | 108/128)   |\n",
      "|    policyGradLoss     | -0.0192    |\n",
      "|    value_loss         | 0.229      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 34054144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023370065 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0139     |\n",
      "|    mean_step_reward   | 0.11864871  |\n",
      "|    n_updates          | 112/128)    |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.277       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 34062336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025965659 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0176      |\n",
      "|    mean_step_reward   | 0.14322421  |\n",
      "|    n_updates          | 116/128)    |\n",
      "|    policyGradLoss     | -0.0214     |\n",
      "|    value_loss         | 0.156       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 774        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 327        |\n",
      "|    total_timesteps    | 34070528   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03492077 |\n",
      "|    entropy_loss       | -1.74      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0635    |\n",
      "|    mean_step_reward   | 0.13675389 |\n",
      "|    n_updates          | 120/128)   |\n",
      "|    policyGradLoss     | -0.0236    |\n",
      "|    value_loss         | 0.0855     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 34078720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02954515  |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0501     |\n",
      "|    mean_step_reward   | 0.124450356 |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.251       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_129.zip\n",
      "[EVAL] Mean Return: 152.327, Best Return: 159.327\n",
      "Saved video to ./runs_smw/videos/Run/Run_129_152.33.mp4\n",
      "\n",
      "=== Round 131 | Learn 262144 steps (Total trained: 34078720) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1156     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 34086912 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 912         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 34095104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02794779  |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0499     |\n",
      "|    mean_step_reward   | 0.116932824 |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.238       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 860         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 34103296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030664504 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0221     |\n",
      "|    mean_step_reward   | 0.14854932  |\n",
      "|    n_updates          | 8/128)      |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.153       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 843         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 34111488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029261846 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0616     |\n",
      "|    mean_step_reward   | 0.12930769  |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.124       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 831         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 34119680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021616569 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00112     |\n",
      "|    mean_step_reward   | 0.1456378   |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.172       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 34127872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016549598 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0149     |\n",
      "|    mean_step_reward   | 0.1267639   |\n",
      "|    n_updates          | 20/128)     |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.17        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 812        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 70         |\n",
      "|    total_timesteps    | 34136064   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02911829 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.968      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0419    |\n",
      "|    mean_step_reward   | 0.14014874 |\n",
      "|    n_updates          | 24/128)    |\n",
      "|    policyGradLoss     | -0.0177    |\n",
      "|    value_loss         | 0.249      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 807        |\n",
      "|    iterations         | 8          |\n",
      "|    time_elapsed       | 81         |\n",
      "|    total_timesteps    | 34144256   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0331803  |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.971      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.017     |\n",
      "|    mean_step_reward   | 0.11741368 |\n",
      "|    n_updates          | 28/128)    |\n",
      "|    policyGradLoss     | -0.0197    |\n",
      "|    value_loss         | 0.181      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 34152448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023343883 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.05       |\n",
      "|    mean_step_reward   | 0.14819475  |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.264       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 34160640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023178903 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0281     |\n",
      "|    mean_step_reward   | 0.12252539  |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.0136     |\n",
      "|    value_loss         | 0.258       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 112         |\n",
      "|    total_timesteps    | 34168832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030375823 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0202     |\n",
      "|    mean_step_reward   | 0.14197887  |\n",
      "|    n_updates          | 40/128)     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.245       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 34177024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019602519 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0205     |\n",
      "|    mean_step_reward   | 0.10407975  |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 34185216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019634742 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.031       |\n",
      "|    mean_step_reward   | 0.14489576  |\n",
      "|    n_updates          | 48/128)     |\n",
      "|    policyGradLoss     | -0.017      |\n",
      "|    value_loss         | 0.306       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 789        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 145        |\n",
      "|    total_timesteps    | 34193408   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02662969 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.969      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0661    |\n",
      "|    mean_step_reward   | 0.12046686 |\n",
      "|    n_updates          | 52/128)    |\n",
      "|    policyGradLoss     | -0.0191    |\n",
      "|    value_loss         | 0.203      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 34201600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018076994 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0123      |\n",
      "|    mean_step_reward   | 0.13504471  |\n",
      "|    n_updates          | 56/128)     |\n",
      "|    policyGradLoss     | -0.012      |\n",
      "|    value_loss         | 0.315       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 34209792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026889414 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0401     |\n",
      "|    mean_step_reward   | 0.1153584   |\n",
      "|    n_updates          | 60/128)     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.197       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 34217984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034775786 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0747     |\n",
      "|    mean_step_reward   | 0.1456109   |\n",
      "|    n_updates          | 64/128)     |\n",
      "|    policyGradLoss     | -0.0213     |\n",
      "|    value_loss         | 0.112       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 34226176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02746487  |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0252      |\n",
      "|    mean_step_reward   | 0.117631435 |\n",
      "|    n_updates          | 68/128)     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.217       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 782        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 198        |\n",
      "|    total_timesteps    | 34234368   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03343563 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0272    |\n",
      "|    mean_step_reward   | 0.1415982  |\n",
      "|    n_updates          | 72/128)    |\n",
      "|    policyGradLoss     | -0.0206    |\n",
      "|    value_loss         | 0.181      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 34242560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029779954 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0594     |\n",
      "|    mean_step_reward   | 0.12211822  |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.172       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 34250752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026324736 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0303     |\n",
      "|    mean_step_reward   | 0.12767597  |\n",
      "|    n_updates          | 80/128)     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.183       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 231        |\n",
      "|    total_timesteps    | 34258944   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03135226 |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.984      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0676    |\n",
      "|    mean_step_reward   | 0.13815346 |\n",
      "|    n_updates          | 84/128)    |\n",
      "|    policyGradLoss     | -0.0204    |\n",
      "|    value_loss         | 0.121      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 34267136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028099012 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00509    |\n",
      "|    mean_step_reward   | 0.11957426  |\n",
      "|    n_updates          | 88/128)     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.345       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 34275328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018082991 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0156     |\n",
      "|    mean_step_reward   | 0.13579443  |\n",
      "|    n_updates          | 92/128)     |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.278       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 34283520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032117456 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0238     |\n",
      "|    mean_step_reward   | 0.12875181  |\n",
      "|    n_updates          | 96/128)     |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.208       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 776        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 274        |\n",
      "|    total_timesteps    | 34291712   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0314122  |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.971      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0564    |\n",
      "|    mean_step_reward   | 0.13040888 |\n",
      "|    n_updates          | 100/128)   |\n",
      "|    policyGradLoss     | -0.0201    |\n",
      "|    value_loss         | 0.171      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 776        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 284        |\n",
      "|    total_timesteps    | 34299904   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02262157 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.967      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0491    |\n",
      "|    mean_step_reward   | 0.12773421 |\n",
      "|    n_updates          | 104/128)   |\n",
      "|    policyGradLoss     | -0.0176    |\n",
      "|    value_loss         | 0.204      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 34308096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028336463 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.011      |\n",
      "|    mean_step_reward   | 0.12933204  |\n",
      "|    n_updates          | 108/128)    |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.224       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 34316288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026427632 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0412     |\n",
      "|    mean_step_reward   | 0.13412032  |\n",
      "|    n_updates          | 112/128)    |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.158       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 34324480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025378799 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0555     |\n",
      "|    mean_step_reward   | 0.13200314  |\n",
      "|    n_updates          | 116/128)    |\n",
      "|    policyGradLoss     | -0.0212     |\n",
      "|    value_loss         | 0.178       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 776        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 327        |\n",
      "|    total_timesteps    | 34332672   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03210467 |\n",
      "|    entropy_loss       | -1.76      |\n",
      "|    explained_variance | 0.97       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0337    |\n",
      "|    mean_step_reward   | 0.13170765 |\n",
      "|    n_updates          | 120/128)   |\n",
      "|    policyGradLoss     | -0.0191    |\n",
      "|    value_loss         | 0.25       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 776        |\n",
      "|    iterations         | 32         |\n",
      "|    time_elapsed       | 337        |\n",
      "|    total_timesteps    | 34340864   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03147127 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.972      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0152    |\n",
      "|    mean_step_reward   | 0.13532197 |\n",
      "|    n_updates          | 124/128)   |\n",
      "|    policyGradLoss     | -0.0193    |\n",
      "|    value_loss         | 0.194      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_130.zip\n",
      "[EVAL] Mean Return: 156.930, Best Return: 163.930\n",
      "Saved video to ./runs_smw/videos/Run/Run_130_156.93.mp4\n",
      "\n",
      "=== Round 132 | Learn 262144 steps (Total trained: 34340864) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1171     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 34349056 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 942        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 34357248   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02477815 |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.963      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00817   |\n",
      "|    mean_step_reward   | 0.12691867 |\n",
      "|    n_updates          | 4/128)     |\n",
      "|    policyGradLoss     | -0.0186    |\n",
      "|    value_loss         | 0.263      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 880         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 34365440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019998375 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0173     |\n",
      "|    mean_step_reward   | 0.13545823  |\n",
      "|    n_updates          | 8/128)      |\n",
      "|    policyGradLoss     | -0.0117     |\n",
      "|    value_loss         | 0.354       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 847         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 34373632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018376747 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0105     |\n",
      "|    mean_step_reward   | 0.1379346   |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.0155     |\n",
      "|    value_loss         | 0.311       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 829         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 34381824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028952923 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0495     |\n",
      "|    mean_step_reward   | 0.13759667  |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.114       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 34390016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027786093 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00784    |\n",
      "|    mean_step_reward   | 0.1418404   |\n",
      "|    n_updates          | 20/128)     |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.161       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 34398208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025793482 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0386     |\n",
      "|    mean_step_reward   | 0.12501115  |\n",
      "|    n_updates          | 24/128)     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.184       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 80          |\n",
      "|    total_timesteps    | 34406400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026186207 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0586     |\n",
      "|    mean_step_reward   | 0.15105486  |\n",
      "|    n_updates          | 28/128)     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.166       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 803        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 91         |\n",
      "|    total_timesteps    | 34414592   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03182426 |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.982      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0616    |\n",
      "|    mean_step_reward   | 0.1251252  |\n",
      "|    n_updates          | 32/128)    |\n",
      "|    policyGradLoss     | -0.018     |\n",
      "|    value_loss         | 0.132      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 802         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 34422784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017442364 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0343      |\n",
      "|    mean_step_reward   | 0.13902247  |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.0135     |\n",
      "|    value_loss         | 0.288       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 797         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 34430976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025857495 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0291     |\n",
      "|    mean_step_reward   | 0.12931472  |\n",
      "|    n_updates          | 40/128)     |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.204       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 34439168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034141973 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0487     |\n",
      "|    mean_step_reward   | 0.13349338  |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.148       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 133         |\n",
      "|    total_timesteps    | 34447360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025424264 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0849      |\n",
      "|    mean_step_reward   | 0.12908201  |\n",
      "|    n_updates          | 48/128)     |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 34455552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027720902 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0504     |\n",
      "|    mean_step_reward   | 0.13825388  |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.143       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 34463744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029832784 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0543     |\n",
      "|    mean_step_reward   | 0.1295908   |\n",
      "|    n_updates          | 56/128)     |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.119       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 793        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 165        |\n",
      "|    total_timesteps    | 34471936   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.036463   |\n",
      "|    entropy_loss       | -1.74      |\n",
      "|    explained_variance | 0.98       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0509    |\n",
      "|    mean_step_reward   | 0.14147927 |\n",
      "|    n_updates          | 60/128)    |\n",
      "|    policyGradLoss     | -0.0201    |\n",
      "|    value_loss         | 0.18       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 175         |\n",
      "|    total_timesteps    | 34480128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031180684 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0602     |\n",
      "|    mean_step_reward   | 0.13319117  |\n",
      "|    n_updates          | 64/128)     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.149       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 791        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 186        |\n",
      "|    total_timesteps    | 34488320   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03348487 |\n",
      "|    entropy_loss       | -1.74      |\n",
      "|    explained_variance | 0.968      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.055     |\n",
      "|    mean_step_reward   | 0.13528234 |\n",
      "|    n_updates          | 68/128)    |\n",
      "|    policyGradLoss     | -0.0183    |\n",
      "|    value_loss         | 0.23       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 197         |\n",
      "|    total_timesteps    | 34496512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.039132733 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0363     |\n",
      "|    mean_step_reward   | 0.12717745  |\n",
      "|    n_updates          | 72/128)     |\n",
      "|    policyGradLoss     | -0.0213     |\n",
      "|    value_loss         | 0.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 207         |\n",
      "|    total_timesteps    | 34504704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031687837 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0278     |\n",
      "|    mean_step_reward   | 0.13505477  |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.209       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 788        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 218        |\n",
      "|    total_timesteps    | 34512896   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03562618 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.983      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0568    |\n",
      "|    mean_step_reward   | 0.1419164  |\n",
      "|    n_updates          | 80/128)    |\n",
      "|    policyGradLoss     | -0.0222    |\n",
      "|    value_loss         | 0.117      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 789         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 228         |\n",
      "|    total_timesteps    | 34521088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030204382 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0492      |\n",
      "|    mean_step_reward   | 0.13104668  |\n",
      "|    n_updates          | 84/128)     |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.136       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 788        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 238        |\n",
      "|    total_timesteps    | 34529280   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.030394   |\n",
      "|    entropy_loss       | -1.71      |\n",
      "|    explained_variance | 0.968      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 8.5e-05    |\n",
      "|    mean_step_reward   | 0.13328245 |\n",
      "|    n_updates          | 88/128)    |\n",
      "|    policyGradLoss     | -0.0155    |\n",
      "|    value_loss         | 0.271      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 249         |\n",
      "|    total_timesteps    | 34537472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026273943 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0104     |\n",
      "|    mean_step_reward   | 0.12226271  |\n",
      "|    n_updates          | 92/128)     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.252       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 788        |\n",
      "|    iterations         | 25         |\n",
      "|    time_elapsed       | 259        |\n",
      "|    total_timesteps    | 34545664   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03057752 |\n",
      "|    entropy_loss       | -1.72      |\n",
      "|    explained_variance | 0.98       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0472    |\n",
      "|    mean_step_reward   | 0.15039894 |\n",
      "|    n_updates          | 96/128)    |\n",
      "|    policyGradLoss     | -0.0195    |\n",
      "|    value_loss         | 0.142      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 787         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 270         |\n",
      "|    total_timesteps    | 34553856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017784495 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0355     |\n",
      "|    mean_step_reward   | 0.123677686 |\n",
      "|    n_updates          | 100/128)    |\n",
      "|    policyGradLoss     | -0.0148     |\n",
      "|    value_loss         | 0.227       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 281         |\n",
      "|    total_timesteps    | 34562048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030072043 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0346     |\n",
      "|    mean_step_reward   | 0.147187    |\n",
      "|    n_updates          | 104/128)    |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.183       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 785        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 291        |\n",
      "|    total_timesteps    | 34570240   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03369438 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.974      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.000665  |\n",
      "|    mean_step_reward   | 0.13209069 |\n",
      "|    n_updates          | 108/128)   |\n",
      "|    policyGradLoss     | -0.0212    |\n",
      "|    value_loss         | 0.172      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 302         |\n",
      "|    total_timesteps    | 34578432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028528053 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0563     |\n",
      "|    mean_step_reward   | 0.1412324   |\n",
      "|    n_updates          | 112/128)    |\n",
      "|    policyGradLoss     | -0.0218     |\n",
      "|    value_loss         | 0.166       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 313         |\n",
      "|    total_timesteps    | 34586624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017933168 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0585     |\n",
      "|    mean_step_reward   | 0.13263968  |\n",
      "|    n_updates          | 116/128)    |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.176       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 324         |\n",
      "|    total_timesteps    | 34594816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026328556 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0112     |\n",
      "|    mean_step_reward   | 0.1350103   |\n",
      "|    n_updates          | 120/128)    |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 334         |\n",
      "|    total_timesteps    | 34603008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031464852 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0377     |\n",
      "|    mean_step_reward   | 0.123942    |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.255       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_131.zip\n",
      "[EVAL] Mean Return: 136.729, Best Return: 142.729\n",
      "Saved video to ./runs_smw/videos/Run/Run_131_136.73.mp4\n",
      "\n",
      "=== Round 133 | Learn 262144 steps (Total trained: 34603008) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1089     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 34611200 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 894         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 34619392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026980033 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0179     |\n",
      "|    mean_step_reward   | 0.10906286  |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.255       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 846         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 34627584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034479838 |\n",
      "|    entropy_loss       | -1.67       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0669     |\n",
      "|    mean_step_reward   | 0.15163466  |\n",
      "|    n_updates          | 8/128)      |\n",
      "|    policyGradLoss     | -0.0213     |\n",
      "|    value_loss         | 0.113       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 34635776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020745313 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0193      |\n",
      "|    mean_step_reward   | 0.12440365  |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.221       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 34643968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028849453 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00626     |\n",
      "|    mean_step_reward   | 0.14781708  |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.204       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 34652160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034932747 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0334     |\n",
      "|    mean_step_reward   | 0.1286264   |\n",
      "|    n_updates          | 20/128)     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.156       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 34660352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.037617788 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0792     |\n",
      "|    mean_step_reward   | 0.14262217  |\n",
      "|    n_updates          | 24/128)     |\n",
      "|    policyGradLoss     | -0.0223     |\n",
      "|    value_loss         | 0.143       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 34668544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.035629258 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0515     |\n",
      "|    mean_step_reward   | 0.12872323  |\n",
      "|    n_updates          | 28/128)     |\n",
      "|    policyGradLoss     | -0.022      |\n",
      "|    value_loss         | 0.135       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 34676736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024522992 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00939     |\n",
      "|    mean_step_reward   | 0.12930322  |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.274       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 34684928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.041073725 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0685     |\n",
      "|    mean_step_reward   | 0.14928056  |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.0264     |\n",
      "|    value_loss         | 0.102       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 34693120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032410547 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0542     |\n",
      "|    mean_step_reward   | 0.12800625  |\n",
      "|    n_updates          | 40/128)     |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 34701312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.038346227 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.029      |\n",
      "|    mean_step_reward   | 0.14036989  |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.188       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 784         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 34709504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030177072 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0049     |\n",
      "|    mean_step_reward   | 0.11896536  |\n",
      "|    n_updates          | 48/128)     |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 34717696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025517233 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00198    |\n",
      "|    mean_step_reward   | 0.1400432   |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.272       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 34725888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034389608 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.047      |\n",
      "|    mean_step_reward   | 0.12562013  |\n",
      "|    n_updates          | 56/128)     |\n",
      "|    policyGradLoss     | -0.0217     |\n",
      "|    value_loss         | 0.172       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 782        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 167        |\n",
      "|    total_timesteps    | 34734080   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03314349 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.98       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0315    |\n",
      "|    mean_step_reward   | 0.13646606 |\n",
      "|    n_updates          | 60/128)    |\n",
      "|    policyGradLoss     | -0.0212    |\n",
      "|    value_loss         | 0.192      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 34742272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.036464065 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0418     |\n",
      "|    mean_step_reward   | 0.1375854   |\n",
      "|    n_updates          | 64/128)     |\n",
      "|    policyGradLoss     | -0.0235     |\n",
      "|    value_loss         | 0.161       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 781        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 188        |\n",
      "|    total_timesteps    | 34750464   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03280346 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0415    |\n",
      "|    mean_step_reward   | 0.13174248 |\n",
      "|    n_updates          | 68/128)    |\n",
      "|    policyGradLoss     | -0.0187    |\n",
      "|    value_loss         | 0.175      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 34758656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.038390223 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0709     |\n",
      "|    mean_step_reward   | 0.14883474  |\n",
      "|    n_updates          | 72/128)     |\n",
      "|    policyGradLoss     | -0.0219     |\n",
      "|    value_loss         | 0.0978      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 210        |\n",
      "|    total_timesteps    | 34766848   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0338984  |\n",
      "|    entropy_loss       | -1.72      |\n",
      "|    explained_variance | 0.977      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0482    |\n",
      "|    mean_step_reward   | 0.12884788 |\n",
      "|    n_updates          | 76/128)    |\n",
      "|    policyGradLoss     | -0.0189    |\n",
      "|    value_loss         | 0.175      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 34775040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031734046 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0579     |\n",
      "|    mean_step_reward   | 0.13378097  |\n",
      "|    n_updates          | 80/128)     |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.169       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 779        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 231        |\n",
      "|    total_timesteps    | 34783232   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02792396 |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.97       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0892     |\n",
      "|    mean_step_reward   | 0.1272117  |\n",
      "|    n_updates          | 84/128)    |\n",
      "|    policyGradLoss     | -0.0158    |\n",
      "|    value_loss         | 0.205      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 34791424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020908516 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0149     |\n",
      "|    mean_step_reward   | 0.13942052  |\n",
      "|    n_updates          | 88/128)     |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.281       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 34799616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.052003257 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0392      |\n",
      "|    mean_step_reward   | 0.12202723  |\n",
      "|    n_updates          | 92/128)     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.236       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 34807808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025841935 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0764      |\n",
      "|    mean_step_reward   | 0.14032355  |\n",
      "|    n_updates          | 96/128)     |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.289       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 273        |\n",
      "|    total_timesteps    | 34816000   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.04433442 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.98       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0716    |\n",
      "|    mean_step_reward   | 0.1258147  |\n",
      "|    n_updates          | 100/128)   |\n",
      "|    policyGradLoss     | -0.0245    |\n",
      "|    value_loss         | 0.116      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 34824192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017820973 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00581    |\n",
      "|    mean_step_reward   | 0.14444628  |\n",
      "|    n_updates          | 104/128)    |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 34832384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032047544 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0573     |\n",
      "|    mean_step_reward   | 0.122677244 |\n",
      "|    n_updates          | 108/128)    |\n",
      "|    policyGradLoss     | -0.021      |\n",
      "|    value_loss         | 0.183       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 778        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 305        |\n",
      "|    total_timesteps    | 34840576   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03273751 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.963      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0345    |\n",
      "|    mean_step_reward   | 0.14494924 |\n",
      "|    n_updates          | 112/128)   |\n",
      "|    policyGradLoss     | -0.0167    |\n",
      "|    value_loss         | 0.243      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 34848768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032988973 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0528     |\n",
      "|    mean_step_reward   | 0.118399456 |\n",
      "|    n_updates          | 116/128)    |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 34856960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024633624 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0157     |\n",
      "|    mean_step_reward   | 0.14051342  |\n",
      "|    n_updates          | 120/128)    |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.242       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 777         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 34865152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.037648488 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0112     |\n",
      "|    mean_step_reward   | 0.12372513  |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.249       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_132.zip\n",
      "[EVAL] Mean Return: 157.649, Best Return: 164.649\n",
      "Saved video to ./runs_smw/videos/Run/Run_132_157.65.mp4\n",
      "\n",
      "=== Round 134 | Learn 262144 steps (Total trained: 34865152) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1155     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 34873344 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 927         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 34881536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029885488 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0488     |\n",
      "|    mean_step_reward   | 0.13400371  |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.161       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 860         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 34889728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033196267 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0658     |\n",
      "|    mean_step_reward   | 0.13893646  |\n",
      "|    n_updates          | 8/128)      |\n",
      "|    policyGradLoss     | -0.0228     |\n",
      "|    value_loss         | 0.105       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 833         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 34897920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029574696 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0444     |\n",
      "|    mean_step_reward   | 0.13438287  |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.156       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 34906112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027468098 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.061      |\n",
      "|    mean_step_reward   | 0.13448907  |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.179       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 34914304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028060708 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0342     |\n",
      "|    mean_step_reward   | 0.124886066 |\n",
      "|    n_updates          | 20/128)     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.257       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 800         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 34922496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033084318 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0332     |\n",
      "|    mean_step_reward   | 0.13072626  |\n",
      "|    n_updates          | 24/128)     |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 796         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 34930688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032696035 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0463     |\n",
      "|    mean_step_reward   | 0.1395111   |\n",
      "|    n_updates          | 28/128)     |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.231       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 793         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 34938880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020418892 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0116      |\n",
      "|    mean_step_reward   | 0.10418026  |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.405       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 788         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 34947072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023153417 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0221     |\n",
      "|    mean_step_reward   | 0.14641535  |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.277       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 786         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 34955264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026196707 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0105     |\n",
      "|    mean_step_reward   | 0.108253255 |\n",
      "|    n_updates          | 40/128)     |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.256       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 34963456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025288016 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0401     |\n",
      "|    mean_step_reward   | 0.14452839  |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.206       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 34971648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021256594 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0256     |\n",
      "|    mean_step_reward   | 0.091594875 |\n",
      "|    n_updates          | 48/128)     |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.279       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 781         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 34979840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029372947 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0258     |\n",
      "|    mean_step_reward   | 0.14031363  |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.245       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 779         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 34988032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031012956 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.062      |\n",
      "|    mean_step_reward   | 0.11563819  |\n",
      "|    n_updates          | 56/128)     |\n",
      "|    policyGradLoss     | -0.0218     |\n",
      "|    value_loss         | 0.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 168         |\n",
      "|    total_timesteps    | 34996224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029142138 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0337     |\n",
      "|    mean_step_reward   | 0.13763905  |\n",
      "|    n_updates          | 60/128)     |\n",
      "|    policyGradLoss     | -0.0209     |\n",
      "|    value_loss         | 0.185       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 778         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 35004416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020933073 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0235     |\n",
      "|    mean_step_reward   | 0.12708423  |\n",
      "|    n_updates          | 64/128)     |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.21        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 189        |\n",
      "|    total_timesteps    | 35012608   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01831352 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.974      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0347    |\n",
      "|    mean_step_reward   | 0.13206947 |\n",
      "|    n_updates          | 68/128)    |\n",
      "|    policyGradLoss     | -0.0163    |\n",
      "|    value_loss         | 0.203      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 776         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 35020800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033308674 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0564     |\n",
      "|    mean_step_reward   | 0.123435535 |\n",
      "|    n_updates          | 72/128)     |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.147       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 35028992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033890843 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0386     |\n",
      "|    mean_step_reward   | 0.12625697  |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0212     |\n",
      "|    value_loss         | 0.206       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 35037184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024628133 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.129       |\n",
      "|    mean_step_reward   | 0.13241246  |\n",
      "|    n_updates          | 80/128)     |\n",
      "|    policyGradLoss     | -0.0136     |\n",
      "|    value_loss         | 0.305       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 774        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 232        |\n",
      "|    total_timesteps    | 35045376   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02780163 |\n",
      "|    entropy_loss       | -1.76      |\n",
      "|    explained_variance | 0.973      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0545     |\n",
      "|    mean_step_reward   | 0.13196708 |\n",
      "|    n_updates          | 84/128)    |\n",
      "|    policyGradLoss     | -0.0174    |\n",
      "|    value_loss         | 0.187      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 35053568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028235238 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0601     |\n",
      "|    mean_step_reward   | 0.14333822  |\n",
      "|    n_updates          | 88/128)     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.175       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 773         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 254         |\n",
      "|    total_timesteps    | 35061760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019234326 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0364     |\n",
      "|    mean_step_reward   | 0.1238073   |\n",
      "|    n_updates          | 92/128)     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.162       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 773        |\n",
      "|    iterations         | 25         |\n",
      "|    time_elapsed       | 264        |\n",
      "|    total_timesteps    | 35069952   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03416209 |\n",
      "|    entropy_loss       | -1.72      |\n",
      "|    explained_variance | 0.982      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0656    |\n",
      "|    mean_step_reward   | 0.14851753 |\n",
      "|    n_updates          | 96/128)    |\n",
      "|    policyGradLoss     | -0.0214    |\n",
      "|    value_loss         | 0.135      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 275         |\n",
      "|    total_timesteps    | 35078144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022731334 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.036      |\n",
      "|    mean_step_reward   | 0.119159736 |\n",
      "|    n_updates          | 100/128)    |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.167       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 286         |\n",
      "|    total_timesteps    | 35086336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031613935 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0271     |\n",
      "|    mean_step_reward   | 0.13920195  |\n",
      "|    n_updates          | 104/128)    |\n",
      "|    policyGradLoss     | -0.0208     |\n",
      "|    value_loss         | 0.174       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 35094528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030047994 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0627     |\n",
      "|    mean_step_reward   | 0.13530996  |\n",
      "|    n_updates          | 108/128)    |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.114       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 307         |\n",
      "|    total_timesteps    | 35102720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024566421 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0548     |\n",
      "|    mean_step_reward   | 0.1415496   |\n",
      "|    n_updates          | 112/128)    |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.247       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 35110912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030903399 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0379     |\n",
      "|    mean_step_reward   | 0.12668723  |\n",
      "|    n_updates          | 116/128)    |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.172       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 35119104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017539943 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0343     |\n",
      "|    mean_step_reward   | 0.13599618  |\n",
      "|    n_updates          | 120/128)    |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.163       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 772        |\n",
      "|    iterations         | 32         |\n",
      "|    time_elapsed       | 339        |\n",
      "|    total_timesteps    | 35127296   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0342499  |\n",
      "|    entropy_loss       | -1.74      |\n",
      "|    explained_variance | 0.979      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0475    |\n",
      "|    mean_step_reward   | 0.13852501 |\n",
      "|    n_updates          | 124/128)   |\n",
      "|    policyGradLoss     | -0.0192    |\n",
      "|    value_loss         | 0.118      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_133.zip\n",
      "[EVAL] Mean Return: 156.965, Best Return: 163.965\n",
      "Saved video to ./runs_smw/videos/Run/Run_133_156.96.mp4\n",
      "\n",
      "=== Round 135 | Learn 262144 steps (Total trained: 35127296) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1139     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 35135488 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 912         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 35143680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018954813 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0229     |\n",
      "|    mean_step_reward   | 0.13053963  |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.217       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 864         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 35151872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021102838 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.026      |\n",
      "|    mean_step_reward   | 0.13840264  |\n",
      "|    n_updates          | 8/128)      |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.228       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 832         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 35160064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029641783 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0617     |\n",
      "|    mean_step_reward   | 0.12914023  |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.0208     |\n",
      "|    value_loss         | 0.152       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 35168256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.035561517 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0633     |\n",
      "|    mean_step_reward   | 0.1367178   |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.023      |\n",
      "|    value_loss         | 0.115       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 35176448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.040770248 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0637     |\n",
      "|    mean_step_reward   | 0.13596529  |\n",
      "|    n_updates          | 20/128)     |\n",
      "|    policyGradLoss     | -0.0227     |\n",
      "|    value_loss         | 0.117       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 35184640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031147504 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0427     |\n",
      "|    mean_step_reward   | 0.14954229  |\n",
      "|    n_updates          | 24/128)     |\n",
      "|    policyGradLoss     | -0.0218     |\n",
      "|    value_loss         | 0.156       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 35192832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027396265 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0598     |\n",
      "|    mean_step_reward   | 0.12660874  |\n",
      "|    n_updates          | 28/128)     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.152       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 798         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 35201024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033975452 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.038      |\n",
      "|    mean_step_reward   | 0.15283573  |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.0223     |\n",
      "|    value_loss         | 0.152       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 795         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 35209216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030046917 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0388     |\n",
      "|    mean_step_reward   | 0.11207663  |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.234       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 793        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 113        |\n",
      "|    total_timesteps    | 35217408   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02198312 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.96       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0381    |\n",
      "|    mean_step_reward   | 0.14850196 |\n",
      "|    n_updates          | 40/128)    |\n",
      "|    policyGradLoss     | -0.015     |\n",
      "|    value_loss         | 0.322      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 35225600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030324986 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0624     |\n",
      "|    mean_step_reward   | 0.12750587  |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0248     |\n",
      "|    value_loss         | 0.0894      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 134         |\n",
      "|    total_timesteps    | 35233792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021938924 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0492     |\n",
      "|    mean_step_reward   | 0.13851869  |\n",
      "|    n_updates          | 48/128)     |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 35241984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030249484 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0618     |\n",
      "|    mean_step_reward   | 0.115487754 |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.231       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 35250176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030408874 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.041      |\n",
      "|    mean_step_reward   | 0.13441578  |\n",
      "|    n_updates          | 56/128)     |\n",
      "|    policyGradLoss     | -0.0211     |\n",
      "|    value_loss         | 0.173       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 791        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 165        |\n",
      "|    total_timesteps    | 35258368   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01934624 |\n",
      "|    entropy_loss       | -1.76      |\n",
      "|    explained_variance | 0.973      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0287    |\n",
      "|    mean_step_reward   | 0.12755807 |\n",
      "|    n_updates          | 60/128)    |\n",
      "|    policyGradLoss     | -0.0175    |\n",
      "|    value_loss         | 0.239      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 791         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 35266560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026219215 |\n",
      "|    entropy_loss       | -1.69       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00125    |\n",
      "|    mean_step_reward   | 0.14451103  |\n",
      "|    n_updates          | 64/128)     |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.294       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 186         |\n",
      "|    total_timesteps    | 35274752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018669989 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0409      |\n",
      "|    mean_step_reward   | 0.12681995  |\n",
      "|    n_updates          | 68/128)     |\n",
      "|    policyGradLoss     | -0.0123     |\n",
      "|    value_loss         | 0.185       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 801         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 194         |\n",
      "|    total_timesteps    | 35282944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024528602 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0661     |\n",
      "|    mean_step_reward   | 0.15148321  |\n",
      "|    n_updates          | 72/128)     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.132       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 202         |\n",
      "|    total_timesteps    | 35291136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025846556 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0475     |\n",
      "|    mean_step_reward   | 0.12631811  |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.138       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 815        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 210        |\n",
      "|    total_timesteps    | 35299328   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03215906 |\n",
      "|    entropy_loss       | -1.71      |\n",
      "|    explained_variance | 0.976      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0149    |\n",
      "|    mean_step_reward   | 0.13368662 |\n",
      "|    n_updates          | 80/128)    |\n",
      "|    policyGradLoss     | -0.0197    |\n",
      "|    value_loss         | 0.209      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 35307520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032540668 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0751     |\n",
      "|    mean_step_reward   | 0.1380558   |\n",
      "|    n_updates          | 84/128)     |\n",
      "|    policyGradLoss     | -0.0213     |\n",
      "|    value_loss         | 0.144       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 827         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 227         |\n",
      "|    total_timesteps    | 35315712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019488141 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0258     |\n",
      "|    mean_step_reward   | 0.1393933   |\n",
      "|    n_updates          | 88/128)     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.189       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 832        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 236        |\n",
      "|    total_timesteps    | 35323904   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03710357 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.964      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0189    |\n",
      "|    mean_step_reward   | 0.12289144 |\n",
      "|    n_updates          | 92/128)    |\n",
      "|    policyGradLoss     | -0.02      |\n",
      "|    value_loss         | 0.238      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 35332096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030216899 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0488     |\n",
      "|    mean_step_reward   | 0.13703586  |\n",
      "|    n_updates          | 96/128)     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.167       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 841         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 35340288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024339238 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0283     |\n",
      "|    mean_step_reward   | 0.13459347  |\n",
      "|    n_updates          | 100/128)    |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.237       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 844         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 35348480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027906246 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0498      |\n",
      "|    mean_step_reward   | 0.12916541  |\n",
      "|    n_updates          | 104/128)    |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.294       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 847         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 270         |\n",
      "|    total_timesteps    | 35356672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02335416  |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0354      |\n",
      "|    mean_step_reward   | 0.124626614 |\n",
      "|    n_updates          | 108/128)    |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.273       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 845         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 280         |\n",
      "|    total_timesteps    | 35364864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024321608 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0194     |\n",
      "|    mean_step_reward   | 0.14278162  |\n",
      "|    n_updates          | 112/128)    |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.235       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 845        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 290        |\n",
      "|    total_timesteps    | 35373056   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03331332 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.98       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.112      |\n",
      "|    mean_step_reward   | 0.13003394 |\n",
      "|    n_updates          | 116/128)   |\n",
      "|    policyGradLoss     | -0.0227    |\n",
      "|    value_loss         | 0.15       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 848         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 299         |\n",
      "|    total_timesteps    | 35381248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033660814 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.048      |\n",
      "|    mean_step_reward   | 0.1293199   |\n",
      "|    n_updates          | 120/128)    |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.238       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 850        |\n",
      "|    iterations         | 32         |\n",
      "|    time_elapsed       | 308        |\n",
      "|    total_timesteps    | 35389440   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01904924 |\n",
      "|    entropy_loss       | -1.76      |\n",
      "|    explained_variance | 0.963      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0309     |\n",
      "|    mean_step_reward   | 0.12515713 |\n",
      "|    n_updates          | 124/128)   |\n",
      "|    policyGradLoss     | -0.0148    |\n",
      "|    value_loss         | 0.283      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_134.zip\n",
      "[EVAL] Mean Return: 157.006, Best Return: 164.006\n",
      "Saved video to ./runs_smw/videos/Run/Run_134_157.01.mp4\n",
      "\n",
      "=== Round 136 | Learn 262144 steps (Total trained: 35389440) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1600     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 35397632 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1086        |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 15          |\n",
      "|    total_timesteps    | 35405824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026768029 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0534      |\n",
      "|    mean_step_reward   | 0.117780045 |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 847         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 35414016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030012254 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0446     |\n",
      "|    mean_step_reward   | 0.1279396   |\n",
      "|    n_updates          | 8/128)      |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.287       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 858         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 35422208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029390316 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0368     |\n",
      "|    mean_step_reward   | 0.123601735 |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.182       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 875         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 46          |\n",
      "|    total_timesteps    | 35430400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027745398 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0449     |\n",
      "|    mean_step_reward   | 0.13548014  |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.0212     |\n",
      "|    value_loss         | 0.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 883         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 55          |\n",
      "|    total_timesteps    | 35438592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027742565 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00758    |\n",
      "|    mean_step_reward   | 0.12022717  |\n",
      "|    n_updates          | 20/128)     |\n",
      "|    policyGradLoss     | -0.0209     |\n",
      "|    value_loss         | 0.243       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 884        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 64         |\n",
      "|    total_timesteps    | 35446784   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02142156 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.968      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0122    |\n",
      "|    mean_step_reward   | 0.11764423 |\n",
      "|    n_updates          | 24/128)    |\n",
      "|    policyGradLoss     | -0.0158    |\n",
      "|    value_loss         | 0.235      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 871         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 75          |\n",
      "|    total_timesteps    | 35454976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029438991 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0447     |\n",
      "|    mean_step_reward   | 0.13957144  |\n",
      "|    n_updates          | 28/128)     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.199       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 864         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 35463168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031846635 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.06       |\n",
      "|    mean_step_reward   | 0.13606983  |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.0223     |\n",
      "|    value_loss         | 0.101       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 860         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 95          |\n",
      "|    total_timesteps    | 35471360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029539295 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0422     |\n",
      "|    mean_step_reward   | 0.13684557  |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.175       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 858         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 35479552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029443633 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0222     |\n",
      "|    mean_step_reward   | 0.12466717  |\n",
      "|    n_updates          | 40/128)     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.237       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 857         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 35487744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030903053 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0284     |\n",
      "|    mean_step_reward   | 0.13783942  |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.246       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 862         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 35495936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024822146 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0119      |\n",
      "|    mean_step_reward   | 0.1274415   |\n",
      "|    n_updates          | 48/128)     |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.214       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 865         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 132         |\n",
      "|    total_timesteps    | 35504128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.035669055 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0658     |\n",
      "|    mean_step_reward   | 0.14666447  |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.0211     |\n",
      "|    value_loss         | 0.126       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 862         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 35512320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020001046 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0453     |\n",
      "|    mean_step_reward   | 0.13042885  |\n",
      "|    n_updates          | 56/128)     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.108       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 862         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 151         |\n",
      "|    total_timesteps    | 35520512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.035306983 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0657     |\n",
      "|    mean_step_reward   | 0.14313912  |\n",
      "|    n_updates          | 60/128)     |\n",
      "|    policyGradLoss     | -0.0213     |\n",
      "|    value_loss         | 0.125       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 866         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 35528704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023892015 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0678     |\n",
      "|    mean_step_reward   | 0.12035404  |\n",
      "|    n_updates          | 64/128)     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.148       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 870         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 35536896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.035576858 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0598     |\n",
      "|    mean_step_reward   | 0.14159232  |\n",
      "|    n_updates          | 68/128)     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.131       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 873         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 35545088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021793978 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0335     |\n",
      "|    mean_step_reward   | 0.13357234  |\n",
      "|    n_updates          | 72/128)     |\n",
      "|    policyGradLoss     | -0.00959    |\n",
      "|    value_loss         | 0.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 876         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 186         |\n",
      "|    total_timesteps    | 35553280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031610433 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0463     |\n",
      "|    mean_step_reward   | 0.1462727   |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.179       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 879         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 195         |\n",
      "|    total_timesteps    | 35561472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029762458 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.03       |\n",
      "|    mean_step_reward   | 0.13326     |\n",
      "|    n_updates          | 80/128)     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.219       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 882        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 204        |\n",
      "|    total_timesteps    | 35569664   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03485103 |\n",
      "|    entropy_loss       | -1.71      |\n",
      "|    explained_variance | 0.979      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0534    |\n",
      "|    mean_step_reward   | 0.14427441 |\n",
      "|    n_updates          | 84/128)    |\n",
      "|    policyGradLoss     | -0.0207    |\n",
      "|    value_loss         | 0.148      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 871         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 216         |\n",
      "|    total_timesteps    | 35577856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032948762 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.059      |\n",
      "|    mean_step_reward   | 0.12422772  |\n",
      "|    n_updates          | 88/128)     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.184       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 872        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 225        |\n",
      "|    total_timesteps    | 35586048   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02531929 |\n",
      "|    entropy_loss       | -1.7       |\n",
      "|    explained_variance | 0.97       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0263     |\n",
      "|    mean_step_reward   | 0.13314757 |\n",
      "|    n_updates          | 92/128)    |\n",
      "|    policyGradLoss     | -0.0163    |\n",
      "|    value_loss         | 0.284      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 874         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 234         |\n",
      "|    total_timesteps    | 35594240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030195521 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0601     |\n",
      "|    mean_step_reward   | 0.1287102   |\n",
      "|    n_updates          | 96/128)     |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.184       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 876         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 35602432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023576777 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0131     |\n",
      "|    mean_step_reward   | 0.12228706  |\n",
      "|    n_updates          | 100/128)    |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.268       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 878         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 35610624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025991969 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0247     |\n",
      "|    mean_step_reward   | 0.13536626  |\n",
      "|    n_updates          | 104/128)    |\n",
      "|    policyGradLoss     | -0.0154     |\n",
      "|    value_loss         | 0.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 874         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 35618816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028182995 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.034       |\n",
      "|    mean_step_reward   | 0.12661877  |\n",
      "|    n_updates          | 108/128)    |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.21        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 872        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 272        |\n",
      "|    total_timesteps    | 35627008   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03383526 |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.969      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0458    |\n",
      "|    mean_step_reward   | 0.13075143 |\n",
      "|    n_updates          | 112/128)   |\n",
      "|    policyGradLoss     | -0.0214    |\n",
      "|    value_loss         | 0.173      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 870        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 282        |\n",
      "|    total_timesteps    | 35635200   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02384664 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.973      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00176   |\n",
      "|    mean_step_reward   | 0.12035388 |\n",
      "|    n_updates          | 116/128)   |\n",
      "|    policyGradLoss     | -0.0173    |\n",
      "|    value_loss         | 0.236      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 868         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 35643392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.035717208 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0792     |\n",
      "|    mean_step_reward   | 0.13472077  |\n",
      "|    n_updates          | 120/128)    |\n",
      "|    policyGradLoss     | -0.0216     |\n",
      "|    value_loss         | 0.127       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 868         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 301         |\n",
      "|    total_timesteps    | 35651584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019231286 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.052      |\n",
      "|    mean_step_reward   | 0.13288283  |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.139       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_135.zip\n",
      "[EVAL] Mean Return: 155.954, Best Return: 162.954\n",
      "Saved video to ./runs_smw/videos/Run/Run_135_155.95.mp4\n",
      "\n",
      "=== Round 137 | Learn 262144 steps (Total trained: 35651584) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1335     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 35659776 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1046       |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 15         |\n",
      "|    total_timesteps    | 35667968   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02633458 |\n",
      "|    entropy_loss       | -1.72      |\n",
      "|    explained_variance | 0.973      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0542    |\n",
      "|    mean_step_reward   | 0.13195178 |\n",
      "|    n_updates          | 4/128)     |\n",
      "|    policyGradLoss     | -0.0192    |\n",
      "|    value_loss         | 0.22       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1008       |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 24         |\n",
      "|    total_timesteps    | 35676160   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0359983  |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.983      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0639    |\n",
      "|    mean_step_reward   | 0.12463216 |\n",
      "|    n_updates          | 8/128)     |\n",
      "|    policyGradLoss     | -0.0233    |\n",
      "|    value_loss         | 0.0986     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 994         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 32          |\n",
      "|    total_timesteps    | 35684352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026963403 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.029      |\n",
      "|    mean_step_reward   | 0.13255218  |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.208       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 977         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 35692544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029760703 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0378     |\n",
      "|    mean_step_reward   | 0.12214692  |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.154       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 969         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 35700736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023033526 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0336     |\n",
      "|    mean_step_reward   | 0.124794334 |\n",
      "|    n_updates          | 20/128)     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.356       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 966         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 35708928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026050087 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0515     |\n",
      "|    mean_step_reward   | 0.13373412  |\n",
      "|    n_updates          | 24/128)     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.218       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 960         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 35717120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014023817 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0198      |\n",
      "|    mean_step_reward   | 0.13005632  |\n",
      "|    n_updates          | 28/128)     |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.265       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 919        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 80         |\n",
      "|    total_timesteps    | 35725312   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03035938 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.971      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0437    |\n",
      "|    mean_step_reward   | 0.13078767 |\n",
      "|    n_updates          | 32/128)    |\n",
      "|    policyGradLoss     | -0.0185    |\n",
      "|    value_loss         | 0.251      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 915         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 89          |\n",
      "|    total_timesteps    | 35733504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025152557 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0179     |\n",
      "|    mean_step_reward   | 0.11293534  |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.252       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 918         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 35741696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029142909 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0386     |\n",
      "|    mean_step_reward   | 0.14676696  |\n",
      "|    n_updates          | 40/128)     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.212       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 918         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 107         |\n",
      "|    total_timesteps    | 35749888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029567208 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0658     |\n",
      "|    mean_step_reward   | 0.11181097  |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.202       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 919        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 115        |\n",
      "|    total_timesteps    | 35758080   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02324067 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.973      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0369    |\n",
      "|    mean_step_reward   | 0.14204076 |\n",
      "|    n_updates          | 48/128)    |\n",
      "|    policyGradLoss     | -0.0172    |\n",
      "|    value_loss         | 0.197      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 907         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 126         |\n",
      "|    total_timesteps    | 35766272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034157015 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0461     |\n",
      "|    mean_step_reward   | 0.12395052  |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.0221     |\n",
      "|    value_loss         | 0.169       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 899         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 35774464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021984175 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.036      |\n",
      "|    mean_step_reward   | 0.14792502  |\n",
      "|    n_updates          | 56/128)     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.143       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 894         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 35782656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031057416 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0305     |\n",
      "|    mean_step_reward   | 0.122611485 |\n",
      "|    n_updates          | 60/128)     |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.223       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 890         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 35790848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029720267 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0147     |\n",
      "|    mean_step_reward   | 0.1292083   |\n",
      "|    n_updates          | 64/128)     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 887         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 35799040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027748857 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0643     |\n",
      "|    mean_step_reward   | 0.11636952  |\n",
      "|    n_updates          | 68/128)     |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 886         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 175         |\n",
      "|    total_timesteps    | 35807232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017731167 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0472      |\n",
      "|    mean_step_reward   | 0.12358566  |\n",
      "|    n_updates          | 72/128)     |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.396       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 888         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 184         |\n",
      "|    total_timesteps    | 35815424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019805832 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00436    |\n",
      "|    mean_step_reward   | 0.12492108  |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.015      |\n",
      "|    value_loss         | 0.287       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 887         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 193         |\n",
      "|    total_timesteps    | 35823616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.045506097 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.06       |\n",
      "|    mean_step_reward   | 0.1305717   |\n",
      "|    n_updates          | 80/128)     |\n",
      "|    policyGradLoss     | -0.0212     |\n",
      "|    value_loss         | 0.276       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 883         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 203         |\n",
      "|    total_timesteps    | 35831808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032328583 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0364     |\n",
      "|    mean_step_reward   | 0.110940844 |\n",
      "|    n_updates          | 84/128)     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.247       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 886         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 212         |\n",
      "|    total_timesteps    | 35840000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033333126 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0345     |\n",
      "|    mean_step_reward   | 0.1320481   |\n",
      "|    n_updates          | 88/128)     |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.224       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 888         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 35848192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030022237 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0397     |\n",
      "|    mean_step_reward   | 0.11149083  |\n",
      "|    n_updates          | 92/128)     |\n",
      "|    policyGradLoss     | -0.021      |\n",
      "|    value_loss         | 0.177       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 889         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 35856384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030888595 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0338     |\n",
      "|    mean_step_reward   | 0.14822869  |\n",
      "|    n_updates          | 96/128)     |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.229       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 891        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 239        |\n",
      "|    total_timesteps    | 35864576   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03608048 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.962      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0536    |\n",
      "|    mean_step_reward   | 0.11466949 |\n",
      "|    n_updates          | 100/128)   |\n",
      "|    policyGradLoss     | -0.0208    |\n",
      "|    value_loss         | 0.193      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 892         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 247         |\n",
      "|    total_timesteps    | 35872768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034959424 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0557     |\n",
      "|    mean_step_reward   | 0.13870136  |\n",
      "|    n_updates          | 104/128)    |\n",
      "|    policyGradLoss     | -0.0235     |\n",
      "|    value_loss         | 0.211       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 894         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 256         |\n",
      "|    total_timesteps    | 35880960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024823353 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0457     |\n",
      "|    mean_step_reward   | 0.12416541  |\n",
      "|    n_updates          | 108/128)    |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.196       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 891         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 266         |\n",
      "|    total_timesteps    | 35889152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029350545 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0709     |\n",
      "|    mean_step_reward   | 0.12230678  |\n",
      "|    n_updates          | 112/128)    |\n",
      "|    policyGradLoss     | -0.0227     |\n",
      "|    value_loss         | 0.131       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 871         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 35897344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034113873 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0257     |\n",
      "|    mean_step_reward   | 0.13436612  |\n",
      "|    n_updates          | 116/128)    |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.239       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 864         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 35905536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.039382756 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0412     |\n",
      "|    mean_step_reward   | 0.11985181  |\n",
      "|    n_updates          | 120/128)    |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.169       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 860         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 35913728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024992928 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0425     |\n",
      "|    mean_step_reward   | 0.13972658  |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.182       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_136.zip\n",
      "[EVAL] Mean Return: 155.482, Best Return: 162.482\n",
      "Saved video to ./runs_smw/videos/Run/Run_136_155.48.mp4\n",
      "\n",
      "=== Round 138 | Learn 262144 steps (Total trained: 35913728) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 987      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 35921920 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 792         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 20          |\n",
      "|    total_timesteps    | 35930112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030504113 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00672    |\n",
      "|    mean_step_reward   | 0.13429382  |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.0162     |\n",
      "|    value_loss         | 0.235       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 32          |\n",
      "|    total_timesteps    | 35938304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034777395 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0603     |\n",
      "|    mean_step_reward   | 0.12812614  |\n",
      "|    n_updates          | 8/128)      |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.163       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 749         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 43          |\n",
      "|    total_timesteps    | 35946496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028055271 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00488     |\n",
      "|    mean_step_reward   | 0.13733369  |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 742         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 55          |\n",
      "|    total_timesteps    | 35954688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018526383 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00123     |\n",
      "|    mean_step_reward   | 0.106245704 |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.4         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 728        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 67         |\n",
      "|    total_timesteps    | 35962880   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03698259 |\n",
      "|    entropy_loss       | -1.76      |\n",
      "|    explained_variance | 0.978      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0639    |\n",
      "|    mean_step_reward   | 0.1460446  |\n",
      "|    n_updates          | 20/128)    |\n",
      "|    policyGradLoss     | -0.021     |\n",
      "|    value_loss         | 0.117      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 696         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 35971072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030884953 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0643     |\n",
      "|    mean_step_reward   | 0.12051915  |\n",
      "|    n_updates          | 24/128)     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.147       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 694         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 94          |\n",
      "|    total_timesteps    | 35979264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031336457 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0274     |\n",
      "|    mean_step_reward   | 0.1468206   |\n",
      "|    n_updates          | 28/128)     |\n",
      "|    policyGradLoss     | -0.0218     |\n",
      "|    value_loss         | 0.177       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 695         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 35987456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028771609 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0384     |\n",
      "|    mean_step_reward   | 0.11997217  |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.241       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 700         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 117         |\n",
      "|    total_timesteps    | 35995648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032474462 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0475     |\n",
      "|    mean_step_reward   | 0.14074144  |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.0219     |\n",
      "|    value_loss         | 0.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 702         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 128         |\n",
      "|    total_timesteps    | 36003840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030292774 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0478     |\n",
      "|    mean_step_reward   | 0.10941378  |\n",
      "|    n_updates          | 40/128)     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 703         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 139         |\n",
      "|    total_timesteps    | 36012032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032547344 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0597     |\n",
      "|    mean_step_reward   | 0.15179843  |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0226     |\n",
      "|    value_loss         | 0.156       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 700        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 151        |\n",
      "|    total_timesteps    | 36020224   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03423179 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.978      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0661    |\n",
      "|    mean_step_reward   | 0.12229079 |\n",
      "|    n_updates          | 48/128)    |\n",
      "|    policyGradLoss     | -0.0236    |\n",
      "|    value_loss         | 0.13       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 690         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 36028416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027970456 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00664    |\n",
      "|    mean_step_reward   | 0.12486972  |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.246       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 680        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 180        |\n",
      "|    total_timesteps    | 36036608   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03817457 |\n",
      "|    entropy_loss       | -1.76      |\n",
      "|    explained_variance | 0.977      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0554    |\n",
      "|    mean_step_reward   | 0.12824243 |\n",
      "|    n_updates          | 56/128)    |\n",
      "|    policyGradLoss     | -0.0226    |\n",
      "|    value_loss         | 0.181      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 682        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 191        |\n",
      "|    total_timesteps    | 36044800   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02869974 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.974      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0522    |\n",
      "|    mean_step_reward   | 0.12996548 |\n",
      "|    n_updates          | 60/128)    |\n",
      "|    policyGradLoss     | -0.0196    |\n",
      "|    value_loss         | 0.2        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 686        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 202        |\n",
      "|    total_timesteps    | 36052992   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03125204 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.968      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0199     |\n",
      "|    mean_step_reward   | 0.1260849  |\n",
      "|    n_updates          | 64/128)    |\n",
      "|    policyGradLoss     | -0.021     |\n",
      "|    value_loss         | 0.204      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 687         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 214         |\n",
      "|    total_timesteps    | 36061184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027174426 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.109       |\n",
      "|    mean_step_reward   | 0.1376669   |\n",
      "|    n_updates          | 68/128)     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.233       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 684         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 227         |\n",
      "|    total_timesteps    | 36069376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014829354 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0114     |\n",
      "|    mean_step_reward   | 0.12848012  |\n",
      "|    n_updates          | 72/128)     |\n",
      "|    policyGradLoss     | -0.0137     |\n",
      "|    value_loss         | 0.229       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 678         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 36077568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026926786 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0165     |\n",
      "|    mean_step_reward   | 0.12981367  |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.269       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 673         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 36085760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024430929 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0489     |\n",
      "|    mean_step_reward   | 0.113750994 |\n",
      "|    n_updates          | 80/128)     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.181       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 671         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 268         |\n",
      "|    total_timesteps    | 36093952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033938617 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.07       |\n",
      "|    mean_step_reward   | 0.15069036  |\n",
      "|    n_updates          | 84/128)     |\n",
      "|    policyGradLoss     | -0.0226     |\n",
      "|    value_loss         | 0.125       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 670         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 280         |\n",
      "|    total_timesteps    | 36102144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032694783 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0605     |\n",
      "|    mean_step_reward   | 0.12162222  |\n",
      "|    n_updates          | 88/128)     |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.207       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 672         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 36110336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030035768 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0683      |\n",
      "|    mean_step_reward   | 0.12859572  |\n",
      "|    n_updates          | 92/128)     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.327       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 678         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 301         |\n",
      "|    total_timesteps    | 36118528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016456898 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00827    |\n",
      "|    mean_step_reward   | 0.1255683   |\n",
      "|    n_updates          | 96/128)     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.268       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 683         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 311         |\n",
      "|    total_timesteps    | 36126720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029690826 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0464     |\n",
      "|    mean_step_reward   | 0.13088     |\n",
      "|    n_updates          | 100/128)    |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.182       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 684        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 323        |\n",
      "|    total_timesteps    | 36134912   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.04086346 |\n",
      "|    entropy_loss       | -1.76      |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0462    |\n",
      "|    mean_step_reward   | 0.13837144 |\n",
      "|    n_updates          | 104/128)   |\n",
      "|    policyGradLoss     | -0.0227    |\n",
      "|    value_loss         | 0.157      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 682        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 336        |\n",
      "|    total_timesteps    | 36143104   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03218467 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.972      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00953    |\n",
      "|    mean_step_reward   | 0.12320885 |\n",
      "|    n_updates          | 108/128)   |\n",
      "|    policyGradLoss     | -0.0215    |\n",
      "|    value_loss         | 0.215      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 681         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 348         |\n",
      "|    total_timesteps    | 36151296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019046476 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0686      |\n",
      "|    mean_step_reward   | 0.10998632  |\n",
      "|    n_updates          | 112/128)    |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.348       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 680         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 360         |\n",
      "|    total_timesteps    | 36159488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033705845 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0621     |\n",
      "|    mean_step_reward   | 0.13368656  |\n",
      "|    n_updates          | 116/128)    |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.173       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 680        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 373        |\n",
      "|    total_timesteps    | 36167680   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03176397 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.979      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0454    |\n",
      "|    mean_step_reward   | 0.11800879 |\n",
      "|    n_updates          | 120/128)   |\n",
      "|    policyGradLoss     | -0.023     |\n",
      "|    value_loss         | 0.181      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 680         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 385         |\n",
      "|    total_timesteps    | 36175872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030089078 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0482     |\n",
      "|    mean_step_reward   | 0.12458825  |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.216       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_137.zip\n",
      "[EVAL] Mean Return: 156.546, Best Return: 163.546\n",
      "Saved video to ./runs_smw/videos/Run/Run_137_156.55.mp4\n",
      "\n",
      "=== Round 139 | Learn 262144 steps (Total trained: 36175872) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1035     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 36184064 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 19          |\n",
      "|    total_timesteps    | 36192256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029417362 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.000882   |\n",
      "|    mean_step_reward   | 0.13686132  |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.206       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 783         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 31          |\n",
      "|    total_timesteps    | 36200448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029179223 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0528     |\n",
      "|    mean_step_reward   | 0.1171073   |\n",
      "|    n_updates          | 8/128)      |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.202       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 769         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 42          |\n",
      "|    total_timesteps    | 36208640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031944618 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00423    |\n",
      "|    mean_step_reward   | 0.13021876  |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.297       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 53          |\n",
      "|    total_timesteps    | 36216832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.03153058  |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0495     |\n",
      "|    mean_step_reward   | 0.122906715 |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.25        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 751        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 65         |\n",
      "|    total_timesteps    | 36225024   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03520223 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.974      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0447    |\n",
      "|    mean_step_reward   | 0.13346115 |\n",
      "|    n_updates          | 20/128)    |\n",
      "|    policyGradLoss     | -0.0213    |\n",
      "|    value_loss         | 0.179      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 716         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 80          |\n",
      "|    total_timesteps    | 36233216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020034797 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00691    |\n",
      "|    mean_step_reward   | 0.12673569  |\n",
      "|    n_updates          | 24/128)     |\n",
      "|    policyGradLoss     | -0.0174     |\n",
      "|    value_loss         | 0.239       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 701         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 36241408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.037140846 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0345      |\n",
      "|    mean_step_reward   | 0.13317123  |\n",
      "|    n_updates          | 28/128)     |\n",
      "|    policyGradLoss     | -0.0234     |\n",
      "|    value_loss         | 0.178       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 694        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 106        |\n",
      "|    total_timesteps    | 36249600   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0318061  |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.964      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00508    |\n",
      "|    mean_step_reward   | 0.13645074 |\n",
      "|    n_updates          | 32/128)    |\n",
      "|    policyGradLoss     | -0.0197    |\n",
      "|    value_loss         | 0.217      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 694         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 117         |\n",
      "|    total_timesteps    | 36257792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030403912 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0431     |\n",
      "|    mean_step_reward   | 0.12539628  |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.0219     |\n",
      "|    value_loss         | 0.2         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 694        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 129        |\n",
      "|    total_timesteps    | 36265984   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03041006 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.968      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0625    |\n",
      "|    mean_step_reward   | 0.13070215 |\n",
      "|    n_updates          | 40/128)    |\n",
      "|    policyGradLoss     | -0.0203    |\n",
      "|    value_loss         | 0.221      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 692         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 36274176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025446706 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0504     |\n",
      "|    mean_step_reward   | 0.12562796  |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.239       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 690         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 36282368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027834643 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0314     |\n",
      "|    mean_step_reward   | 0.133484    |\n",
      "|    n_updates          | 48/128)     |\n",
      "|    policyGradLoss     | -0.0167     |\n",
      "|    value_loss         | 0.208       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 688        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 166        |\n",
      "|    total_timesteps    | 36290560   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02855739 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.967      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0334    |\n",
      "|    mean_step_reward   | 0.12814772 |\n",
      "|    n_updates          | 52/128)    |\n",
      "|    policyGradLoss     | -0.0173    |\n",
      "|    value_loss         | 0.224      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 684         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 36298752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030322537 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0319     |\n",
      "|    mean_step_reward   | 0.1403702   |\n",
      "|    n_updates          | 56/128)     |\n",
      "|    policyGradLoss     | -0.02       |\n",
      "|    value_loss         | 0.241       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 681         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 192         |\n",
      "|    total_timesteps    | 36306944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031006875 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0529     |\n",
      "|    mean_step_reward   | 0.11654158  |\n",
      "|    n_updates          | 60/128)     |\n",
      "|    policyGradLoss     | -0.023      |\n",
      "|    value_loss         | 0.186       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 681         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 204         |\n",
      "|    total_timesteps    | 36315136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030456137 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0626     |\n",
      "|    mean_step_reward   | 0.13102743  |\n",
      "|    n_updates          | 64/128)     |\n",
      "|    policyGradLoss     | -0.0206     |\n",
      "|    value_loss         | 0.165       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 682        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 215        |\n",
      "|    total_timesteps    | 36323328   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03848039 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.969      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0318    |\n",
      "|    mean_step_reward   | 0.13257469 |\n",
      "|    n_updates          | 68/128)    |\n",
      "|    policyGradLoss     | -0.0215    |\n",
      "|    value_loss         | 0.219      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 684         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 227         |\n",
      "|    total_timesteps    | 36331520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025007814 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0206      |\n",
      "|    mean_step_reward   | 0.10718472  |\n",
      "|    n_updates          | 72/128)     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.313       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 683         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 239         |\n",
      "|    total_timesteps    | 36339712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.036858108 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0434     |\n",
      "|    mean_step_reward   | 0.13663223  |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0212     |\n",
      "|    value_loss         | 0.154       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 689         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 249         |\n",
      "|    total_timesteps    | 36347904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019357955 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0224      |\n",
      "|    mean_step_reward   | 0.10667397  |\n",
      "|    n_updates          | 80/128)     |\n",
      "|    policyGradLoss     | -0.0163     |\n",
      "|    value_loss         | 0.279       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 696         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 258         |\n",
      "|    total_timesteps    | 36356096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034080565 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0779     |\n",
      "|    mean_step_reward   | 0.13911107  |\n",
      "|    n_updates          | 84/128)     |\n",
      "|    policyGradLoss     | -0.0207     |\n",
      "|    value_loss         | 0.173       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 701         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 268         |\n",
      "|    total_timesteps    | 36364288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026014527 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0502     |\n",
      "|    mean_step_reward   | 0.105031714 |\n",
      "|    n_updates          | 88/128)     |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 699         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 281         |\n",
      "|    total_timesteps    | 36372480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027897358 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0602     |\n",
      "|    mean_step_reward   | 0.124378696 |\n",
      "|    n_updates          | 92/128)     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 698         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 36380672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.03133619  |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0386     |\n",
      "|    mean_step_reward   | 0.102097526 |\n",
      "|    n_updates          | 96/128)     |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.185       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 700         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 36388864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028321698 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0479     |\n",
      "|    mean_step_reward   | 0.13389757  |\n",
      "|    n_updates          | 100/128)    |\n",
      "|    policyGradLoss     | -0.0219     |\n",
      "|    value_loss         | 0.196       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 695         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 36397056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021730606 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0198     |\n",
      "|    mean_step_reward   | 0.10975078  |\n",
      "|    n_updates          | 104/128)    |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.249       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 693         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 36405248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029201383 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0529      |\n",
      "|    mean_step_reward   | 0.12307138  |\n",
      "|    n_updates          | 108/128)    |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.276       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 693         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 342         |\n",
      "|    total_timesteps    | 36413440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031816892 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0708     |\n",
      "|    mean_step_reward   | 0.12158483  |\n",
      "|    n_updates          | 112/128)    |\n",
      "|    policyGradLoss     | -0.0211     |\n",
      "|    value_loss         | 0.159       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 695         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 353         |\n",
      "|    total_timesteps    | 36421632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025008094 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0528     |\n",
      "|    mean_step_reward   | 0.12950712  |\n",
      "|    n_updates          | 116/128)    |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.207       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 693         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 365         |\n",
      "|    total_timesteps    | 36429824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030711064 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0553     |\n",
      "|    mean_step_reward   | 0.124102555 |\n",
      "|    n_updates          | 120/128)    |\n",
      "|    policyGradLoss     | -0.0214     |\n",
      "|    value_loss         | 0.127       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 691         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 379         |\n",
      "|    total_timesteps    | 36438016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.040590037 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0553     |\n",
      "|    mean_step_reward   | 0.139047    |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.187       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_138.zip\n",
      "[EVAL] Mean Return: 153.674, Best Return: 160.674\n",
      "Saved video to ./runs_smw/videos/Run/Run_138_153.67.mp4\n",
      "\n",
      "=== Round 140 | Learn 262144 steps (Total trained: 36438016) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1071     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 36446208 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 20          |\n",
      "|    total_timesteps    | 36454400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031245347 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0281     |\n",
      "|    mean_step_reward   | 0.13696164  |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.0208     |\n",
      "|    value_loss         | 0.241       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 750         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 32          |\n",
      "|    total_timesteps    | 36462592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032566205 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0605     |\n",
      "|    mean_step_reward   | 0.12037353  |\n",
      "|    n_updates          | 8/128)      |\n",
      "|    policyGradLoss     | -0.024      |\n",
      "|    value_loss         | 0.157       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 725         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 45          |\n",
      "|    total_timesteps    | 36470784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014516512 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0288     |\n",
      "|    mean_step_reward   | 0.120988704 |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.328       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 709         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 57          |\n",
      "|    total_timesteps    | 36478976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.037690066 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0397     |\n",
      "|    mean_step_reward   | 0.139102    |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.0221     |\n",
      "|    value_loss         | 0.164       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 709         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 69          |\n",
      "|    total_timesteps    | 36487168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030540738 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0513     |\n",
      "|    mean_step_reward   | 0.12018554  |\n",
      "|    n_updates          | 20/128)     |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.163       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 706        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 81         |\n",
      "|    total_timesteps    | 36495360   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03259842 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.961      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0124     |\n",
      "|    mean_step_reward   | 0.14117926 |\n",
      "|    n_updates          | 24/128)    |\n",
      "|    policyGradLoss     | -0.0188    |\n",
      "|    value_loss         | 0.278      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 700         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 36503552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031831816 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0444     |\n",
      "|    mean_step_reward   | 0.11506212  |\n",
      "|    n_updates          | 28/128)     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.162       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 697         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 36511744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030559437 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0416     |\n",
      "|    mean_step_reward   | 0.13839343  |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.0184     |\n",
      "|    value_loss         | 0.209       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 697         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 117         |\n",
      "|    total_timesteps    | 36519936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.035536073 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0235     |\n",
      "|    mean_step_reward   | 0.12168814  |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.243       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 700        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 128        |\n",
      "|    total_timesteps    | 36528128   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03220939 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.973      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.052     |\n",
      "|    mean_step_reward   | 0.12023756 |\n",
      "|    n_updates          | 40/128)    |\n",
      "|    policyGradLoss     | -0.0206    |\n",
      "|    value_loss         | 0.206      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 685        |\n",
      "|    iterations         | 12         |\n",
      "|    time_elapsed       | 143        |\n",
      "|    total_timesteps    | 36536320   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03303618 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.974      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0256    |\n",
      "|    mean_step_reward   | 0.1243059  |\n",
      "|    n_updates          | 44/128)    |\n",
      "|    policyGradLoss     | -0.0238    |\n",
      "|    value_loss         | 0.158      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 687         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 36544512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028225154 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0626     |\n",
      "|    mean_step_reward   | 0.123122066 |\n",
      "|    n_updates          | 48/128)     |\n",
      "|    policyGradLoss     | -0.022      |\n",
      "|    value_loss         | 0.167       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 688         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 36552704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029092722 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0265     |\n",
      "|    mean_step_reward   | 0.12542024  |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.191       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 689         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 36560896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016308822 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00843    |\n",
      "|    mean_step_reward   | 0.11786674  |\n",
      "|    n_updates          | 56/128)     |\n",
      "|    policyGradLoss     | -0.0148     |\n",
      "|    value_loss         | 0.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 687         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 36569088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027448675 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0295     |\n",
      "|    mean_step_reward   | 0.1343747   |\n",
      "|    n_updates          | 60/128)     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.226       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 686         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 202         |\n",
      "|    total_timesteps    | 36577280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030692017 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0278      |\n",
      "|    mean_step_reward   | 0.12142562  |\n",
      "|    n_updates          | 64/128)     |\n",
      "|    policyGradLoss     | -0.0233     |\n",
      "|    value_loss         | 0.157       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 690        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 213        |\n",
      "|    total_timesteps    | 36585472   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02940868 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.971      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0329    |\n",
      "|    mean_step_reward   | 0.12958373 |\n",
      "|    n_updates          | 68/128)    |\n",
      "|    policyGradLoss     | -0.0208    |\n",
      "|    value_loss         | 0.191      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 694         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 224         |\n",
      "|    total_timesteps    | 36593664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0207167   |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0223     |\n",
      "|    mean_step_reward   | 0.110958785 |\n",
      "|    n_updates          | 72/128)     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.249       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 694         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 235         |\n",
      "|    total_timesteps    | 36601856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029034676 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0368     |\n",
      "|    mean_step_reward   | 0.14694394  |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.181       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 693         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 248         |\n",
      "|    total_timesteps    | 36610048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019351907 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0827      |\n",
      "|    mean_step_reward   | 0.11386506  |\n",
      "|    n_updates          | 80/128)     |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 694         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 259         |\n",
      "|    total_timesteps    | 36618240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022640597 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.000951   |\n",
      "|    mean_step_reward   | 0.11964543  |\n",
      "|    n_updates          | 84/128)     |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.431       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 696        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 270        |\n",
      "|    total_timesteps    | 36626432   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03247061 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.968      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0276    |\n",
      "|    mean_step_reward   | 0.12896472 |\n",
      "|    n_updates          | 88/128)    |\n",
      "|    policyGradLoss     | -0.019     |\n",
      "|    value_loss         | 0.209      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 695         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 36634624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018644521 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0137      |\n",
      "|    mean_step_reward   | 0.11788771  |\n",
      "|    n_updates          | 92/128)     |\n",
      "|    policyGradLoss     | -0.0181     |\n",
      "|    value_loss         | 0.29        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 689        |\n",
      "|    iterations         | 25         |\n",
      "|    time_elapsed       | 297        |\n",
      "|    total_timesteps    | 36642816   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03488337 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.965      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.041     |\n",
      "|    mean_step_reward   | 0.14139725 |\n",
      "|    n_updates          | 96/128)    |\n",
      "|    policyGradLoss     | -0.0187    |\n",
      "|    value_loss         | 0.226      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 688         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 309         |\n",
      "|    total_timesteps    | 36651008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.048237644 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0319     |\n",
      "|    mean_step_reward   | 0.11456604  |\n",
      "|    n_updates          | 100/128)    |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 688         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 321         |\n",
      "|    total_timesteps    | 36659200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031847857 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0339     |\n",
      "|    mean_step_reward   | 0.13957213  |\n",
      "|    n_updates          | 104/128)    |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.257       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 689         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 332         |\n",
      "|    total_timesteps    | 36667392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019469976 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0181     |\n",
      "|    mean_step_reward   | 0.110815875 |\n",
      "|    n_updates          | 108/128)    |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 691         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 343         |\n",
      "|    total_timesteps    | 36675584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014997222 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.024       |\n",
      "|    mean_step_reward   | 0.1341995   |\n",
      "|    n_updates          | 112/128)    |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.262       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 692        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 355        |\n",
      "|    total_timesteps    | 36683776   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02744032 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.969      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0178    |\n",
      "|    mean_step_reward   | 0.12673411 |\n",
      "|    n_updates          | 116/128)   |\n",
      "|    policyGradLoss     | -0.0151    |\n",
      "|    value_loss         | 0.207      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 692         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 366         |\n",
      "|    total_timesteps    | 36691968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022657894 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.041      |\n",
      "|    mean_step_reward   | 0.12982117  |\n",
      "|    n_updates          | 120/128)    |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.187       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 685         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 382         |\n",
      "|    total_timesteps    | 36700160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023032818 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0486     |\n",
      "|    mean_step_reward   | 0.120237224 |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.235       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_139.zip\n",
      "[EVAL] Mean Return: 156.598, Best Return: 163.598\n",
      "Saved video to ./runs_smw/videos/Run/Run_139_156.60.mp4\n",
      "\n",
      "=== Round 141 | Learn 262144 steps (Total trained: 36700160) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1163     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 36708352 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 847        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 19         |\n",
      "|    total_timesteps    | 36716544   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02442089 |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.972      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0213    |\n",
      "|    mean_step_reward   | 0.13648883 |\n",
      "|    n_updates          | 4/128)     |\n",
      "|    policyGradLoss     | -0.0187    |\n",
      "|    value_loss         | 0.212      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 774         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 31          |\n",
      "|    total_timesteps    | 36724736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026452722 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0376     |\n",
      "|    mean_step_reward   | 0.13532875  |\n",
      "|    n_updates          | 8/128)      |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.186       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 738         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 44          |\n",
      "|    total_timesteps    | 36732928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.038172327 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0702     |\n",
      "|    mean_step_reward   | 0.12687469  |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.139       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 713         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 57          |\n",
      "|    total_timesteps    | 36741120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029774982 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0597     |\n",
      "|    mean_step_reward   | 0.13083716  |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.201       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 703         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 69          |\n",
      "|    total_timesteps    | 36749312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021778546 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0161     |\n",
      "|    mean_step_reward   | 0.1162741   |\n",
      "|    n_updates          | 20/128)     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.275       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 705        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 81         |\n",
      "|    total_timesteps    | 36757504   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03145547 |\n",
      "|    entropy_loss       | -1.74      |\n",
      "|    explained_variance | 0.982      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0723    |\n",
      "|    mean_step_reward   | 0.13621819 |\n",
      "|    n_updates          | 24/128)    |\n",
      "|    policyGradLoss     | -0.0216    |\n",
      "|    value_loss         | 0.131      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 707         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 36765696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024187054 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0612     |\n",
      "|    mean_step_reward   | 0.12156521  |\n",
      "|    n_updates          | 28/128)     |\n",
      "|    policyGradLoss     | -0.0198     |\n",
      "|    value_loss         | 0.162       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 702         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 36773888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.037078768 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.069      |\n",
      "|    mean_step_reward   | 0.14276098  |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.0229     |\n",
      "|    value_loss         | 0.119       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 690         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 118         |\n",
      "|    total_timesteps    | 36782080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.039753433 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0685     |\n",
      "|    mean_step_reward   | 0.12708858  |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.0218     |\n",
      "|    value_loss         | 0.148       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 687         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 131         |\n",
      "|    total_timesteps    | 36790272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.035577226 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0608     |\n",
      "|    mean_step_reward   | 0.12921865  |\n",
      "|    n_updates          | 40/128)     |\n",
      "|    policyGradLoss     | -0.0208     |\n",
      "|    value_loss         | 0.141       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 685         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 143         |\n",
      "|    total_timesteps    | 36798464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.044082526 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.071      |\n",
      "|    mean_step_reward   | 0.14436024  |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0236     |\n",
      "|    value_loss         | 0.111       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 687         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 36806656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033668745 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.025      |\n",
      "|    mean_step_reward   | 0.109053716 |\n",
      "|    n_updates          | 48/128)     |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.217       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 697        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 164        |\n",
      "|    total_timesteps    | 36814848   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0406852  |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0813    |\n",
      "|    mean_step_reward   | 0.14733298 |\n",
      "|    n_updates          | 52/128)    |\n",
      "|    policyGradLoss     | -0.0239    |\n",
      "|    value_loss         | 0.107      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 706         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 173         |\n",
      "|    total_timesteps    | 36823040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033296693 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0567     |\n",
      "|    mean_step_reward   | 0.119827665 |\n",
      "|    n_updates          | 56/128)     |\n",
      "|    policyGradLoss     | -0.0222     |\n",
      "|    value_loss         | 0.105       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 714       |\n",
      "|    iterations         | 16        |\n",
      "|    time_elapsed       | 183       |\n",
      "|    total_timesteps    | 36831232  |\n",
      "| train/                |           |\n",
      "|    approx_kl          | 0.0365877 |\n",
      "|    entropy_loss       | -1.74     |\n",
      "|    explained_variance | 0.981     |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    loss               | -0.056    |\n",
      "|    mean_step_reward   | 0.1508175 |\n",
      "|    n_updates          | 60/128)   |\n",
      "|    policyGradLoss     | -0.0206   |\n",
      "|    value_loss         | 0.146     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 702         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 36839424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.045065526 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0509     |\n",
      "|    mean_step_reward   | 0.12119369  |\n",
      "|    n_updates          | 64/128)     |\n",
      "|    policyGradLoss     | -0.0253     |\n",
      "|    value_loss         | 0.0986      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 702        |\n",
      "|    iterations         | 18         |\n",
      "|    time_elapsed       | 209        |\n",
      "|    total_timesteps    | 36847616   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02421315 |\n",
      "|    entropy_loss       | -1.74      |\n",
      "|    explained_variance | 0.986      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0353    |\n",
      "|    mean_step_reward   | 0.1497967  |\n",
      "|    n_updates          | 68/128)    |\n",
      "|    policyGradLoss     | -0.0186    |\n",
      "|    value_loss         | 0.141      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 703         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 36855808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030972324 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0288     |\n",
      "|    mean_step_reward   | 0.123740815 |\n",
      "|    n_updates          | 72/128)     |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.181       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 701         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 36864000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030099947 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0301     |\n",
      "|    mean_step_reward   | 0.1282925   |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.256       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 698         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 246         |\n",
      "|    total_timesteps    | 36872192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026542671 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.04       |\n",
      "|    mean_step_reward   | 0.12635067  |\n",
      "|    n_updates          | 80/128)     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 695         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 259         |\n",
      "|    total_timesteps    | 36880384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030119013 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0231     |\n",
      "|    mean_step_reward   | 0.12532508  |\n",
      "|    n_updates          | 84/128)     |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.166       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 694         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 36888576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030768294 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00155    |\n",
      "|    mean_step_reward   | 0.11858687  |\n",
      "|    n_updates          | 88/128)     |\n",
      "|    policyGradLoss     | -0.0176     |\n",
      "|    value_loss         | 0.312       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 694         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 36896768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028547741 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0634     |\n",
      "|    mean_step_reward   | 0.11660443  |\n",
      "|    n_updates          | 92/128)     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.248       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 693        |\n",
      "|    iterations         | 25         |\n",
      "|    time_elapsed       | 295        |\n",
      "|    total_timesteps    | 36904960   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02511122 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.966      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0354    |\n",
      "|    mean_step_reward   | 0.14049158 |\n",
      "|    n_updates          | 96/128)    |\n",
      "|    policyGradLoss     | -0.0164    |\n",
      "|    value_loss         | 0.224      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 691         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 307         |\n",
      "|    total_timesteps    | 36913152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024496226 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0443     |\n",
      "|    mean_step_reward   | 0.1062692   |\n",
      "|    n_updates          | 100/128)    |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.232       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 692         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 319         |\n",
      "|    total_timesteps    | 36921344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031246386 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0545     |\n",
      "|    mean_step_reward   | 0.1491099   |\n",
      "|    n_updates          | 104/128)    |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.202       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 693         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 36929536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028587528 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0682     |\n",
      "|    mean_step_reward   | 0.10850987  |\n",
      "|    n_updates          | 108/128)    |\n",
      "|    policyGradLoss     | -0.0216     |\n",
      "|    value_loss         | 0.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 695         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 341         |\n",
      "|    total_timesteps    | 36937728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030557014 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0416     |\n",
      "|    mean_step_reward   | 0.1508902   |\n",
      "|    n_updates          | 112/128)    |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.173       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 697         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 352         |\n",
      "|    total_timesteps    | 36945920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030903649 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0429      |\n",
      "|    mean_step_reward   | 0.111663654 |\n",
      "|    n_updates          | 116/128)    |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.203       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 698         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 363         |\n",
      "|    total_timesteps    | 36954112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.037395515 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0285     |\n",
      "|    mean_step_reward   | 0.15120319  |\n",
      "|    n_updates          | 120/128)    |\n",
      "|    policyGradLoss     | -0.0225     |\n",
      "|    value_loss         | 0.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 699         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 374         |\n",
      "|    total_timesteps    | 36962304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.035662442 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0643     |\n",
      "|    mean_step_reward   | 0.11944466  |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.0239     |\n",
      "|    value_loss         | 0.112       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_140.zip\n",
      "[EVAL] Mean Return: 157.656, Best Return: 163.990\n",
      "Saved video to ./runs_smw/videos/Run/Run_140_157.66.mp4\n",
      "\n",
      "=== Round 142 | Learn 262144 steps (Total trained: 36962304) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1110     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 36970496 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 20          |\n",
      "|    total_timesteps    | 36978688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022561276 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0333     |\n",
      "|    mean_step_reward   | 0.11591098  |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.0225     |\n",
      "|    value_loss         | 0.128       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 772         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 31          |\n",
      "|    total_timesteps    | 36986880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023951348 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0654      |\n",
      "|    mean_step_reward   | 0.119170666 |\n",
      "|    n_updates          | 8/128)      |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.256       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 750        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 43         |\n",
      "|    total_timesteps    | 36995072   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03393466 |\n",
      "|    entropy_loss       | -1.72      |\n",
      "|    explained_variance | 0.979      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.035     |\n",
      "|    mean_step_reward   | 0.15098654 |\n",
      "|    n_updates          | 12/128)    |\n",
      "|    policyGradLoss     | -0.0169    |\n",
      "|    value_loss         | 0.181      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 728         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 56          |\n",
      "|    total_timesteps    | 37003264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021724133 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0159     |\n",
      "|    mean_step_reward   | 0.114110686 |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.203       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 717        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 68         |\n",
      "|    total_timesteps    | 37011456   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03342028 |\n",
      "|    entropy_loss       | -1.68      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0764    |\n",
      "|    mean_step_reward   | 0.17108251 |\n",
      "|    n_updates          | 20/128)    |\n",
      "|    policyGradLoss     | -0.023     |\n",
      "|    value_loss         | 0.0765     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 717        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 79         |\n",
      "|    total_timesteps    | 37019648   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03901793 |\n",
      "|    entropy_loss       | -1.86      |\n",
      "|    explained_variance | 0.978      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.018     |\n",
      "|    mean_step_reward   | 0.10400442 |\n",
      "|    n_updates          | 24/128)    |\n",
      "|    policyGradLoss     | -0.0164    |\n",
      "|    value_loss         | 0.14       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 721         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 90          |\n",
      "|    total_timesteps    | 37027840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032546178 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00582    |\n",
      "|    mean_step_reward   | 0.1548924   |\n",
      "|    n_updates          | 28/128)     |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.236       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 705         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 37036032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030151064 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0573      |\n",
      "|    mean_step_reward   | 0.10197484  |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.0158     |\n",
      "|    value_loss         | 0.253       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 702        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 116        |\n",
      "|    total_timesteps    | 37044224   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03510587 |\n",
      "|    entropy_loss       | -1.72      |\n",
      "|    explained_variance | 0.979      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0671    |\n",
      "|    mean_step_reward   | 0.14279392 |\n",
      "|    n_updates          | 36/128)    |\n",
      "|    policyGradLoss     | -0.0232    |\n",
      "|    value_loss         | 0.179      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 713         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 126         |\n",
      "|    total_timesteps    | 37052416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027108837 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00546     |\n",
      "|    mean_step_reward   | 0.110963814 |\n",
      "|    n_updates          | 40/128)     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.296       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 725         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 135         |\n",
      "|    total_timesteps    | 37060608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024846865 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0624      |\n",
      "|    mean_step_reward   | 0.12147653  |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0183     |\n",
      "|    value_loss         | 0.313       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 735         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 37068800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015864491 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0449     |\n",
      "|    mean_step_reward   | 0.12756     |\n",
      "|    n_updates          | 48/128)     |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.209       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 734         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 37076992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023680288 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0161     |\n",
      "|    mean_step_reward   | 0.13092026  |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.209       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 730          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 168          |\n",
      "|    total_timesteps    | 37085184     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0141439885 |\n",
      "|    entropy_loss       | -1.77        |\n",
      "|    explained_variance | 0.976        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0158      |\n",
      "|    mean_step_reward   | 0.12316383   |\n",
      "|    n_updates          | 56/128)      |\n",
      "|    policyGradLoss     | -0.0164      |\n",
      "|    value_loss         | 0.197        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 726        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 180        |\n",
      "|    total_timesteps    | 37093376   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01936278 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.955      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0562     |\n",
      "|    mean_step_reward   | 0.12530202 |\n",
      "|    n_updates          | 60/128)    |\n",
      "|    policyGradLoss     | -0.0142    |\n",
      "|    value_loss         | 0.355      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 721        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 193        |\n",
      "|    total_timesteps    | 37101568   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03160657 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.975      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.063     |\n",
      "|    mean_step_reward   | 0.12977697 |\n",
      "|    n_updates          | 64/128)    |\n",
      "|    policyGradLoss     | -0.0212    |\n",
      "|    value_loss         | 0.165      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 715         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 206         |\n",
      "|    total_timesteps    | 37109760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029030984 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0481     |\n",
      "|    mean_step_reward   | 0.12386267  |\n",
      "|    n_updates          | 68/128)     |\n",
      "|    policyGradLoss     | -0.0139     |\n",
      "|    value_loss         | 0.237       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 713        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 218        |\n",
      "|    total_timesteps    | 37117952   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02502794 |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.965      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0283    |\n",
      "|    mean_step_reward   | 0.12777616 |\n",
      "|    n_updates          | 72/128)    |\n",
      "|    policyGradLoss     | -0.0186    |\n",
      "|    value_loss         | 0.264      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 712         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 37126144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028284878 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0587     |\n",
      "|    mean_step_reward   | 0.13060178  |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.254       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 712         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 37134336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027841713 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0512     |\n",
      "|    mean_step_reward   | 0.13251536  |\n",
      "|    n_updates          | 80/128)     |\n",
      "|    policyGradLoss     | -0.0215     |\n",
      "|    value_loss         | 0.137       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 706         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 37142528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024064481 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0275     |\n",
      "|    mean_step_reward   | 0.13105758  |\n",
      "|    n_updates          | 84/128)     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.178       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 705         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 266         |\n",
      "|    total_timesteps    | 37150720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033985212 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0572     |\n",
      "|    mean_step_reward   | 0.14119557  |\n",
      "|    n_updates          | 88/128)     |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.155       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 703         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 279         |\n",
      "|    total_timesteps    | 37158912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.036519058 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0473     |\n",
      "|    mean_step_reward   | 0.12325344  |\n",
      "|    n_updates          | 92/128)     |\n",
      "|    policyGradLoss     | -0.0261     |\n",
      "|    value_loss         | 0.138       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 702         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 291         |\n",
      "|    total_timesteps    | 37167104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027758203 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0338     |\n",
      "|    mean_step_reward   | 0.12600431  |\n",
      "|    n_updates          | 96/128)     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.272       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 702         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 302         |\n",
      "|    total_timesteps    | 37175296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030614441 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0464     |\n",
      "|    mean_step_reward   | 0.12969142  |\n",
      "|    n_updates          | 100/128)    |\n",
      "|    policyGradLoss     | -0.0228     |\n",
      "|    value_loss         | 0.153       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 704         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 313         |\n",
      "|    total_timesteps    | 37183488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029243294 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0582     |\n",
      "|    mean_step_reward   | 0.1260472   |\n",
      "|    n_updates          | 104/128)    |\n",
      "|    policyGradLoss     | -0.0218     |\n",
      "|    value_loss         | 0.156       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 705         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 324         |\n",
      "|    total_timesteps    | 37191680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.036557578 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0676     |\n",
      "|    mean_step_reward   | 0.13659695  |\n",
      "|    n_updates          | 108/128)    |\n",
      "|    policyGradLoss     | -0.023      |\n",
      "|    value_loss         | 0.138       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 699         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 37199872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028420478 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00719    |\n",
      "|    mean_step_reward   | 0.122502774 |\n",
      "|    n_updates          | 112/128)    |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.225       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 697        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 352        |\n",
      "|    total_timesteps    | 37208064   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.04432162 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.984      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0651    |\n",
      "|    mean_step_reward   | 0.13321176 |\n",
      "|    n_updates          | 116/128)   |\n",
      "|    policyGradLoss     | -0.0241    |\n",
      "|    value_loss         | 0.116      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 696         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 364         |\n",
      "|    total_timesteps    | 37216256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018212603 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0383     |\n",
      "|    mean_step_reward   | 0.13493851  |\n",
      "|    n_updates          | 120/128)    |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.189       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 697         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 375         |\n",
      "|    total_timesteps    | 37224448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025454856 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0122      |\n",
      "|    mean_step_reward   | 0.109162405 |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.0169     |\n",
      "|    value_loss         | 0.356       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_141.zip\n",
      "[EVAL] Mean Return: 155.028, Best Return: 162.694\n",
      "Saved video to ./runs_smw/videos/Run/Run_141_155.03.mp4\n",
      "\n",
      "=== Round 143 | Learn 262144 steps (Total trained: 37224448) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1009     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 37232640 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 782         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 20          |\n",
      "|    total_timesteps    | 37240832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031353552 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0628     |\n",
      "|    mean_step_reward   | 0.11676287  |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.0209     |\n",
      "|    value_loss         | 0.121       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 33          |\n",
      "|    total_timesteps    | 37249024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033717122 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0659     |\n",
      "|    mean_step_reward   | 0.13732144  |\n",
      "|    n_updates          | 8/128)      |\n",
      "|    policyGradLoss     | -0.0237     |\n",
      "|    value_loss         | 0.16        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 739        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 44         |\n",
      "|    total_timesteps    | 37257216   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03224699 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.968      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00703   |\n",
      "|    mean_step_reward   | 0.12339972 |\n",
      "|    n_updates          | 12/128)    |\n",
      "|    policyGradLoss     | -0.0188    |\n",
      "|    value_loss         | 0.197      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 739         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 55          |\n",
      "|    total_timesteps    | 37265408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032554757 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0494     |\n",
      "|    mean_step_reward   | 0.14737366  |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.154       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 717         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 37273600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017630562 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0443     |\n",
      "|    mean_step_reward   | 0.1294193   |\n",
      "|    n_updates          | 20/128)     |\n",
      "|    policyGradLoss     | -0.0147     |\n",
      "|    value_loss         | 0.217       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 703         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 37281792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030759653 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.065      |\n",
      "|    mean_step_reward   | 0.13323835  |\n",
      "|    n_updates          | 24/128)     |\n",
      "|    policyGradLoss     | -0.0221     |\n",
      "|    value_loss         | 0.147       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 705         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 37289984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031986892 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0428     |\n",
      "|    mean_step_reward   | 0.13553551  |\n",
      "|    n_updates          | 28/128)     |\n",
      "|    policyGradLoss     | -0.0199     |\n",
      "|    value_loss         | 0.191       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 720         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 37298176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032945685 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.063      |\n",
      "|    mean_step_reward   | 0.13869113  |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.0205     |\n",
      "|    value_loss         | 0.16        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 733        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 111        |\n",
      "|    total_timesteps    | 37306368   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03990809 |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.983      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0614    |\n",
      "|    mean_step_reward   | 0.13660493 |\n",
      "|    n_updates          | 36/128)    |\n",
      "|    policyGradLoss     | -0.0219    |\n",
      "|    value_loss         | 0.139      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 743         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 121         |\n",
      "|    total_timesteps    | 37314560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015528397 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0216      |\n",
      "|    mean_step_reward   | 0.12379059  |\n",
      "|    n_updates          | 40/128)     |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.342       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 741         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 132         |\n",
      "|    total_timesteps    | 37322752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.038964972 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0737     |\n",
      "|    mean_step_reward   | 0.13786496  |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0218     |\n",
      "|    value_loss         | 0.126       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 740         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 143         |\n",
      "|    total_timesteps    | 37330944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030267408 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0225     |\n",
      "|    mean_step_reward   | 0.1279014   |\n",
      "|    n_updates          | 48/128)     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.223       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 721         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 37339136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034112614 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0438     |\n",
      "|    mean_step_reward   | 0.12693553  |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.221       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 718        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 171        |\n",
      "|    total_timesteps    | 37347328   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03679569 |\n",
      "|    entropy_loss       | -1.74      |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0642    |\n",
      "|    mean_step_reward   | 0.14077407 |\n",
      "|    n_updates          | 56/128)    |\n",
      "|    policyGradLoss     | -0.0234    |\n",
      "|    value_loss         | 0.149      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 716         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 182         |\n",
      "|    total_timesteps    | 37355520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.039428264 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0514     |\n",
      "|    mean_step_reward   | 0.13538274  |\n",
      "|    n_updates          | 60/128)     |\n",
      "|    policyGradLoss     | -0.0257     |\n",
      "|    value_loss         | 0.0965      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 712         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 195         |\n",
      "|    total_timesteps    | 37363712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034968235 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0423     |\n",
      "|    mean_step_reward   | 0.1169473   |\n",
      "|    n_updates          | 64/128)     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.218       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 709         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 207         |\n",
      "|    total_timesteps    | 37371904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030368851 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0358     |\n",
      "|    mean_step_reward   | 0.13715038  |\n",
      "|    n_updates          | 68/128)     |\n",
      "|    policyGradLoss     | -0.0192     |\n",
      "|    value_loss         | 0.155       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 707        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 220        |\n",
      "|    total_timesteps    | 37380096   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0344772  |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.963      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0406     |\n",
      "|    mean_step_reward   | 0.10581978 |\n",
      "|    n_updates          | 72/128)    |\n",
      "|    policyGradLoss     | -0.0196    |\n",
      "|    value_loss         | 0.244      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 706         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 37388288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031257078 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0331     |\n",
      "|    mean_step_reward   | 0.132754    |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 703         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 37396480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.040876925 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0641     |\n",
      "|    mean_step_reward   | 0.13173857  |\n",
      "|    n_updates          | 80/128)     |\n",
      "|    policyGradLoss     | -0.0235     |\n",
      "|    value_loss         | 0.155       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 700         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 257         |\n",
      "|    total_timesteps    | 37404672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034842245 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0858     |\n",
      "|    mean_step_reward   | 0.13512337  |\n",
      "|    n_updates          | 84/128)     |\n",
      "|    policyGradLoss     | -0.0279     |\n",
      "|    value_loss         | 0.116       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 697         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 269         |\n",
      "|    total_timesteps    | 37412864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027129233 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0488     |\n",
      "|    mean_step_reward   | 0.13486913  |\n",
      "|    n_updates          | 88/128)     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.165       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 698         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 281         |\n",
      "|    total_timesteps    | 37421056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033285543 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0683     |\n",
      "|    mean_step_reward   | 0.12849227  |\n",
      "|    n_updates          | 92/128)     |\n",
      "|    policyGradLoss     | -0.0224     |\n",
      "|    value_loss         | 0.112       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 699        |\n",
      "|    iterations         | 25         |\n",
      "|    time_elapsed       | 292        |\n",
      "|    total_timesteps    | 37429248   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03705002 |\n",
      "|    entropy_loss       | -1.77      |\n",
      "|    explained_variance | 0.982      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0788    |\n",
      "|    mean_step_reward   | 0.1175631  |\n",
      "|    n_updates          | 96/128)    |\n",
      "|    policyGradLoss     | -0.0204    |\n",
      "|    value_loss         | 0.132      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 696        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 305        |\n",
      "|    total_timesteps    | 37437440   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03807527 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.979      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0562    |\n",
      "|    mean_step_reward   | 0.13926335 |\n",
      "|    n_updates          | 100/128)   |\n",
      "|    policyGradLoss     | -0.0219    |\n",
      "|    value_loss         | 0.177      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 695         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 37445632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029947028 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0537     |\n",
      "|    mean_step_reward   | 0.11800927  |\n",
      "|    n_updates          | 104/128)    |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.203       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 694         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 37453824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031088134 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0459     |\n",
      "|    mean_step_reward   | 0.14279366  |\n",
      "|    n_updates          | 108/128)    |\n",
      "|    policyGradLoss     | -0.0208     |\n",
      "|    value_loss         | 0.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 693         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 342         |\n",
      "|    total_timesteps    | 37462016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.035049573 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0548     |\n",
      "|    mean_step_reward   | 0.12897848  |\n",
      "|    n_updates          | 112/128)    |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.142       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 693         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 354         |\n",
      "|    total_timesteps    | 37470208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025865432 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0318      |\n",
      "|    mean_step_reward   | 0.12431332  |\n",
      "|    n_updates          | 116/128)    |\n",
      "|    policyGradLoss     | -0.0156     |\n",
      "|    value_loss         | 0.234       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 695         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 365         |\n",
      "|    total_timesteps    | 37478400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018289603 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0094      |\n",
      "|    mean_step_reward   | 0.123442896 |\n",
      "|    n_updates          | 120/128)    |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.258       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 696         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 376         |\n",
      "|    total_timesteps    | 37486592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.038057923 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0511     |\n",
      "|    mean_step_reward   | 0.13283245  |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.0242     |\n",
      "|    value_loss         | 0.163       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_142.zip\n",
      "[EVAL] Mean Return: 157.253, Best Return: 164.920\n",
      "Saved video to ./runs_smw/videos/Run/Run_142_157.25.mp4\n",
      "\n",
      "=== Round 144 | Learn 262144 steps (Total trained: 37486592) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1186     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 37494784 |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 925        |\n",
      "|    iterations         | 2          |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 37502976   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02850926 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.971      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0366    |\n",
      "|    mean_step_reward   | 0.13886476 |\n",
      "|    n_updates          | 4/128)     |\n",
      "|    policyGradLoss     | -0.0195    |\n",
      "|    value_loss         | 0.198      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 839         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 37511168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015693894 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0119      |\n",
      "|    mean_step_reward   | 0.13239715  |\n",
      "|    n_updates          | 8/128)      |\n",
      "|    policyGradLoss     | -0.0133     |\n",
      "|    value_loss         | 0.274       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 780         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 37519360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030585757 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0614     |\n",
      "|    mean_step_reward   | 0.1258449   |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.153       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 54          |\n",
      "|    total_timesteps    | 37527552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032164443 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00749     |\n",
      "|    mean_step_reward   | 0.11517492  |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.0164     |\n",
      "|    value_loss         | 0.244       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 752         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 65          |\n",
      "|    total_timesteps    | 37535744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.038023077 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0469     |\n",
      "|    mean_step_reward   | 0.1429168   |\n",
      "|    n_updates          | 20/128)     |\n",
      "|    policyGradLoss     | -0.0195     |\n",
      "|    value_loss         | 0.144       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 759         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 75          |\n",
      "|    total_timesteps    | 37543936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0308556   |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00494    |\n",
      "|    mean_step_reward   | 0.121268384 |\n",
      "|    n_updates          | 24/128)     |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.262       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 37552128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020590633 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0189     |\n",
      "|    mean_step_reward   | 0.12952164  |\n",
      "|    n_updates          | 28/128)     |\n",
      "|    policyGradLoss     | -0.0166     |\n",
      "|    value_loss         | 0.188       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 746         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 37560320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031280078 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0764     |\n",
      "|    mean_step_reward   | 0.14788122  |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.0238     |\n",
      "|    value_loss         | 0.125       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 738         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 110         |\n",
      "|    total_timesteps    | 37568512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.036135875 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0802     |\n",
      "|    mean_step_reward   | 0.11566506  |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.0241     |\n",
      "|    value_loss         | 0.0937      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 731         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 37576704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034094267 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0352     |\n",
      "|    mean_step_reward   | 0.12744202  |\n",
      "|    n_updates          | 40/128)     |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.226       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 722         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 37584896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023299325 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0342     |\n",
      "|    mean_step_reward   | 0.13365889  |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.216       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 722         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 37593088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.037536085 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0618     |\n",
      "|    mean_step_reward   | 0.14046511  |\n",
      "|    n_updates          | 48/128)     |\n",
      "|    policyGradLoss     | -0.0242     |\n",
      "|    value_loss         | 0.109       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 718         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 159         |\n",
      "|    total_timesteps    | 37601280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033769086 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00846    |\n",
      "|    mean_step_reward   | 0.1322824   |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.181       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 714         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 171         |\n",
      "|    total_timesteps    | 37609472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.036466673 |\n",
      "|    entropy_loss       | -1.7        |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.066      |\n",
      "|    mean_step_reward   | 0.14284217  |\n",
      "|    n_updates          | 56/128)     |\n",
      "|    policyGradLoss     | -0.0238     |\n",
      "|    value_loss         | 0.128       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 713         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 183         |\n",
      "|    total_timesteps    | 37617664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028801017 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0133     |\n",
      "|    mean_step_reward   | 0.12889875  |\n",
      "|    n_updates          | 60/128)     |\n",
      "|    policyGradLoss     | -0.0161     |\n",
      "|    value_loss         | 0.19        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 714        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 194        |\n",
      "|    total_timesteps    | 37625856   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03242281 |\n",
      "|    entropy_loss       | -1.69      |\n",
      "|    explained_variance | 0.977      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0252    |\n",
      "|    mean_step_reward   | 0.14615363 |\n",
      "|    n_updates          | 64/128)    |\n",
      "|    policyGradLoss     | -0.0192    |\n",
      "|    value_loss         | 0.188      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 716         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 205         |\n",
      "|    total_timesteps    | 37634048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033394918 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.076      |\n",
      "|    mean_step_reward   | 0.13370283  |\n",
      "|    n_updates          | 68/128)     |\n",
      "|    policyGradLoss     | -0.0203     |\n",
      "|    value_loss         | 0.0904      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 707        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 219        |\n",
      "|    total_timesteps    | 37642240   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03537917 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.977      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.029     |\n",
      "|    mean_step_reward   | 0.13050789 |\n",
      "|    n_updates          | 72/128)    |\n",
      "|    policyGradLoss     | -0.0209    |\n",
      "|    value_loss         | 0.204      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 705         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 37650432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.043862514 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0763     |\n",
      "|    mean_step_reward   | 0.12809628  |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0258     |\n",
      "|    value_loss         | 0.11        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 703        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 244        |\n",
      "|    total_timesteps    | 37658624   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03294196 |\n",
      "|    entropy_loss       | -1.74      |\n",
      "|    explained_variance | 0.979      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0672    |\n",
      "|    mean_step_reward   | 0.12759137 |\n",
      "|    n_updates          | 80/128)    |\n",
      "|    policyGradLoss     | -0.0217    |\n",
      "|    value_loss         | 0.169      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 701        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 256        |\n",
      "|    total_timesteps    | 37666816   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03469974 |\n",
      "|    entropy_loss       | -1.73      |\n",
      "|    explained_variance | 0.969      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0134     |\n",
      "|    mean_step_reward   | 0.13534015 |\n",
      "|    n_updates          | 84/128)    |\n",
      "|    policyGradLoss     | -0.0181    |\n",
      "|    value_loss         | 0.254      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 701         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 268         |\n",
      "|    total_timesteps    | 37675008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028842926 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.000283   |\n",
      "|    mean_step_reward   | 0.11224467  |\n",
      "|    n_updates          | 88/128)     |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.371       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 700         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 280         |\n",
      "|    total_timesteps    | 37683200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029739097 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0132      |\n",
      "|    mean_step_reward   | 0.13803425  |\n",
      "|    n_updates          | 92/128)     |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.259       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 699         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 37691392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031106304 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0148     |\n",
      "|    mean_step_reward   | 0.119962245 |\n",
      "|    n_updates          | 96/128)     |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.202       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 697        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 305        |\n",
      "|    total_timesteps    | 37699584   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03729391 |\n",
      "|    entropy_loss       | -1.74      |\n",
      "|    explained_variance | 0.982      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.051     |\n",
      "|    mean_step_reward   | 0.14492902 |\n",
      "|    n_updates          | 100/128)   |\n",
      "|    policyGradLoss     | -0.0224    |\n",
      "|    value_loss         | 0.163      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 694         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 37707776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030977333 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0347     |\n",
      "|    mean_step_reward   | 0.11510745  |\n",
      "|    n_updates          | 104/128)    |\n",
      "|    policyGradLoss     | -0.0196     |\n",
      "|    value_loss         | 0.158       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 693         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 37715968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029837113 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0257     |\n",
      "|    mean_step_reward   | 0.14507706  |\n",
      "|    n_updates          | 108/128)    |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.229       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 695         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 341         |\n",
      "|    total_timesteps    | 37724160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027138632 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0501     |\n",
      "|    mean_step_reward   | 0.12327759  |\n",
      "|    n_updates          | 112/128)    |\n",
      "|    policyGradLoss     | -0.0208     |\n",
      "|    value_loss         | 0.163       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 697         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 352         |\n",
      "|    total_timesteps    | 37732352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026929608 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0255      |\n",
      "|    mean_step_reward   | 0.13320623  |\n",
      "|    n_updates          | 116/128)    |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 699         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 363         |\n",
      "|    total_timesteps    | 37740544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016129475 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0338      |\n",
      "|    mean_step_reward   | 0.093175344 |\n",
      "|    n_updates          | 120/128)    |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.376       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 700         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 374         |\n",
      "|    total_timesteps    | 37748736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025068875 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0238      |\n",
      "|    mean_step_reward   | 0.1305864   |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.0231     |\n",
      "|    value_loss         | 0.325       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_143.zip\n",
      "[EVAL] Mean Return: 156.807, Best Return: 164.474\n",
      "Saved video to ./runs_smw/videos/Run/Run_143_156.81.mp4\n",
      "\n",
      "=== Round 145 | Learn 262144 steps (Total trained: 37748736) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1038     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 37756928 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 856         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 19          |\n",
      "|    total_timesteps    | 37765120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029766161 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0386     |\n",
      "|    mean_step_reward   | 0.14871103  |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.246       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 858         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 37773312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019700034 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0138      |\n",
      "|    mean_step_reward   | 0.110124364 |\n",
      "|    n_updates          | 8/128)      |\n",
      "|    policyGradLoss     | -0.0165     |\n",
      "|    value_loss         | 0.279       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 828         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 37781504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031166734 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0455      |\n",
      "|    mean_step_reward   | 0.13291818  |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.0222     |\n",
      "|    value_loss         | 0.257       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 830        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 49         |\n",
      "|    total_timesteps    | 37789696   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03040602 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.967      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0497    |\n",
      "|    mean_step_reward   | 0.1282392  |\n",
      "|    n_updates          | 16/128)    |\n",
      "|    policyGradLoss     | -0.0233    |\n",
      "|    value_loss         | 0.209      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 37797888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029608287 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0405     |\n",
      "|    mean_step_reward   | 0.12931679  |\n",
      "|    n_updates          | 20/128)     |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.173       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 799        |\n",
      "|    iterations         | 7          |\n",
      "|    time_elapsed       | 71         |\n",
      "|    total_timesteps    | 37806080   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03152487 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.983      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0513    |\n",
      "|    mean_step_reward   | 0.13878708 |\n",
      "|    n_updates          | 24/128)    |\n",
      "|    policyGradLoss     | -0.0234    |\n",
      "|    value_loss         | 0.144      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 790         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 37814272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030635469 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0431     |\n",
      "|    mean_step_reward   | 0.11424904  |\n",
      "|    n_updates          | 28/128)     |\n",
      "|    policyGradLoss     | -0.0226     |\n",
      "|    value_loss         | 0.178       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 785         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 37822464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024346117 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0349     |\n",
      "|    mean_step_reward   | 0.1419533   |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.26        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 780        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 105        |\n",
      "|    total_timesteps    | 37830656   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02198951 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.969      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0307    |\n",
      "|    mean_step_reward   | 0.11910342 |\n",
      "|    n_updates          | 36/128)    |\n",
      "|    policyGradLoss     | -0.0192    |\n",
      "|    value_loss         | 0.23       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 767         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 117         |\n",
      "|    total_timesteps    | 37838848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019048396 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0308      |\n",
      "|    mean_step_reward   | 0.135095    |\n",
      "|    n_updates          | 40/128)     |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 738         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 133         |\n",
      "|    total_timesteps    | 37847040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.025387483 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0576      |\n",
      "|    mean_step_reward   | 0.11219704  |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.379       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 728         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 37855232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027723545 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0374     |\n",
      "|    mean_step_reward   | 0.13917601  |\n",
      "|    n_updates          | 48/128)     |\n",
      "|    policyGradLoss     | -0.0213     |\n",
      "|    value_loss         | 0.163       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 725         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 37863424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020282064 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0554     |\n",
      "|    mean_step_reward   | 0.12668118  |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.0189     |\n",
      "|    value_loss         | 0.136       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 723         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 37871616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032878928 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0691     |\n",
      "|    mean_step_reward   | 0.14101918  |\n",
      "|    n_updates          | 56/128)     |\n",
      "|    policyGradLoss     | -0.0222     |\n",
      "|    value_loss         | 0.172       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 723         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 37879808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024479493 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00595    |\n",
      "|    mean_step_reward   | 0.12426681  |\n",
      "|    n_updates          | 60/128)     |\n",
      "|    policyGradLoss     | -0.0178     |\n",
      "|    value_loss         | 0.243       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 719         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 193         |\n",
      "|    total_timesteps    | 37888000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030682372 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0605     |\n",
      "|    mean_step_reward   | 0.14235479  |\n",
      "|    n_updates          | 64/128)     |\n",
      "|    policyGradLoss     | -0.0188     |\n",
      "|    value_loss         | 0.178       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 714         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 206         |\n",
      "|    total_timesteps    | 37896192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.032828517 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0547     |\n",
      "|    mean_step_reward   | 0.11277577  |\n",
      "|    n_updates          | 68/128)     |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.201       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 710         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 37904384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029488843 |\n",
      "|    entropy_loss       | -1.73       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00377    |\n",
      "|    mean_step_reward   | 0.13454717  |\n",
      "|    n_updates          | 72/128)     |\n",
      "|    policyGradLoss     | -0.018      |\n",
      "|    value_loss         | 0.316       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 707         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 37912576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029410055 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.000609   |\n",
      "|    mean_step_reward   | 0.12669635  |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.185       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 706         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 37920768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.023951832 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0297     |\n",
      "|    mean_step_reward   | 0.11333887  |\n",
      "|    n_updates          | 80/128)     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.269       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 707         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 254         |\n",
      "|    total_timesteps    | 37928960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027597168 |\n",
      "|    entropy_loss       | -1.71       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0174     |\n",
      "|    mean_step_reward   | 0.14418708  |\n",
      "|    n_updates          | 84/128)     |\n",
      "|    policyGradLoss     | -0.0171     |\n",
      "|    value_loss         | 0.223       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 707        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 266        |\n",
      "|    total_timesteps    | 37937152   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03659258 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.967      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00854   |\n",
      "|    mean_step_reward   | 0.10998168 |\n",
      "|    n_updates          | 88/128)    |\n",
      "|    policyGradLoss     | -0.0198    |\n",
      "|    value_loss         | 0.23       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 703         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 279         |\n",
      "|    total_timesteps    | 37945344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027549807 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0193     |\n",
      "|    mean_step_reward   | 0.1293294   |\n",
      "|    n_updates          | 92/128)     |\n",
      "|    policyGradLoss     | -0.0197     |\n",
      "|    value_loss         | 0.233       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 700         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 37953536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033078566 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0485     |\n",
      "|    mean_step_reward   | 0.11606674  |\n",
      "|    n_updates          | 96/128)     |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.214       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 699         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 37961728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033832602 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0496     |\n",
      "|    mean_step_reward   | 0.13844492  |\n",
      "|    n_updates          | 100/128)    |\n",
      "|    policyGradLoss     | -0.0201     |\n",
      "|    value_loss         | 0.194       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 699         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 37969920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027296066 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00359    |\n",
      "|    mean_step_reward   | 0.12400991  |\n",
      "|    n_updates          | 104/128)    |\n",
      "|    policyGradLoss     | -0.016      |\n",
      "|    value_loss         | 0.225       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 700         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 37978112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030964687 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0379     |\n",
      "|    mean_step_reward   | 0.12537754  |\n",
      "|    n_updates          | 108/128)    |\n",
      "|    policyGradLoss     | -0.0202     |\n",
      "|    value_loss         | 0.205       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 701         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 37986304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020443305 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00794    |\n",
      "|    mean_step_reward   | 0.11916952  |\n",
      "|    n_updates          | 112/128)    |\n",
      "|    policyGradLoss     | -0.0185     |\n",
      "|    value_loss         | 0.285       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 702        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 349        |\n",
      "|    total_timesteps    | 37994496   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03615614 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.983      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0689    |\n",
      "|    mean_step_reward   | 0.13609864 |\n",
      "|    n_updates          | 116/128)   |\n",
      "|    policyGradLoss     | -0.0242    |\n",
      "|    value_loss         | 0.139      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 701         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 361         |\n",
      "|    total_timesteps    | 38002688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033549257 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00878    |\n",
      "|    mean_step_reward   | 0.12231786  |\n",
      "|    n_updates          | 120/128)    |\n",
      "|    policyGradLoss     | -0.0222     |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 693         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 377         |\n",
      "|    total_timesteps    | 38010880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.02573381  |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0539     |\n",
      "|    mean_step_reward   | 0.102213554 |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.0172     |\n",
      "|    value_loss         | 0.278       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_144.zip\n",
      "[EVAL] Mean Return: 157.378, Best Return: 165.045\n",
      "Saved video to ./runs_smw/videos/Run/Run_144_157.38.mp4\n",
      "\n",
      "=== Round 146 | Learn 262144 steps (Total trained: 38010880) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1461     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 38019072 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1016        |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 16          |\n",
      "|    total_timesteps    | 38027264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029396765 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0308     |\n",
      "|    mean_step_reward   | 0.101849474 |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.0187     |\n",
      "|    value_loss         | 0.265       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 879         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 38035456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028530492 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0539     |\n",
      "|    mean_step_reward   | 0.13978519  |\n",
      "|    n_updates          | 8/128)      |\n",
      "|    policyGradLoss     | -0.0186     |\n",
      "|    value_loss         | 0.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 38043648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031662405 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0241      |\n",
      "|    mean_step_reward   | 0.115832835 |\n",
      "|    n_updates          | 12/128)     |\n",
      "|    policyGradLoss     | -0.0194     |\n",
      "|    value_loss         | 0.268       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 775         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 38051840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.029178558 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0481     |\n",
      "|    mean_step_reward   | 0.13109516  |\n",
      "|    n_updates          | 16/128)     |\n",
      "|    policyGradLoss     | -0.0182     |\n",
      "|    value_loss         | 0.235       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 745         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 65          |\n",
      "|    total_timesteps    | 38060032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.034844276 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0906      |\n",
      "|    mean_step_reward   | 0.1191317   |\n",
      "|    n_updates          | 20/128)     |\n",
      "|    policyGradLoss     | -0.0204     |\n",
      "|    value_loss         | 0.189       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 731         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 38068224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026324322 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0614     |\n",
      "|    mean_step_reward   | 0.1184023   |\n",
      "|    n_updates          | 24/128)     |\n",
      "|    policyGradLoss     | -0.019      |\n",
      "|    value_loss         | 0.187       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 729         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 89          |\n",
      "|    total_timesteps    | 38076416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.028788384 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0558     |\n",
      "|    mean_step_reward   | 0.11071128  |\n",
      "|    n_updates          | 28/128)     |\n",
      "|    policyGradLoss     | -0.0191     |\n",
      "|    value_loss         | 0.274       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 731         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 100         |\n",
      "|    total_timesteps    | 38084608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.037482925 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0488     |\n",
      "|    mean_step_reward   | 0.108962506 |\n",
      "|    n_updates          | 32/128)     |\n",
      "|    policyGradLoss     | -0.0276     |\n",
      "|    value_loss         | 0.156       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 720         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 38092800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.039404854 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0882     |\n",
      "|    mean_step_reward   | 0.1110282   |\n",
      "|    n_updates          | 36/128)     |\n",
      "|    policyGradLoss     | -0.0254     |\n",
      "|    value_loss         | 0.117       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 709         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 127         |\n",
      "|    total_timesteps    | 38100992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.027811717 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0185      |\n",
      "|    mean_step_reward   | 0.11872329  |\n",
      "|    n_updates          | 40/128)     |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 704         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 139         |\n",
      "|    total_timesteps    | 38109184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.037331007 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00839    |\n",
      "|    mean_step_reward   | 0.12882754  |\n",
      "|    n_updates          | 44/128)     |\n",
      "|    policyGradLoss     | -0.0285     |\n",
      "|    value_loss         | 0.161       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 703         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 151         |\n",
      "|    total_timesteps    | 38117376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.024404004 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0607      |\n",
      "|    mean_step_reward   | 0.1198546   |\n",
      "|    n_updates          | 48/128)     |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.219       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 703         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 162         |\n",
      "|    total_timesteps    | 38125568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.030980421 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0515      |\n",
      "|    mean_step_reward   | 0.14291859  |\n",
      "|    n_updates          | 52/128)     |\n",
      "|    policyGradLoss     | -0.0219     |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 706         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 174         |\n",
      "|    total_timesteps    | 38133760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.033268534 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0624     |\n",
      "|    mean_step_reward   | 0.113565326 |\n",
      "|    n_updates          | 56/128)     |\n",
      "|    policyGradLoss     | -0.0229     |\n",
      "|    value_loss         | 0.133       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 707         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 185         |\n",
      "|    total_timesteps    | 38141952    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022977445 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0491     |\n",
      "|    mean_step_reward   | 0.14177631  |\n",
      "|    n_updates          | 60/128)     |\n",
      "|    policyGradLoss     | -0.021      |\n",
      "|    value_loss         | 0.158       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 707        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 196        |\n",
      "|    total_timesteps    | 38150144   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.02857903 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.969      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0292    |\n",
      "|    mean_step_reward   | 0.11319506 |\n",
      "|    n_updates          | 64/128)    |\n",
      "|    policyGradLoss     | -0.0203    |\n",
      "|    value_loss         | 0.252      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 693         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 212         |\n",
      "|    total_timesteps    | 38158336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020021094 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0924      |\n",
      "|    mean_step_reward   | 0.12843856  |\n",
      "|    n_updates          | 68/128)     |\n",
      "|    policyGradLoss     | -0.0145     |\n",
      "|    value_loss         | 0.372       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 690         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 225         |\n",
      "|    total_timesteps    | 38166528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.035342798 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0649     |\n",
      "|    mean_step_reward   | 0.13868183  |\n",
      "|    n_updates          | 72/128)     |\n",
      "|    policyGradLoss     | -0.0228     |\n",
      "|    value_loss         | 0.141       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 690         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 237         |\n",
      "|    total_timesteps    | 38174720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.035233065 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00926    |\n",
      "|    mean_step_reward   | 0.119648844 |\n",
      "|    n_updates          | 76/128)     |\n",
      "|    policyGradLoss     | -0.0177     |\n",
      "|    value_loss         | 0.217       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 692        |\n",
      "|    iterations         | 21         |\n",
      "|    time_elapsed       | 248        |\n",
      "|    total_timesteps    | 38182912   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01669775 |\n",
      "|    entropy_loss       | -1.74      |\n",
      "|    explained_variance | 0.974      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.018     |\n",
      "|    mean_step_reward   | 0.13486367 |\n",
      "|    n_updates          | 80/128)    |\n",
      "|    policyGradLoss     | -0.0134    |\n",
      "|    value_loss         | 0.238      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 694        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 259        |\n",
      "|    total_timesteps    | 38191104   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03890977 |\n",
      "|    entropy_loss       | -1.75      |\n",
      "|    explained_variance | 0.976      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0481    |\n",
      "|    mean_step_reward   | 0.1360292  |\n",
      "|    n_updates          | 84/128)    |\n",
      "|    policyGradLoss     | -0.0218    |\n",
      "|    value_loss         | 0.191      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 691        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 272        |\n",
      "|    total_timesteps    | 38199296   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03297475 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.979      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0674    |\n",
      "|    mean_step_reward   | 0.13630232 |\n",
      "|    n_updates          | 88/128)    |\n",
      "|    policyGradLoss     | -0.0183    |\n",
      "|    value_loss         | 0.14       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 688         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 38207488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.031424526 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0502     |\n",
      "|    mean_step_reward   | 0.13788529  |\n",
      "|    n_updates          | 92/128)     |\n",
      "|    policyGradLoss     | -0.0209     |\n",
      "|    value_loss         | 0.189       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 686         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 298         |\n",
      "|    total_timesteps    | 38215680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017350988 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0104      |\n",
      "|    mean_step_reward   | 0.11865316  |\n",
      "|    n_updates          | 96/128)     |\n",
      "|    policyGradLoss     | -0.0117     |\n",
      "|    value_loss         | 0.34        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 685         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 310         |\n",
      "|    total_timesteps    | 38223872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.035758134 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0521     |\n",
      "|    mean_step_reward   | 0.14440769  |\n",
      "|    n_updates          | 100/128)    |\n",
      "|    policyGradLoss     | -0.0229     |\n",
      "|    value_loss         | 0.164       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 685         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 322         |\n",
      "|    total_timesteps    | 38232064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.022190599 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.109       |\n",
      "|    mean_step_reward   | 0.10999316  |\n",
      "|    n_updates          | 104/128)    |\n",
      "|    policyGradLoss     | -0.0175     |\n",
      "|    value_loss         | 0.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 687         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 38240256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020189911 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0443     |\n",
      "|    mean_step_reward   | 0.14596847  |\n",
      "|    n_updates          | 108/128)    |\n",
      "|    policyGradLoss     | -0.0179     |\n",
      "|    value_loss         | 0.157       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 688         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 345         |\n",
      "|    total_timesteps    | 38248448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018793203 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.024      |\n",
      "|    mean_step_reward   | 0.12319809  |\n",
      "|    n_updates          | 112/128)    |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.221       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 685         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 358         |\n",
      "|    total_timesteps    | 38256640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019895379 |\n",
      "|    entropy_loss       | -1.72       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0806      |\n",
      "|    mean_step_reward   | 0.1447427   |\n",
      "|    n_updates          | 116/128)    |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.334       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 682        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 372        |\n",
      "|    total_timesteps    | 38264832   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.03709941 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.977      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0591    |\n",
      "|    mean_step_reward   | 0.11190376 |\n",
      "|    n_updates          | 120/128)   |\n",
      "|    policyGradLoss     | -0.021     |\n",
      "|    value_loss         | 0.134      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 684         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 382         |\n",
      "|    total_timesteps    | 38273024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.035092555 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00219    |\n",
      "|    mean_step_reward   | 0.15312594  |\n",
      "|    n_updates          | 124/128)    |\n",
      "|    policyGradLoss     | -0.0193     |\n",
      "|    value_loss         | 0.17        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/Run_145.zip\n",
      "[EVAL] Mean Return: 154.614, Best Return: 162.614\n",
      "Saved video to ./runs_smw/videos/Run/Run_145_154.61.mp4\n",
      "\n",
      "=== Round 147 | Learn 262144 steps (Total trained: 38273024) ===\n",
      "Logging to ./runs_smw/tb/Run_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1053     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 38281216 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 20          |\n",
      "|    total_timesteps    | 38289408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.026080651 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.101       |\n",
      "|    mean_step_reward   | 0.13478564  |\n",
      "|    n_updates          | 4/128)      |\n",
      "|    policyGradLoss     | -0.0173     |\n",
      "|    value_loss         | 0.269       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.Training finished. Environment closed.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.\n",
       "Training interrupted manually.Training finished. Environment closed.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# --- Train ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m trained += chunk\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/custom_policy.py:276\u001b[39m, in \u001b[36mCustomPPO.learn\u001b[39m\u001b[34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[39m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlearn\u001b[39m(\n\u001b[32m    268\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    269\u001b[39m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    274\u001b[39m     progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    275\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/stable_baselines3/common/on_policy_algorithm.py:337\u001b[39m, in \u001b[36mOnPolicyAlgorithm.learn\u001b[39m\u001b[34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[39m\n\u001b[32m    335\u001b[39m         \u001b[38;5;28mself\u001b[39m.dump_logs(iteration)\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m callback.on_training_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/custom_policy.py:240\u001b[39m, in \u001b[36mCustomPPO.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    239\u001b[39m     torch.nn.utils.clip_grad_norm_(\u001b[38;5;28mself\u001b[39m.policy.parameters(), \u001b[38;5;28mself\u001b[39m.max_grad_norm)\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[38;5;28mself\u001b[39m._n_updates += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:517\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    513\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    514\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:82\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/torch/optim/adam.py:247\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    237\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    238\u001b[39m         group,\n\u001b[32m    239\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    244\u001b[39m         state_steps,\n\u001b[32m    245\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:150\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/torch/optim/adam.py:953\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    951\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m953\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/torch/optim/adam.py:759\u001b[39m, in \u001b[36m_multi_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    757\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    758\u001b[39m     bias_correction1 = [\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m         \u001b[32m1\u001b[39m - beta1 ** \u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m device_state_steps\n\u001b[32m    760\u001b[39m     ]\n\u001b[32m    761\u001b[39m     bias_correction2 = [\n\u001b[32m    762\u001b[39m         \u001b[32m1\u001b[39m - beta2 ** _get_value(step) \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m device_state_steps\n\u001b[32m    763\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:97\u001b[39m, in \u001b[36m_get_value\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, torch.Tensor) \u001b[38;5;28;01melse\u001b[39;00m x\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRecursionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     33\u001b[39m         record_video(\n\u001b[32m     34\u001b[39m             model,\n\u001b[32m     35\u001b[39m             GAME,\n\u001b[32m   (...)\u001b[39m\u001b[32m     39\u001b[39m             prefix=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtagged_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_ret\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     40\u001b[39m         )\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mTraining interrupted manually.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     46\u001b[39m     train_env.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/rich/file_proxy.py:43\u001b[39m, in \u001b[36mFileProxy.write\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m lines:\n\u001b[32m     42\u001b[39m     console = \u001b[38;5;28mself\u001b[39m.__console\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconsole\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mText\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__ansi_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlines\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconsole\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/rich/console.py:870\u001b[39m, in \u001b[36mConsole.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_value, traceback)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type: Any, exc_value: Any, traceback: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    869\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Exit buffer context.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m870\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_exit_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/rich/console.py:826\u001b[39m, in \u001b[36mConsole._exit_buffer\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    824\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Leave buffer context, and render content if required.\"\"\"\u001b[39;00m\n\u001b[32m    825\u001b[39m \u001b[38;5;28mself\u001b[39m._buffer_index -= \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m826\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/rich/console.py:2038\u001b[39m, in \u001b[36mConsole._check_buffer\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2035\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   2037\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2038\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_write_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2039\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBrokenPipeError\u001b[39;00m:\n\u001b[32m   2040\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_broken_pipe()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/rich/console.py:2054\u001b[39m, in \u001b[36mConsole._write_buffer\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2051\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_jupyter:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[32m   2052\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mjupyter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display\n\u001b[32m-> \u001b[39m\u001b[32m2054\u001b[39m     \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_render_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_buffer\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2055\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer[:]\n\u001b[32m   2056\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/rich/jupyter.py:91\u001b[39m, in \u001b[36mdisplay\u001b[39m\u001b[34m(segments, text)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display \u001b[38;5;28;01mas\u001b[39;00m ipython_display\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     \u001b[43mipython_display\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjupyter_renderable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[32m     93\u001b[39m     \u001b[38;5;66;03m# Handle the case where the Console has force_jupyter=True,\u001b[39;00m\n\u001b[32m     94\u001b[39m     \u001b[38;5;66;03m# but IPython is not installed.\u001b[39;00m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/IPython/core/display_functions.py:285\u001b[39m, in \u001b[36mdisplay\u001b[39m\u001b[34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[39m\n\u001b[32m    282\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m metadata:\n\u001b[32m    283\u001b[39m             \u001b[38;5;66;03m# kwarg-specified metadata gets precedence\u001b[39;00m\n\u001b[32m    284\u001b[39m             _merge(md_dict, metadata)\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m         \u001b[43mpublish_display_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mformat_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmd_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m display_id:\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DisplayHandle(display_id)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/IPython/core/display_functions.py:73\u001b[39m, in \u001b[36mpublish_display_data\u001b[39m\u001b[34m(data, metadata, transient, **kwargs)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m transient:\n\u001b[32m     71\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mtransient\u001b[39m\u001b[33m'\u001b[39m] = transient\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43mdisplay_pub\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpublish\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/ipykernel/zmqshell.py:149\u001b[39m, in \u001b[36mZMQDisplayPublisher.publish\u001b[39m\u001b[34m(self, data, metadata, transient, update, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    146\u001b[39m         outputs.setdefault(exec_count, []).append(\n\u001b[32m    147\u001b[39m             HistoryOutput(output_type=\u001b[33m\"\u001b[39m\u001b[33mdisplay_data\u001b[39m\u001b[33m\"\u001b[39m, bundle=data)\n\u001b[32m    148\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flush_streams\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    151\u001b[39m     metadata = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/ipykernel/zmqshell.py:93\u001b[39m, in \u001b[36mZMQDisplayPublisher._flush_streams\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_flush_streams\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     92\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"flush IO Streams prior to display\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m     sys.stderr.flush()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/rich/file_proxy.py:53\u001b[39m, in \u001b[36mFileProxy.flush\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     51\u001b[39m output = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mself\u001b[39m.__buffer)\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output:\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__console\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__buffer[:]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/rich/console.py:1697\u001b[39m, in \u001b[36mConsole.print\u001b[39m\u001b[34m(self, sep, end, style, justify, overflow, no_wrap, emoji, markup, highlight, width, height, crop, soft_wrap, new_line_start, *objects)\u001b[39m\n\u001b[32m   1695\u001b[39m     crop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1696\u001b[39m render_hooks = \u001b[38;5;28mself\u001b[39m._render_hooks[:]\n\u001b[32m-> \u001b[39m\u001b[32m1697\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   1698\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrenderables\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_collect_renderables\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1699\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1700\u001b[39m \u001b[43m        \u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1705\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhighlight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhighlight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1706\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1707\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhook\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrender_hooks\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/rich/console.py:870\u001b[39m, in \u001b[36mConsole.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_value, traceback)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type: Any, exc_value: Any, traceback: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    869\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Exit buffer context.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m870\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_exit_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/rich/console.py:826\u001b[39m, in \u001b[36mConsole._exit_buffer\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    824\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Leave buffer context, and render content if required.\"\"\"\u001b[39;00m\n\u001b[32m    825\u001b[39m \u001b[38;5;28mself\u001b[39m._buffer_index -= \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m826\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/rich/console.py:2038\u001b[39m, in \u001b[36mConsole._check_buffer\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2035\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   2037\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2038\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_write_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2039\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBrokenPipeError\u001b[39;00m:\n\u001b[32m   2040\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_broken_pipe()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/rich/console.py:2054\u001b[39m, in \u001b[36mConsole._write_buffer\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2051\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_jupyter:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[32m   2052\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mjupyter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display\n\u001b[32m-> \u001b[39m\u001b[32m2054\u001b[39m     \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_render_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_buffer\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2055\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer[:]\n\u001b[32m   2056\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/rich/jupyter.py:91\u001b[39m, in \u001b[36mdisplay\u001b[39m\u001b[34m(segments, text)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display \u001b[38;5;28;01mas\u001b[39;00m ipython_display\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     \u001b[43mipython_display\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjupyter_renderable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[32m     93\u001b[39m     \u001b[38;5;66;03m# Handle the case where the Console has force_jupyter=True,\u001b[39;00m\n\u001b[32m     94\u001b[39m     \u001b[38;5;66;03m# but IPython is not installed.\u001b[39;00m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/IPython/core/display_functions.py:285\u001b[39m, in \u001b[36mdisplay\u001b[39m\u001b[34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[39m\n\u001b[32m    282\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m metadata:\n\u001b[32m    283\u001b[39m             \u001b[38;5;66;03m# kwarg-specified metadata gets precedence\u001b[39;00m\n\u001b[32m    284\u001b[39m             _merge(md_dict, metadata)\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m         \u001b[43mpublish_display_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mformat_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmd_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m display_id:\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DisplayHandle(display_id)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/IPython/core/display_functions.py:73\u001b[39m, in \u001b[36mpublish_display_data\u001b[39m\u001b[34m(data, metadata, transient, **kwargs)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m transient:\n\u001b[32m     71\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mtransient\u001b[39m\u001b[33m'\u001b[39m] = transient\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43mdisplay_pub\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpublish\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/ipykernel/zmqshell.py:149\u001b[39m, in \u001b[36mZMQDisplayPublisher.publish\u001b[39m\u001b[34m(self, data, metadata, transient, update, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    146\u001b[39m         outputs.setdefault(exec_count, []).append(\n\u001b[32m    147\u001b[39m             HistoryOutput(output_type=\u001b[33m\"\u001b[39m\u001b[33mdisplay_data\u001b[39m\u001b[33m\"\u001b[39m, bundle=data)\n\u001b[32m    148\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flush_streams\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    151\u001b[39m     metadata = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/ipykernel/zmqshell.py:93\u001b[39m, in \u001b[36mZMQDisplayPublisher._flush_streams\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_flush_streams\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     92\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"flush IO Streams prior to display\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m     sys.stderr.flush()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/rich/file_proxy.py:53\u001b[39m, in \u001b[36mFileProxy.flush\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     51\u001b[39m output = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mself\u001b[39m.__buffer)\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output:\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__console\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__buffer[:]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/rich/console.py:1697\u001b[39m, in \u001b[36mConsole.print\u001b[39m\u001b[34m(self, sep, end, style, justify, overflow, no_wrap, emoji, markup, highlight, width, height, crop, soft_wrap, new_line_start, *objects)\u001b[39m\n\u001b[32m   1695\u001b[39m     crop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1696\u001b[39m render_hooks = \u001b[38;5;28mself\u001b[39m._render_hooks[:]\n\u001b[32m-> \u001b[39m\u001b[32m1697\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   1698\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrenderables\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_collect_renderables\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1699\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1700\u001b[39m \u001b[43m        \u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1705\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhighlight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhighlight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1706\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1707\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhook\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrender_hooks\u001b[49m\u001b[43m:\u001b[49m\n",
      "    \u001b[31m[... skipping similar frames: Console.__exit__ at line 870 (268 times), Console._check_buffer at line 2038 (268 times), Console._exit_buffer at line 826 (268 times), Console._write_buffer at line 2054 (268 times), ZMQDisplayPublisher._flush_streams at line 93 (267 times), display at line 91 (267 times), display at line 285 (267 times), FileProxy.flush at line 53 (267 times), Console.print at line 1697 (267 times), ZMQDisplayPublisher.publish at line 149 (267 times), publish_display_data at line 73 (267 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/rich/jupyter.py:91\u001b[39m, in \u001b[36mdisplay\u001b[39m\u001b[34m(segments, text)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display \u001b[38;5;28;01mas\u001b[39;00m ipython_display\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     \u001b[43mipython_display\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjupyter_renderable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[32m     93\u001b[39m     \u001b[38;5;66;03m# Handle the case where the Console has force_jupyter=True,\u001b[39;00m\n\u001b[32m     94\u001b[39m     \u001b[38;5;66;03m# but IPython is not installed.\u001b[39;00m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/IPython/core/display_functions.py:285\u001b[39m, in \u001b[36mdisplay\u001b[39m\u001b[34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[39m\n\u001b[32m    282\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m metadata:\n\u001b[32m    283\u001b[39m             \u001b[38;5;66;03m# kwarg-specified metadata gets precedence\u001b[39;00m\n\u001b[32m    284\u001b[39m             _merge(md_dict, metadata)\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m         \u001b[43mpublish_display_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mformat_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmd_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m display_id:\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DisplayHandle(display_id)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/IPython/core/display_functions.py:73\u001b[39m, in \u001b[36mpublish_display_data\u001b[39m\u001b[34m(data, metadata, transient, **kwargs)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m transient:\n\u001b[32m     71\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mtransient\u001b[39m\u001b[33m'\u001b[39m] = transient\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43mdisplay_pub\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpublish\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/ipykernel/zmqshell.py:149\u001b[39m, in \u001b[36mZMQDisplayPublisher.publish\u001b[39m\u001b[34m(self, data, metadata, transient, update, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    146\u001b[39m         outputs.setdefault(exec_count, []).append(\n\u001b[32m    147\u001b[39m             HistoryOutput(output_type=\u001b[33m\"\u001b[39m\u001b[33mdisplay_data\u001b[39m\u001b[33m\"\u001b[39m, bundle=data)\n\u001b[32m    148\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flush_streams\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    151\u001b[39m     metadata = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/ipykernel/zmqshell.py:93\u001b[39m, in \u001b[36mZMQDisplayPublisher._flush_streams\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_flush_streams\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     92\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"flush IO Streams prior to display\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m     sys.stderr.flush()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/rich/file_proxy.py:53\u001b[39m, in \u001b[36mFileProxy.flush\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     51\u001b[39m output = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mself\u001b[39m.__buffer)\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output:\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__console\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__buffer[:]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/rich/console.py:1697\u001b[39m, in \u001b[36mConsole.print\u001b[39m\u001b[34m(self, sep, end, style, justify, overflow, no_wrap, emoji, markup, highlight, width, height, crop, soft_wrap, new_line_start, *objects)\u001b[39m\n\u001b[32m   1695\u001b[39m     crop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1696\u001b[39m render_hooks = \u001b[38;5;28mself\u001b[39m._render_hooks[:]\n\u001b[32m-> \u001b[39m\u001b[32m1697\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   1698\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrenderables\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_collect_renderables\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1699\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1700\u001b[39m \u001b[43m        \u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1705\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhighlight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhighlight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1706\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1707\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhook\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrender_hooks\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/rich/console.py:870\u001b[39m, in \u001b[36mConsole.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_value, traceback)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type: Any, exc_value: Any, traceback: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    869\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Exit buffer context.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m870\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_exit_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/rich/console.py:826\u001b[39m, in \u001b[36mConsole._exit_buffer\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    824\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Leave buffer context, and render content if required.\"\"\"\u001b[39;00m\n\u001b[32m    825\u001b[39m \u001b[38;5;28mself\u001b[39m._buffer_index -= \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m826\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/rich/console.py:2038\u001b[39m, in \u001b[36mConsole._check_buffer\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2035\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   2037\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2038\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_write_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2039\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBrokenPipeError\u001b[39;00m:\n\u001b[32m   2040\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_broken_pipe()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/rich/console.py:2054\u001b[39m, in \u001b[36mConsole._write_buffer\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2051\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_jupyter:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[32m   2052\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mjupyter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display\n\u001b[32m-> \u001b[39m\u001b[32m2054\u001b[39m     \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_render_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_buffer\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2055\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer[:]\n\u001b[32m   2056\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/rich/jupyter.py:86\u001b[39m, in \u001b[36mdisplay\u001b[39m\u001b[34m(segments, text)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdisplay\u001b[39m(segments: Iterable[Segment], text: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     85\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Render segments to Jupyter.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     html = \u001b[43m_render_segments\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m     jupyter_renderable = JupyterRenderable(html, text)\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/rich/jupyter.py:67\u001b[39m, in \u001b[36m_render_segments\u001b[39m\u001b[34m(segments)\u001b[39m\n\u001b[32m     65\u001b[39m append_fragment = fragments.append\n\u001b[32m     66\u001b[39m theme = DEFAULT_TERMINAL_THEME\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSegment\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimplify\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegments\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mcontinue\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Lab8/.venv/lib/python3.12/site-packages/rich/segment.py:541\u001b[39m, in \u001b[36mSegment.simplify\u001b[39m\u001b[34m(cls, segments)\u001b[39m\n\u001b[32m    539\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m segment \u001b[38;5;129;01min\u001b[39;00m iter_segments:\n\u001b[32m    540\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m last_segment.style == segment.style \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m segment.control:\n\u001b[32m--> \u001b[39m\u001b[32m541\u001b[39m         last_segment = \u001b[43m_Segment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    542\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlast_segment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_segment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstyle\u001b[49m\n\u001b[32m    543\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    544\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    545\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m last_segment\n",
      "\u001b[31mRecursionError\u001b[39m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    while trained < TOTAL_STEPS:\n",
    "        round_idx += 1\n",
    "        chunk = min(TRAIN_CHUNK, TOTAL_STEPS - trained)\n",
    "        # chunk = 2000\n",
    "        label = \"Run\"\n",
    "        tagged_label = f\"{label}_{int(trained/TRAIN_CHUNK)}\"\n",
    "\n",
    "        print(f\"\\n=== Round {round_idx} | Learn {chunk} steps (Total trained: {trained}) ===\")\n",
    "        \n",
    "        # --- Train ---\n",
    "        model.learn(total_timesteps=chunk, reset_num_timesteps=False, tb_log_name=label)\n",
    "        trained += chunk\n",
    "\n",
    "        # --- Save Checkpoint ---\n",
    "        ckpt_path = os.path.join(CKPT_DIR, f\"{tagged_label}.zip\")\n",
    "        model.save(ckpt_path)\n",
    "        print(f\"Saved checkpoint: {ckpt_path}\")\n",
    "\n",
    "        # --- Evaluate ---\n",
    "        mean_ret, best_ret = evaluate_policy(\n",
    "            model,\n",
    "            GAME,\n",
    "            STATE,\n",
    "            n_episodes=EVAL_EPISODES,\n",
    "            max_steps=EVAL_MAX_STEPS,\n",
    "        )\n",
    "        print(f\"[EVAL] Mean Return: {mean_ret:.3f}, Best Return: {best_ret:.3f}\")\n",
    "\n",
    "        # --- Record Video ---\n",
    "        out_path = os.path.join(VIDEO_DIR, label)\n",
    "        os.makedirs(out_path,  exist_ok=True)\n",
    "        record_video(\n",
    "            model,\n",
    "            GAME,\n",
    "            STATE,\n",
    "            VIDEO_DIR,\n",
    "            video_len=RECORD_STEPS,\n",
    "            prefix=f\"{label}/{tagged_label}_{mean_ret:.2f}\",\n",
    "        )\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nTraining interrupted manually.\")\n",
    "\n",
    "finally:\n",
    "    train_env.close()\n",
    "    print(\"Training finished. Environment closed.\")\n",
    "    \n",
    "\"\"\"\n",
    "tensorboard --logdir=./runs_smw/tb\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f088b0b3-2418-4866-b332-0312c9f6467f",
   "metadata": {},
   "source": [
    "## Display Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73191bb-e875-4939-b04c-a4670abd9612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "import glob\n",
    "# label = \"Dec22A\"\n",
    "\n",
    "# list_of_files = glob.glob(os.path.join(VIDEO_DIR, label, '*.mp4')) \n",
    "# if list_of_files:\n",
    "#     latest_file = max(list_of_files, key=os.path.getctime)\n",
    "#     print(f\"Playing: {latest_file}\")\n",
    "#     latest_file = \"runs_smw/videos/Dec22A/Dec22A_73_596.54.mp4\"\n",
    "#     print(f\"Playing: {latest_file}\")\n",
    "#     display(Video(latest_file, embed=True, width=768))\n",
    "# else:\n",
    "#     print(\"No videos found yet.\")\n",
    "    \n",
    "video = \"./runs_smw/videos/test_126.mp4\"\n",
    "display(Video(video, embed=True, width=768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942adf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(\"runs_smw/videos/test_16.mp4\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    cv2.imshow(\"Frame-by-Frame\", frame)\n",
    "\n",
    "    # 關鍵：這裡等待按鍵。按 'n' 鍵跳到下一幀，按 'q' 離開\n",
    "    key = cv2.waitKey(0) \n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('n'):\n",
    "        continue\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1865a364",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "[070] coins: 12 | score: 3540\n",
    "[071] coins: 10 | score: 2260\n",
    "[072] coins: 11 | score: 2760\n",
    "[073] coins:  2 | score:  690\n",
    "[074] coins: 12 | score: 3450\n",
    "[075] coins: 12 | score: 3515\n",
    "[076] coins: 12 | score: 3545\n",
    "[077] coins: 12 | score: 3545\n",
    "[078] coins: 10 | score: 2460\n",
    "[079] coins: 12 | score: 3515\n",
    "[080] coins: 12 | score: 3580\n",
    "[081] coins: 11 | score: 2750\n",
    "[082] coins: 12 | score: 3545\n",
    "[083] coins: 12 | score: 3565\n",
    "[084] coins: 11 | score: 3475\n",
    "[085] coins:  0 | score:    0\n",
    "[086] coins: 12 | score: 3535\n",
    "[087] coins: 12 | score: 3560\n",
    "[088] coins:  9 | score: 1420\n",
    "[089] coins: 11 | score: 3640\n",
    "[090] coins:  1 | score:  380\n",
    "[091] coins: 10 | score: 2440\n",
    "[092] coins: 12 | score: 3570\n",
    "[093] coins: 12 | score: 3490\n",
    "[094] coins: 11 | score: 2745\n",
    "[095] coins: 12 | score: 3565\n",
    "[096] coins:  0 | score:    0\n",
    "[097] coins: 12 | score: 3490\n",
    "[098] coins: 12 | score: 3570\n",
    "[099] coins:  2 | score:  560\n",
    "[100] coins:  2 | score:  660\n",
    "[101] coins: 12 | score: 3580\n",
    "[102] coins:  9 | score: 1420\n",
    "[103] coins: 12 | score: 3575\n",
    "[104] coins: 12 | score: 3585\n",
    "[105] coins: 12 | score: 3580\n",
    "[106] coins: 12 | score: 3525\n",
    "[107] coins:  2 | score:  540\n",
    "[108] coins:  2 | score:  660\n",
    "[109] coins: 10 | score: 2420\n",
    "[110] coins:  1 | score:  140\n",
    "[111] coins: 11 | score: 2680\n",
    "[112] coins:  2 | score:  580\n",
    "[113] coins:  2 | score:  580\n",
    "[114] coins:  2 | score:  560\n",
    "[115] coins: 11 | score: 2765\n",
    "[116] coins:  2 | score:  560\n",
    "[117] coins:  0 | score:    0\n",
    "[118] coins: 12 | score: 3570\n",
    "[119] coins:  1 | score:  340\n",
    "[120] coins: 11 | score: 2735\n",
    "[121] coins: 12 | score: 3570\n",
    "[122] coins: 12 | score: 3515\n",
    "[123] coins: 12 | score: 3580\n",
    "[124] coins: 12 | score: 3585\n",
    "[125] coins: 12 | score: 3560\n",
    "[126] coins: 12 | score: 3595\n",
    "[127] coins: 12 | score: 3515\n",
    "\n",
    "所有測試結束。\n",
    "在 reward 紀錄上，紀錄前10幀的 action 是甚麼，然後檢查\n",
    "\n",
    "--Run--\n",
    "[57] coins: 12 | score: 3630\n",
    "[58] coins: 12 | score: 3490\n",
    "[59] coins: 11 | score: 2855\n",
    "[60] coins: 12 | score: 3620\n",
    "[61] coins: 12 | score: 3690\n",
    "[62] coins: 12 | score: 3685\n",
    "[63] coins: 11 | score: 2860\n",
    "[64] coins: 10 | score: 2245\n",
    "[65] coins: 12 | score: 3685\n",
    "[66] coins: 12 | score: 3670\n",
    "[67] coins: 12 | score: 3565\n",
    "[68] coins: 12 | score: 3575\n",
    "[69] coins: 11 | score: 2880\n",
    "[70] coins: 12 | score: 3685\n",
    "\n",
    "[72] coins: 9 | score: 1315\n",
    "[73] coins: 12 | score: 3535\n",
    "[74] coins: 12 | score: 3570\n",
    "[75] coins: 12 | score: 3645\n",
    "[76] coins: 12 | score: 3690\n",
    "[77] coins: 8 | score: 1020\n",
    "[78] coins: 12 | score: 3695\n",
    "[79] coins: 11 | score: 2780\n",
    "[80] coins: 12 | score: 3695\n",
    "[81] coins: 12 | score: 3695\n",
    "[82] coins: 12 | score: 3655\n",
    "[83] coins: 12 | score: 3690\n",
    "[84] coins: 12 | score: 3635\n",
    "[85] coins: 11 | score: 2840\n",
    "[86] coins: 12 | score: 3680\n",
    "[87] coins: 12 | score: 3645\n",
    "[88] coins: 12 | score: 3625\n",
    "[89] coins: 0 | score: 0\n",
    "[90] coins: 12 | score: 3650\n",
    "[91] coins: 12 | score: 3695\n",
    "[92] coins: 12 | score: 3695\n",
    "[93] coins: 12 | score: 3700\n",
    "[94] coins: 12 | score: 3700\n",
    "[95] coins: 12 | score: 3625\n",
    "[96] coins: 12 | score: 3700\n",
    "[97] coins: 12 | score: 3705\n",
    "[98] coins: 12 | score: 3695\n",
    "[99] coins: 2 | score: 640\n",
    "[100] coins: 12 | score: 3705\n",
    "[101] coins: 9 | score: 1400\n",
    "[102] coins: 9 | score: 1420\n",
    "[103] coins: 12 | score: 3705\n",
    "[104] coins: 2 | score: 770\n",
    "[105] coins: 12 | score: 3705\n",
    "[106] coins: 12 | score: 3705\n",
    "[107] coins: 1 | score: 380\n",
    "[108] coins: 12 | score: 3745 *\n",
    "[109] coins: 12 | score: 3660\n",
    "[110] coins: 11 | score: 2915\n",
    "[111] coins: 5 | score: 2810\n",
    "[112] coins: 12 | score: 3680\n",
    "[113] coins: 12 | score: 3540\n",
    "[114] coins: 11 | score: 2860\n",
    "[115] coins: 12 | score: 3740\n",
    "[116] coins: 12 | score: 3730\n",
    "[117] coins: 12 | score: 3725\n",
    "[118] coins: 12 | score: 3680\n",
    "[119] coins: 6 | score: 3650\n",
    "[120] coins: 12 | score: 3745\n",
    "[121] coins: 12 | score: 3770 *\n",
    "[122] coins: 11 | score: 2885\n",
    "[123] coins: 12 | score: 3720\n",
    "[124] coins: 12 | score: 3710\n",
    "[125] coins: 11 | score: 2685\n",
    "[126] coins: 12 | score: 3510\n",
    "[127] coins: 12 | score: 3750 *\n",
    "[128] coins: 12 | score: 3730\n",
    "[129] coins: 12 | score: 3635\n",
    "[130] coins: 12 | score: 3730\n",
    "[131] coins: 11 | score: 2745\n",
    "[132] coins: 12 | score: 3720\n",
    "[133] coins: 12 | score: 3760 *\n",
    "[134] coins: 12 | score: 3730\n",
    "[135] coins: 12 | score: 3735\n",
    "[136] coins: 12 | score: 3715\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lab8 (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
