{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dceedafe-2782-41a1-8119-50ee3d6c21fd",
   "metadata": {},
   "source": [
    "# 2025 DL Lab8: RL Assignment_Super Mario World"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fa555a-e61c-4fb3-b5d0-289b66570139",
   "metadata": {},
   "source": [
    "**Your Answer:**    \n",
    "Hi I'm XXX, XXXXXXXXXX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5b0974-9605-488a-9fd5-00816e7832cc",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This project implements a **Deep Reinforcement Learning** pipeline to train an autonomous agent for Super Mario World. Leveraging the **Proximal Policy Optimization (PPO)** algorithm, the system interacts with the **stable-retro** environment to master the YoshiIsland1 level. Key components include a custom Vision Backbone for extracting features from raw pixel data and a suite of Environment Wrappers that handle frame preprocessing, action discretization, and reward shaping to facilitate efficient learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02696447",
   "metadata": {},
   "source": [
    "Reward function implement  \n",
    "should do something in the beginning (monster attack)  \n",
    "Custom PPO implement  \n",
    "pre train weight 差不多，主要是 reward function  \n",
    "model weight capacity 1GB  \n",
    "class name 不要動 (可以新增，但是原本有的不要動)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8a0ab9-f86d-4038-833d-761ec81fc4f2",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00b10def-362c-4910-9ed0-f3d0904343ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import retro\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "\n",
    "from eval import evaluate_policy, record_video\n",
    "from custom_policy import VisionBackbonePolicy, CustomPPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10361fd-f291-4d93-b50d-cc749a3af588",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b4f6a25-738c-49dd-8e66-ae164b74a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game Settings\n",
    "GAME = \"SuperMarioWorld-Snes\"\n",
    "STATE = \"YoshiIsland1\"\n",
    "\n",
    "# Training Settings\n",
    "TOTAL_STEPS = 13_107_200\n",
    "TRAIN_CHUNK =    327_680\n",
    "N_ENVS = 16\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# Evaluation & Recording Settings\n",
    "EVAL_EPISODES = 3\n",
    "EVAL_MAX_STEPS = 18000\n",
    "RECORD_STEPS = 1800\n",
    "\n",
    "# Directories\n",
    "LOG_DIR = \"./runs_smw\"\n",
    "VIDEO_DIR       = os.path.join(LOG_DIR, \"videos\")\n",
    "CKPT_DIR        = os.path.join(LOG_DIR, \"checkpoints\")\n",
    "TENSORBOARD_LOG = os.path.join(LOG_DIR, \"tb\")\n",
    "\n",
    "os.makedirs(LOG_DIR,   exist_ok=True)\n",
    "os.makedirs(CKPT_DIR,  exist_ok=True)\n",
    "os.makedirs(VIDEO_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a34b783-0273-4835-ad2e-f9186064f76f",
   "metadata": {},
   "source": [
    "## Environment Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c34213d-2c7c-42b8-922d-bafa285d1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrappers import make_base_env\n",
    "def _make_env_thunk(game: str, state: str):\n",
    "    \"\"\"Return a function that creates an environment (for multiprocessing).\"\"\"\n",
    "    def _thunk():\n",
    "        return make_base_env(game, state)\n",
    "    return _thunk\n",
    "\n",
    "def make_vec_env(game: str, state: str, n_envs: int, use_subproc: bool = True):\n",
    "    \"\"\"Create a vectorized environment (multiple envs running in parallel).\"\"\"\n",
    "    env_fns = [_make_env_thunk(game, state) for _ in range(n_envs)]\n",
    "    \n",
    "    if use_subproc and n_envs > 1:\n",
    "        vec_env = SubprocVecEnv(env_fns)\n",
    "    else:\n",
    "        vec_env = DummyVecEnv(env_fns)\n",
    "\n",
    "    return vec_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dff476-ea2e-4262-8780-afb32ef1b233",
   "metadata": {},
   "source": [
    "## Initialize Env & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c7c5fe-6421-4dbc-9bd8-822d61769c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment created: SuperMarioWorld-Snes - YoshiIsland1 with 16 parallel envs.\n",
      "Fail to load None...\n",
      "Using cuda:0 device\n"
     ]
    }
   ],
   "source": [
    "# 1. Create Training Environment\n",
    "train_env = make_vec_env(GAME, STATE, n_envs=N_ENVS)\n",
    "# train_env = VecNormalize(train_env, norm_obs=True, norm_reward=True, clip_obs=10., clip_reward=10.)\n",
    "print(f\"Environment created: {GAME} - {STATE} with {N_ENVS} parallel envs.\")\n",
    "\n",
    "checkpoint_path = \"None\"\n",
    "# checkpoint_path = \"runs_smw/checkpoints/SF84_step_1600000.zip\"\n",
    "# checkpoint_path = \"runs_smw/checkpoints/SF84G_6553600.zip\"\n",
    "# checkpoint_path = \"runs_smw/checkpoints/SF84G_5.zip\"\n",
    "\n",
    "# 2. Initialize Model\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\"Loading model from {checkpoint_path}...\")\n",
    "    # 讀取現有模型\n",
    "    model = CustomPPO.load(\n",
    "        checkpoint_path, \n",
    "        env=train_env,\n",
    "        device=\"cuda:0\" # 確保使用 GPU\n",
    "    )\n",
    "else:\n",
    "    print(f\"Fail to load {checkpoint_path}...\")\n",
    "    model = CustomPPO(\n",
    "        VisionBackbonePolicy,\n",
    "        train_env,\n",
    "        policy_kwargs   = dict(normalize_images=False),\n",
    "        n_epochs        = 4,\n",
    "        n_steps         = 512,\n",
    "        batch_size      = 512,\n",
    "        learning_rate   = LEARNING_RATE,\n",
    "        verbose         = 1,\n",
    "        gamma           = 0.99,\n",
    "        kl_coef         = 1,\n",
    "        clip_range      = 0.125,\n",
    "        tensorboard_log = TENSORBOARD_LOG,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cb3d0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"policy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f594e443-843f-42c1-9fc6-3fbc82962021",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3af4932-c531-4113-a33a-defc6fb5858e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Round 1 | Learn 327680 steps (Total trained: 0) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/m314834001/Lab8/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1118 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 7    |\n",
      "|    total_timesteps | 8192 |\n",
      "-----------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 931         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 16384       |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005228821 |\n",
      "|    entropy_loss       | -2.48       |\n",
      "|    explained_variance | -0.00291    |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0387     |\n",
      "|    mean_step_reward   | 0.008536389 |\n",
      "|    n_updates          | 4           |\n",
      "|    policyGradLoss     | -0.0122     |\n",
      "|    value_loss         | 0.0917      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 879          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 24576        |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0056412937 |\n",
      "|    entropy_loss       | -2.47        |\n",
      "|    explained_variance | 0.152        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.026       |\n",
      "|    mean_step_reward   | 0.01597616   |\n",
      "|    n_updates          | 8            |\n",
      "|    policyGradLoss     | -0.00936     |\n",
      "|    value_loss         | 0.124        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 855         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 32768       |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005275719 |\n",
      "|    entropy_loss       | -2.45       |\n",
      "|    explained_variance | 0.547       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0125     |\n",
      "|    mean_step_reward   | 0.022042472 |\n",
      "|    n_updates          | 12          |\n",
      "|    policyGradLoss     | -0.00796    |\n",
      "|    value_loss         | 0.164       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 843          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 48           |\n",
      "|    total_timesteps    | 40960        |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0040843273 |\n",
      "|    entropy_loss       | -2.42        |\n",
      "|    explained_variance | 0.736        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0309       |\n",
      "|    mean_step_reward   | 0.025979366  |\n",
      "|    n_updates          | 16           |\n",
      "|    policyGradLoss     | -0.00545     |\n",
      "|    value_loss         | 0.199        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 837          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 58           |\n",
      "|    total_timesteps    | 49152        |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028158426 |\n",
      "|    entropy_loss       | -2.39        |\n",
      "|    explained_variance | 0.823        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0192       |\n",
      "|    mean_step_reward   | 0.026524307  |\n",
      "|    n_updates          | 20           |\n",
      "|    policyGradLoss     | -0.00316     |\n",
      "|    value_loss         | 0.196        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 832          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 68           |\n",
      "|    total_timesteps    | 57344        |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026827543 |\n",
      "|    entropy_loss       | -2.36        |\n",
      "|    explained_variance | 0.891        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0162       |\n",
      "|    mean_step_reward   | 0.03160651   |\n",
      "|    n_updates          | 24           |\n",
      "|    policyGradLoss     | -0.00262     |\n",
      "|    value_loss         | 0.157        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 828         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 79          |\n",
      "|    total_timesteps    | 65536       |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003314303 |\n",
      "|    entropy_loss       | -2.33       |\n",
      "|    explained_variance | 0.898       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0365      |\n",
      "|    mean_step_reward   | 0.034698784 |\n",
      "|    n_updates          | 28          |\n",
      "|    policyGradLoss     | -0.00251    |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 822          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 89           |\n",
      "|    total_timesteps    | 73728        |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0015799446 |\n",
      "|    entropy_loss       | -2.29        |\n",
      "|    explained_variance | 0.929        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0252      |\n",
      "|    mean_step_reward   | 0.038103312  |\n",
      "|    n_updates          | 32           |\n",
      "|    policyGradLoss     | -0.00151     |\n",
      "|    value_loss         | 0.142        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 819          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 99           |\n",
      "|    total_timesteps    | 81920        |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0024536357 |\n",
      "|    entropy_loss       | -2.28        |\n",
      "|    explained_variance | 0.926        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0272       |\n",
      "|    mean_step_reward   | 0.03682156   |\n",
      "|    n_updates          | 36           |\n",
      "|    policyGradLoss     | -0.00147     |\n",
      "|    value_loss         | 0.168        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 816          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 110          |\n",
      "|    total_timesteps    | 90112        |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027074725 |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.929        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0287       |\n",
      "|    mean_step_reward   | 0.041532263  |\n",
      "|    n_updates          | 40           |\n",
      "|    policyGradLoss     | -0.00182     |\n",
      "|    value_loss         | 0.202        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 98304       |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.001490177 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0351      |\n",
      "|    mean_step_reward   | 0.041804373 |\n",
      "|    n_updates          | 44          |\n",
      "|    policyGradLoss     | -0.00092    |\n",
      "|    value_loss         | 0.259       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 813           |\n",
      "|    iterations         | 13            |\n",
      "|    time_elapsed       | 130           |\n",
      "|    total_timesteps    | 106496        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.00096519536 |\n",
      "|    entropy_loss       | -2.23         |\n",
      "|    explained_variance | 0.892         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.0942        |\n",
      "|    mean_step_reward   | 0.040937133   |\n",
      "|    n_updates          | 48            |\n",
      "|    policyGradLoss     | -0.000577     |\n",
      "|    value_loss         | 0.318         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 813          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 141          |\n",
      "|    total_timesteps    | 114688       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028673834 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.966        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0196      |\n",
      "|    mean_step_reward   | 0.038942084  |\n",
      "|    n_updates          | 52           |\n",
      "|    policyGradLoss     | -0.00199     |\n",
      "|    value_loss         | 0.097        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 812          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 151          |\n",
      "|    total_timesteps    | 122880       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028317631 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.925        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0302       |\n",
      "|    mean_step_reward   | 0.044139944  |\n",
      "|    n_updates          | 56           |\n",
      "|    policyGradLoss     | -0.00152     |\n",
      "|    value_loss         | 0.275        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 810           |\n",
      "|    iterations         | 16            |\n",
      "|    time_elapsed       | 161           |\n",
      "|    total_timesteps    | 131072        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.00028349136 |\n",
      "|    entropy_loss       | -2.17         |\n",
      "|    explained_variance | 0.936         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.0439        |\n",
      "|    mean_step_reward   | 0.04516433    |\n",
      "|    n_updates          | 60            |\n",
      "|    policyGradLoss     | 2.59e-05      |\n",
      "|    value_loss         | 0.192         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 810          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 171          |\n",
      "|    total_timesteps    | 139264       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0003149215 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.939        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0319       |\n",
      "|    mean_step_reward   | 0.044634283  |\n",
      "|    n_updates          | 64           |\n",
      "|    policyGradLoss     | -0.000257    |\n",
      "|    value_loss         | 0.263        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 810          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 182          |\n",
      "|    total_timesteps    | 147456       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0020251842 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.912        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0896       |\n",
      "|    mean_step_reward   | 0.042934805  |\n",
      "|    n_updates          | 68           |\n",
      "|    policyGradLoss     | -0.0015      |\n",
      "|    value_loss         | 0.33         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 192         |\n",
      "|    total_timesteps    | 155648      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.001611665 |\n",
      "|    entropy_loss       | -2.16       |\n",
      "|    explained_variance | 0.91        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.166       |\n",
      "|    mean_step_reward   | 0.043779984 |\n",
      "|    n_updates          | 72          |\n",
      "|    policyGradLoss     | -0.000767   |\n",
      "|    value_loss         | 0.379       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 809          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 202          |\n",
      "|    total_timesteps    | 163840       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0021094123 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.933        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0205       |\n",
      "|    mean_step_reward   | 0.038817853  |\n",
      "|    n_updates          | 76           |\n",
      "|    policyGradLoss     | -0.00073     |\n",
      "|    value_loss         | 0.233        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 809          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 212          |\n",
      "|    total_timesteps    | 172032       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0010413458 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.923        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.114        |\n",
      "|    mean_step_reward   | 0.04248632   |\n",
      "|    n_updates          | 80           |\n",
      "|    policyGradLoss     | -0.000405    |\n",
      "|    value_loss         | 0.348        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 223         |\n",
      "|    total_timesteps    | 180224      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.00097584  |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.864       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.223       |\n",
      "|    mean_step_reward   | 0.048977237 |\n",
      "|    n_updates          | 84          |\n",
      "|    policyGradLoss     | -0.000666   |\n",
      "|    value_loss         | 0.685       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 807          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 233          |\n",
      "|    total_timesteps    | 188416       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0012568133 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.901        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.106        |\n",
      "|    mean_step_reward   | 0.046714097  |\n",
      "|    n_updates          | 88           |\n",
      "|    policyGradLoss     | -0.00028     |\n",
      "|    value_loss         | 0.427        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 808          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 243          |\n",
      "|    total_timesteps    | 196608       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0014645311 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.911        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0698       |\n",
      "|    mean_step_reward   | 0.040168606  |\n",
      "|    n_updates          | 92           |\n",
      "|    policyGradLoss     | -0.000989    |\n",
      "|    value_loss         | 0.319        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 807          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 253          |\n",
      "|    total_timesteps    | 204800       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0015430588 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.904        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.158        |\n",
      "|    mean_step_reward   | 0.042662784  |\n",
      "|    n_updates          | 96           |\n",
      "|    policyGradLoss     | -0.000954    |\n",
      "|    value_loss         | 0.357        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 807          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 263          |\n",
      "|    total_timesteps    | 212992       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0010171458 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.917        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0735       |\n",
      "|    mean_step_reward   | 0.044839114  |\n",
      "|    n_updates          | 100          |\n",
      "|    policyGradLoss     | -0.00075     |\n",
      "|    value_loss         | 0.314        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 806          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 274          |\n",
      "|    total_timesteps    | 221184       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023223353 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.939        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0462       |\n",
      "|    mean_step_reward   | 0.04373704   |\n",
      "|    n_updates          | 104          |\n",
      "|    policyGradLoss     | -0.000978    |\n",
      "|    value_loss         | 0.243        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 806          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 284          |\n",
      "|    total_timesteps    | 229376       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0008447035 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.919        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0626       |\n",
      "|    mean_step_reward   | 0.044394914  |\n",
      "|    n_updates          | 108          |\n",
      "|    policyGradLoss     | 8.65e-05     |\n",
      "|    value_loss         | 0.385        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 805          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 294          |\n",
      "|    total_timesteps    | 237568       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0024433676 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.93         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0392       |\n",
      "|    mean_step_reward   | 0.04329684   |\n",
      "|    n_updates          | 112          |\n",
      "|    policyGradLoss     | -0.000845    |\n",
      "|    value_loss         | 0.299        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 805          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 305          |\n",
      "|    total_timesteps    | 245760       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0016006147 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.913        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.048        |\n",
      "|    mean_step_reward   | 0.04272612   |\n",
      "|    n_updates          | 116          |\n",
      "|    policyGradLoss     | -0.00106     |\n",
      "|    value_loss         | 0.331        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 804          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 315          |\n",
      "|    total_timesteps    | 253952       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0024928504 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.905        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0943       |\n",
      "|    mean_step_reward   | 0.043634526  |\n",
      "|    n_updates          | 120          |\n",
      "|    policyGradLoss     | -0.000466    |\n",
      "|    value_loss         | 0.337        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 804          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 325          |\n",
      "|    total_timesteps    | 262144       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0017225107 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.899        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0634       |\n",
      "|    mean_step_reward   | 0.043778546  |\n",
      "|    n_updates          | 124          |\n",
      "|    policyGradLoss     | -0.000885    |\n",
      "|    value_loss         | 0.38         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 805          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 335          |\n",
      "|    total_timesteps    | 270336       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0018489603 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.894        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0613       |\n",
      "|    mean_step_reward   | 0.04347065   |\n",
      "|    n_updates          | 128          |\n",
      "|    policyGradLoss     | -0.000281    |\n",
      "|    value_loss         | 0.371        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 804          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 346          |\n",
      "|    total_timesteps    | 278528       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0019525271 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.916        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.173        |\n",
      "|    mean_step_reward   | 0.046280503  |\n",
      "|    n_updates          | 132          |\n",
      "|    policyGradLoss     | -0.00132     |\n",
      "|    value_loss         | 0.395        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 804          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 356          |\n",
      "|    total_timesteps    | 286720       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0016827531 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.883        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.191        |\n",
      "|    mean_step_reward   | 0.04980006   |\n",
      "|    n_updates          | 136          |\n",
      "|    policyGradLoss     | -0.000761    |\n",
      "|    value_loss         | 0.681        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 805          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 366          |\n",
      "|    total_timesteps    | 294912       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0011080698 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.88         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.238        |\n",
      "|    mean_step_reward   | 0.047585726  |\n",
      "|    n_updates          | 140          |\n",
      "|    policyGradLoss     | -0.00135     |\n",
      "|    value_loss         | 0.678        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 376         |\n",
      "|    total_timesteps    | 303104      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.001186532 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.892       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.181       |\n",
      "|    mean_step_reward   | 0.049936116 |\n",
      "|    n_updates          | 144         |\n",
      "|    policyGradLoss     | -0.00145    |\n",
      "|    value_loss         | 0.602       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 386         |\n",
      "|    total_timesteps    | 311296      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.000469439 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.856       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.187       |\n",
      "|    mean_step_reward   | 0.047170214 |\n",
      "|    n_updates          | 148         |\n",
      "|    policyGradLoss     | -3.99e-05   |\n",
      "|    value_loss         | 0.771       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 805          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 396          |\n",
      "|    total_timesteps    | 319488       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0015998654 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.898        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.059        |\n",
      "|    mean_step_reward   | 0.041567385  |\n",
      "|    n_updates          | 152          |\n",
      "|    policyGradLoss     | -0.00106     |\n",
      "|    value_loss         | 0.438        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 406         |\n",
      "|    total_timesteps    | 327680      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.00237671  |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0343      |\n",
      "|    mean_step_reward   | 0.040772416 |\n",
      "|    n_updates          | 156         |\n",
      "|    policyGradLoss     | -0.00187    |\n",
      "|    value_loss         | 0.232       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_0.zip\n",
      "[EVAL] Mean Return: -0.274, Best Return: -0.274\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_0_-0.27.mp4\n",
      "\n",
      "=== Round 2 | Learn 327680 steps (Total trained: 327680) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1094   |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 7      |\n",
      "|    total_timesteps | 335872 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 920           |\n",
      "|    iterations         | 2             |\n",
      "|    time_elapsed       | 17            |\n",
      "|    total_timesteps    | 344064        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.00090827805 |\n",
      "|    entropy_loss       | -2.25         |\n",
      "|    explained_variance | 0.871         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.105         |\n",
      "|    mean_step_reward   | 0.044746313   |\n",
      "|    n_updates          | 164           |\n",
      "|    policyGradLoss     | -0.000617     |\n",
      "|    value_loss         | 0.524         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 873          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 352256       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0015958643 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.899        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.176        |\n",
      "|    mean_step_reward   | 0.053590856  |\n",
      "|    n_updates          | 168          |\n",
      "|    policyGradLoss     | -0.000906    |\n",
      "|    value_loss         | 0.544        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 851          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 38           |\n",
      "|    total_timesteps    | 360448       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0012120672 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.926        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.025        |\n",
      "|    mean_step_reward   | 0.04351709   |\n",
      "|    n_updates          | 172          |\n",
      "|    policyGradLoss     | -0.000607    |\n",
      "|    value_loss         | 0.305        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 835          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 49           |\n",
      "|    total_timesteps    | 368640       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030804276 |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.909        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.114        |\n",
      "|    mean_step_reward   | 0.045766857  |\n",
      "|    n_updates          | 176          |\n",
      "|    policyGradLoss     | -0.00193     |\n",
      "|    value_loss         | 0.37         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 827          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 59           |\n",
      "|    total_timesteps    | 376832       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027855032 |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.93         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.00306      |\n",
      "|    mean_step_reward   | 0.04286872   |\n",
      "|    n_updates          | 180          |\n",
      "|    policyGradLoss     | -0.00217     |\n",
      "|    value_loss         | 0.291        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 69          |\n",
      "|    total_timesteps    | 385024      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.001158127 |\n",
      "|    entropy_loss       | -2.26       |\n",
      "|    explained_variance | 0.879       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.209       |\n",
      "|    mean_step_reward   | 0.04935245  |\n",
      "|    n_updates          | 184         |\n",
      "|    policyGradLoss     | -0.000848   |\n",
      "|    value_loss         | 0.645       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 818          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 80           |\n",
      "|    total_timesteps    | 393216       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0014982386 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.897        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.125        |\n",
      "|    mean_step_reward   | 0.05029919   |\n",
      "|    n_updates          | 188          |\n",
      "|    policyGradLoss     | -0.000402    |\n",
      "|    value_loss         | 0.465        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 815          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 90           |\n",
      "|    total_timesteps    | 401408       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0011041786 |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.886        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.148        |\n",
      "|    mean_step_reward   | 0.04341755   |\n",
      "|    n_updates          | 192          |\n",
      "|    policyGradLoss     | -0.001       |\n",
      "|    value_loss         | 0.561        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 813          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 100          |\n",
      "|    total_timesteps    | 409600       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027263062 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.933        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.125        |\n",
      "|    mean_step_reward   | 0.04971505   |\n",
      "|    n_updates          | 196          |\n",
      "|    policyGradLoss     | -0.00178     |\n",
      "|    value_loss         | 0.404        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 809           |\n",
      "|    iterations         | 11            |\n",
      "|    time_elapsed       | 111           |\n",
      "|    total_timesteps    | 417792        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.00073384587 |\n",
      "|    entropy_loss       | -2.25         |\n",
      "|    explained_variance | 0.885         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.107         |\n",
      "|    mean_step_reward   | 0.04147777    |\n",
      "|    n_updates          | 200           |\n",
      "|    policyGradLoss     | 0.000139      |\n",
      "|    value_loss         | 0.39          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 810          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 121          |\n",
      "|    total_timesteps    | 425984       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0024417914 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.932        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0776       |\n",
      "|    mean_step_reward   | 0.044551857  |\n",
      "|    n_updates          | 204          |\n",
      "|    policyGradLoss     | -0.00173     |\n",
      "|    value_loss         | 0.328        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 809          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 131          |\n",
      "|    total_timesteps    | 434176       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038729974 |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.951        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0296      |\n",
      "|    mean_step_reward   | 0.04419238   |\n",
      "|    n_updates          | 208          |\n",
      "|    policyGradLoss     | -0.00173     |\n",
      "|    value_loss         | 0.184        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 807          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 142          |\n",
      "|    total_timesteps    | 442368       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0015977575 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.896        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.15         |\n",
      "|    mean_step_reward   | 0.044970874  |\n",
      "|    n_updates          | 212          |\n",
      "|    policyGradLoss     | -0.00115     |\n",
      "|    value_loss         | 0.495        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 152         |\n",
      "|    total_timesteps    | 450560      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002151088 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.858       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.219       |\n",
      "|    mean_step_reward   | 0.044503108 |\n",
      "|    n_updates          | 216         |\n",
      "|    policyGradLoss     | -0.00178    |\n",
      "|    value_loss         | 0.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 162         |\n",
      "|    total_timesteps    | 458752      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.001207574 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.883       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.291       |\n",
      "|    mean_step_reward   | 0.050073486 |\n",
      "|    n_updates          | 220         |\n",
      "|    policyGradLoss     | -0.000775   |\n",
      "|    value_loss         | 0.793       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 806          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 172          |\n",
      "|    total_timesteps    | 466944       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0024058002 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.941        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0867       |\n",
      "|    mean_step_reward   | 0.049093973  |\n",
      "|    n_updates          | 224          |\n",
      "|    policyGradLoss     | -0.00139     |\n",
      "|    value_loss         | 0.26         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 805          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 183          |\n",
      "|    total_timesteps    | 475136       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0014922932 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.86         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.186        |\n",
      "|    mean_step_reward   | 0.045500554  |\n",
      "|    n_updates          | 228          |\n",
      "|    policyGradLoss     | 1.71e-05     |\n",
      "|    value_loss         | 0.522        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 805          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 193          |\n",
      "|    total_timesteps    | 483328       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0008130928 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.889        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.315        |\n",
      "|    mean_step_reward   | 0.051189035  |\n",
      "|    n_updates          | 232          |\n",
      "|    policyGradLoss     | -0.000283    |\n",
      "|    value_loss         | 0.696        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 805          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 203          |\n",
      "|    total_timesteps    | 491520       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0018232336 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.908        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.247        |\n",
      "|    mean_step_reward   | 0.04705136   |\n",
      "|    n_updates          | 236          |\n",
      "|    policyGradLoss     | -0.000879    |\n",
      "|    value_loss         | 0.561        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 805          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 213          |\n",
      "|    total_timesteps    | 499712       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0010010448 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.9          |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.227        |\n",
      "|    mean_step_reward   | 0.049573906  |\n",
      "|    n_updates          | 240          |\n",
      "|    policyGradLoss     | -0.000677    |\n",
      "|    value_loss         | 0.676        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 805          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 223          |\n",
      "|    total_timesteps    | 507904       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0021188995 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.903        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.192        |\n",
      "|    mean_step_reward   | 0.048519656  |\n",
      "|    n_updates          | 244          |\n",
      "|    policyGradLoss     | -0.00201     |\n",
      "|    value_loss         | 0.634        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 806           |\n",
      "|    iterations         | 23            |\n",
      "|    time_elapsed       | 233           |\n",
      "|    total_timesteps    | 516096        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.00085740024 |\n",
      "|    entropy_loss       | -2.22         |\n",
      "|    explained_variance | 0.893         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.157         |\n",
      "|    mean_step_reward   | 0.047780722   |\n",
      "|    n_updates          | 248           |\n",
      "|    policyGradLoss     | -0.000901     |\n",
      "|    value_loss         | 0.541         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 524288      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.001161643 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.886       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.172       |\n",
      "|    mean_step_reward   | 0.046914466 |\n",
      "|    n_updates          | 252         |\n",
      "|    policyGradLoss     | -0.00177    |\n",
      "|    value_loss         | 0.561       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 254         |\n",
      "|    total_timesteps    | 532480      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002556438 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.901       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.155       |\n",
      "|    mean_step_reward   | 0.053967472 |\n",
      "|    n_updates          | 256         |\n",
      "|    policyGradLoss     | -0.00067    |\n",
      "|    value_loss         | 0.671       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 805          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 264          |\n",
      "|    total_timesteps    | 540672       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0015359581 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.832        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.221        |\n",
      "|    mean_step_reward   | 0.048240364  |\n",
      "|    n_updates          | 260          |\n",
      "|    policyGradLoss     | -0.00113     |\n",
      "|    value_loss         | 0.894        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 805          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 274          |\n",
      "|    total_timesteps    | 548864       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0016136518 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.895        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.135        |\n",
      "|    mean_step_reward   | 0.047235955  |\n",
      "|    n_updates          | 264          |\n",
      "|    policyGradLoss     | -0.00207     |\n",
      "|    value_loss         | 0.579        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 804           |\n",
      "|    iterations         | 28            |\n",
      "|    time_elapsed       | 285           |\n",
      "|    total_timesteps    | 557056        |\n",
      "| train/                |               |\n",
      "|    approx_kl          | 0.00078708725 |\n",
      "|    entropy_loss       | -2.25         |\n",
      "|    explained_variance | 0.877         |\n",
      "|    learning_rate      | 0.0001        |\n",
      "|    loss               | 0.256         |\n",
      "|    mean_step_reward   | 0.046369717   |\n",
      "|    n_updates          | 268           |\n",
      "|    policyGradLoss     | -0.000828     |\n",
      "|    value_loss         | 0.598         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 565248      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002262425 |\n",
      "|    entropy_loss       | -2.24       |\n",
      "|    explained_variance | 0.856       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.245       |\n",
      "|    mean_step_reward   | 0.052308172 |\n",
      "|    n_updates          | 272         |\n",
      "|    policyGradLoss     | 5.25e-05    |\n",
      "|    value_loss         | 0.722       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 804          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 305          |\n",
      "|    total_timesteps    | 573440       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0015954078 |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.901        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0771       |\n",
      "|    mean_step_reward   | 0.047870375  |\n",
      "|    n_updates          | 276          |\n",
      "|    policyGradLoss     | -0.00174     |\n",
      "|    value_loss         | 0.489        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 803          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 315          |\n",
      "|    total_timesteps    | 581632       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0014252263 |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.9          |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0521       |\n",
      "|    mean_step_reward   | 0.041352805  |\n",
      "|    n_updates          | 280          |\n",
      "|    policyGradLoss     | -0.00175     |\n",
      "|    value_loss         | 0.446        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 803         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 589824      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.00210226  |\n",
      "|    entropy_loss       | -2.29       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00529     |\n",
      "|    mean_step_reward   | 0.044139985 |\n",
      "|    n_updates          | 284         |\n",
      "|    policyGradLoss     | -0.00278    |\n",
      "|    value_loss         | 0.362       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 803          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 336          |\n",
      "|    total_timesteps    | 598016       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0019887225 |\n",
      "|    entropy_loss       | -2.27        |\n",
      "|    explained_variance | 0.906        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0148       |\n",
      "|    mean_step_reward   | 0.046151645  |\n",
      "|    n_updates          | 288          |\n",
      "|    policyGradLoss     | -0.00239     |\n",
      "|    value_loss         | 0.438        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 803          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 346          |\n",
      "|    total_timesteps    | 606208       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0016070476 |\n",
      "|    entropy_loss       | -2.26        |\n",
      "|    explained_variance | 0.872        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.228        |\n",
      "|    mean_step_reward   | 0.04507252   |\n",
      "|    n_updates          | 292          |\n",
      "|    policyGradLoss     | -0.00221     |\n",
      "|    value_loss         | 0.574        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 804          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 356          |\n",
      "|    total_timesteps    | 614400       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0016898306 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.91         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.157        |\n",
      "|    mean_step_reward   | 0.049668826  |\n",
      "|    n_updates          | 296          |\n",
      "|    policyGradLoss     | -0.00146     |\n",
      "|    value_loss         | 0.469        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 804          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 366          |\n",
      "|    total_timesteps    | 622592       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0015647379 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.868        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.262        |\n",
      "|    mean_step_reward   | 0.04780019   |\n",
      "|    n_updates          | 300          |\n",
      "|    policyGradLoss     | -0.000963    |\n",
      "|    value_loss         | 0.752        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 804          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 376          |\n",
      "|    total_timesteps    | 630784       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0015233505 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.884        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.204        |\n",
      "|    mean_step_reward   | 0.047658287  |\n",
      "|    n_updates          | 304          |\n",
      "|    policyGradLoss     | -0.00128     |\n",
      "|    value_loss         | 0.598        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 804          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 387          |\n",
      "|    total_timesteps    | 638976       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0015932753 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.89         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.234        |\n",
      "|    mean_step_reward   | 0.050920907  |\n",
      "|    n_updates          | 308          |\n",
      "|    policyGradLoss     | -0.000333    |\n",
      "|    value_loss         | 0.604        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 804         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 397         |\n",
      "|    total_timesteps    | 647168      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.001948724 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.889       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.198       |\n",
      "|    mean_step_reward   | 0.052655064 |\n",
      "|    n_updates          | 312         |\n",
      "|    policyGradLoss     | -0.00145    |\n",
      "|    value_loss         | 0.6         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 804          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 407          |\n",
      "|    total_timesteps    | 655360       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025433789 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.877        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.251        |\n",
      "|    mean_step_reward   | 0.048462845  |\n",
      "|    n_updates          | 316          |\n",
      "|    policyGradLoss     | -0.00119     |\n",
      "|    value_loss         | 0.728        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_1.zip\n",
      "[EVAL] Mean Return: -0.274, Best Return: -0.274\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_1_-0.27.mp4\n",
      "\n",
      "=== Round 3 | Learn 327680 steps (Total trained: 655360) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1104   |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 7      |\n",
      "|    total_timesteps | 663552 |\n",
      "-------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 927         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 671744      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.00288287  |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.045       |\n",
      "|    mean_step_reward   | 0.048408493 |\n",
      "|    n_updates          | 324         |\n",
      "|    policyGradLoss     | -0.000576   |\n",
      "|    value_loss         | 0.325       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 878          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 679936       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0018903934 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.888        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.395        |\n",
      "|    mean_step_reward   | 0.05119897   |\n",
      "|    n_updates          | 328          |\n",
      "|    policyGradLoss     | -0.00159     |\n",
      "|    value_loss         | 0.72         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 855          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 38           |\n",
      "|    total_timesteps    | 688128       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0017564262 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.872        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.171        |\n",
      "|    mean_step_reward   | 0.04755781   |\n",
      "|    n_updates          | 332          |\n",
      "|    policyGradLoss     | -0.00155     |\n",
      "|    value_loss         | 0.603        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 843          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 48           |\n",
      "|    total_timesteps    | 696320       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0018004866 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.892        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.163        |\n",
      "|    mean_step_reward   | 0.04568033   |\n",
      "|    n_updates          | 336          |\n",
      "|    policyGradLoss     | -0.0019      |\n",
      "|    value_loss         | 0.467        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 832         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 704512      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002112128 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.881       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.125       |\n",
      "|    mean_step_reward   | 0.048858427 |\n",
      "|    n_updates          | 340         |\n",
      "|    policyGradLoss     | 0.000224    |\n",
      "|    value_loss         | 0.551       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 826          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 69           |\n",
      "|    total_timesteps    | 712704       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027650176 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.9          |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.154        |\n",
      "|    mean_step_reward   | 0.044206478  |\n",
      "|    n_updates          | 344          |\n",
      "|    policyGradLoss     | -0.00178     |\n",
      "|    value_loss         | 0.469        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 821          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 79           |\n",
      "|    total_timesteps    | 720896       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023242123 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.916        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.224        |\n",
      "|    mean_step_reward   | 0.043505482  |\n",
      "|    n_updates          | 348          |\n",
      "|    policyGradLoss     | -0.00076     |\n",
      "|    value_loss         | 0.393        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 819          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 89           |\n",
      "|    total_timesteps    | 729088       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0029871692 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.867        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.206        |\n",
      "|    mean_step_reward   | 0.050115436  |\n",
      "|    n_updates          | 352          |\n",
      "|    policyGradLoss     | -0.00122     |\n",
      "|    value_loss         | 0.603        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 100         |\n",
      "|    total_timesteps    | 737280      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002439294 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.904       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.187       |\n",
      "|    mean_step_reward   | 0.049478512 |\n",
      "|    n_updates          | 356         |\n",
      "|    policyGradLoss     | -0.00316    |\n",
      "|    value_loss         | 0.496       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 813          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 110          |\n",
      "|    total_timesteps    | 745472       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0017830052 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.863        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.232        |\n",
      "|    mean_step_reward   | 0.05227184   |\n",
      "|    n_updates          | 360          |\n",
      "|    policyGradLoss     | -0.00154     |\n",
      "|    value_loss         | 0.753        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 811          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 121          |\n",
      "|    total_timesteps    | 753664       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033015623 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.897        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.212        |\n",
      "|    mean_step_reward   | 0.05332239   |\n",
      "|    n_updates          | 364          |\n",
      "|    policyGradLoss     | -0.000632    |\n",
      "|    value_loss         | 0.546        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 810          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 131          |\n",
      "|    total_timesteps    | 761856       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026069195 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.886        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.173        |\n",
      "|    mean_step_reward   | 0.04739932   |\n",
      "|    n_updates          | 368          |\n",
      "|    policyGradLoss     | -0.00246     |\n",
      "|    value_loss         | 0.639        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 811          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 141          |\n",
      "|    total_timesteps    | 770048       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025925296 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.873        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.314        |\n",
      "|    mean_step_reward   | 0.052284867  |\n",
      "|    n_updates          | 372          |\n",
      "|    policyGradLoss     | 9.26e-05     |\n",
      "|    value_loss         | 0.706        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 811          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 151          |\n",
      "|    total_timesteps    | 778240       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0012811201 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.89         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.186        |\n",
      "|    mean_step_reward   | 0.050959606  |\n",
      "|    n_updates          | 376          |\n",
      "|    policyGradLoss     | -0.000156    |\n",
      "|    value_loss         | 0.724        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 161         |\n",
      "|    total_timesteps    | 786432      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002339573 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.879       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.239       |\n",
      "|    mean_step_reward   | 0.047549143 |\n",
      "|    n_updates          | 380         |\n",
      "|    policyGradLoss     | -0.00295    |\n",
      "|    value_loss         | 0.765       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 811          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 171          |\n",
      "|    total_timesteps    | 794624       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0017832074 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.882        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.224        |\n",
      "|    mean_step_reward   | 0.05092595   |\n",
      "|    n_updates          | 384          |\n",
      "|    policyGradLoss     | -0.00181     |\n",
      "|    value_loss         | 0.668        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 802816      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002543624 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.855       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.348       |\n",
      "|    mean_step_reward   | 0.05200774  |\n",
      "|    n_updates          | 388         |\n",
      "|    policyGradLoss     | -0.0021     |\n",
      "|    value_loss         | 0.907       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 811          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 191          |\n",
      "|    total_timesteps    | 811008       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0017902687 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.876        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.349        |\n",
      "|    mean_step_reward   | 0.0548482    |\n",
      "|    n_updates          | 392          |\n",
      "|    policyGradLoss     | -0.00085     |\n",
      "|    value_loss         | 0.849        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 811          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 201          |\n",
      "|    total_timesteps    | 819200       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0028185768 |\n",
      "|    entropy_loss       | -2.25        |\n",
      "|    explained_variance | 0.862        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.13         |\n",
      "|    mean_step_reward   | 0.045726404  |\n",
      "|    n_updates          | 396          |\n",
      "|    policyGradLoss     | -0.00134     |\n",
      "|    value_loss         | 0.611        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 810          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 212          |\n",
      "|    total_timesteps    | 827392       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025462322 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.887        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.309        |\n",
      "|    mean_step_reward   | 0.050467964  |\n",
      "|    n_updates          | 400          |\n",
      "|    policyGradLoss     | -0.00154     |\n",
      "|    value_loss         | 0.76         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 809          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 222          |\n",
      "|    total_timesteps    | 835584       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0021610619 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.887        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.113        |\n",
      "|    mean_step_reward   | 0.047948383  |\n",
      "|    n_updates          | 404          |\n",
      "|    policyGradLoss     | -0.00193     |\n",
      "|    value_loss         | 0.624        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 810          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 232          |\n",
      "|    total_timesteps    | 843776       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0029552984 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.849        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.269        |\n",
      "|    mean_step_reward   | 0.054359242  |\n",
      "|    n_updates          | 408          |\n",
      "|    policyGradLoss     | -0.000229    |\n",
      "|    value_loss         | 0.928        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 851968      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004303768 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.883       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.245       |\n",
      "|    mean_step_reward   | 0.05190081  |\n",
      "|    n_updates          | 412         |\n",
      "|    policyGradLoss     | -0.00202    |\n",
      "|    value_loss         | 0.702       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 808          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 253          |\n",
      "|    total_timesteps    | 860160       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025860316 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.87         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.38         |\n",
      "|    mean_step_reward   | 0.056301624  |\n",
      "|    n_updates          | 416          |\n",
      "|    policyGradLoss     | -0.000156    |\n",
      "|    value_loss         | 0.887        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 807          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 263          |\n",
      "|    total_timesteps    | 868352       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0026522023 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.86         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.34         |\n",
      "|    mean_step_reward   | 0.052533966  |\n",
      "|    n_updates          | 420          |\n",
      "|    policyGradLoss     | -0.00196     |\n",
      "|    value_loss         | 0.884        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 807          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 273          |\n",
      "|    total_timesteps    | 876544       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025304034 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.857        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.375        |\n",
      "|    mean_step_reward   | 0.051450912  |\n",
      "|    n_updates          | 424          |\n",
      "|    policyGradLoss     | -0.00256     |\n",
      "|    value_loss         | 0.884        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 884736      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002738313 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.865       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.278       |\n",
      "|    mean_step_reward   | 0.054114714 |\n",
      "|    n_updates          | 428         |\n",
      "|    policyGradLoss     | -0.000658   |\n",
      "|    value_loss         | 0.912       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 805          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 294          |\n",
      "|    total_timesteps    | 892928       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027544822 |\n",
      "|    entropy_loss       | -2.18        |\n",
      "|    explained_variance | 0.868        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.313        |\n",
      "|    mean_step_reward   | 0.059585586  |\n",
      "|    n_updates          | 432          |\n",
      "|    policyGradLoss     | -0.00187     |\n",
      "|    value_loss         | 0.909        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 806          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 304          |\n",
      "|    total_timesteps    | 901120       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030626764 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.869        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.259        |\n",
      "|    mean_step_reward   | 0.050413497  |\n",
      "|    n_updates          | 436          |\n",
      "|    policyGradLoss     | -0.00159     |\n",
      "|    value_loss         | 0.824        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 314         |\n",
      "|    total_timesteps    | 909312      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002467621 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.893       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.286       |\n",
      "|    mean_step_reward   | 0.04983759  |\n",
      "|    n_updates          | 440         |\n",
      "|    policyGradLoss     | -0.000727   |\n",
      "|    value_loss         | 0.7         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 806          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 325          |\n",
      "|    total_timesteps    | 917504       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027765466 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.879        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.339        |\n",
      "|    mean_step_reward   | 0.051791936  |\n",
      "|    n_updates          | 444          |\n",
      "|    policyGradLoss     | -0.00147     |\n",
      "|    value_loss         | 0.779        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 806          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 335          |\n",
      "|    total_timesteps    | 925696       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0029282423 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.872        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.22         |\n",
      "|    mean_step_reward   | 0.04697167   |\n",
      "|    n_updates          | 448          |\n",
      "|    policyGradLoss     | -0.00192     |\n",
      "|    value_loss         | 0.689        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 805          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 345          |\n",
      "|    total_timesteps    | 933888       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0023847036 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.874        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.209        |\n",
      "|    mean_step_reward   | 0.051326957  |\n",
      "|    n_updates          | 452          |\n",
      "|    policyGradLoss     | -0.00286     |\n",
      "|    value_loss         | 0.744        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 805          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 355          |\n",
      "|    total_timesteps    | 942080       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0031793746 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.905        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.187        |\n",
      "|    mean_step_reward   | 0.054709315  |\n",
      "|    n_updates          | 456          |\n",
      "|    policyGradLoss     | -0.00254     |\n",
      "|    value_loss         | 0.567        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 805          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 366          |\n",
      "|    total_timesteps    | 950272       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0032193358 |\n",
      "|    entropy_loss       | -2.22        |\n",
      "|    explained_variance | 0.844        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.22         |\n",
      "|    mean_step_reward   | 0.049202863  |\n",
      "|    n_updates          | 460          |\n",
      "|    policyGradLoss     | -0.00156     |\n",
      "|    value_loss         | 0.817        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 805          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 376          |\n",
      "|    total_timesteps    | 958464       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030548044 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.853        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.342        |\n",
      "|    mean_step_reward   | 0.057305433  |\n",
      "|    n_updates          | 464          |\n",
      "|    policyGradLoss     | -0.00201     |\n",
      "|    value_loss         | 0.984        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 805          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 386          |\n",
      "|    total_timesteps    | 966656       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0036837005 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.867        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.248        |\n",
      "|    mean_step_reward   | 0.0521801    |\n",
      "|    n_updates          | 468          |\n",
      "|    policyGradLoss     | -0.00204     |\n",
      "|    value_loss         | 0.764        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 805          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 396          |\n",
      "|    total_timesteps    | 974848       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038648604 |\n",
      "|    entropy_loss       | -2.23        |\n",
      "|    explained_variance | 0.871        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.239        |\n",
      "|    mean_step_reward   | 0.05164639   |\n",
      "|    n_updates          | 472          |\n",
      "|    policyGradLoss     | -0.00417     |\n",
      "|    value_loss         | 0.709        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 406         |\n",
      "|    total_timesteps    | 983040      |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002254569 |\n",
      "|    entropy_loss       | -2.21       |\n",
      "|    explained_variance | 0.891       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.107       |\n",
      "|    mean_step_reward   | 0.051266264 |\n",
      "|    n_updates          | 476         |\n",
      "|    policyGradLoss     | -0.00142    |\n",
      "|    value_loss         | 0.721       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_2.zip\n",
      "[EVAL] Mean Return: -0.274, Best Return: -0.274\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_2_-0.27.mp4\n",
      "\n",
      "=== Round 4 | Learn 327680 steps (Total trained: 983040) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1117   |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 7      |\n",
      "|    total_timesteps | 991232 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 927          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 999424       |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0044983127 |\n",
      "|    entropy_loss       | -2.19        |\n",
      "|    explained_variance | 0.916        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.137        |\n",
      "|    mean_step_reward   | 0.054435894  |\n",
      "|    n_updates          | 484          |\n",
      "|    policyGradLoss     | -0.0014      |\n",
      "|    value_loss         | 0.574        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 886          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 1007616      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0022577022 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.873        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.241        |\n",
      "|    mean_step_reward   | 0.060569853  |\n",
      "|    n_updates          | 488          |\n",
      "|    policyGradLoss     | -0.00183     |\n",
      "|    value_loss         | 0.952        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 865          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 37           |\n",
      "|    total_timesteps    | 1015808      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027299696 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.871        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.274        |\n",
      "|    mean_step_reward   | 0.06123336   |\n",
      "|    n_updates          | 492          |\n",
      "|    policyGradLoss     | -0.00228     |\n",
      "|    value_loss         | 0.926        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 851          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 48           |\n",
      "|    total_timesteps    | 1024000      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0030996078 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.87         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.296        |\n",
      "|    mean_step_reward   | 0.05693183   |\n",
      "|    n_updates          | 496          |\n",
      "|    policyGradLoss     | -0.00283     |\n",
      "|    value_loss         | 0.927        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 844         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 1032192     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.002881752 |\n",
      "|    entropy_loss       | -2.17       |\n",
      "|    explained_variance | 0.862       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.387       |\n",
      "|    mean_step_reward   | 0.055155087 |\n",
      "|    n_updates          | 500         |\n",
      "|    policyGradLoss     | -0.00193    |\n",
      "|    value_loss         | 1.02        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 837          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 68           |\n",
      "|    total_timesteps    | 1040384      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0024319228 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.861        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.454        |\n",
      "|    mean_step_reward   | 0.05655726   |\n",
      "|    n_updates          | 504          |\n",
      "|    policyGradLoss     | -0.00181     |\n",
      "|    value_loss         | 1.09         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 831          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 78           |\n",
      "|    total_timesteps    | 1048576      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0037837392 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.846        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.251        |\n",
      "|    mean_step_reward   | 0.06278449   |\n",
      "|    n_updates          | 508          |\n",
      "|    policyGradLoss     | -0.00216     |\n",
      "|    value_loss         | 1.03         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 831          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 88           |\n",
      "|    total_timesteps    | 1056768      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0025391332 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.871        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.286        |\n",
      "|    mean_step_reward   | 0.0555205    |\n",
      "|    n_updates          | 512          |\n",
      "|    policyGradLoss     | -0.00258     |\n",
      "|    value_loss         | 0.931        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 828          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 98           |\n",
      "|    total_timesteps    | 1064960      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0035137082 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.871        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.305        |\n",
      "|    mean_step_reward   | 0.05558843   |\n",
      "|    n_updates          | 516          |\n",
      "|    policyGradLoss     | -0.00184     |\n",
      "|    value_loss         | 0.993        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 827         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 108         |\n",
      "|    total_timesteps    | 1073152     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003627534 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.88        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.269       |\n",
      "|    mean_step_reward   | 0.053201403 |\n",
      "|    n_updates          | 520         |\n",
      "|    policyGradLoss     | -0.00253    |\n",
      "|    value_loss         | 0.772       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 1081344     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004253256 |\n",
      "|    entropy_loss       | -2.19       |\n",
      "|    explained_variance | 0.855       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.281       |\n",
      "|    mean_step_reward   | 0.053506017 |\n",
      "|    n_updates          | 524         |\n",
      "|    policyGradLoss     | -0.000697   |\n",
      "|    value_loss         | 0.935       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 822          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 129          |\n",
      "|    total_timesteps    | 1089536      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0041540936 |\n",
      "|    entropy_loss       | -2.24        |\n",
      "|    explained_variance | 0.87         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.268        |\n",
      "|    mean_step_reward   | 0.043852076  |\n",
      "|    n_updates          | 528          |\n",
      "|    policyGradLoss     | -0.00314     |\n",
      "|    value_loss         | 0.711        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 820          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 139          |\n",
      "|    total_timesteps    | 1097728      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0037446783 |\n",
      "|    entropy_loss       | -2.2         |\n",
      "|    explained_variance | 0.842        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.317        |\n",
      "|    mean_step_reward   | 0.05632741   |\n",
      "|    n_updates          | 532          |\n",
      "|    policyGradLoss     | -0.00286     |\n",
      "|    value_loss         | 0.965        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 820          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 149          |\n",
      "|    total_timesteps    | 1105920      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038912622 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.864        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.191        |\n",
      "|    mean_step_reward   | 0.05868476   |\n",
      "|    n_updates          | 536          |\n",
      "|    policyGradLoss     | -0.00213     |\n",
      "|    value_loss         | 0.781        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 818          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 160          |\n",
      "|    total_timesteps    | 1114112      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038864268 |\n",
      "|    entropy_loss       | -2.21        |\n",
      "|    explained_variance | 0.9          |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.136        |\n",
      "|    mean_step_reward   | 0.048169285  |\n",
      "|    n_updates          | 540          |\n",
      "|    policyGradLoss     | -0.00357     |\n",
      "|    value_loss         | 0.6          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 1122304     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004751506 |\n",
      "|    entropy_loss       | -2.22       |\n",
      "|    explained_variance | 0.869       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.286       |\n",
      "|    mean_step_reward   | 0.053364635 |\n",
      "|    n_updates          | 544         |\n",
      "|    policyGradLoss     | -0.00323    |\n",
      "|    value_loss         | 0.783       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 1130496     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004178427 |\n",
      "|    entropy_loss       | -2.23       |\n",
      "|    explained_variance | 0.865       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.299       |\n",
      "|    mean_step_reward   | 0.04936865  |\n",
      "|    n_updates          | 548         |\n",
      "|    policyGradLoss     | -0.00435    |\n",
      "|    value_loss         | 0.827       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 1138688     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004512907 |\n",
      "|    entropy_loss       | -2.2        |\n",
      "|    explained_variance | 0.866       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.243       |\n",
      "|    mean_step_reward   | 0.0536644   |\n",
      "|    n_updates          | 552         |\n",
      "|    policyGradLoss     | -0.00143    |\n",
      "|    value_loss         | 0.926       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 1146880     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004114542 |\n",
      "|    entropy_loss       | -2.18       |\n",
      "|    explained_variance | 0.87        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.406       |\n",
      "|    mean_step_reward   | 0.0620004   |\n",
      "|    n_updates          | 556         |\n",
      "|    policyGradLoss     | -0.0027     |\n",
      "|    value_loss         | 0.904       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 815          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 211          |\n",
      "|    total_timesteps    | 1155072      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0048942226 |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.882        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.166        |\n",
      "|    mean_step_reward   | 0.067608245  |\n",
      "|    n_updates          | 560          |\n",
      "|    policyGradLoss     | -0.0026      |\n",
      "|    value_loss         | 0.734        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 814          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 221          |\n",
      "|    total_timesteps    | 1163264      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033975928 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.855        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.391        |\n",
      "|    mean_step_reward   | 0.055627953  |\n",
      "|    n_updates          | 564          |\n",
      "|    policyGradLoss     | -0.00266     |\n",
      "|    value_loss         | 1.04         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 1171456     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003597949 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.852       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.424       |\n",
      "|    mean_step_reward   | 0.061185803 |\n",
      "|    n_updates          | 568         |\n",
      "|    policyGradLoss     | -0.00257    |\n",
      "|    value_loss         | 1.07        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 1179648     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004184348 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.871       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.38        |\n",
      "|    mean_step_reward   | 0.06322914  |\n",
      "|    n_updates          | 572         |\n",
      "|    policyGradLoss     | -0.00414    |\n",
      "|    value_loss         | 1.04        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 812          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 252          |\n",
      "|    total_timesteps    | 1187840      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0036789908 |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.86         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.313        |\n",
      "|    mean_step_reward   | 0.060467847  |\n",
      "|    n_updates          | 576          |\n",
      "|    policyGradLoss     | -0.00302     |\n",
      "|    value_loss         | 1.06         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 811          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 262          |\n",
      "|    total_timesteps    | 1196032      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033294153 |\n",
      "|    entropy_loss       | -2.16        |\n",
      "|    explained_variance | 0.879        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.404        |\n",
      "|    mean_step_reward   | 0.055417053  |\n",
      "|    n_updates          | 580          |\n",
      "|    policyGradLoss     | -0.00254     |\n",
      "|    value_loss         | 1.02         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 1204224     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003436447 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.853       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.341       |\n",
      "|    mean_step_reward   | 0.059368715 |\n",
      "|    n_updates          | 584         |\n",
      "|    policyGradLoss     | -0.00369    |\n",
      "|    value_loss         | 1.17        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 810          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 283          |\n",
      "|    total_timesteps    | 1212416      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0038629745 |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.865        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.432        |\n",
      "|    mean_step_reward   | 0.06119372   |\n",
      "|    n_updates          | 588          |\n",
      "|    policyGradLoss     | -0.00401     |\n",
      "|    value_loss         | 1.03         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 809          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 293          |\n",
      "|    total_timesteps    | 1220608      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0033817207 |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.885        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.283        |\n",
      "|    mean_step_reward   | 0.065642685  |\n",
      "|    n_updates          | 592          |\n",
      "|    policyGradLoss     | -0.00309     |\n",
      "|    value_loss         | 0.872        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 810          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 303          |\n",
      "|    total_timesteps    | 1228800      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0036131674 |\n",
      "|    entropy_loss       | -2.13        |\n",
      "|    explained_variance | 0.869        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.385        |\n",
      "|    mean_step_reward   | 0.058887493  |\n",
      "|    n_updates          | 596          |\n",
      "|    policyGradLoss     | -0.00298     |\n",
      "|    value_loss         | 0.994        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 809          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 313          |\n",
      "|    total_timesteps    | 1236992      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0036637648 |\n",
      "|    entropy_loss       | -2.15        |\n",
      "|    explained_variance | 0.86         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.311        |\n",
      "|    mean_step_reward   | 0.05472389   |\n",
      "|    n_updates          | 600          |\n",
      "|    policyGradLoss     | -0.00286     |\n",
      "|    value_loss         | 1.04         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 323         |\n",
      "|    total_timesteps    | 1245184     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004080159 |\n",
      "|    entropy_loss       | -2.15       |\n",
      "|    explained_variance | 0.89        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.187       |\n",
      "|    mean_step_reward   | 0.056299746 |\n",
      "|    n_updates          | 604         |\n",
      "|    policyGradLoss     | -0.00312    |\n",
      "|    value_loss         | 0.764       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 809          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 333          |\n",
      "|    total_timesteps    | 1253376      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0027684146 |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.869        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.4          |\n",
      "|    mean_step_reward   | 0.061087895  |\n",
      "|    n_updates          | 608          |\n",
      "|    policyGradLoss     | -0.00299     |\n",
      "|    value_loss         | 1.11         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 344         |\n",
      "|    total_timesteps    | 1261568     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004923649 |\n",
      "|    entropy_loss       | -2.1        |\n",
      "|    explained_variance | 0.859       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.397       |\n",
      "|    mean_step_reward   | 0.06694433  |\n",
      "|    n_updates          | 612         |\n",
      "|    policyGradLoss     | -0.0048     |\n",
      "|    value_loss         | 1.11        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 354         |\n",
      "|    total_timesteps    | 1269760     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004466923 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.86        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.216       |\n",
      "|    mean_step_reward   | 0.06304802  |\n",
      "|    n_updates          | 616         |\n",
      "|    policyGradLoss     | -0.00392    |\n",
      "|    value_loss         | 0.977       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 364         |\n",
      "|    total_timesteps    | 1277952     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004660318 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.839       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.522       |\n",
      "|    mean_step_reward   | 0.066091724 |\n",
      "|    n_updates          | 620         |\n",
      "|    policyGradLoss     | -0.00445    |\n",
      "|    value_loss         | 1.18        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 809        |\n",
      "|    iterations         | 37         |\n",
      "|    time_elapsed       | 374        |\n",
      "|    total_timesteps    | 1286144    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0061732  |\n",
      "|    entropy_loss       | -2.1       |\n",
      "|    explained_variance | 0.873      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.317      |\n",
      "|    mean_step_reward   | 0.06295407 |\n",
      "|    n_updates          | 624        |\n",
      "|    policyGradLoss     | -0.0031    |\n",
      "|    value_loss         | 0.801      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 384         |\n",
      "|    total_timesteps    | 1294336     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004842142 |\n",
      "|    entropy_loss       | -2.12       |\n",
      "|    explained_variance | 0.829       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.379       |\n",
      "|    mean_step_reward   | 0.06350773  |\n",
      "|    n_updates          | 628         |\n",
      "|    policyGradLoss     | -0.00226    |\n",
      "|    value_loss         | 1.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 395         |\n",
      "|    total_timesteps    | 1302528     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004049829 |\n",
      "|    entropy_loss       | -2.13       |\n",
      "|    explained_variance | 0.869       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.348       |\n",
      "|    mean_step_reward   | 0.061362043 |\n",
      "|    n_updates          | 632         |\n",
      "|    policyGradLoss     | -0.00434    |\n",
      "|    value_loss         | 1.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 405         |\n",
      "|    total_timesteps    | 1310720     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004415473 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.876       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.288       |\n",
      "|    mean_step_reward   | 0.060854524 |\n",
      "|    n_updates          | 636         |\n",
      "|    policyGradLoss     | -0.00309    |\n",
      "|    value_loss         | 0.897       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_3.zip\n",
      "[EVAL] Mean Return: 270.864, Best Return: 270.864\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_3_270.86.mp4\n",
      "\n",
      "=== Round 5 | Learn 327680 steps (Total trained: 1310720) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1129    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 1318912 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 942          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 1327104      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0041003097 |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.851        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.346        |\n",
      "|    mean_step_reward   | 0.060339093  |\n",
      "|    n_updates          | 644          |\n",
      "|    policyGradLoss     | -0.00336     |\n",
      "|    value_loss         | 1.2          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 884          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 1335296      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0054148426 |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.897        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.24         |\n",
      "|    mean_step_reward   | 0.061705783  |\n",
      "|    n_updates          | 648          |\n",
      "|    policyGradLoss     | -0.0043      |\n",
      "|    value_loss         | 0.775        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 862          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 37           |\n",
      "|    total_timesteps    | 1343488      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0039604614 |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.875        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.37         |\n",
      "|    mean_step_reward   | 0.06467227   |\n",
      "|    n_updates          | 652          |\n",
      "|    policyGradLoss     | -0.00295     |\n",
      "|    value_loss         | 1.03         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 851          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 48           |\n",
      "|    total_timesteps    | 1351680      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0054554716 |\n",
      "|    entropy_loss       | -2.07        |\n",
      "|    explained_variance | 0.867        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.222        |\n",
      "|    mean_step_reward   | 0.07430261   |\n",
      "|    n_updates          | 656          |\n",
      "|    policyGradLoss     | -0.0045      |\n",
      "|    value_loss         | 0.897        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 848          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 57           |\n",
      "|    total_timesteps    | 1359872      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0047275666 |\n",
      "|    entropy_loss       | -2.09        |\n",
      "|    explained_variance | 0.851        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.408        |\n",
      "|    mean_step_reward   | 0.06540788   |\n",
      "|    n_updates          | 660          |\n",
      "|    policyGradLoss     | -0.00366     |\n",
      "|    value_loss         | 1.22         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 843          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 67           |\n",
      "|    total_timesteps    | 1368064      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0044076084 |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.86         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.544        |\n",
      "|    mean_step_reward   | 0.0663759    |\n",
      "|    n_updates          | 664          |\n",
      "|    policyGradLoss     | -0.004       |\n",
      "|    value_loss         | 1.28         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 841         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 77          |\n",
      "|    total_timesteps    | 1376256     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004961324 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.868       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.476       |\n",
      "|    mean_step_reward   | 0.068010405 |\n",
      "|    n_updates          | 668         |\n",
      "|    policyGradLoss     | -0.00258    |\n",
      "|    value_loss         | 1.14        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 837          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 88           |\n",
      "|    total_timesteps    | 1384448      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0050344765 |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.871        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.287        |\n",
      "|    mean_step_reward   | 0.06438379   |\n",
      "|    n_updates          | 672          |\n",
      "|    policyGradLoss     | -0.00442     |\n",
      "|    value_loss         | 1.02         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 833         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 1392640     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005665073 |\n",
      "|    entropy_loss       | -2.14       |\n",
      "|    explained_variance | 0.863       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.332       |\n",
      "|    mean_step_reward   | 0.05889398  |\n",
      "|    n_updates          | 676         |\n",
      "|    policyGradLoss     | -0.00508    |\n",
      "|    value_loss         | 0.974       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 830          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 108          |\n",
      "|    total_timesteps    | 1400832      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0048053684 |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.861        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.301        |\n",
      "|    mean_step_reward   | 0.066123895  |\n",
      "|    n_updates          | 680          |\n",
      "|    policyGradLoss     | -0.00276     |\n",
      "|    value_loss         | 1.07         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 827          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 118          |\n",
      "|    total_timesteps    | 1409024      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0056768795 |\n",
      "|    entropy_loss       | -2.17        |\n",
      "|    explained_variance | 0.896        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.207        |\n",
      "|    mean_step_reward   | 0.0552663    |\n",
      "|    n_updates          | 684          |\n",
      "|    policyGradLoss     | -0.0031      |\n",
      "|    value_loss         | 0.757        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 826          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 128          |\n",
      "|    total_timesteps    | 1417216      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0054856874 |\n",
      "|    entropy_loss       | -2.14        |\n",
      "|    explained_variance | 0.868        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.37         |\n",
      "|    mean_step_reward   | 0.062414266  |\n",
      "|    n_updates          | 688          |\n",
      "|    policyGradLoss     | -0.00505     |\n",
      "|    value_loss         | 1.08         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 825          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 138          |\n",
      "|    total_timesteps    | 1425408      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0036294232 |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.856        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.392        |\n",
      "|    mean_step_reward   | 0.06702928   |\n",
      "|    n_updates          | 692          |\n",
      "|    policyGradLoss     | -0.00304     |\n",
      "|    value_loss         | 1.22         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 1433600     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005359857 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.84        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.317       |\n",
      "|    mean_step_reward   | 0.07208854  |\n",
      "|    n_updates          | 696         |\n",
      "|    policyGradLoss     | -0.0048     |\n",
      "|    value_loss         | 1.03        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 823          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 159          |\n",
      "|    total_timesteps    | 1441792      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0056004245 |\n",
      "|    entropy_loss       | -2.12        |\n",
      "|    explained_variance | 0.883        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.24         |\n",
      "|    mean_step_reward   | 0.062125795  |\n",
      "|    n_updates          | 700          |\n",
      "|    policyGradLoss     | -0.00217     |\n",
      "|    value_loss         | 0.938        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 1449984     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008496594 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.904       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.184       |\n",
      "|    mean_step_reward   | 0.070489824 |\n",
      "|    n_updates          | 704         |\n",
      "|    policyGradLoss     | -0.00468    |\n",
      "|    value_loss         | 0.754       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 819          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 180          |\n",
      "|    total_timesteps    | 1458176      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0047651855 |\n",
      "|    entropy_loss       | -2.09        |\n",
      "|    explained_variance | 0.871        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.19         |\n",
      "|    mean_step_reward   | 0.069225155  |\n",
      "|    n_updates          | 708          |\n",
      "|    policyGradLoss     | -0.00384     |\n",
      "|    value_loss         | 0.863        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 1466368     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.004849523 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.854       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.3         |\n",
      "|    mean_step_reward   | 0.06130003  |\n",
      "|    n_updates          | 712         |\n",
      "|    policyGradLoss     | -0.00311    |\n",
      "|    value_loss         | 1.19        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 816          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 200          |\n",
      "|    total_timesteps    | 1474560      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0058670584 |\n",
      "|    entropy_loss       | -2.11        |\n",
      "|    explained_variance | 0.884        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.371        |\n",
      "|    mean_step_reward   | 0.05809652   |\n",
      "|    n_updates          | 716          |\n",
      "|    policyGradLoss     | -0.00505     |\n",
      "|    value_loss         | 0.943        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 1482752     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006586249 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.871       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.328       |\n",
      "|    mean_step_reward   | 0.07016261  |\n",
      "|    n_updates          | 720         |\n",
      "|    policyGradLoss     | -0.00409    |\n",
      "|    value_loss         | 1.09        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 815        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 220        |\n",
      "|    total_timesteps    | 1490944    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00662935 |\n",
      "|    entropy_loss       | -2.05      |\n",
      "|    explained_variance | 0.844      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.263      |\n",
      "|    mean_step_reward   | 0.07421826 |\n",
      "|    n_updates          | 724        |\n",
      "|    policyGradLoss     | -0.00555   |\n",
      "|    value_loss         | 1.16       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 1499136     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.003910051 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.861       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.34        |\n",
      "|    mean_step_reward   | 0.07122806  |\n",
      "|    n_updates          | 728         |\n",
      "|    policyGradLoss     | -0.0044     |\n",
      "|    value_loss         | 1.1         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 814          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 241          |\n",
      "|    total_timesteps    | 1507328      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0054246066 |\n",
      "|    entropy_loss       | -2.06        |\n",
      "|    explained_variance | 0.835        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.32         |\n",
      "|    mean_step_reward   | 0.06677044   |\n",
      "|    n_updates          | 732          |\n",
      "|    policyGradLoss     | -0.00328     |\n",
      "|    value_loss         | 1.24         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 815          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 250          |\n",
      "|    total_timesteps    | 1515520      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0060624285 |\n",
      "|    entropy_loss       | -2.07        |\n",
      "|    explained_variance | 0.874        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.54         |\n",
      "|    mean_step_reward   | 0.069281906  |\n",
      "|    n_updates          | 736          |\n",
      "|    policyGradLoss     | -0.00383     |\n",
      "|    value_loss         | 1.24         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 815          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 261          |\n",
      "|    total_timesteps    | 1523712      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0058078156 |\n",
      "|    entropy_loss       | -2.08        |\n",
      "|    explained_variance | 0.859        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.419        |\n",
      "|    mean_step_reward   | 0.06793481   |\n",
      "|    n_updates          | 740          |\n",
      "|    policyGradLoss     | -0.00482     |\n",
      "|    value_loss         | 1.08         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 814          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 271          |\n",
      "|    total_timesteps    | 1531904      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0051189293 |\n",
      "|    entropy_loss       | -2.09        |\n",
      "|    explained_variance | 0.849        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.341        |\n",
      "|    mean_step_reward   | 0.07145144   |\n",
      "|    n_updates          | 744          |\n",
      "|    policyGradLoss     | -0.004       |\n",
      "|    value_loss         | 1.18         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 281         |\n",
      "|    total_timesteps    | 1540096     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006587568 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.886       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.346       |\n",
      "|    mean_step_reward   | 0.06612007  |\n",
      "|    n_updates          | 748         |\n",
      "|    policyGradLoss     | -0.00198    |\n",
      "|    value_loss         | 0.989       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 814          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 291          |\n",
      "|    total_timesteps    | 1548288      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0074690687 |\n",
      "|    entropy_loss       | -2.1         |\n",
      "|    explained_variance | 0.863        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.361        |\n",
      "|    mean_step_reward   | 0.06357468   |\n",
      "|    n_updates          | 752          |\n",
      "|    policyGradLoss     | -0.00574     |\n",
      "|    value_loss         | 1.01         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 301         |\n",
      "|    total_timesteps    | 1556480     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005975264 |\n",
      "|    entropy_loss       | -2.11       |\n",
      "|    explained_variance | 0.872       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.324       |\n",
      "|    mean_step_reward   | 0.06042003  |\n",
      "|    n_updates          | 756         |\n",
      "|    policyGradLoss     | -0.00296    |\n",
      "|    value_loss         | 1.01        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 813          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 312          |\n",
      "|    total_timesteps    | 1564672      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0069278707 |\n",
      "|    entropy_loss       | -2.08        |\n",
      "|    explained_variance | 0.834        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.414        |\n",
      "|    mean_step_reward   | 0.065867305  |\n",
      "|    n_updates          | 760          |\n",
      "|    policyGradLoss     | -0.00339     |\n",
      "|    value_loss         | 1.18         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 322         |\n",
      "|    total_timesteps    | 1572864     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005314243 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.838       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.405       |\n",
      "|    mean_step_reward   | 0.07703527  |\n",
      "|    n_updates          | 764         |\n",
      "|    policyGradLoss     | -0.00304    |\n",
      "|    value_loss         | 1.04        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 813          |\n",
      "|    iterations         | 33           |\n",
      "|    time_elapsed       | 332          |\n",
      "|    total_timesteps    | 1581056      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0061858734 |\n",
      "|    entropy_loss       | -2.05        |\n",
      "|    explained_variance | 0.81         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.315        |\n",
      "|    mean_step_reward   | 0.06588739   |\n",
      "|    n_updates          | 768          |\n",
      "|    policyGradLoss     | -0.003       |\n",
      "|    value_loss         | 1.24         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 813          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 342          |\n",
      "|    total_timesteps    | 1589248      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0058039133 |\n",
      "|    entropy_loss       | -2.03        |\n",
      "|    explained_variance | 0.841        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.384        |\n",
      "|    mean_step_reward   | 0.07404299   |\n",
      "|    n_updates          | 772          |\n",
      "|    policyGradLoss     | -0.00301     |\n",
      "|    value_loss         | 1.26         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 812          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 352          |\n",
      "|    total_timesteps    | 1597440      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0065980777 |\n",
      "|    entropy_loss       | -2.01        |\n",
      "|    explained_variance | 0.84         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.32         |\n",
      "|    mean_step_reward   | 0.07679586   |\n",
      "|    n_updates          | 776          |\n",
      "|    policyGradLoss     | -0.00414     |\n",
      "|    value_loss         | 1.1          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 812          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 362          |\n",
      "|    total_timesteps    | 1605632      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0073421416 |\n",
      "|    entropy_loss       | -2.03        |\n",
      "|    explained_variance | 0.856        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.199        |\n",
      "|    mean_step_reward   | 0.07090491   |\n",
      "|    n_updates          | 780          |\n",
      "|    policyGradLoss     | -0.00229     |\n",
      "|    value_loss         | 0.931        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 373         |\n",
      "|    total_timesteps    | 1613824     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007221388 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.873       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.407       |\n",
      "|    mean_step_reward   | 0.068907596 |\n",
      "|    n_updates          | 784         |\n",
      "|    policyGradLoss     | -0.00524    |\n",
      "|    value_loss         | 1.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 383         |\n",
      "|    total_timesteps    | 1622016     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008901922 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.857       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.437       |\n",
      "|    mean_step_reward   | 0.07237066  |\n",
      "|    n_updates          | 788         |\n",
      "|    policyGradLoss     | -0.0053     |\n",
      "|    value_loss         | 1.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 393         |\n",
      "|    total_timesteps    | 1630208     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007780199 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.858       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.242       |\n",
      "|    mean_step_reward   | 0.08248492  |\n",
      "|    n_updates          | 792         |\n",
      "|    policyGradLoss     | -0.00255    |\n",
      "|    value_loss         | 0.84        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 810          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 404          |\n",
      "|    total_timesteps    | 1638400      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0072548427 |\n",
      "|    entropy_loss       | -2.01        |\n",
      "|    explained_variance | 0.831        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.372        |\n",
      "|    mean_step_reward   | 0.06353675   |\n",
      "|    n_updates          | 796          |\n",
      "|    policyGradLoss     | -0.00295     |\n",
      "|    value_loss         | 1.27         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_4.zip\n",
      "[EVAL] Mean Return: -0.274, Best Return: -0.274\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_4_-0.27.mp4\n",
      "\n",
      "=== Round 6 | Learn 327680 steps (Total trained: 1638400) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1132    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 1646592 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 948         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 1654784     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008576376 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.87        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.39        |\n",
      "|    mean_step_reward   | 0.07470573  |\n",
      "|    n_updates          | 804         |\n",
      "|    policyGradLoss     | -0.00486    |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 892         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 1662976     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006818037 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.87        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.395       |\n",
      "|    mean_step_reward   | 0.07590056  |\n",
      "|    n_updates          | 808         |\n",
      "|    policyGradLoss     | -0.00628    |\n",
      "|    value_loss         | 0.998       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 858          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 38           |\n",
      "|    total_timesteps    | 1671168      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0061372034 |\n",
      "|    entropy_loss       | -1.99        |\n",
      "|    explained_variance | 0.886        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.453        |\n",
      "|    mean_step_reward   | 0.074098945  |\n",
      "|    n_updates          | 812          |\n",
      "|    policyGradLoss     | -0.00365     |\n",
      "|    value_loss         | 1.12         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 846          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 48           |\n",
      "|    total_timesteps    | 1679360      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0053670807 |\n",
      "|    entropy_loss       | -2           |\n",
      "|    explained_variance | 0.836        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.506        |\n",
      "|    mean_step_reward   | 0.07349506   |\n",
      "|    n_updates          | 816          |\n",
      "|    policyGradLoss     | -0.00409     |\n",
      "|    value_loss         | 1.55         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 839         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 1687552     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005777418 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.872       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.376       |\n",
      "|    mean_step_reward   | 0.07976195  |\n",
      "|    n_updates          | 820         |\n",
      "|    policyGradLoss     | -0.00353    |\n",
      "|    value_loss         | 1.14        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 832          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 68           |\n",
      "|    total_timesteps    | 1695744      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0065494645 |\n",
      "|    entropy_loss       | -1.99        |\n",
      "|    explained_variance | 0.862        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.347        |\n",
      "|    mean_step_reward   | 0.07854453   |\n",
      "|    n_updates          | 824          |\n",
      "|    policyGradLoss     | -0.00416     |\n",
      "|    value_loss         | 1.15         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 827         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 79          |\n",
      "|    total_timesteps    | 1703936     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005764719 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.86        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.346       |\n",
      "|    mean_step_reward   | 0.075809106 |\n",
      "|    n_updates          | 828         |\n",
      "|    policyGradLoss     | -0.00348    |\n",
      "|    value_loss         | 1.02        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 823          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 89           |\n",
      "|    total_timesteps    | 1712128      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0068571996 |\n",
      "|    entropy_loss       | -2           |\n",
      "|    explained_variance | 0.883        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.215        |\n",
      "|    mean_step_reward   | 0.08348054   |\n",
      "|    n_updates          | 832          |\n",
      "|    policyGradLoss     | -0.00568     |\n",
      "|    value_loss         | 0.811        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 822          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 99           |\n",
      "|    total_timesteps    | 1720320      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0058067883 |\n",
      "|    entropy_loss       | -2.02        |\n",
      "|    explained_variance | 0.866        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.584        |\n",
      "|    mean_step_reward   | 0.06947106   |\n",
      "|    n_updates          | 836          |\n",
      "|    policyGradLoss     | -0.00445     |\n",
      "|    value_loss         | 1.32         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 1728512     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006383267 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.876       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.262       |\n",
      "|    mean_step_reward   | 0.073138095 |\n",
      "|    n_updates          | 840         |\n",
      "|    policyGradLoss     | -0.00344    |\n",
      "|    value_loss         | 0.95        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 1736704     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006759147 |\n",
      "|    entropy_loss       | -2.06       |\n",
      "|    explained_variance | 0.874       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.542       |\n",
      "|    mean_step_reward   | 0.066718675 |\n",
      "|    n_updates          | 844         |\n",
      "|    policyGradLoss     | -0.00373    |\n",
      "|    value_loss         | 1.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 130         |\n",
      "|    total_timesteps    | 1744896     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007395928 |\n",
      "|    entropy_loss       | -2.09       |\n",
      "|    explained_variance | 0.877       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.394       |\n",
      "|    mean_step_reward   | 0.066075586 |\n",
      "|    n_updates          | 848         |\n",
      "|    policyGradLoss     | -0.00411    |\n",
      "|    value_loss         | 1.07        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 140         |\n",
      "|    total_timesteps    | 1753088     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008950431 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.822       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.373       |\n",
      "|    mean_step_reward   | 0.071298525 |\n",
      "|    n_updates          | 852         |\n",
      "|    policyGradLoss     | -0.00189    |\n",
      "|    value_loss         | 1.5         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 150         |\n",
      "|    total_timesteps    | 1761280     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007026237 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.854       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.384       |\n",
      "|    mean_step_reward   | 0.069411084 |\n",
      "|    n_updates          | 856         |\n",
      "|    policyGradLoss     | -0.00333    |\n",
      "|    value_loss         | 1.11        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 814          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 160          |\n",
      "|    total_timesteps    | 1769472      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0070610745 |\n",
      "|    entropy_loss       | -2.06        |\n",
      "|    explained_variance | 0.849        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.321        |\n",
      "|    mean_step_reward   | 0.07086428   |\n",
      "|    n_updates          | 860          |\n",
      "|    policyGradLoss     | -0.00292     |\n",
      "|    value_loss         | 1.38         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 1777664     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008508034 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.847       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.382       |\n",
      "|    mean_step_reward   | 0.07201323  |\n",
      "|    n_updates          | 864         |\n",
      "|    policyGradLoss     | -0.00208    |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 1785856     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007012898 |\n",
      "|    entropy_loss       | -2.05       |\n",
      "|    explained_variance | 0.894       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.305       |\n",
      "|    mean_step_reward   | 0.06771562  |\n",
      "|    n_updates          | 868         |\n",
      "|    policyGradLoss     | -0.00557    |\n",
      "|    value_loss         | 0.94        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 1794048     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007407263 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.888       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.35        |\n",
      "|    mean_step_reward   | 0.07879868  |\n",
      "|    n_updates          | 872         |\n",
      "|    policyGradLoss     | -0.00289    |\n",
      "|    value_loss         | 0.95        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 811          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 201          |\n",
      "|    total_timesteps    | 1802240      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0074259765 |\n",
      "|    entropy_loss       | -1.99        |\n",
      "|    explained_variance | 0.881        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.196        |\n",
      "|    mean_step_reward   | 0.08214699   |\n",
      "|    n_updates          | 876          |\n",
      "|    policyGradLoss     | -0.00396     |\n",
      "|    value_loss         | 0.84         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 212         |\n",
      "|    total_timesteps    | 1810432     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006681931 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.86        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.586       |\n",
      "|    mean_step_reward   | 0.07505891  |\n",
      "|    n_updates          | 880         |\n",
      "|    policyGradLoss     | -0.0036     |\n",
      "|    value_loss         | 1.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 1818624     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007343083 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.889       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.351       |\n",
      "|    mean_step_reward   | 0.072283    |\n",
      "|    n_updates          | 884         |\n",
      "|    policyGradLoss     | -0.00301    |\n",
      "|    value_loss         | 0.919       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 1826816     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008154821 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.857       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.331       |\n",
      "|    mean_step_reward   | 0.07638234  |\n",
      "|    n_updates          | 888         |\n",
      "|    policyGradLoss     | -0.00427    |\n",
      "|    value_loss         | 1.11        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 809          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 242          |\n",
      "|    total_timesteps    | 1835008      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0075161294 |\n",
      "|    entropy_loss       | -2           |\n",
      "|    explained_variance | 0.869        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.49         |\n",
      "|    mean_step_reward   | 0.077672265  |\n",
      "|    n_updates          | 892          |\n",
      "|    policyGradLoss     | -0.00376     |\n",
      "|    value_loss         | 0.945        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 1843200     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005412302 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.878       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.293       |\n",
      "|    mean_step_reward   | 0.08322243  |\n",
      "|    n_updates          | 896         |\n",
      "|    policyGradLoss     | -0.00319    |\n",
      "|    value_loss         | 0.937       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 808          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 263          |\n",
      "|    total_timesteps    | 1851392      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0064397114 |\n",
      "|    entropy_loss       | -1.99        |\n",
      "|    explained_variance | 0.862        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.474        |\n",
      "|    mean_step_reward   | 0.073588446  |\n",
      "|    n_updates          | 900          |\n",
      "|    policyGradLoss     | -0.00539     |\n",
      "|    value_loss         | 1.3          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 808          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 273          |\n",
      "|    total_timesteps    | 1859584      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0066966373 |\n",
      "|    entropy_loss       | -1.99        |\n",
      "|    explained_variance | 0.881        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.399        |\n",
      "|    mean_step_reward   | 0.07330333   |\n",
      "|    n_updates          | 904          |\n",
      "|    policyGradLoss     | -0.00155     |\n",
      "|    value_loss         | 1.2          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 807          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 284          |\n",
      "|    total_timesteps    | 1867776      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0054038377 |\n",
      "|    entropy_loss       | -2           |\n",
      "|    explained_variance | 0.871        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.429        |\n",
      "|    mean_step_reward   | 0.078844845  |\n",
      "|    n_updates          | 908          |\n",
      "|    policyGradLoss     | -0.00327     |\n",
      "|    value_loss         | 1.31         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 1875968     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006246746 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.855       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.272       |\n",
      "|    mean_step_reward   | 0.08456676  |\n",
      "|    n_updates          | 912         |\n",
      "|    policyGradLoss     | -0.00483    |\n",
      "|    value_loss         | 1.04        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 807          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 304          |\n",
      "|    total_timesteps    | 1884160      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0063731596 |\n",
      "|    entropy_loss       | -2.01        |\n",
      "|    explained_variance | 0.829        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.566        |\n",
      "|    mean_step_reward   | 0.07878536   |\n",
      "|    n_updates          | 916          |\n",
      "|    policyGradLoss     | -0.00309     |\n",
      "|    value_loss         | 1.31         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 807          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 314          |\n",
      "|    total_timesteps    | 1892352      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0061638765 |\n",
      "|    entropy_loss       | -2           |\n",
      "|    explained_variance | 0.887        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.289        |\n",
      "|    mean_step_reward   | 0.07796494   |\n",
      "|    n_updates          | 920          |\n",
      "|    policyGradLoss     | -0.00355     |\n",
      "|    value_loss         | 0.978        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 806        |\n",
      "|    iterations         | 32         |\n",
      "|    time_elapsed       | 325        |\n",
      "|    total_timesteps    | 1900544    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00683381 |\n",
      "|    entropy_loss       | -2         |\n",
      "|    explained_variance | 0.86       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.403      |\n",
      "|    mean_step_reward   | 0.07960619 |\n",
      "|    n_updates          | 924        |\n",
      "|    policyGradLoss     | -0.00562   |\n",
      "|    value_loss         | 1.2        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 335         |\n",
      "|    total_timesteps    | 1908736     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006456388 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.853       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.426       |\n",
      "|    mean_step_reward   | 0.083105825 |\n",
      "|    n_updates          | 928         |\n",
      "|    policyGradLoss     | -0.00331    |\n",
      "|    value_loss         | 1.09        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 806          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 345          |\n",
      "|    total_timesteps    | 1916928      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0063528377 |\n",
      "|    entropy_loss       | -2           |\n",
      "|    explained_variance | 0.854        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.51         |\n",
      "|    mean_step_reward   | 0.07763317   |\n",
      "|    n_updates          | 932          |\n",
      "|    policyGradLoss     | -0.00243     |\n",
      "|    value_loss         | 1.51         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 805          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 355          |\n",
      "|    total_timesteps    | 1925120      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0074578645 |\n",
      "|    entropy_loss       | -2.01        |\n",
      "|    explained_variance | 0.869        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.443        |\n",
      "|    mean_step_reward   | 0.074358374  |\n",
      "|    n_updates          | 936          |\n",
      "|    policyGradLoss     | -0.00554     |\n",
      "|    value_loss         | 1.13         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 805          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 365          |\n",
      "|    total_timesteps    | 1933312      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0063052266 |\n",
      "|    entropy_loss       | -2.02        |\n",
      "|    explained_variance | 0.867        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.519        |\n",
      "|    mean_step_reward   | 0.074109055  |\n",
      "|    n_updates          | 940          |\n",
      "|    policyGradLoss     | -0.00488     |\n",
      "|    value_loss         | 1.32         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 805        |\n",
      "|    iterations         | 37         |\n",
      "|    time_elapsed       | 376        |\n",
      "|    total_timesteps    | 1941504    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00939481 |\n",
      "|    entropy_loss       | -2.01      |\n",
      "|    explained_variance | 0.877      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.237      |\n",
      "|    mean_step_reward   | 0.0826797  |\n",
      "|    n_updates          | 944        |\n",
      "|    policyGradLoss     | -0.00434   |\n",
      "|    value_loss         | 0.887      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 386         |\n",
      "|    total_timesteps    | 1949696     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007900784 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.258       |\n",
      "|    mean_step_reward   | 0.08591603  |\n",
      "|    n_updates          | 948         |\n",
      "|    policyGradLoss     | -0.00471    |\n",
      "|    value_loss         | 0.713       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 805          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 396          |\n",
      "|    total_timesteps    | 1957888      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0065399706 |\n",
      "|    entropy_loss       | -2.02        |\n",
      "|    explained_variance | 0.887        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.328        |\n",
      "|    mean_step_reward   | 0.07383411   |\n",
      "|    n_updates          | 952          |\n",
      "|    policyGradLoss     | -0.00394     |\n",
      "|    value_loss         | 0.982        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 406         |\n",
      "|    total_timesteps    | 1966080     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006026588 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.889       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.382       |\n",
      "|    mean_step_reward   | 0.083870165 |\n",
      "|    n_updates          | 956         |\n",
      "|    policyGradLoss     | -0.00472    |\n",
      "|    value_loss         | 1.02        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_5.zip\n",
      "[EVAL] Mean Return: 5.688, Best Return: 5.688\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_5_5.69.mp4\n",
      "\n",
      "=== Round 7 | Learn 327680 steps (Total trained: 1966080) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1107    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 1974272 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 920         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 1982464     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010430824 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.874       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.291       |\n",
      "|    mean_step_reward   | 0.075343445 |\n",
      "|    n_updates          | 964         |\n",
      "|    policyGradLoss     | -0.00258    |\n",
      "|    value_loss         | 1.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 876         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 1990656     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007484205 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.86        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.358       |\n",
      "|    mean_step_reward   | 0.084889606 |\n",
      "|    n_updates          | 968         |\n",
      "|    policyGradLoss     | -0.0039     |\n",
      "|    value_loss         | 1.11        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 854          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 38           |\n",
      "|    total_timesteps    | 1998848      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0068222345 |\n",
      "|    entropy_loss       | -2.03        |\n",
      "|    explained_variance | 0.874        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.287        |\n",
      "|    mean_step_reward   | 0.075603515  |\n",
      "|    n_updates          | 972          |\n",
      "|    policyGradLoss     | -0.00151     |\n",
      "|    value_loss         | 0.999        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 842          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 48           |\n",
      "|    total_timesteps    | 2007040      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0071859844 |\n",
      "|    entropy_loss       | -2.04        |\n",
      "|    explained_variance | 0.891        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.316        |\n",
      "|    mean_step_reward   | 0.072199106  |\n",
      "|    n_updates          | 976          |\n",
      "|    policyGradLoss     | -0.00371     |\n",
      "|    value_loss         | 0.977        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 838          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 58           |\n",
      "|    total_timesteps    | 2015232      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0070154155 |\n",
      "|    entropy_loss       | -2.02        |\n",
      "|    explained_variance | 0.863        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.188        |\n",
      "|    mean_step_reward   | 0.08419876   |\n",
      "|    n_updates          | 980          |\n",
      "|    policyGradLoss     | -0.00309     |\n",
      "|    value_loss         | 1.01         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 831          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 69           |\n",
      "|    total_timesteps    | 2023424      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0068435124 |\n",
      "|    entropy_loss       | -2.03        |\n",
      "|    explained_variance | 0.857        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.421        |\n",
      "|    mean_step_reward   | 0.079459     |\n",
      "|    n_updates          | 984          |\n",
      "|    policyGradLoss     | -0.00448     |\n",
      "|    value_loss         | 1.22         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 824          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 79           |\n",
      "|    total_timesteps    | 2031616      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0063815014 |\n",
      "|    entropy_loss       | -2.03        |\n",
      "|    explained_variance | 0.862        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.453        |\n",
      "|    mean_step_reward   | 0.07161527   |\n",
      "|    n_updates          | 988          |\n",
      "|    policyGradLoss     | -0.00494     |\n",
      "|    value_loss         | 1.19         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 821          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 89           |\n",
      "|    total_timesteps    | 2039808      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0070920354 |\n",
      "|    entropy_loss       | -2           |\n",
      "|    explained_variance | 0.868        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.391        |\n",
      "|    mean_step_reward   | 0.07731281   |\n",
      "|    n_updates          | 992          |\n",
      "|    policyGradLoss     | -0.00296     |\n",
      "|    value_loss         | 1.14         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 99          |\n",
      "|    total_timesteps    | 2048000     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008296806 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.867       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.296       |\n",
      "|    mean_step_reward   | 0.08101485  |\n",
      "|    n_updates          | 996         |\n",
      "|    policyGradLoss     | -0.00524    |\n",
      "|    value_loss         | 0.955       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 110         |\n",
      "|    total_timesteps    | 2056192     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006801077 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.884       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.304       |\n",
      "|    mean_step_reward   | 0.08107592  |\n",
      "|    n_updates          | 1000        |\n",
      "|    policyGradLoss     | -0.00521    |\n",
      "|    value_loss         | 0.753       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 817          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 120          |\n",
      "|    total_timesteps    | 2064384      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0074493103 |\n",
      "|    entropy_loss       | -2.02        |\n",
      "|    explained_variance | 0.815        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.395        |\n",
      "|    mean_step_reward   | 0.080568284  |\n",
      "|    n_updates          | 1004         |\n",
      "|    policyGradLoss     | -0.00618     |\n",
      "|    value_loss         | 1.34         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 816        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 130        |\n",
      "|    total_timesteps    | 2072576    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00690437 |\n",
      "|    entropy_loss       | -2.01      |\n",
      "|    explained_variance | 0.872      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.293      |\n",
      "|    mean_step_reward   | 0.07943869 |\n",
      "|    n_updates          | 1008       |\n",
      "|    policyGradLoss     | -0.00284   |\n",
      "|    value_loss         | 1.17       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 140         |\n",
      "|    total_timesteps    | 2080768     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007929369 |\n",
      "|    entropy_loss       | -2.04       |\n",
      "|    explained_variance | 0.856       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.461       |\n",
      "|    mean_step_reward   | 0.07796441  |\n",
      "|    n_updates          | 1012        |\n",
      "|    policyGradLoss     | -0.00501    |\n",
      "|    value_loss         | 1.12        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 816          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 150          |\n",
      "|    total_timesteps    | 2088960      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0074635455 |\n",
      "|    entropy_loss       | -2.05        |\n",
      "|    explained_variance | 0.898        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.363        |\n",
      "|    mean_step_reward   | 0.07786936   |\n",
      "|    n_updates          | 1016         |\n",
      "|    policyGradLoss     | -0.00586     |\n",
      "|    value_loss         | 0.902        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 2097152     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009013407 |\n",
      "|    entropy_loss       | -2.07       |\n",
      "|    explained_variance | 0.827       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.606       |\n",
      "|    mean_step_reward   | 0.07676055  |\n",
      "|    n_updates          | 1020        |\n",
      "|    policyGradLoss     | -0.00389    |\n",
      "|    value_loss         | 1.43        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 814          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 171          |\n",
      "|    total_timesteps    | 2105344      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0065834275 |\n",
      "|    entropy_loss       | -2.04        |\n",
      "|    explained_variance | 0.89         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.361        |\n",
      "|    mean_step_reward   | 0.075100526  |\n",
      "|    n_updates          | 1024         |\n",
      "|    policyGradLoss     | -0.0051      |\n",
      "|    value_loss         | 0.926        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 814          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 181          |\n",
      "|    total_timesteps    | 2113536      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0069991895 |\n",
      "|    entropy_loss       | -2.04        |\n",
      "|    explained_variance | 0.848        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.427        |\n",
      "|    mean_step_reward   | 0.07799205   |\n",
      "|    n_updates          | 1028         |\n",
      "|    policyGradLoss     | -0.0046      |\n",
      "|    value_loss         | 1.24         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 2121728     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008524662 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.885       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.175       |\n",
      "|    mean_step_reward   | 0.080574796 |\n",
      "|    n_updates          | 1032        |\n",
      "|    policyGradLoss     | -0.0051     |\n",
      "|    value_loss         | 0.706       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 813          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 201          |\n",
      "|    total_timesteps    | 2129920      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0073013175 |\n",
      "|    entropy_loss       | -2.04        |\n",
      "|    explained_variance | 0.888        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.272        |\n",
      "|    mean_step_reward   | 0.07071761   |\n",
      "|    n_updates          | 1036         |\n",
      "|    policyGradLoss     | -0.00214     |\n",
      "|    value_loss         | 1.13         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 2138112     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007434466 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.887       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.211       |\n",
      "|    mean_step_reward   | 0.08594887  |\n",
      "|    n_updates          | 1040        |\n",
      "|    policyGradLoss     | -0.00081    |\n",
      "|    value_loss         | 0.816       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 2146304     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008109565 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.88        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.267       |\n",
      "|    mean_step_reward   | 0.079897486 |\n",
      "|    n_updates          | 1044        |\n",
      "|    policyGradLoss     | -0.00564    |\n",
      "|    value_loss         | 1.05        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 813          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 231          |\n",
      "|    total_timesteps    | 2154496      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0077893436 |\n",
      "|    entropy_loss       | -2.02        |\n",
      "|    explained_variance | 0.838        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.482        |\n",
      "|    mean_step_reward   | 0.076859064  |\n",
      "|    n_updates          | 1048         |\n",
      "|    policyGradLoss     | -0.00332     |\n",
      "|    value_loss         | 1.47         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 2162688     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007222644 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.871       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.436       |\n",
      "|    mean_step_reward   | 0.07990506  |\n",
      "|    n_updates          | 1052        |\n",
      "|    policyGradLoss     | -0.00435    |\n",
      "|    value_loss         | 1.14        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 814          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 251          |\n",
      "|    total_timesteps    | 2170880      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0068630567 |\n",
      "|    entropy_loss       | -1.98        |\n",
      "|    explained_variance | 0.891        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.135        |\n",
      "|    mean_step_reward   | 0.08574761   |\n",
      "|    n_updates          | 1056         |\n",
      "|    policyGradLoss     | -0.00469     |\n",
      "|    value_loss         | 0.754        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 814          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 261          |\n",
      "|    total_timesteps    | 2179072      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0056276335 |\n",
      "|    entropy_loss       | -2           |\n",
      "|    explained_variance | 0.895        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.323        |\n",
      "|    mean_step_reward   | 0.07532987   |\n",
      "|    n_updates          | 1060         |\n",
      "|    policyGradLoss     | -0.00395     |\n",
      "|    value_loss         | 0.903        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 2187264     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007522721 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.848       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.348       |\n",
      "|    mean_step_reward   | 0.084015846 |\n",
      "|    n_updates          | 1064        |\n",
      "|    policyGradLoss     | -0.00547    |\n",
      "|    value_loss         | 1.26        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 814          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 281          |\n",
      "|    total_timesteps    | 2195456      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0074649565 |\n",
      "|    entropy_loss       | -1.98        |\n",
      "|    explained_variance | 0.892        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.244        |\n",
      "|    mean_step_reward   | 0.08515273   |\n",
      "|    n_updates          | 1068         |\n",
      "|    policyGradLoss     | -0.00515     |\n",
      "|    value_loss         | 0.849        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 291         |\n",
      "|    total_timesteps    | 2203648     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006923438 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.896       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.395       |\n",
      "|    mean_step_reward   | 0.083482206 |\n",
      "|    n_updates          | 1072        |\n",
      "|    policyGradLoss     | -0.00411    |\n",
      "|    value_loss         | 1.25        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 814        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 301        |\n",
      "|    total_timesteps    | 2211840    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00672581 |\n",
      "|    entropy_loss       | -1.96      |\n",
      "|    explained_variance | 0.893      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.278      |\n",
      "|    mean_step_reward   | 0.09452717 |\n",
      "|    n_updates          | 1076       |\n",
      "|    policyGradLoss     | -0.00444   |\n",
      "|    value_loss         | 0.79       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 311         |\n",
      "|    total_timesteps    | 2220032     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.00795246  |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.856       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.414       |\n",
      "|    mean_step_reward   | 0.081685126 |\n",
      "|    n_updates          | 1080        |\n",
      "|    policyGradLoss     | -0.00502    |\n",
      "|    value_loss         | 1.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 321         |\n",
      "|    total_timesteps    | 2228224     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008857721 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.875       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.264       |\n",
      "|    mean_step_reward   | 0.08377367  |\n",
      "|    n_updates          | 1084        |\n",
      "|    policyGradLoss     | -0.00595    |\n",
      "|    value_loss         | 0.965       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 332         |\n",
      "|    total_timesteps    | 2236416     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009880586 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.886       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.328       |\n",
      "|    mean_step_reward   | 0.079190224 |\n",
      "|    n_updates          | 1088        |\n",
      "|    policyGradLoss     | -0.00502    |\n",
      "|    value_loss         | 1.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 342         |\n",
      "|    total_timesteps    | 2244608     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007827764 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.887       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.262       |\n",
      "|    mean_step_reward   | 0.08971329  |\n",
      "|    n_updates          | 1092        |\n",
      "|    policyGradLoss     | -0.00418    |\n",
      "|    value_loss         | 0.734       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 813          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 352          |\n",
      "|    total_timesteps    | 2252800      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0060861297 |\n",
      "|    entropy_loss       | -1.98        |\n",
      "|    explained_variance | 0.875        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.271        |\n",
      "|    mean_step_reward   | 0.08023856   |\n",
      "|    n_updates          | 1096         |\n",
      "|    policyGradLoss     | -0.00339     |\n",
      "|    value_loss         | 1.2          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 362         |\n",
      "|    total_timesteps    | 2260992     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006495651 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.874       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.269       |\n",
      "|    mean_step_reward   | 0.090410165 |\n",
      "|    n_updates          | 1100        |\n",
      "|    policyGradLoss     | -0.006      |\n",
      "|    value_loss         | 0.834       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 813          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 372          |\n",
      "|    total_timesteps    | 2269184      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0074890126 |\n",
      "|    entropy_loss       | -1.96        |\n",
      "|    explained_variance | 0.892        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.292        |\n",
      "|    mean_step_reward   | 0.08738957   |\n",
      "|    n_updates          | 1104         |\n",
      "|    policyGradLoss     | -0.00629     |\n",
      "|    value_loss         | 0.976        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 813          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 382          |\n",
      "|    total_timesteps    | 2277376      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0052564936 |\n",
      "|    entropy_loss       | -1.94        |\n",
      "|    explained_variance | 0.878        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.245        |\n",
      "|    mean_step_reward   | 0.08489628   |\n",
      "|    n_updates          | 1108         |\n",
      "|    policyGradLoss     | -0.0039      |\n",
      "|    value_loss         | 1.12         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 393         |\n",
      "|    total_timesteps    | 2285568     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008807243 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.886       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.252       |\n",
      "|    mean_step_reward   | 0.086356945 |\n",
      "|    n_updates          | 1112        |\n",
      "|    policyGradLoss     | -0.00624    |\n",
      "|    value_loss         | 1.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 403         |\n",
      "|    total_timesteps    | 2293760     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007304969 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.902       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.327       |\n",
      "|    mean_step_reward   | 0.08493382  |\n",
      "|    n_updates          | 1116        |\n",
      "|    policyGradLoss     | -0.00496    |\n",
      "|    value_loss         | 0.979       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_6.zip\n",
      "[EVAL] Mean Return: 5.644, Best Return: 5.644\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_6_5.64.mp4\n",
      "\n",
      "=== Round 8 | Learn 327680 steps (Total trained: 2293760) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1111    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 2301952 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 939         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 2310144     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009665249 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.903       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.145       |\n",
      "|    mean_step_reward   | 0.08902687  |\n",
      "|    n_updates          | 1124        |\n",
      "|    policyGradLoss     | -0.00555    |\n",
      "|    value_loss         | 0.824       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 902         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 2318336     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007362506 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.867       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.357       |\n",
      "|    mean_step_reward   | 0.08022237  |\n",
      "|    n_updates          | 1128        |\n",
      "|    policyGradLoss     | -0.0032     |\n",
      "|    value_loss         | 1.1         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 872          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 37           |\n",
      "|    total_timesteps    | 2326528      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0063109985 |\n",
      "|    entropy_loss       | -1.96        |\n",
      "|    explained_variance | 0.86         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.55         |\n",
      "|    mean_step_reward   | 0.08355287   |\n",
      "|    n_updates          | 1132         |\n",
      "|    policyGradLoss     | -0.00252     |\n",
      "|    value_loss         | 1.38         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 857          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 47           |\n",
      "|    total_timesteps    | 2334720      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0076307002 |\n",
      "|    entropy_loss       | -1.95        |\n",
      "|    explained_variance | 0.872        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.4          |\n",
      "|    mean_step_reward   | 0.08418654   |\n",
      "|    n_updates          | 1136         |\n",
      "|    policyGradLoss     | -0.00387     |\n",
      "|    value_loss         | 1.46         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 845         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 2342912     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008713396 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.9         |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.287       |\n",
      "|    mean_step_reward   | 0.0887052   |\n",
      "|    n_updates          | 1140        |\n",
      "|    policyGradLoss     | -0.00564    |\n",
      "|    value_loss         | 0.874       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 837          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 68           |\n",
      "|    total_timesteps    | 2351104      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0075251115 |\n",
      "|    entropy_loss       | -1.95        |\n",
      "|    explained_variance | 0.878        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.483        |\n",
      "|    mean_step_reward   | 0.08400239   |\n",
      "|    n_updates          | 1144         |\n",
      "|    policyGradLoss     | -0.00211     |\n",
      "|    value_loss         | 1.37         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 833         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 2359296     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009271681 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.876       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.138       |\n",
      "|    mean_step_reward   | 0.09239426  |\n",
      "|    n_updates          | 1148        |\n",
      "|    policyGradLoss     | -0.00546    |\n",
      "|    value_loss         | 0.843       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 829         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 88          |\n",
      "|    total_timesteps    | 2367488     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007873546 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.864       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.29        |\n",
      "|    mean_step_reward   | 0.08798174  |\n",
      "|    n_updates          | 1152        |\n",
      "|    policyGradLoss     | -0.00442    |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 828         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 2375680     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008356381 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.893       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.185       |\n",
      "|    mean_step_reward   | 0.08363913  |\n",
      "|    n_updates          | 1156        |\n",
      "|    policyGradLoss     | -0.0053     |\n",
      "|    value_loss         | 0.76        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 2383872     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.005295308 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.877       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.338       |\n",
      "|    mean_step_reward   | 0.081804186 |\n",
      "|    n_updates          | 1160        |\n",
      "|    policyGradLoss     | -0.00249    |\n",
      "|    value_loss         | 1.2         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 824          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 119          |\n",
      "|    total_timesteps    | 2392064      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0064265253 |\n",
      "|    entropy_loss       | -1.94        |\n",
      "|    explained_variance | 0.892        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.263        |\n",
      "|    mean_step_reward   | 0.085207276  |\n",
      "|    n_updates          | 1164         |\n",
      "|    policyGradLoss     | -0.00494     |\n",
      "|    value_loss         | 0.874        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 129         |\n",
      "|    total_timesteps    | 2400256     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007859898 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.908       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.189       |\n",
      "|    mean_step_reward   | 0.08638994  |\n",
      "|    n_updates          | 1168        |\n",
      "|    policyGradLoss     | -0.00255    |\n",
      "|    value_loss         | 0.749       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 139         |\n",
      "|    total_timesteps    | 2408448     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008494776 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.896       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.411       |\n",
      "|    mean_step_reward   | 0.07441751  |\n",
      "|    n_updates          | 1172        |\n",
      "|    policyGradLoss     | -0.00584    |\n",
      "|    value_loss         | 1.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 149         |\n",
      "|    total_timesteps    | 2416640     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008352507 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.203       |\n",
      "|    mean_step_reward   | 0.07584344  |\n",
      "|    n_updates          | 1176        |\n",
      "|    policyGradLoss     | -0.00547    |\n",
      "|    value_loss         | 0.665       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 2424832     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006072715 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.293       |\n",
      "|    mean_step_reward   | 0.083543    |\n",
      "|    n_updates          | 1180        |\n",
      "|    policyGradLoss     | -0.00507    |\n",
      "|    value_loss         | 0.968       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 2433024     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008359946 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.863       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.617       |\n",
      "|    mean_step_reward   | 0.079786815 |\n",
      "|    n_updates          | 1184        |\n",
      "|    policyGradLoss     | -0.00258    |\n",
      "|    value_loss         | 1.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 2441216     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009666565 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.855       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.368       |\n",
      "|    mean_step_reward   | 0.08118711  |\n",
      "|    n_updates          | 1188        |\n",
      "|    policyGradLoss     | -0.000676   |\n",
      "|    value_loss         | 1.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 2449408     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008227702 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.893       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.511       |\n",
      "|    mean_step_reward   | 0.08077225  |\n",
      "|    n_updates          | 1192        |\n",
      "|    policyGradLoss     | -0.00565    |\n",
      "|    value_loss         | 0.969       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 2457600     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008519892 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.863       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.371       |\n",
      "|    mean_step_reward   | 0.08398843  |\n",
      "|    n_updates          | 1196        |\n",
      "|    policyGradLoss     | -0.00637    |\n",
      "|    value_loss         | 0.97        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 814          |\n",
      "|    iterations         | 21           |\n",
      "|    time_elapsed       | 211          |\n",
      "|    total_timesteps    | 2465792      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0068979175 |\n",
      "|    entropy_loss       | -1.99        |\n",
      "|    explained_variance | 0.853        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.429        |\n",
      "|    mean_step_reward   | 0.085197695  |\n",
      "|    n_updates          | 1200         |\n",
      "|    policyGradLoss     | -0.00432     |\n",
      "|    value_loss         | 1.22         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 814          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 221          |\n",
      "|    total_timesteps    | 2473984      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0090642795 |\n",
      "|    entropy_loss       | -1.98        |\n",
      "|    explained_variance | 0.846        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.396        |\n",
      "|    mean_step_reward   | 0.079428665  |\n",
      "|    n_updates          | 1204         |\n",
      "|    policyGradLoss     | -0.00521     |\n",
      "|    value_loss         | 1.25         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 2482176     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009792442 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.842       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.225       |\n",
      "|    mean_step_reward   | 0.08789852  |\n",
      "|    n_updates          | 1208        |\n",
      "|    policyGradLoss     | -0.0036     |\n",
      "|    value_loss         | 0.863       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 2490368     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007183766 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.877       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.14        |\n",
      "|    mean_step_reward   | 0.0867025   |\n",
      "|    n_updates          | 1212        |\n",
      "|    policyGradLoss     | -0.00733    |\n",
      "|    value_loss         | 0.927       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 2498560     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.00911672  |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.858       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.252       |\n",
      "|    mean_step_reward   | 0.083229005 |\n",
      "|    n_updates          | 1216        |\n",
      "|    policyGradLoss     | -0.005      |\n",
      "|    value_loss         | 0.945       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 813          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 261          |\n",
      "|    total_timesteps    | 2506752      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0070094415 |\n",
      "|    entropy_loss       | -1.95        |\n",
      "|    explained_variance | 0.91         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.308        |\n",
      "|    mean_step_reward   | 0.08931743   |\n",
      "|    n_updates          | 1220         |\n",
      "|    policyGradLoss     | -0.00632     |\n",
      "|    value_loss         | 0.834        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 2514944     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008996786 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.858       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.321       |\n",
      "|    mean_step_reward   | 0.08980358  |\n",
      "|    n_updates          | 1224        |\n",
      "|    policyGradLoss     | -0.00496    |\n",
      "|    value_loss         | 1.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 2523136     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008258179 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.902       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.167       |\n",
      "|    mean_step_reward   | 0.08020294  |\n",
      "|    n_updates          | 1228        |\n",
      "|    policyGradLoss     | -0.00804    |\n",
      "|    value_loss         | 0.609       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 2531328     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007250512 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.872       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.44        |\n",
      "|    mean_step_reward   | 0.07970153  |\n",
      "|    n_updates          | 1232        |\n",
      "|    policyGradLoss     | -0.00356    |\n",
      "|    value_loss         | 1.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 302         |\n",
      "|    total_timesteps    | 2539520     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007247148 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.84        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.319       |\n",
      "|    mean_step_reward   | 0.08779218  |\n",
      "|    n_updates          | 1236        |\n",
      "|    policyGradLoss     | -0.00177    |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 810        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 313        |\n",
      "|    total_timesteps    | 2547712    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00788406 |\n",
      "|    entropy_loss       | -1.93      |\n",
      "|    explained_variance | 0.869      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.204      |\n",
      "|    mean_step_reward   | 0.09323618 |\n",
      "|    n_updates          | 1240       |\n",
      "|    policyGradLoss     | -0.00549   |\n",
      "|    value_loss         | 1          |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 811          |\n",
      "|    iterations         | 32           |\n",
      "|    time_elapsed       | 323          |\n",
      "|    total_timesteps    | 2555904      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0072840815 |\n",
      "|    entropy_loss       | -1.93        |\n",
      "|    explained_variance | 0.895        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.409        |\n",
      "|    mean_step_reward   | 0.08795713   |\n",
      "|    n_updates          | 1244         |\n",
      "|    policyGradLoss     | -0.00605     |\n",
      "|    value_loss         | 1.15         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 2564096     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009578839 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.883       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.112       |\n",
      "|    mean_step_reward   | 0.0953148   |\n",
      "|    n_updates          | 1248        |\n",
      "|    policyGradLoss     | -0.00733    |\n",
      "|    value_loss         | 0.682       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 343         |\n",
      "|    total_timesteps    | 2572288     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008754408 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.888       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.245       |\n",
      "|    mean_step_reward   | 0.09107717  |\n",
      "|    n_updates          | 1252        |\n",
      "|    policyGradLoss     | -0.00464    |\n",
      "|    value_loss         | 0.813       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 811          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 353          |\n",
      "|    total_timesteps    | 2580480      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0065091336 |\n",
      "|    entropy_loss       | -1.93        |\n",
      "|    explained_variance | 0.887        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.27         |\n",
      "|    mean_step_reward   | 0.08792681   |\n",
      "|    n_updates          | 1256         |\n",
      "|    policyGradLoss     | -0.00473     |\n",
      "|    value_loss         | 1.16         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 363         |\n",
      "|    total_timesteps    | 2588672     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007839914 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.893       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0705      |\n",
      "|    mean_step_reward   | 0.096259594 |\n",
      "|    n_updates          | 1260        |\n",
      "|    policyGradLoss     | -0.00686    |\n",
      "|    value_loss         | 0.561       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 809          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 374          |\n",
      "|    total_timesteps    | 2596864      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0068376833 |\n",
      "|    entropy_loss       | -1.97        |\n",
      "|    explained_variance | 0.874        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.324        |\n",
      "|    mean_step_reward   | 0.08258194   |\n",
      "|    n_updates          | 1264         |\n",
      "|    policyGradLoss     | -0.00447     |\n",
      "|    value_loss         | 1.17         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 809          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 384          |\n",
      "|    total_timesteps    | 2605056      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0073375483 |\n",
      "|    entropy_loss       | -1.93        |\n",
      "|    explained_variance | 0.879        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.38         |\n",
      "|    mean_step_reward   | 0.09844668   |\n",
      "|    n_updates          | 1268         |\n",
      "|    policyGradLoss     | -0.00335     |\n",
      "|    value_loss         | 1.3          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 394         |\n",
      "|    total_timesteps    | 2613248     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006658028 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.867       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.323       |\n",
      "|    mean_step_reward   | 0.08764413  |\n",
      "|    n_updates          | 1272        |\n",
      "|    policyGradLoss     | -0.00577    |\n",
      "|    value_loss         | 1.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 404         |\n",
      "|    total_timesteps    | 2621440     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007892744 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.89        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.231       |\n",
      "|    mean_step_reward   | 0.09115578  |\n",
      "|    n_updates          | 1276        |\n",
      "|    policyGradLoss     | -0.00622    |\n",
      "|    value_loss         | 0.799       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_7.zip\n",
      "[EVAL] Mean Return: 67.332, Best Return: 67.382\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_7_67.33.mp4\n",
      "\n",
      "=== Round 9 | Learn 327680 steps (Total trained: 2621440) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1111    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 2629632 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 931          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 2637824      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0063825687 |\n",
      "|    entropy_loss       | -1.95        |\n",
      "|    explained_variance | 0.832        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.623        |\n",
      "|    mean_step_reward   | 0.08553681   |\n",
      "|    n_updates          | 1284         |\n",
      "|    policyGradLoss     | -0.00227     |\n",
      "|    value_loss         | 1.6          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 877          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 2646016      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0074420357 |\n",
      "|    entropy_loss       | -1.93        |\n",
      "|    explained_variance | 0.896        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.297        |\n",
      "|    mean_step_reward   | 0.09197761   |\n",
      "|    n_updates          | 1288         |\n",
      "|    policyGradLoss     | -0.00642     |\n",
      "|    value_loss         | 0.787        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 859        |\n",
      "|    iterations         | 4          |\n",
      "|    time_elapsed       | 38         |\n",
      "|    total_timesteps    | 2654208    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.006678   |\n",
      "|    entropy_loss       | -1.92      |\n",
      "|    explained_variance | 0.888      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.214      |\n",
      "|    mean_step_reward   | 0.09061607 |\n",
      "|    n_updates          | 1292       |\n",
      "|    policyGradLoss     | -0.00779   |\n",
      "|    value_loss         | 0.922      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 845         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 48          |\n",
      "|    total_timesteps    | 2662400     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007977666 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.86        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.277       |\n",
      "|    mean_step_reward   | 0.092601284 |\n",
      "|    n_updates          | 1296        |\n",
      "|    policyGradLoss     | -0.00619    |\n",
      "|    value_loss         | 1.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 2670592     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008248523 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.879       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.197       |\n",
      "|    mean_step_reward   | 0.08688561  |\n",
      "|    n_updates          | 1300        |\n",
      "|    policyGradLoss     | -0.00785    |\n",
      "|    value_loss         | 0.881       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 832          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 68           |\n",
      "|    total_timesteps    | 2678784      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0075476537 |\n",
      "|    entropy_loss       | -1.93        |\n",
      "|    explained_variance | 0.888        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.367        |\n",
      "|    mean_step_reward   | 0.08495082   |\n",
      "|    n_updates          | 1304         |\n",
      "|    policyGradLoss     | -0.00712     |\n",
      "|    value_loss         | 1.13         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 79          |\n",
      "|    total_timesteps    | 2686976     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008718872 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.185       |\n",
      "|    mean_step_reward   | 0.09519629  |\n",
      "|    n_updates          | 1308        |\n",
      "|    policyGradLoss     | -0.00712    |\n",
      "|    value_loss         | 0.734       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 825          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 89           |\n",
      "|    total_timesteps    | 2695168      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0066704685 |\n",
      "|    entropy_loss       | -1.94        |\n",
      "|    explained_variance | 0.899        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.337        |\n",
      "|    mean_step_reward   | 0.08823184   |\n",
      "|    n_updates          | 1312         |\n",
      "|    policyGradLoss     | -0.00642     |\n",
      "|    value_loss         | 0.948        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 823         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 99          |\n",
      "|    total_timesteps    | 2703360     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008005103 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.896       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.442       |\n",
      "|    mean_step_reward   | 0.09220298  |\n",
      "|    n_updates          | 1316        |\n",
      "|    policyGradLoss     | -0.00738    |\n",
      "|    value_loss         | 1.11        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 2711552     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007994427 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.909       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.231       |\n",
      "|    mean_step_reward   | 0.09616346  |\n",
      "|    n_updates          | 1320        |\n",
      "|    policyGradLoss     | -0.00782    |\n",
      "|    value_loss         | 0.783       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 2719744     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008249892 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.908       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.26        |\n",
      "|    mean_step_reward   | 0.094450966 |\n",
      "|    n_updates          | 1324        |\n",
      "|    policyGradLoss     | -0.00474    |\n",
      "|    value_loss         | 0.705       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 129         |\n",
      "|    total_timesteps    | 2727936     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006418288 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.242       |\n",
      "|    mean_step_reward   | 0.09289064  |\n",
      "|    n_updates          | 1328        |\n",
      "|    policyGradLoss     | -0.00615    |\n",
      "|    value_loss         | 0.956       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 140         |\n",
      "|    total_timesteps    | 2736128     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007305934 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.902       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.168       |\n",
      "|    mean_step_reward   | 0.093721144 |\n",
      "|    n_updates          | 1332        |\n",
      "|    policyGradLoss     | -0.00726    |\n",
      "|    value_loss         | 0.708       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 150         |\n",
      "|    total_timesteps    | 2744320     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006870331 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.903       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.256       |\n",
      "|    mean_step_reward   | 0.089893945 |\n",
      "|    n_updates          | 1336        |\n",
      "|    policyGradLoss     | -0.00524    |\n",
      "|    value_loss         | 0.949       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 2752512     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006753713 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.876       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.209       |\n",
      "|    mean_step_reward   | 0.09946783  |\n",
      "|    n_updates          | 1340        |\n",
      "|    policyGradLoss     | -0.0062     |\n",
      "|    value_loss         | 0.838       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 2760704     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006590157 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.861       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.589       |\n",
      "|    mean_step_reward   | 0.08659901  |\n",
      "|    n_updates          | 1344        |\n",
      "|    policyGradLoss     | -0.00338    |\n",
      "|    value_loss         | 1.76        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 2768896     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007040223 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.863       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.318       |\n",
      "|    mean_step_reward   | 0.0922086   |\n",
      "|    n_updates          | 1348        |\n",
      "|    policyGradLoss     | -0.00607    |\n",
      "|    value_loss         | 1.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 2777088     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007604447 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.896       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.172       |\n",
      "|    mean_step_reward   | 0.08783715  |\n",
      "|    n_updates          | 1352        |\n",
      "|    policyGradLoss     | -0.00652    |\n",
      "|    value_loss         | 0.944       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 814          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 201          |\n",
      "|    total_timesteps    | 2785280      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0077713095 |\n",
      "|    entropy_loss       | -1.95        |\n",
      "|    explained_variance | 0.91         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.178        |\n",
      "|    mean_step_reward   | 0.08739391   |\n",
      "|    n_updates          | 1356         |\n",
      "|    policyGradLoss     | -0.00681     |\n",
      "|    value_loss         | 0.784        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 2793472     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007090495 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.885       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.402       |\n",
      "|    mean_step_reward   | 0.090062514 |\n",
      "|    n_updates          | 1360        |\n",
      "|    policyGradLoss     | -0.00642    |\n",
      "|    value_loss         | 1.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 2801664     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008190743 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.898       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.281       |\n",
      "|    mean_step_reward   | 0.09787309  |\n",
      "|    n_updates          | 1364        |\n",
      "|    policyGradLoss     | -0.00549    |\n",
      "|    value_loss         | 0.827       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 813          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 231          |\n",
      "|    total_timesteps    | 2809856      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0074468507 |\n",
      "|    entropy_loss       | -1.97        |\n",
      "|    explained_variance | 0.882        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.209        |\n",
      "|    mean_step_reward   | 0.086870536  |\n",
      "|    n_updates          | 1368         |\n",
      "|    policyGradLoss     | -0.00612     |\n",
      "|    value_loss         | 1.08         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 2818048     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006639853 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.835       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.69        |\n",
      "|    mean_step_reward   | 0.09031685  |\n",
      "|    n_updates          | 1372        |\n",
      "|    policyGradLoss     | -0.00355    |\n",
      "|    value_loss         | 1.8         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 2826240     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007248661 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.874       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.195       |\n",
      "|    mean_step_reward   | 0.09733652  |\n",
      "|    n_updates          | 1376        |\n",
      "|    policyGradLoss     | -0.00722    |\n",
      "|    value_loss         | 0.919       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 2834432     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008695162 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.871       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.46        |\n",
      "|    mean_step_reward   | 0.093232736 |\n",
      "|    n_updates          | 1380        |\n",
      "|    policyGradLoss     | -0.00376    |\n",
      "|    value_loss         | 1.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 2842624     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006965348 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.873       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.439       |\n",
      "|    mean_step_reward   | 0.09359293  |\n",
      "|    n_updates          | 1384        |\n",
      "|    policyGradLoss     | -0.0049     |\n",
      "|    value_loss         | 1.22        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 811          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 282          |\n",
      "|    total_timesteps    | 2850816      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0079042595 |\n",
      "|    entropy_loss       | -1.98        |\n",
      "|    explained_variance | 0.908        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.365        |\n",
      "|    mean_step_reward   | 0.09552981   |\n",
      "|    n_updates          | 1388         |\n",
      "|    policyGradLoss     | -0.00649     |\n",
      "|    value_loss         | 0.869        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 2859008     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007535071 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.313       |\n",
      "|    mean_step_reward   | 0.09150804  |\n",
      "|    n_updates          | 1392        |\n",
      "|    policyGradLoss     | -0.00611    |\n",
      "|    value_loss         | 1.04        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 810          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 303          |\n",
      "|    total_timesteps    | 2867200      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0064564757 |\n",
      "|    entropy_loss       | -1.98        |\n",
      "|    explained_variance | 0.884        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.309        |\n",
      "|    mean_step_reward   | 0.086288765  |\n",
      "|    n_updates          | 1396         |\n",
      "|    policyGradLoss     | -0.00393     |\n",
      "|    value_loss         | 1.11         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 313         |\n",
      "|    total_timesteps    | 2875392     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008067849 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.878       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.452       |\n",
      "|    mean_step_reward   | 0.08797072  |\n",
      "|    n_updates          | 1400        |\n",
      "|    policyGradLoss     | -0.00414    |\n",
      "|    value_loss         | 1.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 323         |\n",
      "|    total_timesteps    | 2883584     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007746814 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.881       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.379       |\n",
      "|    mean_step_reward   | 0.0930099   |\n",
      "|    n_updates          | 1404        |\n",
      "|    policyGradLoss     | -0.0077     |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 334         |\n",
      "|    total_timesteps    | 2891776     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008800494 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.892       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.23        |\n",
      "|    mean_step_reward   | 0.09416816  |\n",
      "|    n_updates          | 1408        |\n",
      "|    policyGradLoss     | -0.00739    |\n",
      "|    value_loss         | 0.862       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 344         |\n",
      "|    total_timesteps    | 2899968     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009338461 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.879       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.255       |\n",
      "|    mean_step_reward   | 0.08533606  |\n",
      "|    n_updates          | 1412        |\n",
      "|    policyGradLoss     | -0.00598    |\n",
      "|    value_loss         | 0.967       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 354         |\n",
      "|    total_timesteps    | 2908160     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008017477 |\n",
      "|    entropy_loss       | -2.03       |\n",
      "|    explained_variance | 0.848       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.636       |\n",
      "|    mean_step_reward   | 0.08462933  |\n",
      "|    n_updates          | 1416        |\n",
      "|    policyGradLoss     | -0.00406    |\n",
      "|    value_loss         | 1.64        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 808          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 364          |\n",
      "|    total_timesteps    | 2916352      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0076527577 |\n",
      "|    entropy_loss       | -2           |\n",
      "|    explained_variance | 0.867        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.324        |\n",
      "|    mean_step_reward   | 0.085180715  |\n",
      "|    n_updates          | 1420         |\n",
      "|    policyGradLoss     | -0.00353     |\n",
      "|    value_loss         | 1.41         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 809          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 374          |\n",
      "|    total_timesteps    | 2924544      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0092367465 |\n",
      "|    entropy_loss       | -2           |\n",
      "|    explained_variance | 0.883        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.177        |\n",
      "|    mean_step_reward   | 0.09206994   |\n",
      "|    n_updates          | 1424         |\n",
      "|    policyGradLoss     | -0.00529     |\n",
      "|    value_loss         | 0.785        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 384         |\n",
      "|    total_timesteps    | 2932736     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007957289 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.872       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.281       |\n",
      "|    mean_step_reward   | 0.091044195 |\n",
      "|    n_updates          | 1428        |\n",
      "|    policyGradLoss     | -0.00569    |\n",
      "|    value_loss         | 0.967       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 395         |\n",
      "|    total_timesteps    | 2940928     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009253391 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.881       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.153       |\n",
      "|    mean_step_reward   | 0.09074918  |\n",
      "|    n_updates          | 1432        |\n",
      "|    policyGradLoss     | -0.00576    |\n",
      "|    value_loss         | 0.689       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 405         |\n",
      "|    total_timesteps    | 2949120     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008357199 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.322       |\n",
      "|    mean_step_reward   | 0.09274406  |\n",
      "|    n_updates          | 1436        |\n",
      "|    policyGradLoss     | -0.00637    |\n",
      "|    value_loss         | 0.864       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_8.zip\n",
      "[EVAL] Mean Return: 18.170, Best Return: 18.220\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_8_18.17.mp4\n",
      "\n",
      "=== Round 10 | Learn 327680 steps (Total trained: 2949120) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1077    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 2957312 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 930         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 2965504     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008207271 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.862       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.387       |\n",
      "|    mean_step_reward   | 0.086823076 |\n",
      "|    n_updates          | 1444        |\n",
      "|    policyGradLoss     | -0.0059     |\n",
      "|    value_loss         | 1.11        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 892         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 2973696     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010985564 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.874       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.293       |\n",
      "|    mean_step_reward   | 0.09385525  |\n",
      "|    n_updates          | 1448        |\n",
      "|    policyGradLoss     | -0.00524    |\n",
      "|    value_loss         | 0.869       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 872         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 37          |\n",
      "|    total_timesteps    | 2981888     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008315541 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.883       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.153       |\n",
      "|    mean_step_reward   | 0.09177175  |\n",
      "|    n_updates          | 1452        |\n",
      "|    policyGradLoss     | -0.00588    |\n",
      "|    value_loss         | 0.832       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 858         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 47          |\n",
      "|    total_timesteps    | 2990080     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009135992 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.829       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.475       |\n",
      "|    mean_step_reward   | 0.0898422   |\n",
      "|    n_updates          | 1456        |\n",
      "|    policyGradLoss     | -0.00432    |\n",
      "|    value_loss         | 1.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 850         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 57          |\n",
      "|    total_timesteps    | 2998272     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008302392 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.87        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.19        |\n",
      "|    mean_step_reward   | 0.091684476 |\n",
      "|    n_updates          | 1460        |\n",
      "|    policyGradLoss     | -0.0066     |\n",
      "|    value_loss         | 0.832       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 844          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 67           |\n",
      "|    total_timesteps    | 3006464      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0077669206 |\n",
      "|    entropy_loss       | -1.97        |\n",
      "|    explained_variance | 0.862        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.217        |\n",
      "|    mean_step_reward   | 0.08919871   |\n",
      "|    n_updates          | 1464         |\n",
      "|    policyGradLoss     | -0.00327     |\n",
      "|    value_loss         | 0.888        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 3014656     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008175583 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.894       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.157       |\n",
      "|    mean_step_reward   | 0.09330389  |\n",
      "|    n_updates          | 1468        |\n",
      "|    policyGradLoss     | -0.0067     |\n",
      "|    value_loss         | 0.67        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 832        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 88         |\n",
      "|    total_timesteps    | 3022848    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00803145 |\n",
      "|    entropy_loss       | -1.96      |\n",
      "|    explained_variance | 0.929      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0597     |\n",
      "|    mean_step_reward   | 0.10198371 |\n",
      "|    n_updates          | 1472       |\n",
      "|    policyGradLoss     | -0.00784   |\n",
      "|    value_loss         | 0.507      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 829         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 3031040     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010718884 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.888       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.112       |\n",
      "|    mean_step_reward   | 0.09170783  |\n",
      "|    n_updates          | 1476        |\n",
      "|    policyGradLoss     | -0.00643    |\n",
      "|    value_loss         | 0.84        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 830         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 108         |\n",
      "|    total_timesteps    | 3039232     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009692942 |\n",
      "|    entropy_loss       | -2.02       |\n",
      "|    explained_variance | 0.863       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.196       |\n",
      "|    mean_step_reward   | 0.08969937  |\n",
      "|    n_updates          | 1480        |\n",
      "|    policyGradLoss     | -0.00447    |\n",
      "|    value_loss         | 0.988       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 829          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 118          |\n",
      "|    total_timesteps    | 3047424      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0095788855 |\n",
      "|    entropy_loss       | -1.96        |\n",
      "|    explained_variance | 0.899        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0514       |\n",
      "|    mean_step_reward   | 0.101637945  |\n",
      "|    n_updates          | 1484         |\n",
      "|    policyGradLoss     | -0.00677     |\n",
      "|    value_loss         | 0.592        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 128         |\n",
      "|    total_timesteps    | 3055616     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009180682 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.903       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.345       |\n",
      "|    mean_step_reward   | 0.086832635 |\n",
      "|    n_updates          | 1488        |\n",
      "|    policyGradLoss     | -0.00581    |\n",
      "|    value_loss         | 0.935       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 3063808     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010259917 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0829      |\n",
      "|    mean_step_reward   | 0.09224737  |\n",
      "|    n_updates          | 1492        |\n",
      "|    policyGradLoss     | -0.00705    |\n",
      "|    value_loss         | 0.579       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 149         |\n",
      "|    total_timesteps    | 3072000     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016138215 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.142       |\n",
      "|    mean_step_reward   | 0.09650333  |\n",
      "|    n_updates          | 1496        |\n",
      "|    policyGradLoss     | -0.00552    |\n",
      "|    value_loss         | 0.53        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 821        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 159        |\n",
      "|    total_timesteps    | 3080192    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00777685 |\n",
      "|    entropy_loss       | -1.97      |\n",
      "|    explained_variance | 0.89       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.153      |\n",
      "|    mean_step_reward   | 0.0869153  |\n",
      "|    n_updates          | 1500       |\n",
      "|    policyGradLoss     | -0.00767   |\n",
      "|    value_loss         | 0.704      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 3088384     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009207528 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.874       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.27        |\n",
      "|    mean_step_reward   | 0.08645955  |\n",
      "|    n_updates          | 1504        |\n",
      "|    policyGradLoss     | -0.00418    |\n",
      "|    value_loss         | 1.04        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 3096576     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013010459 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.902       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.157       |\n",
      "|    mean_step_reward   | 0.0917311   |\n",
      "|    n_updates          | 1508        |\n",
      "|    policyGradLoss     | -0.00474    |\n",
      "|    value_loss         | 0.779       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 3104768     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010231366 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.146       |\n",
      "|    mean_step_reward   | 0.096082434 |\n",
      "|    n_updates          | 1512        |\n",
      "|    policyGradLoss     | -0.00619    |\n",
      "|    value_loss         | 0.715       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 817          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 200          |\n",
      "|    total_timesteps    | 3112960      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0078601595 |\n",
      "|    entropy_loss       | -1.96        |\n",
      "|    explained_variance | 0.916        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.141        |\n",
      "|    mean_step_reward   | 0.08688852   |\n",
      "|    n_updates          | 1516         |\n",
      "|    policyGradLoss     | -0.00592     |\n",
      "|    value_loss         | 0.794        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 3121152     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008822106 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.156       |\n",
      "|    mean_step_reward   | 0.091673866 |\n",
      "|    n_updates          | 1520        |\n",
      "|    policyGradLoss     | -0.0073     |\n",
      "|    value_loss         | 0.713       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 3129344     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008373199 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.213       |\n",
      "|    mean_step_reward   | 0.0930709   |\n",
      "|    n_updates          | 1524        |\n",
      "|    policyGradLoss     | -0.00573    |\n",
      "|    value_loss         | 0.873       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 3137536     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009630103 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.862       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.211       |\n",
      "|    mean_step_reward   | 0.086080894 |\n",
      "|    n_updates          | 1528        |\n",
      "|    policyGradLoss     | -0.00802    |\n",
      "|    value_loss         | 0.824       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 3145728     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010186667 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.877       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.208       |\n",
      "|    mean_step_reward   | 0.09449063  |\n",
      "|    n_updates          | 1532        |\n",
      "|    policyGradLoss     | -0.00352    |\n",
      "|    value_loss         | 1.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 250         |\n",
      "|    total_timesteps    | 3153920     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009553199 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.877       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.381       |\n",
      "|    mean_step_reward   | 0.10023956  |\n",
      "|    n_updates          | 1536        |\n",
      "|    policyGradLoss     | -0.00248    |\n",
      "|    value_loss         | 1.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 260         |\n",
      "|    total_timesteps    | 3162112     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009464147 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.151       |\n",
      "|    mean_step_reward   | 0.094659194 |\n",
      "|    n_updates          | 1540        |\n",
      "|    policyGradLoss     | -0.00815    |\n",
      "|    value_loss         | 0.573       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 817        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 270        |\n",
      "|    total_timesteps    | 3170304    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01289605 |\n",
      "|    entropy_loss       | -1.99      |\n",
      "|    explained_variance | 0.896      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.133      |\n",
      "|    mean_step_reward   | 0.08666235 |\n",
      "|    n_updates          | 1544       |\n",
      "|    policyGradLoss     | -0.00287   |\n",
      "|    value_loss         | 0.738      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 281         |\n",
      "|    total_timesteps    | 3178496     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008421964 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.85        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.676       |\n",
      "|    mean_step_reward   | 0.09795297  |\n",
      "|    n_updates          | 1548        |\n",
      "|    policyGradLoss     | -0.00403    |\n",
      "|    value_loss         | 1.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 291         |\n",
      "|    total_timesteps    | 3186688     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007503027 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.903       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.31        |\n",
      "|    mean_step_reward   | 0.09006662  |\n",
      "|    n_updates          | 1552        |\n",
      "|    policyGradLoss     | -0.00289    |\n",
      "|    value_loss         | 0.899       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 815        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 301        |\n",
      "|    total_timesteps    | 3194880    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00998031 |\n",
      "|    entropy_loss       | -1.94      |\n",
      "|    explained_variance | 0.923      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.185      |\n",
      "|    mean_step_reward   | 0.09877314 |\n",
      "|    n_updates          | 1556       |\n",
      "|    policyGradLoss     | -0.00958   |\n",
      "|    value_loss         | 0.69       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 311         |\n",
      "|    total_timesteps    | 3203072     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007928805 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.134       |\n",
      "|    mean_step_reward   | 0.09615882  |\n",
      "|    n_updates          | 1560        |\n",
      "|    policyGradLoss     | -0.0067     |\n",
      "|    value_loss         | 0.769       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 321         |\n",
      "|    total_timesteps    | 3211264     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007044054 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.223       |\n",
      "|    mean_step_reward   | 0.09370081  |\n",
      "|    n_updates          | 1564        |\n",
      "|    policyGradLoss     | -0.00772    |\n",
      "|    value_loss         | 0.811       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 332         |\n",
      "|    total_timesteps    | 3219456     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010439525 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.22        |\n",
      "|    mean_step_reward   | 0.09423086  |\n",
      "|    n_updates          | 1568        |\n",
      "|    policyGradLoss     | -0.00502    |\n",
      "|    value_loss         | 0.831       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 342         |\n",
      "|    total_timesteps    | 3227648     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007526828 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.906       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.275       |\n",
      "|    mean_step_reward   | 0.08832241  |\n",
      "|    n_updates          | 1572        |\n",
      "|    policyGradLoss     | -0.00624    |\n",
      "|    value_loss         | 0.92        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 352         |\n",
      "|    total_timesteps    | 3235840     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01290116  |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.156       |\n",
      "|    mean_step_reward   | 0.095104545 |\n",
      "|    n_updates          | 1576        |\n",
      "|    policyGradLoss     | -0.00661    |\n",
      "|    value_loss         | 0.654       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 362         |\n",
      "|    total_timesteps    | 3244032     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008801179 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.904       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.477       |\n",
      "|    mean_step_reward   | 0.091522664 |\n",
      "|    n_updates          | 1580        |\n",
      "|    policyGradLoss     | -0.00504    |\n",
      "|    value_loss         | 1.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 372         |\n",
      "|    total_timesteps    | 3252224     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01309749  |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.883       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0708      |\n",
      "|    mean_step_reward   | 0.096842915 |\n",
      "|    n_updates          | 1584        |\n",
      "|    policyGradLoss     | -0.00414    |\n",
      "|    value_loss         | 0.461       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 382         |\n",
      "|    total_timesteps    | 3260416     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009020369 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.243       |\n",
      "|    mean_step_reward   | 0.08748061  |\n",
      "|    n_updates          | 1588        |\n",
      "|    policyGradLoss     | -0.00636    |\n",
      "|    value_loss         | 0.584       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 392         |\n",
      "|    total_timesteps    | 3268608     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010639149 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.889       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.466       |\n",
      "|    mean_step_reward   | 0.09414565  |\n",
      "|    n_updates          | 1592        |\n",
      "|    policyGradLoss     | -0.00643    |\n",
      "|    value_loss         | 0.712       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 402         |\n",
      "|    total_timesteps    | 3276800     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011157883 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.13        |\n",
      "|    mean_step_reward   | 0.09097594  |\n",
      "|    n_updates          | 1596        |\n",
      "|    policyGradLoss     | -0.0073     |\n",
      "|    value_loss         | 0.747       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_9.zip\n",
      "[EVAL] Mean Return: 57.136, Best Return: 57.236\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_9_57.14.mp4\n",
      "\n",
      "=== Round 11 | Learn 327680 steps (Total trained: 3276800) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1124    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 3284992 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 918         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 3293184     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009624194 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.155       |\n",
      "|    mean_step_reward   | 0.0943924   |\n",
      "|    n_updates          | 1604        |\n",
      "|    policyGradLoss     | -0.00597    |\n",
      "|    value_loss         | 0.703       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 874         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 3301376     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010142213 |\n",
      "|    entropy_loss       | -2.01       |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.134       |\n",
      "|    mean_step_reward   | 0.08310434  |\n",
      "|    n_updates          | 1608        |\n",
      "|    policyGradLoss     | -0.00958    |\n",
      "|    value_loss         | 0.758       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 852         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 3309568     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013375453 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.113       |\n",
      "|    mean_step_reward   | 0.09278022  |\n",
      "|    n_updates          | 1612        |\n",
      "|    policyGradLoss     | -0.00677    |\n",
      "|    value_loss         | 0.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 843         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 48          |\n",
      "|    total_timesteps    | 3317760     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010519674 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.892       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.337       |\n",
      "|    mean_step_reward   | 0.09199512  |\n",
      "|    n_updates          | 1616        |\n",
      "|    policyGradLoss     | -0.00738    |\n",
      "|    value_loss         | 0.792       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 834         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 3325952     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008929466 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.886       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.161       |\n",
      "|    mean_step_reward   | 0.09809075  |\n",
      "|    n_updates          | 1620        |\n",
      "|    policyGradLoss     | -0.00318    |\n",
      "|    value_loss         | 0.687       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 828          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 69           |\n",
      "|    total_timesteps    | 3334144      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0114464965 |\n",
      "|    entropy_loss       | -1.95        |\n",
      "|    explained_variance | 0.941        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0816       |\n",
      "|    mean_step_reward   | 0.08994201   |\n",
      "|    n_updates          | 1624         |\n",
      "|    policyGradLoss     | -0.00826     |\n",
      "|    value_loss         | 0.479        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 79          |\n",
      "|    total_timesteps    | 3342336     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009806989 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.867       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.17        |\n",
      "|    mean_step_reward   | 0.0919583   |\n",
      "|    n_updates          | 1628        |\n",
      "|    policyGradLoss     | -0.003      |\n",
      "|    value_loss         | 0.823       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 89          |\n",
      "|    total_timesteps    | 3350528     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011381929 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.91        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.269       |\n",
      "|    mean_step_reward   | 0.10177623  |\n",
      "|    n_updates          | 1632        |\n",
      "|    policyGradLoss     | -0.0031     |\n",
      "|    value_loss         | 0.837       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 99          |\n",
      "|    total_timesteps    | 3358720     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008393507 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.877       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.257       |\n",
      "|    mean_step_reward   | 0.098401666 |\n",
      "|    n_updates          | 1636        |\n",
      "|    policyGradLoss     | -0.00403    |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 3366912     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008687452 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.891       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.039       |\n",
      "|    mean_step_reward   | 0.09757507  |\n",
      "|    n_updates          | 1640        |\n",
      "|    policyGradLoss     | -0.00858    |\n",
      "|    value_loss         | 0.526       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 3375104     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01055184  |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.885       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.157       |\n",
      "|    mean_step_reward   | 0.092221074 |\n",
      "|    n_updates          | 1644        |\n",
      "|    policyGradLoss     | -0.00757    |\n",
      "|    value_loss         | 0.848       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 130         |\n",
      "|    total_timesteps    | 3383296     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009698737 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0843      |\n",
      "|    mean_step_reward   | 0.097553864 |\n",
      "|    n_updates          | 1648        |\n",
      "|    policyGradLoss     | -0.00796    |\n",
      "|    value_loss         | 0.491       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 140         |\n",
      "|    total_timesteps    | 3391488     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009519329 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0741      |\n",
      "|    mean_step_reward   | 0.092076525 |\n",
      "|    n_updates          | 1652        |\n",
      "|    policyGradLoss     | -0.00339    |\n",
      "|    value_loss         | 0.664       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 151         |\n",
      "|    total_timesteps    | 3399680     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010526262 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.902       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.126       |\n",
      "|    mean_step_reward   | 0.097985856 |\n",
      "|    n_updates          | 1656        |\n",
      "|    policyGradLoss     | -0.00683    |\n",
      "|    value_loss         | 0.666       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 161         |\n",
      "|    total_timesteps    | 3407872     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010515641 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.054       |\n",
      "|    mean_step_reward   | 0.099016845 |\n",
      "|    n_updates          | 1660        |\n",
      "|    policyGradLoss     | -0.00876    |\n",
      "|    value_loss         | 0.483       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 171         |\n",
      "|    total_timesteps    | 3416064     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008971749 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.887       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.341       |\n",
      "|    mean_step_reward   | 0.085044086 |\n",
      "|    n_updates          | 1664        |\n",
      "|    policyGradLoss     | -0.00268    |\n",
      "|    value_loss         | 1.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 3424256     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009640688 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.894       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.25        |\n",
      "|    mean_step_reward   | 0.101961836 |\n",
      "|    n_updates          | 1668        |\n",
      "|    policyGradLoss     | -0.0028     |\n",
      "|    value_loss         | 1.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 3432448     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010375919 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0512      |\n",
      "|    mean_step_reward   | 0.094750375 |\n",
      "|    n_updates          | 1672        |\n",
      "|    policyGradLoss     | -0.00823    |\n",
      "|    value_loss         | 0.45        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 3440640     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011610065 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0801      |\n",
      "|    mean_step_reward   | 0.09696627  |\n",
      "|    n_updates          | 1676        |\n",
      "|    policyGradLoss     | -0.00799    |\n",
      "|    value_loss         | 0.629       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 3448832     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009295866 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.867       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.375       |\n",
      "|    mean_step_reward   | 0.092752784 |\n",
      "|    n_updates          | 1680        |\n",
      "|    policyGradLoss     | -0.00759    |\n",
      "|    value_loss         | 1.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 3457024     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006817612 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.896       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 1.01        |\n",
      "|    mean_step_reward   | 0.10205491  |\n",
      "|    n_updates          | 1684        |\n",
      "|    policyGradLoss     | -0.0037     |\n",
      "|    value_loss         | 1.11        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 3465216     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008973105 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.888       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.175       |\n",
      "|    mean_step_reward   | 0.10046504  |\n",
      "|    n_updates          | 1688        |\n",
      "|    policyGradLoss     | -0.00764    |\n",
      "|    value_loss         | 0.806       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 3473408     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011987196 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.165       |\n",
      "|    mean_step_reward   | 0.098604225 |\n",
      "|    n_updates          | 1692        |\n",
      "|    policyGradLoss     | -0.00654    |\n",
      "|    value_loss         | 0.666       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 809        |\n",
      "|    iterations         | 25         |\n",
      "|    time_elapsed       | 252        |\n",
      "|    total_timesteps    | 3481600    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01058358 |\n",
      "|    entropy_loss       | -1.93      |\n",
      "|    explained_variance | 0.92       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.201      |\n",
      "|    mean_step_reward   | 0.09551126 |\n",
      "|    n_updates          | 1696       |\n",
      "|    policyGradLoss     | -0.00864   |\n",
      "|    value_loss         | 0.629      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 3489792     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009555897 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.854       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.219       |\n",
      "|    mean_step_reward   | 0.099877715 |\n",
      "|    n_updates          | 1700        |\n",
      "|    policyGradLoss     | -0.00447    |\n",
      "|    value_loss         | 0.767       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 808          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 273          |\n",
      "|    total_timesteps    | 3497984      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0086289365 |\n",
      "|    entropy_loss       | -1.95        |\n",
      "|    explained_variance | 0.953        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0112       |\n",
      "|    mean_step_reward   | 0.09913728   |\n",
      "|    n_updates          | 1704         |\n",
      "|    policyGradLoss     | -0.00927     |\n",
      "|    value_loss         | 0.364        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 3506176     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009187819 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.132       |\n",
      "|    mean_step_reward   | 0.09608579  |\n",
      "|    n_updates          | 1708        |\n",
      "|    policyGradLoss     | -0.00834    |\n",
      "|    value_loss         | 0.501       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 3514368     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010140417 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.881       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.245       |\n",
      "|    mean_step_reward   | 0.0995524   |\n",
      "|    n_updates          | 1712        |\n",
      "|    policyGradLoss     | -0.00318    |\n",
      "|    value_loss         | 0.761       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 3522560     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008545329 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.894       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.256       |\n",
      "|    mean_step_reward   | 0.0983952   |\n",
      "|    n_updates          | 1716        |\n",
      "|    policyGradLoss     | -0.00673    |\n",
      "|    value_loss         | 0.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 314         |\n",
      "|    total_timesteps    | 3530752     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010442416 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.906       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.108       |\n",
      "|    mean_step_reward   | 0.09360486  |\n",
      "|    n_updates          | 1720        |\n",
      "|    policyGradLoss     | -0.00895    |\n",
      "|    value_loss         | 0.498       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 324         |\n",
      "|    total_timesteps    | 3538944     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008451375 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.878       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.267       |\n",
      "|    mean_step_reward   | 0.09659459  |\n",
      "|    n_updates          | 1724        |\n",
      "|    policyGradLoss     | -0.00316    |\n",
      "|    value_loss         | 1.18        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 334         |\n",
      "|    total_timesteps    | 3547136     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009954252 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0724      |\n",
      "|    mean_step_reward   | 0.10206849  |\n",
      "|    n_updates          | 1728        |\n",
      "|    policyGradLoss     | -0.00692    |\n",
      "|    value_loss         | 0.668       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 345         |\n",
      "|    total_timesteps    | 3555328     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012034055 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.273       |\n",
      "|    mean_step_reward   | 0.10610414  |\n",
      "|    n_updates          | 1732        |\n",
      "|    policyGradLoss     | -0.00763    |\n",
      "|    value_loss         | 0.539       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 355         |\n",
      "|    total_timesteps    | 3563520     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008891759 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.328       |\n",
      "|    mean_step_reward   | 0.09565064  |\n",
      "|    n_updates          | 1736        |\n",
      "|    policyGradLoss     | -0.00707    |\n",
      "|    value_loss         | 0.99        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 365         |\n",
      "|    total_timesteps    | 3571712     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013525596 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.024       |\n",
      "|    mean_step_reward   | 0.103787646 |\n",
      "|    n_updates          | 1740        |\n",
      "|    policyGradLoss     | -0.00884    |\n",
      "|    value_loss         | 0.271       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 376         |\n",
      "|    total_timesteps    | 3579904     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008045993 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.849       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.224       |\n",
      "|    mean_step_reward   | 0.10203019  |\n",
      "|    n_updates          | 1744        |\n",
      "|    policyGradLoss     | -0.0039     |\n",
      "|    value_loss         | 1.09        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 386         |\n",
      "|    total_timesteps    | 3588096     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012801119 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0769      |\n",
      "|    mean_step_reward   | 0.10392648  |\n",
      "|    n_updates          | 1748        |\n",
      "|    policyGradLoss     | -0.00832    |\n",
      "|    value_loss         | 0.524       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 396         |\n",
      "|    total_timesteps    | 3596288     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010720028 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0684      |\n",
      "|    mean_step_reward   | 0.10463807  |\n",
      "|    n_updates          | 1752        |\n",
      "|    policyGradLoss     | -0.006      |\n",
      "|    value_loss         | 0.783       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 407         |\n",
      "|    total_timesteps    | 3604480     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009668333 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.903       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.177       |\n",
      "|    mean_step_reward   | 0.10605953  |\n",
      "|    n_updates          | 1756        |\n",
      "|    policyGradLoss     | -0.00417    |\n",
      "|    value_loss         | 0.616       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_10.zip\n",
      "[EVAL] Mean Return: 280.729, Best Return: 280.829\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_10_280.73.mp4\n",
      "\n",
      "=== Round 12 | Learn 327680 steps (Total trained: 3604480) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1117    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 3612672 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 959         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 3620864     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009023877 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.894       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.252       |\n",
      "|    mean_step_reward   | 0.09732935  |\n",
      "|    n_updates          | 1764        |\n",
      "|    policyGradLoss     | -0.00358    |\n",
      "|    value_loss         | 0.99        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 892         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 3629056     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010370698 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.177       |\n",
      "|    mean_step_reward   | 0.09921405  |\n",
      "|    n_updates          | 1768        |\n",
      "|    policyGradLoss     | -0.00722    |\n",
      "|    value_loss         | 0.538       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 867         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 37          |\n",
      "|    total_timesteps    | 3637248     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009359987 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.862       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.181       |\n",
      "|    mean_step_reward   | 0.09028008  |\n",
      "|    n_updates          | 1772        |\n",
      "|    policyGradLoss     | -0.0053     |\n",
      "|    value_loss         | 0.743       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 852         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 48          |\n",
      "|    total_timesteps    | 3645440     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009110886 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.89        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.135       |\n",
      "|    mean_step_reward   | 0.09847537  |\n",
      "|    n_updates          | 1776        |\n",
      "|    policyGradLoss     | -0.00773    |\n",
      "|    value_loss         | 0.655       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 845         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 3653632     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009286206 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.908       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.171       |\n",
      "|    mean_step_reward   | 0.10178645  |\n",
      "|    n_updates          | 1780        |\n",
      "|    policyGradLoss     | -0.00614    |\n",
      "|    value_loss         | 0.715       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 839         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 3661824     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009498726 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.876       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.356       |\n",
      "|    mean_step_reward   | 0.10444403  |\n",
      "|    n_updates          | 1784        |\n",
      "|    policyGradLoss     | -0.000661   |\n",
      "|    value_loss         | 0.816       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 833         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 3670016     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009451034 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.886       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.212       |\n",
      "|    mean_step_reward   | 0.10139295  |\n",
      "|    n_updates          | 1788        |\n",
      "|    policyGradLoss     | -0.00686    |\n",
      "|    value_loss         | 0.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 831         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 88          |\n",
      "|    total_timesteps    | 3678208     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015007908 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0982      |\n",
      "|    mean_step_reward   | 0.09988559  |\n",
      "|    n_updates          | 1792        |\n",
      "|    policyGradLoss     | -0.0075     |\n",
      "|    value_loss         | 0.515       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 828          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 98           |\n",
      "|    total_timesteps    | 3686400      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0096578095 |\n",
      "|    entropy_loss       | -1.9         |\n",
      "|    explained_variance | 0.929        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0554       |\n",
      "|    mean_step_reward   | 0.09927413   |\n",
      "|    n_updates          | 1796         |\n",
      "|    policyGradLoss     | -0.0103      |\n",
      "|    value_loss         | 0.394        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 828         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 108         |\n",
      "|    total_timesteps    | 3694592     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009160884 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.901       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.175       |\n",
      "|    mean_step_reward   | 0.09164867  |\n",
      "|    n_updates          | 1800        |\n",
      "|    policyGradLoss     | -0.00846    |\n",
      "|    value_loss         | 0.847       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 118         |\n",
      "|    total_timesteps    | 3702784     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010714949 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.886       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.142       |\n",
      "|    mean_step_reward   | 0.09387447  |\n",
      "|    n_updates          | 1804        |\n",
      "|    policyGradLoss     | -0.00767    |\n",
      "|    value_loss         | 0.613       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 823          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 129          |\n",
      "|    total_timesteps    | 3710976      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0094538275 |\n",
      "|    entropy_loss       | -1.9         |\n",
      "|    explained_variance | 0.914        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0717       |\n",
      "|    mean_step_reward   | 0.100360386  |\n",
      "|    n_updates          | 1808         |\n",
      "|    policyGradLoss     | -0.0075      |\n",
      "|    value_loss         | 0.61         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 823         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 139         |\n",
      "|    total_timesteps    | 3719168     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0083053   |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.877       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.429       |\n",
      "|    mean_step_reward   | 0.093888745 |\n",
      "|    n_updates          | 1812        |\n",
      "|    policyGradLoss     | -0.00558    |\n",
      "|    value_loss         | 1           |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 149         |\n",
      "|    total_timesteps    | 3727360     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011804255 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.326       |\n",
      "|    mean_step_reward   | 0.09970148  |\n",
      "|    n_updates          | 1816        |\n",
      "|    policyGradLoss     | -0.00666    |\n",
      "|    value_loss         | 0.703       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 3735552     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009603081 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.903       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.22        |\n",
      "|    mean_step_reward   | 0.08877779  |\n",
      "|    n_updates          | 1820        |\n",
      "|    policyGradLoss     | -0.00594    |\n",
      "|    value_loss         | 0.86        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 3743744     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011259235 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.147       |\n",
      "|    mean_step_reward   | 0.09455484  |\n",
      "|    n_updates          | 1824        |\n",
      "|    policyGradLoss     | -0.00886    |\n",
      "|    value_loss         | 0.838       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 3751936     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008789883 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.902       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0987      |\n",
      "|    mean_step_reward   | 0.08733012  |\n",
      "|    n_updates          | 1828        |\n",
      "|    policyGradLoss     | -0.00727    |\n",
      "|    value_loss         | 0.703       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 3760128     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011783635 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0369      |\n",
      "|    mean_step_reward   | 0.09074134  |\n",
      "|    n_updates          | 1832        |\n",
      "|    policyGradLoss     | -0.00647    |\n",
      "|    value_loss         | 0.467       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 3768320     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009093098 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.904       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.134       |\n",
      "|    mean_step_reward   | 0.08003341  |\n",
      "|    n_updates          | 1836        |\n",
      "|    policyGradLoss     | -0.00491    |\n",
      "|    value_loss         | 0.904       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 3776512     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011344472 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.876       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.246       |\n",
      "|    mean_step_reward   | 0.08577271  |\n",
      "|    n_updates          | 1840        |\n",
      "|    policyGradLoss     | -0.00387    |\n",
      "|    value_loss         | 0.981       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 3784704     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011778037 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0786      |\n",
      "|    mean_step_reward   | 0.08535425  |\n",
      "|    n_updates          | 1844        |\n",
      "|    policyGradLoss     | -0.0101     |\n",
      "|    value_loss         | 0.595       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 3792896     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008936662 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.211       |\n",
      "|    mean_step_reward   | 0.0917695   |\n",
      "|    n_updates          | 1848        |\n",
      "|    policyGradLoss     | -0.00564    |\n",
      "|    value_loss         | 0.79        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 3801088     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012287505 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.887       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.196       |\n",
      "|    mean_step_reward   | 0.09602254  |\n",
      "|    n_updates          | 1852        |\n",
      "|    policyGradLoss     | -0.00701    |\n",
      "|    value_loss         | 0.766       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 810        |\n",
      "|    iterations         | 25         |\n",
      "|    time_elapsed       | 252        |\n",
      "|    total_timesteps    | 3809280    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01037825 |\n",
      "|    entropy_loss       | -1.89      |\n",
      "|    explained_variance | 0.868      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.208      |\n",
      "|    mean_step_reward   | 0.10825486 |\n",
      "|    n_updates          | 1856       |\n",
      "|    policyGradLoss     | -0.00523   |\n",
      "|    value_loss         | 0.911      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 3817472     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011684332 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.185       |\n",
      "|    mean_step_reward   | 0.10004494  |\n",
      "|    n_updates          | 1860        |\n",
      "|    policyGradLoss     | -0.00676    |\n",
      "|    value_loss         | 0.558       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 809        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 273        |\n",
      "|    total_timesteps    | 3825664    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00914608 |\n",
      "|    entropy_loss       | -1.93      |\n",
      "|    explained_variance | 0.839      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.228      |\n",
      "|    mean_step_reward   | 0.08638118 |\n",
      "|    n_updates          | 1864       |\n",
      "|    policyGradLoss     | -0.00432   |\n",
      "|    value_loss         | 0.89       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 3833856     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010965237 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.89        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0847      |\n",
      "|    mean_step_reward   | 0.10529716  |\n",
      "|    n_updates          | 1868        |\n",
      "|    policyGradLoss     | -0.00556    |\n",
      "|    value_loss         | 0.649       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 808          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 293          |\n",
      "|    total_timesteps    | 3842048      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0073733754 |\n",
      "|    entropy_loss       | -1.9         |\n",
      "|    explained_variance | 0.857        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.504        |\n",
      "|    mean_step_reward   | 0.09681527   |\n",
      "|    n_updates          | 1872         |\n",
      "|    policyGradLoss     | -0.0052      |\n",
      "|    value_loss         | 1.28         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 3850240     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009600837 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.908       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0789      |\n",
      "|    mean_step_reward   | 0.09249215  |\n",
      "|    n_updates          | 1876        |\n",
      "|    policyGradLoss     | -0.011      |\n",
      "|    value_loss         | 0.555       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 314         |\n",
      "|    total_timesteps    | 3858432     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009198874 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.883       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.159       |\n",
      "|    mean_step_reward   | 0.09538216  |\n",
      "|    n_updates          | 1880        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.808       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 324         |\n",
      "|    total_timesteps    | 3866624     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008598788 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.815       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.666       |\n",
      "|    mean_step_reward   | 0.09627515  |\n",
      "|    n_updates          | 1884        |\n",
      "|    policyGradLoss     | -0.00475    |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 334         |\n",
      "|    total_timesteps    | 3874816     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008200013 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.84        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.14        |\n",
      "|    mean_step_reward   | 0.10336807  |\n",
      "|    n_updates          | 1888        |\n",
      "|    policyGradLoss     | -0.000861   |\n",
      "|    value_loss         | 1.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 345         |\n",
      "|    total_timesteps    | 3883008     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010779893 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.797       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.557       |\n",
      "|    mean_step_reward   | 0.09560169  |\n",
      "|    n_updates          | 1892        |\n",
      "|    policyGradLoss     | -0.000572   |\n",
      "|    value_loss         | 1.76        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 355         |\n",
      "|    total_timesteps    | 3891200     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009305321 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.895       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.311       |\n",
      "|    mean_step_reward   | 0.10100499  |\n",
      "|    n_updates          | 1896        |\n",
      "|    policyGradLoss     | -0.0046     |\n",
      "|    value_loss         | 0.809       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 365         |\n",
      "|    total_timesteps    | 3899392     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010513701 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.885       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.174       |\n",
      "|    mean_step_reward   | 0.09709312  |\n",
      "|    n_updates          | 1900        |\n",
      "|    policyGradLoss     | -0.00987    |\n",
      "|    value_loss         | 0.725       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 375         |\n",
      "|    total_timesteps    | 3907584     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010674953 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.861       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.314       |\n",
      "|    mean_step_reward   | 0.09804677  |\n",
      "|    n_updates          | 1904        |\n",
      "|    policyGradLoss     | -0.00373    |\n",
      "|    value_loss         | 1.13        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 806        |\n",
      "|    iterations         | 38         |\n",
      "|    time_elapsed       | 385        |\n",
      "|    total_timesteps    | 3915776    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01071229 |\n",
      "|    entropy_loss       | -1.92      |\n",
      "|    explained_variance | 0.907      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.11       |\n",
      "|    mean_step_reward   | 0.10847967 |\n",
      "|    n_updates          | 1908       |\n",
      "|    policyGradLoss     | -0.00959   |\n",
      "|    value_loss         | 0.481      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 396         |\n",
      "|    total_timesteps    | 3923968     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009056078 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.864       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.402       |\n",
      "|    mean_step_reward   | 0.09886261  |\n",
      "|    n_updates          | 1912        |\n",
      "|    policyGradLoss     | -0.00658    |\n",
      "|    value_loss         | 1.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 406         |\n",
      "|    total_timesteps    | 3932160     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012077639 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0736      |\n",
      "|    mean_step_reward   | 0.101561025 |\n",
      "|    n_updates          | 1916        |\n",
      "|    policyGradLoss     | -0.00687    |\n",
      "|    value_loss         | 0.582       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_11.zip\n",
      "[EVAL] Mean Return: -114.586, Best Return: -114.536\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_11_-114.59.mp4\n",
      "\n",
      "=== Round 13 | Learn 327680 steps (Total trained: 3932160) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1111    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 3940352 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 940         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 3948544     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012517181 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.13        |\n",
      "|    mean_step_reward   | 0.10588162  |\n",
      "|    n_updates          | 1924        |\n",
      "|    policyGradLoss     | -0.00249    |\n",
      "|    value_loss         | 0.686       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 890         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 3956736     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012776636 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.871       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.563       |\n",
      "|    mean_step_reward   | 0.09384688  |\n",
      "|    n_updates          | 1928        |\n",
      "|    policyGradLoss     | -0.00349    |\n",
      "|    value_loss         | 1.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 865         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 37          |\n",
      "|    total_timesteps    | 3964928     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010424493 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.884       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0296      |\n",
      "|    mean_step_reward   | 0.101166874 |\n",
      "|    n_updates          | 1932        |\n",
      "|    policyGradLoss     | -0.00263    |\n",
      "|    value_loss         | 0.691       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 847         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 48          |\n",
      "|    total_timesteps    | 3973120     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009334492 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.9         |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.223       |\n",
      "|    mean_step_reward   | 0.105106756 |\n",
      "|    n_updates          | 1936        |\n",
      "|    policyGradLoss     | -0.00707    |\n",
      "|    value_loss         | 0.889       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 842         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 3981312     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008216403 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.877       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.33        |\n",
      "|    mean_step_reward   | 0.10139039  |\n",
      "|    n_updates          | 1940        |\n",
      "|    policyGradLoss     | -0.00532    |\n",
      "|    value_loss         | 1.05        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 837          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 68           |\n",
      "|    total_timesteps    | 3989504      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0082184905 |\n",
      "|    entropy_loss       | -1.89        |\n",
      "|    explained_variance | 0.856        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.204        |\n",
      "|    mean_step_reward   | 0.102333665  |\n",
      "|    n_updates          | 1944         |\n",
      "|    policyGradLoss     | -0.000159    |\n",
      "|    value_loss         | 0.685        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 832         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 3997696     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009052115 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.826       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.486       |\n",
      "|    mean_step_reward   | 0.10400249  |\n",
      "|    n_updates          | 1948        |\n",
      "|    policyGradLoss     | -0.00459    |\n",
      "|    value_loss         | 1.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 830         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 88          |\n",
      "|    total_timesteps    | 4005888     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011034832 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.84        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.533       |\n",
      "|    mean_step_reward   | 0.102659225 |\n",
      "|    n_updates          | 1952        |\n",
      "|    policyGradLoss     | -0.00215    |\n",
      "|    value_loss         | 1.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 827         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 4014080     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009418502 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.902       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.256       |\n",
      "|    mean_step_reward   | 0.10585538  |\n",
      "|    n_updates          | 1956        |\n",
      "|    policyGradLoss     | -0.0043     |\n",
      "|    value_loss         | 0.918       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 4022272     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008742653 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.89        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.149       |\n",
      "|    mean_step_reward   | 0.097886674 |\n",
      "|    n_updates          | 1960        |\n",
      "|    policyGradLoss     | -0.00678    |\n",
      "|    value_loss         | 0.798       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 4030464     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010783433 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.9         |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.143       |\n",
      "|    mean_step_reward   | 0.10224096  |\n",
      "|    n_updates          | 1964        |\n",
      "|    policyGradLoss     | -0.00753    |\n",
      "|    value_loss         | 0.627       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 129         |\n",
      "|    total_timesteps    | 4038656     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013625223 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.878       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.295       |\n",
      "|    mean_step_reward   | 0.09392618  |\n",
      "|    n_updates          | 1968        |\n",
      "|    policyGradLoss     | -0.00387    |\n",
      "|    value_loss         | 1.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 139         |\n",
      "|    total_timesteps    | 4046848     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008615483 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.877       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.309       |\n",
      "|    mean_step_reward   | 0.09783001  |\n",
      "|    n_updates          | 1972        |\n",
      "|    policyGradLoss     | -0.00478    |\n",
      "|    value_loss         | 1.04        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 818          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 150          |\n",
      "|    total_timesteps    | 4055040      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0077870167 |\n",
      "|    entropy_loss       | -1.92        |\n",
      "|    explained_variance | 0.876        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.24         |\n",
      "|    mean_step_reward   | 0.10318358   |\n",
      "|    n_updates          | 1976         |\n",
      "|    policyGradLoss     | -0.0075      |\n",
      "|    value_loss         | 0.873        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 4063232     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008307541 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.908       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.127       |\n",
      "|    mean_step_reward   | 0.09807016  |\n",
      "|    n_updates          | 1980        |\n",
      "|    policyGradLoss     | -0.00882    |\n",
      "|    value_loss         | 0.724       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 4071424     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01079179  |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.873       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.156       |\n",
      "|    mean_step_reward   | 0.097995736 |\n",
      "|    n_updates          | 1984        |\n",
      "|    policyGradLoss     | -0.00455    |\n",
      "|    value_loss         | 1.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 4079616     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008773417 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.894       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.329       |\n",
      "|    mean_step_reward   | 0.10581564  |\n",
      "|    n_updates          | 1988        |\n",
      "|    policyGradLoss     | -0.00912    |\n",
      "|    value_loss         | 0.737       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 4087808     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009057961 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.819       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.732       |\n",
      "|    mean_step_reward   | 0.10097435  |\n",
      "|    n_updates          | 1992        |\n",
      "|    policyGradLoss     | 0.000622    |\n",
      "|    value_loss         | 1.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 4096000     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010040979 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.864       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.305       |\n",
      "|    mean_step_reward   | 0.09096637  |\n",
      "|    n_updates          | 1996        |\n",
      "|    policyGradLoss     | -0.00841    |\n",
      "|    value_loss         | 0.967       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 4104192     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009623321 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.874       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.425       |\n",
      "|    mean_step_reward   | 0.09120865  |\n",
      "|    n_updates          | 2000        |\n",
      "|    policyGradLoss     | -0.00917    |\n",
      "|    value_loss         | 1.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 4112384     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008289754 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.853       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.149       |\n",
      "|    mean_step_reward   | 0.09428693  |\n",
      "|    n_updates          | 2004        |\n",
      "|    policyGradLoss     | -0.00751    |\n",
      "|    value_loss         | 0.82        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 814        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 231        |\n",
      "|    total_timesteps    | 4120576    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01073309 |\n",
      "|    entropy_loss       | -1.93      |\n",
      "|    explained_variance | 0.879      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.108      |\n",
      "|    mean_step_reward   | 0.09648472 |\n",
      "|    n_updates          | 2008       |\n",
      "|    policyGradLoss     | -0.00859   |\n",
      "|    value_loss         | 0.755      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 4128768     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0114003   |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.878       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.245       |\n",
      "|    mean_step_reward   | 0.098153606 |\n",
      "|    n_updates          | 2012        |\n",
      "|    policyGradLoss     | -0.00867    |\n",
      "|    value_loss         | 0.907       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 4136960     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008806705 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.872       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.179       |\n",
      "|    mean_step_reward   | 0.09359873  |\n",
      "|    n_updates          | 2016        |\n",
      "|    policyGradLoss     | -0.00556    |\n",
      "|    value_loss         | 1.06        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 814        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 261        |\n",
      "|    total_timesteps    | 4145152    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00966396 |\n",
      "|    entropy_loss       | -1.93      |\n",
      "|    explained_variance | 0.853      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.161      |\n",
      "|    mean_step_reward   | 0.10162544 |\n",
      "|    n_updates          | 2020       |\n",
      "|    policyGradLoss     | -0.00681   |\n",
      "|    value_loss         | 0.94       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 4153344     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009146527 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.857       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.292       |\n",
      "|    mean_step_reward   | 0.09298265  |\n",
      "|    n_updates          | 2024        |\n",
      "|    policyGradLoss     | -0.00495    |\n",
      "|    value_loss         | 1.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 4161536     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007076398 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.865       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.261       |\n",
      "|    mean_step_reward   | 0.0945217   |\n",
      "|    n_updates          | 2028        |\n",
      "|    policyGradLoss     | -0.00671    |\n",
      "|    value_loss         | 0.886       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 4169728     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010118835 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.844       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.236       |\n",
      "|    mean_step_reward   | 0.09884012  |\n",
      "|    n_updates          | 2032        |\n",
      "|    policyGradLoss     | -0.00631    |\n",
      "|    value_loss         | 0.955       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 812        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 302        |\n",
      "|    total_timesteps    | 4177920    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01038873 |\n",
      "|    entropy_loss       | -1.91      |\n",
      "|    explained_variance | 0.842      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.272      |\n",
      "|    mean_step_reward   | 0.09307175 |\n",
      "|    n_updates          | 2036       |\n",
      "|    policyGradLoss     | -0.00684   |\n",
      "|    value_loss         | 0.938      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 312         |\n",
      "|    total_timesteps    | 4186112     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009852912 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.85        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.245       |\n",
      "|    mean_step_reward   | 0.09438002  |\n",
      "|    n_updates          | 2040        |\n",
      "|    policyGradLoss     | -0.00649    |\n",
      "|    value_loss         | 0.883       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 323         |\n",
      "|    total_timesteps    | 4194304     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008508481 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.866       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.184       |\n",
      "|    mean_step_reward   | 0.0976896   |\n",
      "|    n_updates          | 2044        |\n",
      "|    policyGradLoss     | -0.0049     |\n",
      "|    value_loss         | 0.773       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 4202496     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011970034 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.875       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.213       |\n",
      "|    mean_step_reward   | 0.101948634 |\n",
      "|    n_updates          | 2048        |\n",
      "|    policyGradLoss     | -0.00612    |\n",
      "|    value_loss         | 0.703       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 343         |\n",
      "|    total_timesteps    | 4210688     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009673882 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.822       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.34        |\n",
      "|    mean_step_reward   | 0.09773519  |\n",
      "|    n_updates          | 2052        |\n",
      "|    policyGradLoss     | -0.00144    |\n",
      "|    value_loss         | 1.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 353         |\n",
      "|    total_timesteps    | 4218880     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012619624 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.864       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0512      |\n",
      "|    mean_step_reward   | 0.11283408  |\n",
      "|    n_updates          | 2056        |\n",
      "|    policyGradLoss     | -0.00455    |\n",
      "|    value_loss         | 0.648       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 363         |\n",
      "|    total_timesteps    | 4227072     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009528635 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.83        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.188       |\n",
      "|    mean_step_reward   | 0.09599838  |\n",
      "|    n_updates          | 2060        |\n",
      "|    policyGradLoss     | -0.00194    |\n",
      "|    value_loss         | 1           |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 373         |\n",
      "|    total_timesteps    | 4235264     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009415153 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.881       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.358       |\n",
      "|    mean_step_reward   | 0.107314944 |\n",
      "|    n_updates          | 2064        |\n",
      "|    policyGradLoss     | -0.0045     |\n",
      "|    value_loss         | 0.831       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 384         |\n",
      "|    total_timesteps    | 4243456     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010278057 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.859       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.157       |\n",
      "|    mean_step_reward   | 0.09415752  |\n",
      "|    n_updates          | 2068        |\n",
      "|    policyGradLoss     | -0.0075     |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 394         |\n",
      "|    total_timesteps    | 4251648     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008602539 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.883       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.118       |\n",
      "|    mean_step_reward   | 0.10382271  |\n",
      "|    n_updates          | 2072        |\n",
      "|    policyGradLoss     | -0.00553    |\n",
      "|    value_loss         | 0.578       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 810        |\n",
      "|    iterations         | 40         |\n",
      "|    time_elapsed       | 404        |\n",
      "|    total_timesteps    | 4259840    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01042023 |\n",
      "|    entropy_loss       | -1.9       |\n",
      "|    explained_variance | 0.88       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.222      |\n",
      "|    mean_step_reward   | 0.10314279 |\n",
      "|    n_updates          | 2076       |\n",
      "|    policyGradLoss     | -0.00464   |\n",
      "|    value_loss         | 1.04       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_12.zip\n",
      "[EVAL] Mean Return: 82.358, Best Return: 82.508\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_12_82.36.mp4\n",
      "\n",
      "=== Round 14 | Learn 327680 steps (Total trained: 4259840) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1109    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 4268032 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 928          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 4276224      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0085531175 |\n",
      "|    entropy_loss       | -1.9         |\n",
      "|    explained_variance | 0.847        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.227        |\n",
      "|    mean_step_reward   | 0.10179224   |\n",
      "|    n_updates          | 2084         |\n",
      "|    policyGradLoss     | -0.00384     |\n",
      "|    value_loss         | 0.952        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 880          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 4284416      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0108889155 |\n",
      "|    entropy_loss       | -1.91        |\n",
      "|    explained_variance | 0.833        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.389        |\n",
      "|    mean_step_reward   | 0.103080854  |\n",
      "|    n_updates          | 2088         |\n",
      "|    policyGradLoss     | -0.00509     |\n",
      "|    value_loss         | 1.25         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 862         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 37          |\n",
      "|    total_timesteps    | 4292608     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007945189 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.846       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.452       |\n",
      "|    mean_step_reward   | 0.10712289  |\n",
      "|    n_updates          | 2092        |\n",
      "|    policyGradLoss     | -0.00378    |\n",
      "|    value_loss         | 1.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 852         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 48          |\n",
      "|    total_timesteps    | 4300800     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007907711 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.877       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.239       |\n",
      "|    mean_step_reward   | 0.10225578  |\n",
      "|    n_updates          | 2096        |\n",
      "|    policyGradLoss     | -0.0056     |\n",
      "|    value_loss         | 0.909       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 840         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 4308992     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010858725 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.868       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.182       |\n",
      "|    mean_step_reward   | 0.09355606  |\n",
      "|    n_updates          | 2100        |\n",
      "|    policyGradLoss     | -0.00792    |\n",
      "|    value_loss         | 0.888       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 834         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 4317184     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010733572 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.245       |\n",
      "|    mean_step_reward   | 0.104334146 |\n",
      "|    n_updates          | 2104        |\n",
      "|    policyGradLoss     | -0.00825    |\n",
      "|    value_loss         | 0.667       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 829          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 79           |\n",
      "|    total_timesteps    | 4325376      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0080504315 |\n",
      "|    entropy_loss       | -1.94        |\n",
      "|    explained_variance | 0.873        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.37         |\n",
      "|    mean_step_reward   | 0.10058029   |\n",
      "|    n_updates          | 2108         |\n",
      "|    policyGradLoss     | -0.00663     |\n",
      "|    value_loss         | 1.18         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 89          |\n",
      "|    total_timesteps    | 4333568     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010267578 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.249       |\n",
      "|    mean_step_reward   | 0.09945482  |\n",
      "|    n_updates          | 2112        |\n",
      "|    policyGradLoss     | -0.00766    |\n",
      "|    value_loss         | 0.933       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 822        |\n",
      "|    iterations         | 10         |\n",
      "|    time_elapsed       | 99         |\n",
      "|    total_timesteps    | 4341760    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01170129 |\n",
      "|    entropy_loss       | -1.92      |\n",
      "|    explained_variance | 0.929      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0602     |\n",
      "|    mean_step_reward   | 0.10288607 |\n",
      "|    n_updates          | 2116       |\n",
      "|    policyGradLoss     | -0.005     |\n",
      "|    value_loss         | 0.51       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 4349952     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008988333 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.234       |\n",
      "|    mean_step_reward   | 0.09456618  |\n",
      "|    n_updates          | 2120        |\n",
      "|    policyGradLoss     | -0.00547    |\n",
      "|    value_loss         | 1.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 4358144     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010676343 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.846       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.149       |\n",
      "|    mean_step_reward   | 0.0998022   |\n",
      "|    n_updates          | 2124        |\n",
      "|    policyGradLoss     | -0.00875    |\n",
      "|    value_loss         | 0.812       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 129         |\n",
      "|    total_timesteps    | 4366336     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010793519 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.885       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.181       |\n",
      "|    mean_step_reward   | 0.10241935  |\n",
      "|    n_updates          | 2128        |\n",
      "|    policyGradLoss     | -0.00583    |\n",
      "|    value_loss         | 0.759       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 140         |\n",
      "|    total_timesteps    | 4374528     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008989221 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.883       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.203       |\n",
      "|    mean_step_reward   | 0.09896985  |\n",
      "|    n_updates          | 2132        |\n",
      "|    policyGradLoss     | -0.00755    |\n",
      "|    value_loss         | 1.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 150         |\n",
      "|    total_timesteps    | 4382720     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010172874 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.888       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.389       |\n",
      "|    mean_step_reward   | 0.11398643  |\n",
      "|    n_updates          | 2136        |\n",
      "|    policyGradLoss     | -0.0037     |\n",
      "|    value_loss         | 0.709       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 161         |\n",
      "|    total_timesteps    | 4390912     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010462055 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.841       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.289       |\n",
      "|    mean_step_reward   | 0.103128195 |\n",
      "|    n_updates          | 2140        |\n",
      "|    policyGradLoss     | -0.00224    |\n",
      "|    value_loss         | 1.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 171         |\n",
      "|    total_timesteps    | 4399104     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008821769 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.89        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.264       |\n",
      "|    mean_step_reward   | 0.11394736  |\n",
      "|    n_updates          | 2144        |\n",
      "|    policyGradLoss     | -0.00496    |\n",
      "|    value_loss         | 1.04        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 4407296     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010794711 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.847       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.152       |\n",
      "|    mean_step_reward   | 0.101213254 |\n",
      "|    n_updates          | 2148        |\n",
      "|    policyGradLoss     | -0.00697    |\n",
      "|    value_loss         | 0.864       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 812        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 191        |\n",
      "|    total_timesteps    | 4415488    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0099745  |\n",
      "|    entropy_loss       | -1.9       |\n",
      "|    explained_variance | 0.792      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.262      |\n",
      "|    mean_step_reward   | 0.09250151 |\n",
      "|    n_updates          | 2152       |\n",
      "|    policyGradLoss     | -0.00198   |\n",
      "|    value_loss         | 1.21       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 4423680     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008465122 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.887       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.201       |\n",
      "|    mean_step_reward   | 0.11167126  |\n",
      "|    n_updates          | 2156        |\n",
      "|    policyGradLoss     | -0.00714    |\n",
      "|    value_loss         | 0.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 212         |\n",
      "|    total_timesteps    | 4431872     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008471771 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.816       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.342       |\n",
      "|    mean_step_reward   | 0.10861774  |\n",
      "|    n_updates          | 2160        |\n",
      "|    policyGradLoss     | -0.00507    |\n",
      "|    value_loss         | 1.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 4440064     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008106057 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.883       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.33        |\n",
      "|    mean_step_reward   | 0.10864146  |\n",
      "|    n_updates          | 2164        |\n",
      "|    policyGradLoss     | -0.00712    |\n",
      "|    value_loss         | 1.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 4448256     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006962194 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.824       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.423       |\n",
      "|    mean_step_reward   | 0.105529085 |\n",
      "|    n_updates          | 2168        |\n",
      "|    policyGradLoss     | -0.00463    |\n",
      "|    value_loss         | 1.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 4456448     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009278439 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.798       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.253       |\n",
      "|    mean_step_reward   | 0.105772406 |\n",
      "|    n_updates          | 2172        |\n",
      "|    policyGradLoss     | -0.00396    |\n",
      "|    value_loss         | 1.04        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 4464640     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007972663 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.877       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.157       |\n",
      "|    mean_step_reward   | 0.10412368  |\n",
      "|    n_updates          | 2176        |\n",
      "|    policyGradLoss     | -0.00841    |\n",
      "|    value_loss         | 0.773       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 4472832     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009897033 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.878       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.307       |\n",
      "|    mean_step_reward   | 0.10865061  |\n",
      "|    n_updates          | 2180        |\n",
      "|    policyGradLoss     | -0.00714    |\n",
      "|    value_loss         | 0.91        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 809          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 273          |\n",
      "|    total_timesteps    | 4481024      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0074611166 |\n",
      "|    entropy_loss       | -1.95        |\n",
      "|    explained_variance | 0.807        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0801       |\n",
      "|    mean_step_reward   | 0.09852433   |\n",
      "|    n_updates          | 2184         |\n",
      "|    policyGradLoss     | -0.00282     |\n",
      "|    value_loss         | 0.725        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 4489216     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011085717 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.909       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0173      |\n",
      "|    mean_step_reward   | 0.10607332  |\n",
      "|    n_updates          | 2188        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.467       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 4497408     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008581331 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.842       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.373       |\n",
      "|    mean_step_reward   | 0.10934496  |\n",
      "|    n_updates          | 2192        |\n",
      "|    policyGradLoss     | -0.00249    |\n",
      "|    value_loss         | 1.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 303         |\n",
      "|    total_timesteps    | 4505600     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008057521 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.837       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.128       |\n",
      "|    mean_step_reward   | 0.10716353  |\n",
      "|    n_updates          | 2196        |\n",
      "|    policyGradLoss     | -0.00396    |\n",
      "|    value_loss         | 0.784       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 314         |\n",
      "|    total_timesteps    | 4513792     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009355817 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.872       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.279       |\n",
      "|    mean_step_reward   | 0.10843701  |\n",
      "|    n_updates          | 2200        |\n",
      "|    policyGradLoss     | -0.00552    |\n",
      "|    value_loss         | 1.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 324         |\n",
      "|    total_timesteps    | 4521984     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008735195 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.876       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.259       |\n",
      "|    mean_step_reward   | 0.11154872  |\n",
      "|    n_updates          | 2204        |\n",
      "|    policyGradLoss     | -0.00646    |\n",
      "|    value_loss         | 1.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 334         |\n",
      "|    total_timesteps    | 4530176     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007979601 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.901       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.231       |\n",
      "|    mean_step_reward   | 0.10778531  |\n",
      "|    n_updates          | 2208        |\n",
      "|    policyGradLoss     | -0.0065     |\n",
      "|    value_loss         | 1.11        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 345         |\n",
      "|    total_timesteps    | 4538368     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011459743 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.874       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0498      |\n",
      "|    mean_step_reward   | 0.10624407  |\n",
      "|    n_updates          | 2212        |\n",
      "|    policyGradLoss     | -0.00693    |\n",
      "|    value_loss         | 0.528       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 806        |\n",
      "|    iterations         | 35         |\n",
      "|    time_elapsed       | 355        |\n",
      "|    total_timesteps    | 4546560    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00958557 |\n",
      "|    entropy_loss       | -1.91      |\n",
      "|    explained_variance | 0.886      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.101      |\n",
      "|    mean_step_reward   | 0.09633103 |\n",
      "|    n_updates          | 2216       |\n",
      "|    policyGradLoss     | -0.00704   |\n",
      "|    value_loss         | 1          |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 806          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 365          |\n",
      "|    total_timesteps    | 4554752      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0148357265 |\n",
      "|    entropy_loss       | -1.9         |\n",
      "|    explained_variance | 0.791        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.362        |\n",
      "|    mean_step_reward   | 0.118790336  |\n",
      "|    n_updates          | 2220         |\n",
      "|    policyGradLoss     | 0.00047      |\n",
      "|    value_loss         | 1.31         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 376         |\n",
      "|    total_timesteps    | 4562944     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009021476 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.851       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.136       |\n",
      "|    mean_step_reward   | 0.10572809  |\n",
      "|    n_updates          | 2224        |\n",
      "|    policyGradLoss     | -0.00628    |\n",
      "|    value_loss         | 0.892       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 386         |\n",
      "|    total_timesteps    | 4571136     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007688739 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.859       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.158       |\n",
      "|    mean_step_reward   | 0.109371915 |\n",
      "|    n_updates          | 2228        |\n",
      "|    policyGradLoss     | -0.00575    |\n",
      "|    value_loss         | 1.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 396         |\n",
      "|    total_timesteps    | 4579328     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008520946 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.565       |\n",
      "|    mean_step_reward   | 0.114414714 |\n",
      "|    n_updates          | 2232        |\n",
      "|    policyGradLoss     | -0.00384    |\n",
      "|    value_loss         | 1.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 407         |\n",
      "|    total_timesteps    | 4587520     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010893088 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.807       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.258       |\n",
      "|    mean_step_reward   | 0.10575538  |\n",
      "|    n_updates          | 2236        |\n",
      "|    policyGradLoss     | -0.00476    |\n",
      "|    value_loss         | 1.09        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_13.zip\n",
      "[EVAL] Mean Return: 145.686, Best Return: 145.886\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_13_145.69.mp4\n",
      "\n",
      "=== Round 15 | Learn 327680 steps (Total trained: 4587520) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1129    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 4595712 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 934          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 4603904      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0123361945 |\n",
      "|    entropy_loss       | -1.91        |\n",
      "|    explained_variance | 0.888        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.19         |\n",
      "|    mean_step_reward   | 0.101254225  |\n",
      "|    n_updates          | 2244         |\n",
      "|    policyGradLoss     | -0.0112      |\n",
      "|    value_loss         | 0.739        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 888         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 4612096     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009427647 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.872       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.139       |\n",
      "|    mean_step_reward   | 0.10307108  |\n",
      "|    n_updates          | 2248        |\n",
      "|    policyGradLoss     | -0.00778    |\n",
      "|    value_loss         | 0.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 864         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 37          |\n",
      "|    total_timesteps    | 4620288     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009215107 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.892       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.122       |\n",
      "|    mean_step_reward   | 0.10474782  |\n",
      "|    n_updates          | 2252        |\n",
      "|    policyGradLoss     | -0.0096     |\n",
      "|    value_loss         | 0.704       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 851         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 48          |\n",
      "|    total_timesteps    | 4628480     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008755941 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.807       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.482       |\n",
      "|    mean_step_reward   | 0.100852534 |\n",
      "|    n_updates          | 2256        |\n",
      "|    policyGradLoss     | -0.00204    |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 839         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 4636672     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007309043 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.822       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.142       |\n",
      "|    mean_step_reward   | 0.106788784 |\n",
      "|    n_updates          | 2260        |\n",
      "|    policyGradLoss     | -0.00371    |\n",
      "|    value_loss         | 1.16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 835         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 4644864     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008177178 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0602      |\n",
      "|    mean_step_reward   | 0.10956778  |\n",
      "|    n_updates          | 2264        |\n",
      "|    policyGradLoss     | -0.00629    |\n",
      "|    value_loss         | 0.527       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 829         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 4653056     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008391776 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.764       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.354       |\n",
      "|    mean_step_reward   | 0.0957353   |\n",
      "|    n_updates          | 2268        |\n",
      "|    policyGradLoss     | -0.000152   |\n",
      "|    value_loss         | 1.65        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 89          |\n",
      "|    total_timesteps    | 4661248     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008808555 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.878       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.361       |\n",
      "|    mean_step_reward   | 0.09983324  |\n",
      "|    n_updates          | 2272        |\n",
      "|    policyGradLoss     | -0.00375    |\n",
      "|    value_loss         | 1.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 99          |\n",
      "|    total_timesteps    | 4669440     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008825004 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.893       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.197       |\n",
      "|    mean_step_reward   | 0.11032144  |\n",
      "|    n_updates          | 2276        |\n",
      "|    policyGradLoss     | -0.00819    |\n",
      "|    value_loss         | 0.794       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 4677632     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008625463 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.775       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.733       |\n",
      "|    mean_step_reward   | 0.09662564  |\n",
      "|    n_updates          | 2280        |\n",
      "|    policyGradLoss     | -0.00234    |\n",
      "|    value_loss         | 1.96        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 4685824     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009653121 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.861       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.344       |\n",
      "|    mean_step_reward   | 0.11079003  |\n",
      "|    n_updates          | 2284        |\n",
      "|    policyGradLoss     | -0.00483    |\n",
      "|    value_loss         | 1.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 129         |\n",
      "|    total_timesteps    | 4694016     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006870771 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.804       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.36        |\n",
      "|    mean_step_reward   | 0.103213534 |\n",
      "|    n_updates          | 2288        |\n",
      "|    policyGradLoss     | -0.00273    |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 139         |\n",
      "|    total_timesteps    | 4702208     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006720279 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.84        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.576       |\n",
      "|    mean_step_reward   | 0.10746706  |\n",
      "|    n_updates          | 2292        |\n",
      "|    policyGradLoss     | -0.00393    |\n",
      "|    value_loss         | 1.25        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 817        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 150        |\n",
      "|    total_timesteps    | 4710400    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00610038 |\n",
      "|    entropy_loss       | -1.96      |\n",
      "|    explained_variance | 0.828      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.54       |\n",
      "|    mean_step_reward   | 0.11370374 |\n",
      "|    n_updates          | 2296       |\n",
      "|    policyGradLoss     | -0.00346   |\n",
      "|    value_loss         | 1.52       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 817          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 160          |\n",
      "|    total_timesteps    | 4718592      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0077330526 |\n",
      "|    entropy_loss       | -1.95        |\n",
      "|    explained_variance | 0.862        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.404        |\n",
      "|    mean_step_reward   | 0.10792929   |\n",
      "|    n_updates          | 2300         |\n",
      "|    policyGradLoss     | -0.00546     |\n",
      "|    value_loss         | 1.5          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 4726784     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007755021 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.877       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.446       |\n",
      "|    mean_step_reward   | 0.11475964  |\n",
      "|    n_updates          | 2304        |\n",
      "|    policyGradLoss     | -0.00626    |\n",
      "|    value_loss         | 0.953       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 816          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 180          |\n",
      "|    total_timesteps    | 4734976      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0067877388 |\n",
      "|    entropy_loss       | -1.97        |\n",
      "|    explained_variance | 0.866        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.277        |\n",
      "|    mean_step_reward   | 0.100436896  |\n",
      "|    n_updates          | 2308         |\n",
      "|    policyGradLoss     | -0.00487     |\n",
      "|    value_loss         | 1.11         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 815        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 190        |\n",
      "|    total_timesteps    | 4743168    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00790642 |\n",
      "|    entropy_loss       | -1.95      |\n",
      "|    explained_variance | 0.844      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.208      |\n",
      "|    mean_step_reward   | 0.10475706 |\n",
      "|    n_updates          | 2312       |\n",
      "|    policyGradLoss     | -0.00547   |\n",
      "|    value_loss         | 0.697      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 814          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 201          |\n",
      "|    total_timesteps    | 4751360      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0071116434 |\n",
      "|    entropy_loss       | -1.95        |\n",
      "|    explained_variance | 0.893        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.216        |\n",
      "|    mean_step_reward   | 0.104094066  |\n",
      "|    n_updates          | 2316         |\n",
      "|    policyGradLoss     | -0.00723     |\n",
      "|    value_loss         | 0.868        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 4759552     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009327162 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.879       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.179       |\n",
      "|    mean_step_reward   | 0.108349465 |\n",
      "|    n_updates          | 2320        |\n",
      "|    policyGradLoss     | -0.00812    |\n",
      "|    value_loss         | 0.747       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 814        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 221        |\n",
      "|    total_timesteps    | 4767744    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00883692 |\n",
      "|    entropy_loss       | -1.96      |\n",
      "|    explained_variance | 0.881      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.172      |\n",
      "|    mean_step_reward   | 0.10076881 |\n",
      "|    n_updates          | 2324       |\n",
      "|    policyGradLoss     | -0.00578   |\n",
      "|    value_loss         | 1.04       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 4775936     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008333392 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.898       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.28        |\n",
      "|    mean_step_reward   | 0.10887723  |\n",
      "|    n_updates          | 2328        |\n",
      "|    policyGradLoss     | -0.00713    |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 812        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 241        |\n",
      "|    total_timesteps    | 4784128    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00779288 |\n",
      "|    entropy_loss       | -1.96      |\n",
      "|    explained_variance | 0.857      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0687     |\n",
      "|    mean_step_reward   | 0.10944942 |\n",
      "|    n_updates          | 2332       |\n",
      "|    policyGradLoss     | -0.0082    |\n",
      "|    value_loss         | 0.689      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 4792320     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008768171 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.884       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.102       |\n",
      "|    mean_step_reward   | 0.10332288  |\n",
      "|    n_updates          | 2336        |\n",
      "|    policyGradLoss     | -0.00766    |\n",
      "|    value_loss         | 0.745       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 812          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 262          |\n",
      "|    total_timesteps    | 4800512      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0086332355 |\n",
      "|    entropy_loss       | -1.96        |\n",
      "|    explained_variance | 0.841        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.131        |\n",
      "|    mean_step_reward   | 0.10121322   |\n",
      "|    n_updates          | 2340         |\n",
      "|    policyGradLoss     | -0.0066      |\n",
      "|    value_loss         | 0.825        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 4808704     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008868067 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.253       |\n",
      "|    mean_step_reward   | 0.1005363   |\n",
      "|    n_updates          | 2344        |\n",
      "|    policyGradLoss     | -0.0067     |\n",
      "|    value_loss         | 0.956       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 811          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 282          |\n",
      "|    total_timesteps    | 4816896      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0076550227 |\n",
      "|    entropy_loss       | -1.96        |\n",
      "|    explained_variance | 0.86         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0866       |\n",
      "|    mean_step_reward   | 0.10304971   |\n",
      "|    n_updates          | 2348         |\n",
      "|    policyGradLoss     | -0.00749     |\n",
      "|    value_loss         | 0.82         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 4825088     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009226274 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.907       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0796      |\n",
      "|    mean_step_reward   | 0.10268971  |\n",
      "|    n_updates          | 2352        |\n",
      "|    policyGradLoss     | -0.00941    |\n",
      "|    value_loss         | 0.77        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 810        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 303        |\n",
      "|    total_timesteps    | 4833280    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00879139 |\n",
      "|    entropy_loss       | -1.94      |\n",
      "|    explained_variance | 0.898      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.149      |\n",
      "|    mean_step_reward   | 0.09665157 |\n",
      "|    n_updates          | 2356       |\n",
      "|    policyGradLoss     | -0.00847   |\n",
      "|    value_loss         | 0.831      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 810          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 313          |\n",
      "|    total_timesteps    | 4841472      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0073703607 |\n",
      "|    entropy_loss       | -1.94        |\n",
      "|    explained_variance | 0.914        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.147        |\n",
      "|    mean_step_reward   | 0.113282025  |\n",
      "|    n_updates          | 2360         |\n",
      "|    policyGradLoss     | -0.00727     |\n",
      "|    value_loss         | 0.739        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 323         |\n",
      "|    total_timesteps    | 4849664     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009292001 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.862       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.185       |\n",
      "|    mean_step_reward   | 0.09480671  |\n",
      "|    n_updates          | 2364        |\n",
      "|    policyGradLoss     | -0.00715    |\n",
      "|    value_loss         | 0.832       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 334         |\n",
      "|    total_timesteps    | 4857856     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008004992 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.885       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.146       |\n",
      "|    mean_step_reward   | 0.09774729  |\n",
      "|    n_updates          | 2368        |\n",
      "|    policyGradLoss     | -0.0074     |\n",
      "|    value_loss         | 0.756       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 344         |\n",
      "|    total_timesteps    | 4866048     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008321895 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.817       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.314       |\n",
      "|    mean_step_reward   | 0.10483293  |\n",
      "|    n_updates          | 2372        |\n",
      "|    policyGradLoss     | 0.00114     |\n",
      "|    value_loss         | 1.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 355         |\n",
      "|    total_timesteps    | 4874240     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008664671 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.893       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.358       |\n",
      "|    mean_step_reward   | 0.11281609  |\n",
      "|    n_updates          | 2376        |\n",
      "|    policyGradLoss     | -0.00703    |\n",
      "|    value_loss         | 0.773       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 365         |\n",
      "|    total_timesteps    | 4882432     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007583867 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.868       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.145       |\n",
      "|    mean_step_reward   | 0.09975049  |\n",
      "|    n_updates          | 2380        |\n",
      "|    policyGradLoss     | -0.00407    |\n",
      "|    value_loss         | 0.704       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 375         |\n",
      "|    total_timesteps    | 4890624     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007824637 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.209       |\n",
      "|    mean_step_reward   | 0.10349689  |\n",
      "|    n_updates          | 2384        |\n",
      "|    policyGradLoss     | -0.00927    |\n",
      "|    value_loss         | 1.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 385         |\n",
      "|    total_timesteps    | 4898816     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007920357 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.909       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.113       |\n",
      "|    mean_step_reward   | 0.11256245  |\n",
      "|    n_updates          | 2388        |\n",
      "|    policyGradLoss     | -0.00559    |\n",
      "|    value_loss         | 0.567       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 806          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 396          |\n",
      "|    total_timesteps    | 4907008      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0106686605 |\n",
      "|    entropy_loss       | -1.94        |\n",
      "|    explained_variance | 0.902        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.213        |\n",
      "|    mean_step_reward   | 0.112514086  |\n",
      "|    n_updates          | 2392         |\n",
      "|    policyGradLoss     | -0.00629     |\n",
      "|    value_loss         | 0.905        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 406         |\n",
      "|    total_timesteps    | 4915200     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007023385 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.845       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.167       |\n",
      "|    mean_step_reward   | 0.11064227  |\n",
      "|    n_updates          | 2396        |\n",
      "|    policyGradLoss     | -0.00422    |\n",
      "|    value_loss         | 0.847       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_14.zip\n",
      "[EVAL] Mean Return: 274.507, Best Return: 274.557\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_14_274.51.mp4\n",
      "\n",
      "=== Round 16 | Learn 327680 steps (Total trained: 4915200) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1115    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 4923392 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 943         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 4931584     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009272688 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.25        |\n",
      "|    mean_step_reward   | 0.09772955  |\n",
      "|    n_updates          | 2404        |\n",
      "|    policyGradLoss     | -0.0105     |\n",
      "|    value_loss         | 0.857       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 893         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 4939776     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.00910642  |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.87        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.141       |\n",
      "|    mean_step_reward   | 0.108585246 |\n",
      "|    n_updates          | 2408        |\n",
      "|    policyGradLoss     | -0.00741    |\n",
      "|    value_loss         | 0.91        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 869         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 37          |\n",
      "|    total_timesteps    | 4947968     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009733295 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.886       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.274       |\n",
      "|    mean_step_reward   | 0.10918677  |\n",
      "|    n_updates          | 2412        |\n",
      "|    policyGradLoss     | -0.00575    |\n",
      "|    value_loss         | 0.92        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 855         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 47          |\n",
      "|    total_timesteps    | 4956160     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009364756 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.152       |\n",
      "|    mean_step_reward   | 0.11697308  |\n",
      "|    n_updates          | 2416        |\n",
      "|    policyGradLoss     | -0.00981    |\n",
      "|    value_loss         | 0.615       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 845         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 4964352     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010565834 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.891       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.167       |\n",
      "|    mean_step_reward   | 0.106325164 |\n",
      "|    n_updates          | 2420        |\n",
      "|    policyGradLoss     | -0.00731    |\n",
      "|    value_loss         | 0.753       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 838         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 4972544     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008883348 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.118       |\n",
      "|    mean_step_reward   | 0.12236082  |\n",
      "|    n_updates          | 2424        |\n",
      "|    policyGradLoss     | -0.0112     |\n",
      "|    value_loss         | 0.632       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 834         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 4980736     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008338041 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.904       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.424       |\n",
      "|    mean_step_reward   | 0.11946508  |\n",
      "|    n_updates          | 2428        |\n",
      "|    policyGradLoss     | -0.00711    |\n",
      "|    value_loss         | 1.31        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 833          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 88           |\n",
      "|    total_timesteps    | 4988928      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0071739648 |\n",
      "|    entropy_loss       | -1.95        |\n",
      "|    explained_variance | 0.901        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.262        |\n",
      "|    mean_step_reward   | 0.11895168   |\n",
      "|    n_updates          | 2432         |\n",
      "|    policyGradLoss     | -0.00822     |\n",
      "|    value_loss         | 1.04         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 829          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 98           |\n",
      "|    total_timesteps    | 4997120      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0074267527 |\n",
      "|    entropy_loss       | -1.96        |\n",
      "|    explained_variance | 0.912        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.136        |\n",
      "|    mean_step_reward   | 0.11204839   |\n",
      "|    n_updates          | 2436         |\n",
      "|    policyGradLoss     | -0.00707     |\n",
      "|    value_loss         | 0.735        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 824          |\n",
      "|    iterations         | 11           |\n",
      "|    time_elapsed       | 109          |\n",
      "|    total_timesteps    | 5005312      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0076080444 |\n",
      "|    entropy_loss       | -1.96        |\n",
      "|    explained_variance | 0.847        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.31         |\n",
      "|    mean_step_reward   | 0.10118187   |\n",
      "|    n_updates          | 2440         |\n",
      "|    policyGradLoss     | -0.00183     |\n",
      "|    value_loss         | 1.24         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 823         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 5013504     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008490512 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.816       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.187       |\n",
      "|    mean_step_reward   | 0.09394909  |\n",
      "|    n_updates          | 2444        |\n",
      "|    policyGradLoss     | -0.00503    |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 821          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 129          |\n",
      "|    total_timesteps    | 5021696      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0078085167 |\n",
      "|    entropy_loss       | -1.98        |\n",
      "|    explained_variance | 0.902        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0771       |\n",
      "|    mean_step_reward   | 0.10458347   |\n",
      "|    n_updates          | 2448         |\n",
      "|    policyGradLoss     | -0.00858     |\n",
      "|    value_loss         | 0.639        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 139         |\n",
      "|    total_timesteps    | 5029888     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008154595 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0696      |\n",
      "|    mean_step_reward   | 0.10239497  |\n",
      "|    n_updates          | 2452        |\n",
      "|    policyGradLoss     | -0.00951    |\n",
      "|    value_loss         | 0.588       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 150         |\n",
      "|    total_timesteps    | 5038080     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009389522 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.89        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.342       |\n",
      "|    mean_step_reward   | 0.10022797  |\n",
      "|    n_updates          | 2456        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.889       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 5046272     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009351221 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.855       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.238       |\n",
      "|    mean_step_reward   | 0.09753129  |\n",
      "|    n_updates          | 2460        |\n",
      "|    policyGradLoss     | -0.00611    |\n",
      "|    value_loss         | 0.967       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 5054464     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008911479 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.828       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0447      |\n",
      "|    mean_step_reward   | 0.09752041  |\n",
      "|    n_updates          | 2464        |\n",
      "|    policyGradLoss     | -0.00909    |\n",
      "|    value_loss         | 0.676       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 5062656     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008823722 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.151       |\n",
      "|    mean_step_reward   | 0.10269455  |\n",
      "|    n_updates          | 2468        |\n",
      "|    policyGradLoss     | -0.00436    |\n",
      "|    value_loss         | 0.804       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 5070848     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010364287 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.82        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.293       |\n",
      "|    mean_step_reward   | 0.09283075  |\n",
      "|    n_updates          | 2472        |\n",
      "|    policyGradLoss     | -0.00548    |\n",
      "|    value_loss         | 1.22        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 813        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 201        |\n",
      "|    total_timesteps    | 5079040    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01025833 |\n",
      "|    entropy_loss       | -1.95      |\n",
      "|    explained_variance | 0.881      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.213      |\n",
      "|    mean_step_reward   | 0.10272468 |\n",
      "|    n_updates          | 2476       |\n",
      "|    policyGradLoss     | -0.00553   |\n",
      "|    value_loss         | 0.924      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 5087232     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008981101 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.856       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.122       |\n",
      "|    mean_step_reward   | 0.10243602  |\n",
      "|    n_updates          | 2480        |\n",
      "|    policyGradLoss     | -0.00809    |\n",
      "|    value_loss         | 0.964       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 5095424     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009482903 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.699       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.298       |\n",
      "|    mean_step_reward   | 0.09630123  |\n",
      "|    n_updates          | 2484        |\n",
      "|    policyGradLoss     | -0.00207    |\n",
      "|    value_loss         | 1.54        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 5103616     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008217111 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.886       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.221       |\n",
      "|    mean_step_reward   | 0.099397644 |\n",
      "|    n_updates          | 2488        |\n",
      "|    policyGradLoss     | -0.00791    |\n",
      "|    value_loss         | 1.01        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 5111808     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008957494 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.858       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.149       |\n",
      "|    mean_step_reward   | 0.10749261  |\n",
      "|    n_updates          | 2492        |\n",
      "|    policyGradLoss     | -0.00915    |\n",
      "|    value_loss         | 0.921       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 811        |\n",
      "|    iterations         | 25         |\n",
      "|    time_elapsed       | 252        |\n",
      "|    total_timesteps    | 5120000    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0102464  |\n",
      "|    entropy_loss       | -2.01      |\n",
      "|    explained_variance | 0.892      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0603     |\n",
      "|    mean_step_reward   | 0.09079188 |\n",
      "|    n_updates          | 2496       |\n",
      "|    policyGradLoss     | -0.0115    |\n",
      "|    value_loss         | 0.551      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 5128192     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010379744 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.88        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.14        |\n",
      "|    mean_step_reward   | 0.105831176 |\n",
      "|    n_updates          | 2500        |\n",
      "|    policyGradLoss     | -0.00753    |\n",
      "|    value_loss         | 0.727       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 5136384     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013115117 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.91        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.2         |\n",
      "|    mean_step_reward   | 0.103655875 |\n",
      "|    n_updates          | 2504        |\n",
      "|    policyGradLoss     | -0.00782    |\n",
      "|    value_loss         | 0.89        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 5144576     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011695944 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.124       |\n",
      "|    mean_step_reward   | 0.107294604 |\n",
      "|    n_updates          | 2508        |\n",
      "|    policyGradLoss     | -0.00945    |\n",
      "|    value_loss         | 0.617       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 5152768     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012353822 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.889       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0465      |\n",
      "|    mean_step_reward   | 0.100316934 |\n",
      "|    n_updates          | 2512        |\n",
      "|    policyGradLoss     | -0.00598    |\n",
      "|    value_loss         | 0.61        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 303         |\n",
      "|    total_timesteps    | 5160960     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008795068 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.908       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.158       |\n",
      "|    mean_step_reward   | 0.10655582  |\n",
      "|    n_updates          | 2516        |\n",
      "|    policyGradLoss     | -0.00675    |\n",
      "|    value_loss         | 0.771       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 809          |\n",
      "|    iterations         | 31           |\n",
      "|    time_elapsed       | 313          |\n",
      "|    total_timesteps    | 5169152      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0113818925 |\n",
      "|    entropy_loss       | -1.96        |\n",
      "|    explained_variance | 0.917        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.242        |\n",
      "|    mean_step_reward   | 0.12122672   |\n",
      "|    n_updates          | 2520         |\n",
      "|    policyGradLoss     | -0.00438     |\n",
      "|    value_loss         | 0.986        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 808        |\n",
      "|    iterations         | 32         |\n",
      "|    time_elapsed       | 324        |\n",
      "|    total_timesteps    | 5177344    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01393491 |\n",
      "|    entropy_loss       | -1.94      |\n",
      "|    explained_variance | 0.914      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.184      |\n",
      "|    mean_step_reward   | 0.11045002 |\n",
      "|    n_updates          | 2524       |\n",
      "|    policyGradLoss     | -0.00813   |\n",
      "|    value_loss         | 0.664      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 334         |\n",
      "|    total_timesteps    | 5185536     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010473956 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.178       |\n",
      "|    mean_step_reward   | 0.10544312  |\n",
      "|    n_updates          | 2528        |\n",
      "|    policyGradLoss     | -0.00721    |\n",
      "|    value_loss         | 0.793       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 344         |\n",
      "|    total_timesteps    | 5193728     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009565385 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.912       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.181       |\n",
      "|    mean_step_reward   | 0.11701682  |\n",
      "|    n_updates          | 2532        |\n",
      "|    policyGradLoss     | -0.00973    |\n",
      "|    value_loss         | 0.638       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 354         |\n",
      "|    total_timesteps    | 5201920     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011180507 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.32        |\n",
      "|    mean_step_reward   | 0.10855613  |\n",
      "|    n_updates          | 2536        |\n",
      "|    policyGradLoss     | -0.00656    |\n",
      "|    value_loss         | 0.909       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 364         |\n",
      "|    total_timesteps    | 5210112     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010086579 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.893       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.235       |\n",
      "|    mean_step_reward   | 0.102592185 |\n",
      "|    n_updates          | 2540        |\n",
      "|    policyGradLoss     | -0.00945    |\n",
      "|    value_loss         | 0.865       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 809          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 374          |\n",
      "|    total_timesteps    | 5218304      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0096038245 |\n",
      "|    entropy_loss       | -1.93        |\n",
      "|    explained_variance | 0.931        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.225        |\n",
      "|    mean_step_reward   | 0.12221587   |\n",
      "|    n_updates          | 2544         |\n",
      "|    policyGradLoss     | -0.0068      |\n",
      "|    value_loss         | 0.983        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 385         |\n",
      "|    total_timesteps    | 5226496     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009440193 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.906       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.169       |\n",
      "|    mean_step_reward   | 0.11764297  |\n",
      "|    n_updates          | 2548        |\n",
      "|    policyGradLoss     | -0.00784    |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 808        |\n",
      "|    iterations         | 39         |\n",
      "|    time_elapsed       | 395        |\n",
      "|    total_timesteps    | 5234688    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01042147 |\n",
      "|    entropy_loss       | -1.92      |\n",
      "|    explained_variance | 0.932      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.152      |\n",
      "|    mean_step_reward   | 0.11551526 |\n",
      "|    n_updates          | 2552       |\n",
      "|    policyGradLoss     | -0.00936   |\n",
      "|    value_loss         | 0.898      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 405         |\n",
      "|    total_timesteps    | 5242880     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010246335 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.17        |\n",
      "|    mean_step_reward   | 0.115936585 |\n",
      "|    n_updates          | 2556        |\n",
      "|    policyGradLoss     | -0.00752    |\n",
      "|    value_loss         | 0.625       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_15.zip\n",
      "[EVAL] Mean Return: 23.708, Best Return: 23.758\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_15_23.71.mp4\n",
      "\n",
      "=== Round 17 | Learn 327680 steps (Total trained: 5242880) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1074    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 5251072 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 917         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 5259264     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008452401 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.136       |\n",
      "|    mean_step_reward   | 0.11494108  |\n",
      "|    n_updates          | 2564        |\n",
      "|    policyGradLoss     | -0.00599    |\n",
      "|    value_loss         | 0.773       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 879         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 5267456     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012900188 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.109       |\n",
      "|    mean_step_reward   | 0.111501865 |\n",
      "|    n_updates          | 2568        |\n",
      "|    policyGradLoss     | -0.00888    |\n",
      "|    value_loss         | 0.594       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 862         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 5275648     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010567742 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.293       |\n",
      "|    mean_step_reward   | 0.12195677  |\n",
      "|    n_updates          | 2572        |\n",
      "|    policyGradLoss     | -0.00778    |\n",
      "|    value_loss         | 0.823       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 847        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 48         |\n",
      "|    total_timesteps    | 5283840    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00906406 |\n",
      "|    entropy_loss       | -1.94      |\n",
      "|    explained_variance | 0.944      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.203      |\n",
      "|    mean_step_reward   | 0.12158227 |\n",
      "|    n_updates          | 2576       |\n",
      "|    policyGradLoss     | -0.00769   |\n",
      "|    value_loss         | 0.888      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 839         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 5292032     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010001479 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.156       |\n",
      "|    mean_step_reward   | 0.122940555 |\n",
      "|    n_updates          | 2580        |\n",
      "|    policyGradLoss     | -0.00637    |\n",
      "|    value_loss         | 0.838       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 837          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 68           |\n",
      "|    total_timesteps    | 5300224      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0099331215 |\n",
      "|    entropy_loss       | -1.92        |\n",
      "|    explained_variance | 0.934        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.17         |\n",
      "|    mean_step_reward   | 0.1170077    |\n",
      "|    n_updates          | 2584         |\n",
      "|    policyGradLoss     | -0.00704     |\n",
      "|    value_loss         | 0.921        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 833         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 5308416     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008883494 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.181       |\n",
      "|    mean_step_reward   | 0.123763785 |\n",
      "|    n_updates          | 2588        |\n",
      "|    policyGradLoss     | -0.0067     |\n",
      "|    value_loss         | 0.993       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 830         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 88          |\n",
      "|    total_timesteps    | 5316608     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007842932 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.901       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.247       |\n",
      "|    mean_step_reward   | 0.12878154  |\n",
      "|    n_updates          | 2592        |\n",
      "|    policyGradLoss     | -0.00624    |\n",
      "|    value_loss         | 0.898       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 827         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 5324800     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008496195 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.92        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.313       |\n",
      "|    mean_step_reward   | 0.11436437  |\n",
      "|    n_updates          | 2596        |\n",
      "|    policyGradLoss     | -0.00852    |\n",
      "|    value_loss         | 0.929       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 823         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 5332992     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011773476 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.139       |\n",
      "|    mean_step_reward   | 0.11955138  |\n",
      "|    n_updates          | 2600        |\n",
      "|    policyGradLoss     | -0.00762    |\n",
      "|    value_loss         | 0.699       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 821          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 119          |\n",
      "|    total_timesteps    | 5341184      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0112492405 |\n",
      "|    entropy_loss       | -1.89        |\n",
      "|    explained_variance | 0.939        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0407       |\n",
      "|    mean_step_reward   | 0.115758836  |\n",
      "|    n_updates          | 2604         |\n",
      "|    policyGradLoss     | -0.00752     |\n",
      "|    value_loss         | 0.423        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 129         |\n",
      "|    total_timesteps    | 5349376     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009149637 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.255       |\n",
      "|    mean_step_reward   | 0.12684691  |\n",
      "|    n_updates          | 2608        |\n",
      "|    policyGradLoss     | -0.00441    |\n",
      "|    value_loss         | 0.795       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 139         |\n",
      "|    total_timesteps    | 5357568     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010069635 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.116       |\n",
      "|    mean_step_reward   | 0.12524089  |\n",
      "|    n_updates          | 2612        |\n",
      "|    policyGradLoss     | -0.00672    |\n",
      "|    value_loss         | 0.637       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 149         |\n",
      "|    total_timesteps    | 5365760     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008557497 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.909       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.122       |\n",
      "|    mean_step_reward   | 0.1219963   |\n",
      "|    n_updates          | 2616        |\n",
      "|    policyGradLoss     | -0.00459    |\n",
      "|    value_loss         | 0.726       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 159         |\n",
      "|    total_timesteps    | 5373952     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010175111 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.74        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.274       |\n",
      "|    mean_step_reward   | 0.102973804 |\n",
      "|    n_updates          | 2620        |\n",
      "|    policyGradLoss     | 0.000927    |\n",
      "|    value_loss         | 1.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 5382144     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010838335 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.18        |\n",
      "|    mean_step_reward   | 0.11791289  |\n",
      "|    n_updates          | 2624        |\n",
      "|    policyGradLoss     | -0.00433    |\n",
      "|    value_loss         | 0.885       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 819          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 180          |\n",
      "|    total_timesteps    | 5390336      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0089065675 |\n",
      "|    entropy_loss       | -1.93        |\n",
      "|    explained_variance | 0.906        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0558       |\n",
      "|    mean_step_reward   | 0.115339786  |\n",
      "|    n_updates          | 2628         |\n",
      "|    policyGradLoss     | -0.00779     |\n",
      "|    value_loss         | 0.629        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 817        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 190        |\n",
      "|    total_timesteps    | 5398528    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00976612 |\n",
      "|    entropy_loss       | -1.9       |\n",
      "|    explained_variance | 0.921      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.292      |\n",
      "|    mean_step_reward   | 0.11601296 |\n",
      "|    n_updates          | 2632       |\n",
      "|    policyGradLoss     | -0.00906   |\n",
      "|    value_loss         | 0.735      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 816          |\n",
      "|    iterations         | 20           |\n",
      "|    time_elapsed       | 200          |\n",
      "|    total_timesteps    | 5406720      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0091421325 |\n",
      "|    entropy_loss       | -1.92        |\n",
      "|    explained_variance | 0.926        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0621       |\n",
      "|    mean_step_reward   | 0.11579801   |\n",
      "|    n_updates          | 2636         |\n",
      "|    policyGradLoss     | -0.00683     |\n",
      "|    value_loss         | 0.647        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 5414912     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010468069 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.896       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.123       |\n",
      "|    mean_step_reward   | 0.113961756 |\n",
      "|    n_updates          | 2640        |\n",
      "|    policyGradLoss     | -0.00727    |\n",
      "|    value_loss         | 0.979       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 5423104     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012090632 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.147       |\n",
      "|    mean_step_reward   | 0.13344494  |\n",
      "|    n_updates          | 2644        |\n",
      "|    policyGradLoss     | -0.00196    |\n",
      "|    value_loss         | 1.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 5431296     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014999427 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0159      |\n",
      "|    mean_step_reward   | 0.118350625 |\n",
      "|    n_updates          | 2648        |\n",
      "|    policyGradLoss     | -0.00417    |\n",
      "|    value_loss         | 0.448       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 5439488     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010521115 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.194       |\n",
      "|    mean_step_reward   | 0.12694053  |\n",
      "|    n_updates          | 2652        |\n",
      "|    policyGradLoss     | -0.00307    |\n",
      "|    value_loss         | 0.962       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 5447680     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008635054 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.388       |\n",
      "|    mean_step_reward   | 0.13005924  |\n",
      "|    n_updates          | 2656        |\n",
      "|    policyGradLoss     | -0.00474    |\n",
      "|    value_loss         | 1.22        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 5455872     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012137663 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.218       |\n",
      "|    mean_step_reward   | 0.11150345  |\n",
      "|    n_updates          | 2660        |\n",
      "|    policyGradLoss     | -0.00448    |\n",
      "|    value_loss         | 0.864       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 5464064     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009352599 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.199       |\n",
      "|    mean_step_reward   | 0.11131816  |\n",
      "|    n_updates          | 2664        |\n",
      "|    policyGradLoss     | -0.00902    |\n",
      "|    value_loss         | 0.713       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 5472256     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011484997 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0851      |\n",
      "|    mean_step_reward   | 0.10996753  |\n",
      "|    n_updates          | 2668        |\n",
      "|    policyGradLoss     | -0.00654    |\n",
      "|    value_loss         | 0.624       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 812          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 292          |\n",
      "|    total_timesteps    | 5480448      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0098633235 |\n",
      "|    entropy_loss       | -1.94        |\n",
      "|    explained_variance | 0.911        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.127        |\n",
      "|    mean_step_reward   | 0.12155518   |\n",
      "|    n_updates          | 2672         |\n",
      "|    policyGradLoss     | 0.00273      |\n",
      "|    value_loss         | 0.731        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 302         |\n",
      "|    total_timesteps    | 5488640     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009993879 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.903       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.145       |\n",
      "|    mean_step_reward   | 0.11386904  |\n",
      "|    n_updates          | 2676        |\n",
      "|    policyGradLoss     | -0.0064     |\n",
      "|    value_loss         | 0.731       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 312         |\n",
      "|    total_timesteps    | 5496832     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009245138 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.889       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.107       |\n",
      "|    mean_step_reward   | 0.111024    |\n",
      "|    n_updates          | 2680        |\n",
      "|    policyGradLoss     | -0.00618    |\n",
      "|    value_loss         | 0.743       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 323         |\n",
      "|    total_timesteps    | 5505024     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008401845 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.872       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.142       |\n",
      "|    mean_step_reward   | 0.115851834 |\n",
      "|    n_updates          | 2684        |\n",
      "|    policyGradLoss     | -0.0033     |\n",
      "|    value_loss         | 1.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 5513216     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008438742 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.898       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.156       |\n",
      "|    mean_step_reward   | 0.11056622  |\n",
      "|    n_updates          | 2688        |\n",
      "|    policyGradLoss     | -0.00814    |\n",
      "|    value_loss         | 0.868       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 343         |\n",
      "|    total_timesteps    | 5521408     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007777859 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.873       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.137       |\n",
      "|    mean_step_reward   | 0.11607142  |\n",
      "|    n_updates          | 2692        |\n",
      "|    policyGradLoss     | -0.00569    |\n",
      "|    value_loss         | 0.911       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 810          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 353          |\n",
      "|    total_timesteps    | 5529600      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0073982077 |\n",
      "|    entropy_loss       | -1.96        |\n",
      "|    explained_variance | 0.864        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.194        |\n",
      "|    mean_step_reward   | 0.12562487   |\n",
      "|    n_updates          | 2696         |\n",
      "|    policyGradLoss     | -0.00243     |\n",
      "|    value_loss         | 1.34         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 810          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 363          |\n",
      "|    total_timesteps    | 5537792      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0070927227 |\n",
      "|    entropy_loss       | -1.94        |\n",
      "|    explained_variance | 0.903        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.274        |\n",
      "|    mean_step_reward   | 0.12483264   |\n",
      "|    n_updates          | 2700         |\n",
      "|    policyGradLoss     | -0.00831     |\n",
      "|    value_loss         | 1.18         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 374         |\n",
      "|    total_timesteps    | 5545984     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010870834 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.876       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0814      |\n",
      "|    mean_step_reward   | 0.112974584 |\n",
      "|    n_updates          | 2704        |\n",
      "|    policyGradLoss     | -0.00785    |\n",
      "|    value_loss         | 0.64        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 384         |\n",
      "|    total_timesteps    | 5554176     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008425819 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.167       |\n",
      "|    mean_step_reward   | 0.11742809  |\n",
      "|    n_updates          | 2708        |\n",
      "|    policyGradLoss     | -0.00669    |\n",
      "|    value_loss         | 0.856       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 395         |\n",
      "|    total_timesteps    | 5562368     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009221872 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.185       |\n",
      "|    mean_step_reward   | 0.12462987  |\n",
      "|    n_updates          | 2712        |\n",
      "|    policyGradLoss     | -0.00856    |\n",
      "|    value_loss         | 0.758       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 405         |\n",
      "|    total_timesteps    | 5570560     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010405341 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.864       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.116       |\n",
      "|    mean_step_reward   | 0.11187702  |\n",
      "|    n_updates          | 2716        |\n",
      "|    policyGradLoss     | -0.00449    |\n",
      "|    value_loss         | 0.792       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_16.zip\n",
      "[EVAL] Mean Return: 186.451, Best Return: 186.751\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_16_186.45.mp4\n",
      "\n",
      "=== Round 18 | Learn 327680 steps (Total trained: 5570560) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1138    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 5578752 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 939         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 5586944     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009525218 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.166       |\n",
      "|    mean_step_reward   | 0.1172476   |\n",
      "|    n_updates          | 2724        |\n",
      "|    policyGradLoss     | -0.00799    |\n",
      "|    value_loss         | 0.655       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 881         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 5595136     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010421205 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0828      |\n",
      "|    mean_step_reward   | 0.118390836 |\n",
      "|    n_updates          | 2728        |\n",
      "|    policyGradLoss     | -0.00571    |\n",
      "|    value_loss         | 0.634       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 863         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 37          |\n",
      "|    total_timesteps    | 5603328     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008592333 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.941       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.241       |\n",
      "|    mean_step_reward   | 0.12126187  |\n",
      "|    n_updates          | 2732        |\n",
      "|    policyGradLoss     | -0.00895    |\n",
      "|    value_loss         | 0.865       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 851         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 48          |\n",
      "|    total_timesteps    | 5611520     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008391038 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0578      |\n",
      "|    mean_step_reward   | 0.11716297  |\n",
      "|    n_updates          | 2736        |\n",
      "|    policyGradLoss     | -0.00695    |\n",
      "|    value_loss         | 0.538       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 843         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 5619712     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008486955 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.862       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.115       |\n",
      "|    mean_step_reward   | 0.11861975  |\n",
      "|    n_updates          | 2740        |\n",
      "|    policyGradLoss     | -0.00662    |\n",
      "|    value_loss         | 0.809       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 840         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 5627904     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010050332 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.148       |\n",
      "|    mean_step_reward   | 0.11667253  |\n",
      "|    n_updates          | 2744        |\n",
      "|    policyGradLoss     | -0.00642    |\n",
      "|    value_loss         | 0.78        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 835         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 5636096     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010826829 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.157       |\n",
      "|    mean_step_reward   | 0.11446209  |\n",
      "|    n_updates          | 2748        |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.659       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 833         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 88          |\n",
      "|    total_timesteps    | 5644288     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009489016 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.868       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0396      |\n",
      "|    mean_step_reward   | 0.10359341  |\n",
      "|    n_updates          | 2752        |\n",
      "|    policyGradLoss     | -0.00865    |\n",
      "|    value_loss         | 0.567       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 829         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 5652480     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008540502 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.106       |\n",
      "|    mean_step_reward   | 0.123424046 |\n",
      "|    n_updates          | 2756        |\n",
      "|    policyGradLoss     | -0.0072     |\n",
      "|    value_loss         | 0.632       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 829         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 108         |\n",
      "|    total_timesteps    | 5660672     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009622628 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.11        |\n",
      "|    mean_step_reward   | 0.11939187  |\n",
      "|    n_updates          | 2760        |\n",
      "|    policyGradLoss     | -0.00542    |\n",
      "|    value_loss         | 0.752       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 828         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 118         |\n",
      "|    total_timesteps    | 5668864     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009658409 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.865       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.145       |\n",
      "|    mean_step_reward   | 0.10519019  |\n",
      "|    n_updates          | 2764        |\n",
      "|    policyGradLoss     | -0.00424    |\n",
      "|    value_loss         | 0.783       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 128         |\n",
      "|    total_timesteps    | 5677056     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009116052 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0553      |\n",
      "|    mean_step_reward   | 0.11355241  |\n",
      "|    n_updates          | 2768        |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.518       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 5685248     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016106687 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.165       |\n",
      "|    mean_step_reward   | 0.10838774  |\n",
      "|    n_updates          | 2772        |\n",
      "|    policyGradLoss     | -0.00738    |\n",
      "|    value_loss         | 0.828       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 149         |\n",
      "|    total_timesteps    | 5693440     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010731056 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.9         |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0929      |\n",
      "|    mean_step_reward   | 0.107299715 |\n",
      "|    n_updates          | 2776        |\n",
      "|    policyGradLoss     | -0.00696    |\n",
      "|    value_loss         | 0.73        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 159         |\n",
      "|    total_timesteps    | 5701632     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007939125 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.863       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0703      |\n",
      "|    mean_step_reward   | 0.12300472  |\n",
      "|    n_updates          | 2780        |\n",
      "|    policyGradLoss     | -0.00414    |\n",
      "|    value_loss         | 0.859       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 823         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 5709824     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008644123 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.129       |\n",
      "|    mean_step_reward   | 0.12880622  |\n",
      "|    n_updates          | 2784        |\n",
      "|    policyGradLoss     | -0.00405    |\n",
      "|    value_loss         | 0.84        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 5718016     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006207239 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.836       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.37        |\n",
      "|    mean_step_reward   | 0.11628915  |\n",
      "|    n_updates          | 2788        |\n",
      "|    policyGradLoss     | -0.00125    |\n",
      "|    value_loss         | 1.77        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 821          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 189          |\n",
      "|    total_timesteps    | 5726208      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0108700525 |\n",
      "|    entropy_loss       | -1.93        |\n",
      "|    explained_variance | 0.906        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0572       |\n",
      "|    mean_step_reward   | 0.111668214  |\n",
      "|    n_updates          | 2792         |\n",
      "|    policyGradLoss     | -0.00751     |\n",
      "|    value_loss         | 0.787        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 5734400     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008964846 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.154       |\n",
      "|    mean_step_reward   | 0.11411357  |\n",
      "|    n_updates          | 2796        |\n",
      "|    policyGradLoss     | -0.00707    |\n",
      "|    value_loss         | 0.727       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 5742592     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009135224 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.888       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0593      |\n",
      "|    mean_step_reward   | 0.11845335  |\n",
      "|    n_updates          | 2800        |\n",
      "|    policyGradLoss     | -0.00703    |\n",
      "|    value_loss         | 0.699       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 5750784     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011301871 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.822       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.125       |\n",
      "|    mean_step_reward   | 0.105718516 |\n",
      "|    n_updates          | 2804        |\n",
      "|    policyGradLoss     | -0.00355    |\n",
      "|    value_loss         | 0.806       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 5758976     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009448841 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0654      |\n",
      "|    mean_step_reward   | 0.11164188  |\n",
      "|    n_updates          | 2808        |\n",
      "|    policyGradLoss     | -0.00741    |\n",
      "|    value_loss         | 0.737       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 5767168     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009220473 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.891       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.18        |\n",
      "|    mean_step_reward   | 0.1129352   |\n",
      "|    n_updates          | 2812        |\n",
      "|    policyGradLoss     | -0.00672    |\n",
      "|    value_loss         | 0.716       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 5775360     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008460047 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.142       |\n",
      "|    mean_step_reward   | 0.123818174 |\n",
      "|    n_updates          | 2816        |\n",
      "|    policyGradLoss     | -0.00791    |\n",
      "|    value_loss         | 0.761       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 5783552     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009713251 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0742      |\n",
      "|    mean_step_reward   | 0.12302016  |\n",
      "|    n_updates          | 2820        |\n",
      "|    policyGradLoss     | -0.00606    |\n",
      "|    value_loss         | 0.644       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 813          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 271          |\n",
      "|    total_timesteps    | 5791744      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0094179865 |\n",
      "|    entropy_loss       | -1.96        |\n",
      "|    explained_variance | 0.951        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0645       |\n",
      "|    mean_step_reward   | 0.122351415  |\n",
      "|    n_updates          | 2824         |\n",
      "|    policyGradLoss     | -0.00955     |\n",
      "|    value_loss         | 0.566        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 5799936     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010069686 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.903       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.263       |\n",
      "|    mean_step_reward   | 0.111522816 |\n",
      "|    n_updates          | 2828        |\n",
      "|    policyGradLoss     | -0.00464    |\n",
      "|    value_loss         | 1.14        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 812          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 292          |\n",
      "|    total_timesteps    | 5808128      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0098337475 |\n",
      "|    entropy_loss       | -1.93        |\n",
      "|    explained_variance | 0.949        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0122       |\n",
      "|    mean_step_reward   | 0.11608915   |\n",
      "|    n_updates          | 2832         |\n",
      "|    policyGradLoss     | -0.00994     |\n",
      "|    value_loss         | 0.462        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 302         |\n",
      "|    total_timesteps    | 5816320     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010660994 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0357      |\n",
      "|    mean_step_reward   | 0.12535813  |\n",
      "|    n_updates          | 2836        |\n",
      "|    policyGradLoss     | -0.0116     |\n",
      "|    value_loss         | 0.412       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 312         |\n",
      "|    total_timesteps    | 5824512     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009739138 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.192       |\n",
      "|    mean_step_reward   | 0.120026454 |\n",
      "|    n_updates          | 2840        |\n",
      "|    policyGradLoss     | -0.00364    |\n",
      "|    value_loss         | 0.744       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 322         |\n",
      "|    total_timesteps    | 5832704     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009971861 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.904       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0739      |\n",
      "|    mean_step_reward   | 0.113419    |\n",
      "|    n_updates          | 2844        |\n",
      "|    policyGradLoss     | -0.00366    |\n",
      "|    value_loss         | 0.505       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 332         |\n",
      "|    total_timesteps    | 5840896     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010641767 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0576      |\n",
      "|    mean_step_reward   | 0.11902992  |\n",
      "|    n_updates          | 2848        |\n",
      "|    policyGradLoss     | -0.00789    |\n",
      "|    value_loss         | 0.507       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 343         |\n",
      "|    total_timesteps    | 5849088     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008252826 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.049       |\n",
      "|    mean_step_reward   | 0.12940055  |\n",
      "|    n_updates          | 2852        |\n",
      "|    policyGradLoss     | -0.00562    |\n",
      "|    value_loss         | 0.74        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 353         |\n",
      "|    total_timesteps    | 5857280     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010507285 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.11        |\n",
      "|    mean_step_reward   | 0.12211961  |\n",
      "|    n_updates          | 2856        |\n",
      "|    policyGradLoss     | -0.00984    |\n",
      "|    value_loss         | 0.818       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 811          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 363          |\n",
      "|    total_timesteps    | 5865472      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0101851635 |\n",
      "|    entropy_loss       | -1.93        |\n",
      "|    explained_variance | 0.939        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.129        |\n",
      "|    mean_step_reward   | 0.11126895   |\n",
      "|    n_updates          | 2860         |\n",
      "|    policyGradLoss     | -0.00749     |\n",
      "|    value_loss         | 0.825        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 810          |\n",
      "|    iterations         | 37           |\n",
      "|    time_elapsed       | 373          |\n",
      "|    total_timesteps    | 5873664      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0085561555 |\n",
      "|    entropy_loss       | -1.88        |\n",
      "|    explained_variance | 0.877        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.163        |\n",
      "|    mean_step_reward   | 0.112676665  |\n",
      "|    n_updates          | 2864         |\n",
      "|    policyGradLoss     | -0.00666     |\n",
      "|    value_loss         | 0.767        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 383         |\n",
      "|    total_timesteps    | 5881856     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014121303 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0783      |\n",
      "|    mean_step_reward   | 0.119526565 |\n",
      "|    n_updates          | 2868        |\n",
      "|    policyGradLoss     | -0.00874    |\n",
      "|    value_loss         | 0.431       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 394         |\n",
      "|    total_timesteps    | 5890048     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009122524 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.883       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.191       |\n",
      "|    mean_step_reward   | 0.1131548   |\n",
      "|    n_updates          | 2872        |\n",
      "|    policyGradLoss     | -0.00494    |\n",
      "|    value_loss         | 0.873       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 404         |\n",
      "|    total_timesteps    | 5898240     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009403184 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.91        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.111       |\n",
      "|    mean_step_reward   | 0.10972654  |\n",
      "|    n_updates          | 2876        |\n",
      "|    policyGradLoss     | -0.00742    |\n",
      "|    value_loss         | 0.798       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_17.zip\n",
      "[EVAL] Mean Return: 186.889, Best Return: 187.189\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_17_186.89.mp4\n",
      "\n",
      "=== Round 19 | Learn 327680 steps (Total trained: 5898240) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1115    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 5906432 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 931         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 5914624     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009112071 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.174       |\n",
      "|    mean_step_reward   | 0.12543768  |\n",
      "|    n_updates          | 2884        |\n",
      "|    policyGradLoss     | -0.00611    |\n",
      "|    value_loss         | 0.647       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 885         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 5922816     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011247384 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0909      |\n",
      "|    mean_step_reward   | 0.11673689  |\n",
      "|    n_updates          | 2888        |\n",
      "|    policyGradLoss     | -0.0053     |\n",
      "|    value_loss         | 0.582       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 869         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 37          |\n",
      "|    total_timesteps    | 5931008     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008503043 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.129       |\n",
      "|    mean_step_reward   | 0.1143447   |\n",
      "|    n_updates          | 2892        |\n",
      "|    policyGradLoss     | -0.00536    |\n",
      "|    value_loss         | 0.856       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 852         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 48          |\n",
      "|    total_timesteps    | 5939200     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009847966 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.881       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0572      |\n",
      "|    mean_step_reward   | 0.109345876 |\n",
      "|    n_updates          | 2896        |\n",
      "|    policyGradLoss     | -0.00543    |\n",
      "|    value_loss         | 0.687       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 842         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 5947392     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008451026 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.846       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.206       |\n",
      "|    mean_step_reward   | 0.09477785  |\n",
      "|    n_updates          | 2900        |\n",
      "|    policyGradLoss     | -0.00359    |\n",
      "|    value_loss         | 1.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 834         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 5955584     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007475883 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.853       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.129       |\n",
      "|    mean_step_reward   | 0.10668004  |\n",
      "|    n_updates          | 2904        |\n",
      "|    policyGradLoss     | -0.00595    |\n",
      "|    value_loss         | 0.848       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 830         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 5963776     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012510578 |\n",
      "|    entropy_loss       | -1.99       |\n",
      "|    explained_variance | 0.894       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.293       |\n",
      "|    mean_step_reward   | 0.11075614  |\n",
      "|    n_updates          | 2908        |\n",
      "|    policyGradLoss     | -0.00405    |\n",
      "|    value_loss         | 1.14        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 822        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 89         |\n",
      "|    total_timesteps    | 5971968    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01153045 |\n",
      "|    entropy_loss       | -1.93      |\n",
      "|    explained_variance | 0.859      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.141      |\n",
      "|    mean_step_reward   | 0.10567916 |\n",
      "|    n_updates          | 2912       |\n",
      "|    policyGradLoss     | -0.00506   |\n",
      "|    value_loss         | 0.893      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 99          |\n",
      "|    total_timesteps    | 5980160     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.00926563  |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.864       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0853      |\n",
      "|    mean_step_reward   | 0.105139166 |\n",
      "|    n_updates          | 2916        |\n",
      "|    policyGradLoss     | -0.00949    |\n",
      "|    value_loss         | 0.889       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 818        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 110        |\n",
      "|    total_timesteps    | 5988352    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00786937 |\n",
      "|    entropy_loss       | -1.96      |\n",
      "|    explained_variance | 0.875      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.349      |\n",
      "|    mean_step_reward   | 0.11091571 |\n",
      "|    n_updates          | 2920       |\n",
      "|    policyGradLoss     | -0.00704   |\n",
      "|    value_loss         | 1.14       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 5996544     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009903787 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.868       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0896      |\n",
      "|    mean_step_reward   | 0.12147711  |\n",
      "|    n_updates          | 2924        |\n",
      "|    policyGradLoss     | -0.00241    |\n",
      "|    value_loss         | 1.09        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 130         |\n",
      "|    total_timesteps    | 6004736     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01160562  |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.857       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0809      |\n",
      "|    mean_step_reward   | 0.089102894 |\n",
      "|    n_updates          | 2928        |\n",
      "|    policyGradLoss     | -0.00655    |\n",
      "|    value_loss         | 0.712       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 140         |\n",
      "|    total_timesteps    | 6012928     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009017568 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.89        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.162       |\n",
      "|    mean_step_reward   | 0.115273654 |\n",
      "|    n_updates          | 2932        |\n",
      "|    policyGradLoss     | -0.00715    |\n",
      "|    value_loss         | 0.91        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 813          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 150          |\n",
      "|    total_timesteps    | 6021120      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0075115766 |\n",
      "|    entropy_loss       | -1.94        |\n",
      "|    explained_variance | 0.875        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.119        |\n",
      "|    mean_step_reward   | 0.11697729   |\n",
      "|    n_updates          | 2936         |\n",
      "|    policyGradLoss     | -0.00718     |\n",
      "|    value_loss         | 0.722        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 161         |\n",
      "|    total_timesteps    | 6029312     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010044571 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.144       |\n",
      "|    mean_step_reward   | 0.12675437  |\n",
      "|    n_updates          | 2940        |\n",
      "|    policyGradLoss     | -0.00477    |\n",
      "|    value_loss         | 0.811       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 171         |\n",
      "|    total_timesteps    | 6037504     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011390747 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.138       |\n",
      "|    mean_step_reward   | 0.11535498  |\n",
      "|    n_updates          | 2944        |\n",
      "|    policyGradLoss     | -0.0079     |\n",
      "|    value_loss         | 0.727       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 6045696     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010252762 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.112       |\n",
      "|    mean_step_reward   | 0.12310861  |\n",
      "|    n_updates          | 2948        |\n",
      "|    policyGradLoss     | -0.00312    |\n",
      "|    value_loss         | 0.781       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 6053888     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008450812 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.274       |\n",
      "|    mean_step_reward   | 0.11268014  |\n",
      "|    n_updates          | 2952        |\n",
      "|    policyGradLoss     | -0.00472    |\n",
      "|    value_loss         | 1.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 6062080     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009108805 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.137       |\n",
      "|    mean_step_reward   | 0.12945712  |\n",
      "|    n_updates          | 2956        |\n",
      "|    policyGradLoss     | -0.00746    |\n",
      "|    value_loss         | 0.467       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 212         |\n",
      "|    total_timesteps    | 6070272     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008762881 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.903       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0624      |\n",
      "|    mean_step_reward   | 0.11387767  |\n",
      "|    n_updates          | 2960        |\n",
      "|    policyGradLoss     | -0.00625    |\n",
      "|    value_loss         | 0.712       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 6078464     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007678179 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.893       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0777      |\n",
      "|    mean_step_reward   | 0.116995186 |\n",
      "|    n_updates          | 2964        |\n",
      "|    policyGradLoss     | -0.00724    |\n",
      "|    value_loss         | 0.626       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 6086656     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009737147 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0106      |\n",
      "|    mean_step_reward   | 0.12283056  |\n",
      "|    n_updates          | 2968        |\n",
      "|    policyGradLoss     | -0.00949    |\n",
      "|    value_loss         | 0.334       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 6094848     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009982159 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.909       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.189       |\n",
      "|    mean_step_reward   | 0.12443723  |\n",
      "|    n_updates          | 2972        |\n",
      "|    policyGradLoss     | -0.00204    |\n",
      "|    value_loss         | 0.814       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 6103040     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009473939 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0948      |\n",
      "|    mean_step_reward   | 0.13261577  |\n",
      "|    n_updates          | 2976        |\n",
      "|    policyGradLoss     | -0.00529    |\n",
      "|    value_loss         | 0.672       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 6111232     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007114441 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.875       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.228       |\n",
      "|    mean_step_reward   | 0.11900004  |\n",
      "|    n_updates          | 2980        |\n",
      "|    policyGradLoss     | -0.00624    |\n",
      "|    value_loss         | 0.951       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 6119424     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011386821 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.136       |\n",
      "|    mean_step_reward   | 0.119359285 |\n",
      "|    n_updates          | 2984        |\n",
      "|    policyGradLoss     | -0.00708    |\n",
      "|    value_loss         | 0.546       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 6127616     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008920466 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.909       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.104       |\n",
      "|    mean_step_reward   | 0.11677881  |\n",
      "|    n_updates          | 2988        |\n",
      "|    policyGradLoss     | -0.00647    |\n",
      "|    value_loss         | 0.841       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 6135808     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008541452 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.104       |\n",
      "|    mean_step_reward   | 0.1303159   |\n",
      "|    n_updates          | 2992        |\n",
      "|    policyGradLoss     | -0.00956    |\n",
      "|    value_loss         | 0.443       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 806          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 304          |\n",
      "|    total_timesteps    | 6144000      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0075549185 |\n",
      "|    entropy_loss       | -1.94        |\n",
      "|    explained_variance | 0.925        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.107        |\n",
      "|    mean_step_reward   | 0.1284535    |\n",
      "|    n_updates          | 2996         |\n",
      "|    policyGradLoss     | -0.00285     |\n",
      "|    value_loss         | 0.97         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 314         |\n",
      "|    total_timesteps    | 6152192     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010329181 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.114       |\n",
      "|    mean_step_reward   | 0.12399529  |\n",
      "|    n_updates          | 3000        |\n",
      "|    policyGradLoss     | -0.00511    |\n",
      "|    value_loss         | 0.495       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 6160384     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011840042 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0689      |\n",
      "|    mean_step_reward   | 0.12893824  |\n",
      "|    n_updates          | 3004        |\n",
      "|    policyGradLoss     | -0.00666    |\n",
      "|    value_loss         | 0.655       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 335         |\n",
      "|    total_timesteps    | 6168576     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013280582 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0864      |\n",
      "|    mean_step_reward   | 0.11701355  |\n",
      "|    n_updates          | 3008        |\n",
      "|    policyGradLoss     | -0.00901    |\n",
      "|    value_loss         | 0.404       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 345         |\n",
      "|    total_timesteps    | 6176768     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009979567 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.156       |\n",
      "|    mean_step_reward   | 0.11837702  |\n",
      "|    n_updates          | 3012        |\n",
      "|    policyGradLoss     | -0.0118     |\n",
      "|    value_loss         | 0.641       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 355         |\n",
      "|    total_timesteps    | 6184960     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008347828 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0688      |\n",
      "|    mean_step_reward   | 0.11937748  |\n",
      "|    n_updates          | 3016        |\n",
      "|    policyGradLoss     | -0.00719    |\n",
      "|    value_loss         | 0.663       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 365         |\n",
      "|    total_timesteps    | 6193152     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010567788 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.137       |\n",
      "|    mean_step_reward   | 0.11380477  |\n",
      "|    n_updates          | 3020        |\n",
      "|    policyGradLoss     | -0.00643    |\n",
      "|    value_loss         | 0.684       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 375         |\n",
      "|    total_timesteps    | 6201344     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010215316 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.107       |\n",
      "|    mean_step_reward   | 0.12838858  |\n",
      "|    n_updates          | 3024        |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.567       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 386         |\n",
      "|    total_timesteps    | 6209536     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008999149 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0529      |\n",
      "|    mean_step_reward   | 0.14027984  |\n",
      "|    n_updates          | 3028        |\n",
      "|    policyGradLoss     | -0.00995    |\n",
      "|    value_loss         | 0.443       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 396         |\n",
      "|    total_timesteps    | 6217728     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009113659 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.886       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.104       |\n",
      "|    mean_step_reward   | 0.115483984 |\n",
      "|    n_updates          | 3032        |\n",
      "|    policyGradLoss     | -0.00523    |\n",
      "|    value_loss         | 0.839       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 806          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 406          |\n",
      "|    total_timesteps    | 6225920      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0122318305 |\n",
      "|    entropy_loss       | -1.89        |\n",
      "|    explained_variance | 0.935        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.183        |\n",
      "|    mean_step_reward   | 0.13183099   |\n",
      "|    n_updates          | 3036         |\n",
      "|    policyGradLoss     | -0.00605     |\n",
      "|    value_loss         | 0.547        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_18.zip\n",
      "[EVAL] Mean Return: -0.278, Best Return: -0.278\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_18_-0.28.mp4\n",
      "\n",
      "=== Round 20 | Learn 327680 steps (Total trained: 6225920) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1111    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 6234112 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 935         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 6242304     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013216671 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.1         |\n",
      "|    mean_step_reward   | 0.12600796  |\n",
      "|    n_updates          | 3044        |\n",
      "|    policyGradLoss     | -0.0059     |\n",
      "|    value_loss         | 0.453       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 893        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 27         |\n",
      "|    total_timesteps    | 6250496    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00982499 |\n",
      "|    entropy_loss       | -1.89      |\n",
      "|    explained_variance | 0.93       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.138      |\n",
      "|    mean_step_reward   | 0.11187446 |\n",
      "|    n_updates          | 3048       |\n",
      "|    policyGradLoss     | -0.00595   |\n",
      "|    value_loss         | 0.875      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 867          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 37           |\n",
      "|    total_timesteps    | 6258688      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0121979825 |\n",
      "|    entropy_loss       | -1.9         |\n",
      "|    explained_variance | 0.958        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.127        |\n",
      "|    mean_step_reward   | 0.12861225   |\n",
      "|    n_updates          | 3052         |\n",
      "|    policyGradLoss     | -0.00815     |\n",
      "|    value_loss         | 0.609        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 854         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 47          |\n",
      "|    total_timesteps    | 6266880     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009275854 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.134       |\n",
      "|    mean_step_reward   | 0.12597653  |\n",
      "|    n_updates          | 3056        |\n",
      "|    policyGradLoss     | -0.00951    |\n",
      "|    value_loss         | 0.619       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 842         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 6275072     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009946197 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.893       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.17        |\n",
      "|    mean_step_reward   | 0.12381907  |\n",
      "|    n_updates          | 3060        |\n",
      "|    policyGradLoss     | -0.00521    |\n",
      "|    value_loss         | 0.623       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 835         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 6283264     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013349261 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0315      |\n",
      "|    mean_step_reward   | 0.13463612  |\n",
      "|    n_updates          | 3064        |\n",
      "|    policyGradLoss     | -0.00874    |\n",
      "|    value_loss         | 0.449       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 831         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 6291456     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012508349 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.27        |\n",
      "|    mean_step_reward   | 0.1349211   |\n",
      "|    n_updates          | 3068        |\n",
      "|    policyGradLoss     | -0.00375    |\n",
      "|    value_loss         | 0.728       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 89          |\n",
      "|    total_timesteps    | 6299648     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011036261 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.291       |\n",
      "|    mean_step_reward   | 0.1329934   |\n",
      "|    n_updates          | 3072        |\n",
      "|    policyGradLoss     | -0.00949    |\n",
      "|    value_loss         | 0.604       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 823         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 99          |\n",
      "|    total_timesteps    | 6307840     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009593291 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0491      |\n",
      "|    mean_step_reward   | 0.13740255  |\n",
      "|    n_updates          | 3076        |\n",
      "|    policyGradLoss     | -0.00865    |\n",
      "|    value_loss         | 0.484       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 6316032     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011026727 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0983      |\n",
      "|    mean_step_reward   | 0.13459693  |\n",
      "|    n_updates          | 3080        |\n",
      "|    policyGradLoss     | -0.00767    |\n",
      "|    value_loss         | 0.575       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 6324224     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012062611 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0115      |\n",
      "|    mean_step_reward   | 0.12444712  |\n",
      "|    n_updates          | 3084        |\n",
      "|    policyGradLoss     | -0.0106     |\n",
      "|    value_loss         | 0.285       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 129         |\n",
      "|    total_timesteps    | 6332416     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009765777 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.093       |\n",
      "|    mean_step_reward   | 0.14051513  |\n",
      "|    n_updates          | 3088        |\n",
      "|    policyGradLoss     | -0.00659    |\n",
      "|    value_loss         | 0.495       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 139         |\n",
      "|    total_timesteps    | 6340608     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009772435 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.145       |\n",
      "|    mean_step_reward   | 0.1335373   |\n",
      "|    n_updates          | 3092        |\n",
      "|    policyGradLoss     | -0.00609    |\n",
      "|    value_loss         | 0.592       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 149         |\n",
      "|    total_timesteps    | 6348800     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013962536 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00494     |\n",
      "|    mean_step_reward   | 0.12491408  |\n",
      "|    n_updates          | 3096        |\n",
      "|    policyGradLoss     | -0.0106     |\n",
      "|    value_loss         | 0.306       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 159         |\n",
      "|    total_timesteps    | 6356992     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011585013 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0904      |\n",
      "|    mean_step_reward   | 0.14057285  |\n",
      "|    n_updates          | 3100        |\n",
      "|    policyGradLoss     | -0.00367    |\n",
      "|    value_loss         | 0.477       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 6365184     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008757267 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0231      |\n",
      "|    mean_step_reward   | 0.12526366  |\n",
      "|    n_updates          | 3104        |\n",
      "|    policyGradLoss     | -0.00744    |\n",
      "|    value_loss         | 0.343       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 6373376     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012814632 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0514      |\n",
      "|    mean_step_reward   | 0.13695867  |\n",
      "|    n_updates          | 3108        |\n",
      "|    policyGradLoss     | -0.00853    |\n",
      "|    value_loss         | 0.302       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 6381568     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012555467 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.131       |\n",
      "|    mean_step_reward   | 0.13331354  |\n",
      "|    n_updates          | 3112        |\n",
      "|    policyGradLoss     | -0.00905    |\n",
      "|    value_loss         | 0.343       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 6389760     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011006692 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0104      |\n",
      "|    mean_step_reward   | 0.12153272  |\n",
      "|    n_updates          | 3116        |\n",
      "|    policyGradLoss     | -0.00853    |\n",
      "|    value_loss         | 0.343       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 6397952     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011762554 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0375      |\n",
      "|    mean_step_reward   | 0.12471015  |\n",
      "|    n_updates          | 3120        |\n",
      "|    policyGradLoss     | -0.00945    |\n",
      "|    value_loss         | 0.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 6406144     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010620729 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0652      |\n",
      "|    mean_step_reward   | 0.13140874  |\n",
      "|    n_updates          | 3124        |\n",
      "|    policyGradLoss     | -0.0077     |\n",
      "|    value_loss         | 0.425       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 6414336     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012290424 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.149       |\n",
      "|    mean_step_reward   | 0.13652238  |\n",
      "|    n_updates          | 3128        |\n",
      "|    policyGradLoss     | -0.0104     |\n",
      "|    value_loss         | 0.316       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 814          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 241          |\n",
      "|    total_timesteps    | 6422528      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0114056105 |\n",
      "|    entropy_loss       | -1.89        |\n",
      "|    explained_variance | 0.956        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.06         |\n",
      "|    mean_step_reward   | 0.12134686   |\n",
      "|    n_updates          | 3132         |\n",
      "|    policyGradLoss     | -0.00657     |\n",
      "|    value_loss         | 0.364        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 813          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 251          |\n",
      "|    total_timesteps    | 6430720      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0111438185 |\n",
      "|    entropy_loss       | -1.87        |\n",
      "|    explained_variance | 0.967        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.025        |\n",
      "|    mean_step_reward   | 0.1264113    |\n",
      "|    n_updates          | 3136         |\n",
      "|    policyGradLoss     | -0.00846     |\n",
      "|    value_loss         | 0.324        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 6438912     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011111477 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0185      |\n",
      "|    mean_step_reward   | 0.142063    |\n",
      "|    n_updates          | 3140        |\n",
      "|    policyGradLoss     | -0.0091     |\n",
      "|    value_loss         | 0.231       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 6447104     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010680094 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.191       |\n",
      "|    mean_step_reward   | 0.11686804  |\n",
      "|    n_updates          | 3144        |\n",
      "|    policyGradLoss     | -0.00517    |\n",
      "|    value_loss         | 0.793       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 812        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 282        |\n",
      "|    total_timesteps    | 6455296    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00911386 |\n",
      "|    entropy_loss       | -1.86      |\n",
      "|    explained_variance | 0.956      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.086      |\n",
      "|    mean_step_reward   | 0.13274676 |\n",
      "|    n_updates          | 3148       |\n",
      "|    policyGradLoss     | -0.00348   |\n",
      "|    value_loss         | 0.577      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 6463488     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011402043 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0715      |\n",
      "|    mean_step_reward   | 0.14069504  |\n",
      "|    n_updates          | 3152        |\n",
      "|    policyGradLoss     | -0.00482    |\n",
      "|    value_loss         | 0.378       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 302         |\n",
      "|    total_timesteps    | 6471680     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012144584 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00372     |\n",
      "|    mean_step_reward   | 0.13219386  |\n",
      "|    n_updates          | 3156        |\n",
      "|    policyGradLoss     | -0.00508    |\n",
      "|    value_loss         | 0.267       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 312         |\n",
      "|    total_timesteps    | 6479872     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.0107367   |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.94        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.117       |\n",
      "|    mean_step_reward   | 0.123457044 |\n",
      "|    n_updates          | 3160        |\n",
      "|    policyGradLoss     | -0.0061     |\n",
      "|    value_loss         | 0.717       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 322         |\n",
      "|    total_timesteps    | 6488064     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012424691 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00121    |\n",
      "|    mean_step_reward   | 0.13527939  |\n",
      "|    n_updates          | 3164        |\n",
      "|    policyGradLoss     | -0.00951    |\n",
      "|    value_loss         | 0.236       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 6496256     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008107604 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.081       |\n",
      "|    mean_step_reward   | 0.13482657  |\n",
      "|    n_updates          | 3168        |\n",
      "|    policyGradLoss     | -0.00111    |\n",
      "|    value_loss         | 0.625       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 343         |\n",
      "|    total_timesteps    | 6504448     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010626117 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.046       |\n",
      "|    mean_step_reward   | 0.13594043  |\n",
      "|    n_updates          | 3172        |\n",
      "|    policyGradLoss     | -0.00911    |\n",
      "|    value_loss         | 0.318       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 353         |\n",
      "|    total_timesteps    | 6512640     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008647554 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0374      |\n",
      "|    mean_step_reward   | 0.12693325  |\n",
      "|    n_updates          | 3176        |\n",
      "|    policyGradLoss     | -0.00624    |\n",
      "|    value_loss         | 0.702       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 363         |\n",
      "|    total_timesteps    | 6520832     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012599183 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0709      |\n",
      "|    mean_step_reward   | 0.13328399  |\n",
      "|    n_updates          | 3180        |\n",
      "|    policyGradLoss     | -0.00592    |\n",
      "|    value_loss         | 0.831       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 374         |\n",
      "|    total_timesteps    | 6529024     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011607885 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.095       |\n",
      "|    mean_step_reward   | 0.12014218  |\n",
      "|    n_updates          | 3184        |\n",
      "|    policyGradLoss     | -0.0073     |\n",
      "|    value_loss         | 0.579       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 384         |\n",
      "|    total_timesteps    | 6537216     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009555245 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0203      |\n",
      "|    mean_step_reward   | 0.12746742  |\n",
      "|    n_updates          | 3188        |\n",
      "|    policyGradLoss     | -0.00712    |\n",
      "|    value_loss         | 0.355       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 395         |\n",
      "|    total_timesteps    | 6545408     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008343486 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0942      |\n",
      "|    mean_step_reward   | 0.12753917  |\n",
      "|    n_updates          | 3192        |\n",
      "|    policyGradLoss     | -0.0046     |\n",
      "|    value_loss         | 0.629       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 405         |\n",
      "|    total_timesteps    | 6553600     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011847078 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0233      |\n",
      "|    mean_step_reward   | 0.13833185  |\n",
      "|    n_updates          | 3196        |\n",
      "|    policyGradLoss     | -0.00915    |\n",
      "|    value_loss         | 0.285       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_19.zip\n",
      "[EVAL] Mean Return: 188.412, Best Return: 188.712\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_19_188.41.mp4\n",
      "\n",
      "=== Round 21 | Learn 327680 steps (Total trained: 6553600) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1124    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 6561792 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 949         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 6569984     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009955311 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.315       |\n",
      "|    mean_step_reward   | 0.13553293  |\n",
      "|    n_updates          | 3204        |\n",
      "|    policyGradLoss     | -0.00572    |\n",
      "|    value_loss         | 0.81        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 900         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 6578176     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013017895 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0124      |\n",
      "|    mean_step_reward   | 0.12824163  |\n",
      "|    n_updates          | 3208        |\n",
      "|    policyGradLoss     | -0.00789    |\n",
      "|    value_loss         | 0.405       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 872         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 37          |\n",
      "|    total_timesteps    | 6586368     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009223324 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.871       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.535       |\n",
      "|    mean_step_reward   | 0.12795308  |\n",
      "|    n_updates          | 3212        |\n",
      "|    policyGradLoss     | -0.00241    |\n",
      "|    value_loss         | 1.6         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 855          |\n",
      "|    iterations         | 5            |\n",
      "|    time_elapsed       | 47           |\n",
      "|    total_timesteps    | 6594560      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0091013275 |\n",
      "|    entropy_loss       | -1.9         |\n",
      "|    explained_variance | 0.86         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.241        |\n",
      "|    mean_step_reward   | 0.108887464  |\n",
      "|    n_updates          | 3216         |\n",
      "|    policyGradLoss     | -0.00269     |\n",
      "|    value_loss         | 1.08         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 842         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 6602752     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008838426 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.122       |\n",
      "|    mean_step_reward   | 0.13422902  |\n",
      "|    n_updates          | 3220        |\n",
      "|    policyGradLoss     | -0.00553    |\n",
      "|    value_loss         | 0.616       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 835         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 6610944     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009832276 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.898       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.371       |\n",
      "|    mean_step_reward   | 0.12967087  |\n",
      "|    n_updates          | 3224        |\n",
      "|    policyGradLoss     | -0.00441    |\n",
      "|    value_loss         | 1.6         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 829         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 79          |\n",
      "|    total_timesteps    | 6619136     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009967504 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0369      |\n",
      "|    mean_step_reward   | 0.12892318  |\n",
      "|    n_updates          | 3228        |\n",
      "|    policyGradLoss     | -0.00721    |\n",
      "|    value_loss         | 0.597       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 89          |\n",
      "|    total_timesteps    | 6627328     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008109238 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.858       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.133       |\n",
      "|    mean_step_reward   | 0.12905985  |\n",
      "|    n_updates          | 3232        |\n",
      "|    policyGradLoss     | -0.000949   |\n",
      "|    value_loss         | 0.864       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 99          |\n",
      "|    total_timesteps    | 6635520     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010658566 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.194       |\n",
      "|    mean_step_reward   | 0.13311398  |\n",
      "|    n_updates          | 3236        |\n",
      "|    policyGradLoss     | -0.00668    |\n",
      "|    value_loss         | 0.539       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 6643712     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010312064 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.13        |\n",
      "|    mean_step_reward   | 0.14389002  |\n",
      "|    n_updates          | 3240        |\n",
      "|    policyGradLoss     | -0.004      |\n",
      "|    value_loss         | 0.715       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 6651904     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014249012 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0217     |\n",
      "|    mean_step_reward   | 0.12871635  |\n",
      "|    n_updates          | 3244        |\n",
      "|    policyGradLoss     | -0.0089     |\n",
      "|    value_loss         | 0.236       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 130         |\n",
      "|    total_timesteps    | 6660096     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009179004 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.158       |\n",
      "|    mean_step_reward   | 0.13064477  |\n",
      "|    n_updates          | 3248        |\n",
      "|    policyGradLoss     | -0.00288    |\n",
      "|    value_loss         | 0.9         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 140         |\n",
      "|    total_timesteps    | 6668288     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01094931  |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0581      |\n",
      "|    mean_step_reward   | 0.123496965 |\n",
      "|    n_updates          | 3252        |\n",
      "|    policyGradLoss     | -0.00474    |\n",
      "|    value_loss         | 0.639       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 150         |\n",
      "|    total_timesteps    | 6676480     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012827478 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0289      |\n",
      "|    mean_step_reward   | 0.12804225  |\n",
      "|    n_updates          | 3256        |\n",
      "|    policyGradLoss     | -0.0075     |\n",
      "|    value_loss         | 0.422       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 6684672     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010146009 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.205       |\n",
      "|    mean_step_reward   | 0.1288018   |\n",
      "|    n_updates          | 3260        |\n",
      "|    policyGradLoss     | -0.00207    |\n",
      "|    value_loss         | 0.849       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 814          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 170          |\n",
      "|    total_timesteps    | 6692864      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0104715675 |\n",
      "|    entropy_loss       | -1.89        |\n",
      "|    explained_variance | 0.905        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.168        |\n",
      "|    mean_step_reward   | 0.11824682   |\n",
      "|    n_updates          | 3264         |\n",
      "|    policyGradLoss     | -0.00605     |\n",
      "|    value_loss         | 0.85         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 6701056     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010683892 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0723      |\n",
      "|    mean_step_reward   | 0.12883791  |\n",
      "|    n_updates          | 3268        |\n",
      "|    policyGradLoss     | -0.00836    |\n",
      "|    value_loss         | 0.533       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 6709248     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010482831 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.157       |\n",
      "|    mean_step_reward   | 0.13442108  |\n",
      "|    n_updates          | 3272        |\n",
      "|    policyGradLoss     | -0.00154    |\n",
      "|    value_loss         | 0.851       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 6717440     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007359152 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.854       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.218       |\n",
      "|    mean_step_reward   | 0.124538384 |\n",
      "|    n_updates          | 3276        |\n",
      "|    policyGradLoss     | -0.00124    |\n",
      "|    value_loss         | 1.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 6725632     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008140378 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.882       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.134       |\n",
      "|    mean_step_reward   | 0.11746525  |\n",
      "|    n_updates          | 3280        |\n",
      "|    policyGradLoss     | -0.00561    |\n",
      "|    value_loss         | 0.924       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 812        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 221        |\n",
      "|    total_timesteps    | 6733824    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00885234 |\n",
      "|    entropy_loss       | -1.92      |\n",
      "|    explained_variance | 0.895      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.124      |\n",
      "|    mean_step_reward   | 0.12701225 |\n",
      "|    n_updates          | 3284       |\n",
      "|    policyGradLoss     | -0.0022    |\n",
      "|    value_loss         | 1.05       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 6742016     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006891056 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.877       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.151       |\n",
      "|    mean_step_reward   | 0.12563467  |\n",
      "|    n_updates          | 3288        |\n",
      "|    policyGradLoss     | -0.00349    |\n",
      "|    value_loss         | 0.995       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 6750208     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007307507 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.879       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.062       |\n",
      "|    mean_step_reward   | 0.12436295  |\n",
      "|    n_updates          | 3292        |\n",
      "|    policyGradLoss     | -0.00353    |\n",
      "|    value_loss         | 0.761       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 6758400     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008398454 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0468      |\n",
      "|    mean_step_reward   | 0.13306484  |\n",
      "|    n_updates          | 3296        |\n",
      "|    policyGradLoss     | -0.0067     |\n",
      "|    value_loss         | 0.647       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 811        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 262        |\n",
      "|    total_timesteps    | 6766592    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00864166 |\n",
      "|    entropy_loss       | -1.93      |\n",
      "|    explained_variance | 0.947      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.358      |\n",
      "|    mean_step_reward   | 0.13054173 |\n",
      "|    n_updates          | 3300       |\n",
      "|    policyGradLoss     | -0.00598   |\n",
      "|    value_loss         | 0.831      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 6774784     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008759994 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0301      |\n",
      "|    mean_step_reward   | 0.13044322  |\n",
      "|    n_updates          | 3304        |\n",
      "|    policyGradLoss     | -0.011      |\n",
      "|    value_loss         | 0.433       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 6782976     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006350016 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0184      |\n",
      "|    mean_step_reward   | 0.13895115  |\n",
      "|    n_updates          | 3308        |\n",
      "|    policyGradLoss     | -0.00793    |\n",
      "|    value_loss         | 0.397       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 6791168     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008297573 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0946      |\n",
      "|    mean_step_reward   | 0.1293775   |\n",
      "|    n_updates          | 3312        |\n",
      "|    policyGradLoss     | -0.00707    |\n",
      "|    value_loss         | 1           |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 303         |\n",
      "|    total_timesteps    | 6799360     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009056808 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.898       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0827      |\n",
      "|    mean_step_reward   | 0.1285786   |\n",
      "|    n_updates          | 3316        |\n",
      "|    policyGradLoss     | -0.00452    |\n",
      "|    value_loss         | 0.8         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 313         |\n",
      "|    total_timesteps    | 6807552     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009736162 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.207       |\n",
      "|    mean_step_reward   | 0.13773498  |\n",
      "|    n_updates          | 3320        |\n",
      "|    policyGradLoss     | -0.00511    |\n",
      "|    value_loss         | 0.732       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 323         |\n",
      "|    total_timesteps    | 6815744     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010543894 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.128       |\n",
      "|    mean_step_reward   | 0.123222224 |\n",
      "|    n_updates          | 3324        |\n",
      "|    policyGradLoss     | -0.00715    |\n",
      "|    value_loss         | 0.741       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 6823936     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010757383 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0928      |\n",
      "|    mean_step_reward   | 0.12556246  |\n",
      "|    n_updates          | 3328        |\n",
      "|    policyGradLoss     | -0.00686    |\n",
      "|    value_loss         | 0.663       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 808        |\n",
      "|    iterations         | 34         |\n",
      "|    time_elapsed       | 344        |\n",
      "|    total_timesteps    | 6832128    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01014348 |\n",
      "|    entropy_loss       | -1.91      |\n",
      "|    explained_variance | 0.909      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.141      |\n",
      "|    mean_step_reward   | 0.11765506 |\n",
      "|    n_updates          | 3332       |\n",
      "|    policyGradLoss     | -0.00506   |\n",
      "|    value_loss         | 0.784      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 354         |\n",
      "|    total_timesteps    | 6840320     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008943603 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0682      |\n",
      "|    mean_step_reward   | 0.124019906 |\n",
      "|    n_updates          | 3336        |\n",
      "|    policyGradLoss     | -0.00773    |\n",
      "|    value_loss         | 0.685       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 364         |\n",
      "|    total_timesteps    | 6848512     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008900483 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.845       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.184       |\n",
      "|    mean_step_reward   | 0.10334615  |\n",
      "|    n_updates          | 3340        |\n",
      "|    policyGradLoss     | -0.00238    |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 374         |\n",
      "|    total_timesteps    | 6856704     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010217939 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.915       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.175       |\n",
      "|    mean_step_reward   | 0.11414995  |\n",
      "|    n_updates          | 3344        |\n",
      "|    policyGradLoss     | -0.00444    |\n",
      "|    value_loss         | 0.854       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 808        |\n",
      "|    iterations         | 38         |\n",
      "|    time_elapsed       | 385        |\n",
      "|    total_timesteps    | 6864896    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01089908 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.927      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0642     |\n",
      "|    mean_step_reward   | 0.13193917 |\n",
      "|    n_updates          | 3348       |\n",
      "|    policyGradLoss     | -0.00328   |\n",
      "|    value_loss         | 0.674      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 395         |\n",
      "|    total_timesteps    | 6873088     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012165311 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.2         |\n",
      "|    mean_step_reward   | 0.14462546  |\n",
      "|    n_updates          | 3352        |\n",
      "|    policyGradLoss     | 0.000945    |\n",
      "|    value_loss         | 0.9         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 807        |\n",
      "|    iterations         | 40         |\n",
      "|    time_elapsed       | 405        |\n",
      "|    total_timesteps    | 6881280    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01300111 |\n",
      "|    entropy_loss       | -1.91      |\n",
      "|    explained_variance | 0.926      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.146      |\n",
      "|    mean_step_reward   | 0.11493121 |\n",
      "|    n_updates          | 3356       |\n",
      "|    policyGradLoss     | -0.00582   |\n",
      "|    value_loss         | 0.51       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_20.zip\n",
      "[EVAL] Mean Return: 188.004, Best Return: 188.304\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_20_188.00.mp4\n",
      "\n",
      "=== Round 22 | Learn 327680 steps (Total trained: 6881280) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1082    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 6889472 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 925         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 6897664     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008886844 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0368      |\n",
      "|    mean_step_reward   | 0.11615516  |\n",
      "|    n_updates          | 3364        |\n",
      "|    policyGradLoss     | -0.00438    |\n",
      "|    value_loss         | 0.508       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 876         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 6905856     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009068327 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.172       |\n",
      "|    mean_step_reward   | 0.1267665   |\n",
      "|    n_updates          | 3368        |\n",
      "|    policyGradLoss     | -0.00561    |\n",
      "|    value_loss         | 0.99        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 852         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 6914048     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008346954 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.112       |\n",
      "|    mean_step_reward   | 0.1369634   |\n",
      "|    n_updates          | 3372        |\n",
      "|    policyGradLoss     | -0.00561    |\n",
      "|    value_loss         | 0.634       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 840         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 48          |\n",
      "|    total_timesteps    | 6922240     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009648837 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.906       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.119       |\n",
      "|    mean_step_reward   | 0.11945651  |\n",
      "|    n_updates          | 3376        |\n",
      "|    policyGradLoss     | -0.00347    |\n",
      "|    value_loss         | 1.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 836         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 6930432     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.00899201  |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.856       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.131       |\n",
      "|    mean_step_reward   | 0.117574334 |\n",
      "|    n_updates          | 3380        |\n",
      "|    policyGradLoss     | -0.00511    |\n",
      "|    value_loss         | 1           |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 833         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 6938624     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008643299 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.017       |\n",
      "|    mean_step_reward   | 0.11734079  |\n",
      "|    n_updates          | 3384        |\n",
      "|    policyGradLoss     | -0.00762    |\n",
      "|    value_loss         | 0.379       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 830          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 78           |\n",
      "|    total_timesteps    | 6946816      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0069159493 |\n",
      "|    entropy_loss       | -1.9         |\n",
      "|    explained_variance | 0.859        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.149        |\n",
      "|    mean_step_reward   | 0.11765945   |\n",
      "|    n_updates          | 3388         |\n",
      "|    policyGradLoss     | -0.00534     |\n",
      "|    value_loss         | 0.936        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 826        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 89         |\n",
      "|    total_timesteps    | 6955008    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00799929 |\n",
      "|    entropy_loss       | -1.93      |\n",
      "|    explained_variance | 0.892      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.392      |\n",
      "|    mean_step_reward   | 0.12691773 |\n",
      "|    n_updates          | 3392       |\n",
      "|    policyGradLoss     | -0.00362   |\n",
      "|    value_loss         | 1.05       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 824          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 99           |\n",
      "|    total_timesteps    | 6963200      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0081515815 |\n",
      "|    entropy_loss       | -1.94        |\n",
      "|    explained_variance | 0.922        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0821       |\n",
      "|    mean_step_reward   | 0.12586385   |\n",
      "|    n_updates          | 3396         |\n",
      "|    policyGradLoss     | -0.00481     |\n",
      "|    value_loss         | 0.646        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 6971392     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008930821 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.891       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.181       |\n",
      "|    mean_step_reward   | 0.11745132  |\n",
      "|    n_updates          | 3400        |\n",
      "|    policyGradLoss     | -0.00477    |\n",
      "|    value_loss         | 1.06        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 6979584     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008373095 |\n",
      "|    entropy_loss       | -1.96       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.273       |\n",
      "|    mean_step_reward   | 0.13003266  |\n",
      "|    n_updates          | 3404        |\n",
      "|    policyGradLoss     | -0.00118    |\n",
      "|    value_loss         | 1.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 129         |\n",
      "|    total_timesteps    | 6987776     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007722742 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.873       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.29        |\n",
      "|    mean_step_reward   | 0.12338615  |\n",
      "|    n_updates          | 3408        |\n",
      "|    policyGradLoss     | -0.0052     |\n",
      "|    value_loss         | 1.11        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 140         |\n",
      "|    total_timesteps    | 6995968     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007510339 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.848       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0939      |\n",
      "|    mean_step_reward   | 0.10574341  |\n",
      "|    n_updates          | 3412        |\n",
      "|    policyGradLoss     | -0.00542    |\n",
      "|    value_loss         | 0.857       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 150         |\n",
      "|    total_timesteps    | 7004160     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008112686 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.815       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.118       |\n",
      "|    mean_step_reward   | 0.11326182  |\n",
      "|    n_updates          | 3416        |\n",
      "|    policyGradLoss     | -0.00462    |\n",
      "|    value_loss         | 0.818       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 7012352     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007939265 |\n",
      "|    entropy_loss       | -2          |\n",
      "|    explained_variance | 0.815       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.116       |\n",
      "|    mean_step_reward   | 0.09963198  |\n",
      "|    n_updates          | 3420        |\n",
      "|    policyGradLoss     | -0.00309    |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 7020544     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007732029 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.899       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0444      |\n",
      "|    mean_step_reward   | 0.1129065   |\n",
      "|    n_updates          | 3424        |\n",
      "|    policyGradLoss     | -0.00563    |\n",
      "|    value_loss         | 0.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 7028736     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008116748 |\n",
      "|    entropy_loss       | -1.97       |\n",
      "|    explained_variance | 0.814       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.313       |\n",
      "|    mean_step_reward   | 0.10957448  |\n",
      "|    n_updates          | 3428        |\n",
      "|    policyGradLoss     | -0.00225    |\n",
      "|    value_loss         | 1.68        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 7036928     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007883804 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.907       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.131       |\n",
      "|    mean_step_reward   | 0.1217353   |\n",
      "|    n_updates          | 3432        |\n",
      "|    policyGradLoss     | -0.00476    |\n",
      "|    value_loss         | 0.889       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 7045120     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009752793 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.824       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.105       |\n",
      "|    mean_step_reward   | 0.11390632  |\n",
      "|    n_updates          | 3436        |\n",
      "|    policyGradLoss     | -0.00449    |\n",
      "|    value_loss         | 0.639       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 7053312     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009156464 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.843       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.166       |\n",
      "|    mean_step_reward   | 0.11751156  |\n",
      "|    n_updates          | 3440        |\n",
      "|    policyGradLoss     | -0.00259    |\n",
      "|    value_loss         | 1.52        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 7061504     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008431177 |\n",
      "|    entropy_loss       | -1.98       |\n",
      "|    explained_variance | 0.916       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.357       |\n",
      "|    mean_step_reward   | 0.11988433  |\n",
      "|    n_updates          | 3444        |\n",
      "|    policyGradLoss     | -0.00579    |\n",
      "|    value_loss         | 0.913       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 7069696     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006653047 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.924       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0467      |\n",
      "|    mean_step_reward   | 0.12585242  |\n",
      "|    n_updates          | 3448        |\n",
      "|    policyGradLoss     | -0.0059     |\n",
      "|    value_loss         | 0.617       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 813          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 241          |\n",
      "|    total_timesteps    | 7077888      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0061405385 |\n",
      "|    entropy_loss       | -1.95        |\n",
      "|    explained_variance | 0.9          |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.143        |\n",
      "|    mean_step_reward   | 0.11432352   |\n",
      "|    n_updates          | 3452         |\n",
      "|    policyGradLoss     | -0.00578     |\n",
      "|    value_loss         | 1.03         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 814          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 251          |\n",
      "|    total_timesteps    | 7086080      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0064039263 |\n",
      "|    entropy_loss       | -1.94        |\n",
      "|    explained_variance | 0.914        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.143        |\n",
      "|    mean_step_reward   | 0.12458813   |\n",
      "|    n_updates          | 3456         |\n",
      "|    policyGradLoss     | -0.00609     |\n",
      "|    value_loss         | 0.806        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 7094272     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007877491 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0941      |\n",
      "|    mean_step_reward   | 0.12069174  |\n",
      "|    n_updates          | 3460        |\n",
      "|    policyGradLoss     | -0.00973    |\n",
      "|    value_loss         | 0.831       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 814          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 271          |\n",
      "|    total_timesteps    | 7102464      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0086693885 |\n",
      "|    entropy_loss       | -1.95        |\n",
      "|    explained_variance | 0.934        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0465       |\n",
      "|    mean_step_reward   | 0.13159838   |\n",
      "|    n_updates          | 3464         |\n",
      "|    policyGradLoss     | -0.00766     |\n",
      "|    value_loss         | 0.525        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 281         |\n",
      "|    total_timesteps    | 7110656     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007631699 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.122       |\n",
      "|    mean_step_reward   | 0.12831485  |\n",
      "|    n_updates          | 3468        |\n",
      "|    policyGradLoss     | -0.00715    |\n",
      "|    value_loss         | 0.735       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 291         |\n",
      "|    total_timesteps    | 7118848     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008148206 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0807      |\n",
      "|    mean_step_reward   | 0.1262436   |\n",
      "|    n_updates          | 3472        |\n",
      "|    policyGradLoss     | -0.00613    |\n",
      "|    value_loss         | 0.681       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 302         |\n",
      "|    total_timesteps    | 7127040     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009794949 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.124       |\n",
      "|    mean_step_reward   | 0.13176107  |\n",
      "|    n_updates          | 3476        |\n",
      "|    policyGradLoss     | -0.00948    |\n",
      "|    value_loss         | 0.555       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 814        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 311        |\n",
      "|    total_timesteps    | 7135232    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01409233 |\n",
      "|    entropy_loss       | -1.93      |\n",
      "|    explained_variance | 0.973      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.161      |\n",
      "|    mean_step_reward   | 0.13455278 |\n",
      "|    n_updates          | 3480       |\n",
      "|    policyGradLoss     | -0.00832   |\n",
      "|    value_loss         | 0.366      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 322         |\n",
      "|    total_timesteps    | 7143424     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009795117 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00249     |\n",
      "|    mean_step_reward   | 0.12610154  |\n",
      "|    n_updates          | 3484        |\n",
      "|    policyGradLoss     | -0.00995    |\n",
      "|    value_loss         | 0.199       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 332         |\n",
      "|    total_timesteps    | 7151616     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009584007 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0244      |\n",
      "|    mean_step_reward   | 0.13277584  |\n",
      "|    n_updates          | 3488        |\n",
      "|    policyGradLoss     | -0.00685    |\n",
      "|    value_loss         | 0.363       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 342         |\n",
      "|    total_timesteps    | 7159808     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008041586 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.11        |\n",
      "|    mean_step_reward   | 0.11990686  |\n",
      "|    n_updates          | 3492        |\n",
      "|    policyGradLoss     | -0.00611    |\n",
      "|    value_loss         | 0.658       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 352         |\n",
      "|    total_timesteps    | 7168000     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008102208 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.144       |\n",
      "|    mean_step_reward   | 0.12567958  |\n",
      "|    n_updates          | 3496        |\n",
      "|    policyGradLoss     | -0.00726    |\n",
      "|    value_loss         | 0.596       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 362         |\n",
      "|    total_timesteps    | 7176192     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009545374 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0902      |\n",
      "|    mean_step_reward   | 0.1333135   |\n",
      "|    n_updates          | 3500        |\n",
      "|    policyGradLoss     | -0.011      |\n",
      "|    value_loss         | 0.412       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 373         |\n",
      "|    total_timesteps    | 7184384     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007978944 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.237       |\n",
      "|    mean_step_reward   | 0.12621984  |\n",
      "|    n_updates          | 3504        |\n",
      "|    policyGradLoss     | -0.00512    |\n",
      "|    value_loss         | 0.778       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 383         |\n",
      "|    total_timesteps    | 7192576     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013376515 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00599     |\n",
      "|    mean_step_reward   | 0.1213269   |\n",
      "|    n_updates          | 3508        |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.34        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 393         |\n",
      "|    total_timesteps    | 7200768     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008785156 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0509      |\n",
      "|    mean_step_reward   | 0.14800486  |\n",
      "|    n_updates          | 3512        |\n",
      "|    policyGradLoss     | -0.00492    |\n",
      "|    value_loss         | 0.476       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 403         |\n",
      "|    total_timesteps    | 7208960     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009924199 |\n",
      "|    entropy_loss       | -1.95       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0204      |\n",
      "|    mean_step_reward   | 0.12111959  |\n",
      "|    n_updates          | 3516        |\n",
      "|    policyGradLoss     | -0.00853    |\n",
      "|    value_loss         | 0.282       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_21.zip\n",
      "[EVAL] Mean Return: 162.465, Best Return: 162.715\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_21_162.47.mp4\n",
      "\n",
      "=== Round 23 | Learn 327680 steps (Total trained: 7208960) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1091    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 7217152 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 915         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 7225344     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008005666 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0915      |\n",
      "|    mean_step_reward   | 0.13999669  |\n",
      "|    n_updates          | 3524        |\n",
      "|    policyGradLoss     | -0.00674    |\n",
      "|    value_loss         | 0.498       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 873         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 7233536     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016476814 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0292      |\n",
      "|    mean_step_reward   | 0.12044117  |\n",
      "|    n_updates          | 3528        |\n",
      "|    policyGradLoss     | -0.00849    |\n",
      "|    value_loss         | 0.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 860         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 7241728     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010880105 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0199     |\n",
      "|    mean_step_reward   | 0.1306063   |\n",
      "|    n_updates          | 3532        |\n",
      "|    policyGradLoss     | -0.00956    |\n",
      "|    value_loss         | 0.227       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 851        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 48         |\n",
      "|    total_timesteps    | 7249920    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01379355 |\n",
      "|    entropy_loss       | -1.86      |\n",
      "|    explained_variance | 0.974      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.25       |\n",
      "|    mean_step_reward   | 0.1343908  |\n",
      "|    n_updates          | 3536       |\n",
      "|    policyGradLoss     | -0.00675   |\n",
      "|    value_loss         | 0.642      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 841         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 7258112     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010494924 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0102      |\n",
      "|    mean_step_reward   | 0.13684511  |\n",
      "|    n_updates          | 3540        |\n",
      "|    policyGradLoss     | -0.00421    |\n",
      "|    value_loss         | 0.391       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 833         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 7266304     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009098195 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0162      |\n",
      "|    mean_step_reward   | 0.14137104  |\n",
      "|    n_updates          | 3544        |\n",
      "|    policyGradLoss     | -0.00229    |\n",
      "|    value_loss         | 0.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 829         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 7274496     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009425336 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0865      |\n",
      "|    mean_step_reward   | 0.13831031  |\n",
      "|    n_updates          | 3548        |\n",
      "|    policyGradLoss     | -0.00647    |\n",
      "|    value_loss         | 0.358       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 89          |\n",
      "|    total_timesteps    | 7282688     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009651871 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.2         |\n",
      "|    mean_step_reward   | 0.1407974   |\n",
      "|    n_updates          | 3552        |\n",
      "|    policyGradLoss     | -0.00775    |\n",
      "|    value_loss         | 0.62        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 99          |\n",
      "|    total_timesteps    | 7290880     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011720528 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0586      |\n",
      "|    mean_step_reward   | 0.13401717  |\n",
      "|    n_updates          | 3556        |\n",
      "|    policyGradLoss     | -0.00641    |\n",
      "|    value_loss         | 0.428       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 7299072     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009840624 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00234     |\n",
      "|    mean_step_reward   | 0.13589478  |\n",
      "|    n_updates          | 3560        |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 7307264     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008850262 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0754      |\n",
      "|    mean_step_reward   | 0.13958277  |\n",
      "|    n_updates          | 3564        |\n",
      "|    policyGradLoss     | -0.00855    |\n",
      "|    value_loss         | 0.479       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 130         |\n",
      "|    total_timesteps    | 7315456     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012355633 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.171       |\n",
      "|    mean_step_reward   | 0.13343169  |\n",
      "|    n_updates          | 3568        |\n",
      "|    policyGradLoss     | -0.00783    |\n",
      "|    value_loss         | 0.689       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 140         |\n",
      "|    total_timesteps    | 7323648     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012163483 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.215       |\n",
      "|    mean_step_reward   | 0.12452924  |\n",
      "|    n_updates          | 3572        |\n",
      "|    policyGradLoss     | -0.0065     |\n",
      "|    value_loss         | 0.712       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 150         |\n",
      "|    total_timesteps    | 7331840     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010272235 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.133       |\n",
      "|    mean_step_reward   | 0.12959197  |\n",
      "|    n_updates          | 3576        |\n",
      "|    policyGradLoss     | -0.00788    |\n",
      "|    value_loss         | 0.499       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 7340032     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009392759 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.137       |\n",
      "|    mean_step_reward   | 0.1408062   |\n",
      "|    n_updates          | 3580        |\n",
      "|    policyGradLoss     | -0.0077     |\n",
      "|    value_loss         | 0.561       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 7348224     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011140505 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0169      |\n",
      "|    mean_step_reward   | 0.14745373  |\n",
      "|    n_updates          | 3584        |\n",
      "|    policyGradLoss     | -0.0121     |\n",
      "|    value_loss         | 0.209       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 7356416     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011602575 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00885    |\n",
      "|    mean_step_reward   | 0.14167301  |\n",
      "|    n_updates          | 3588        |\n",
      "|    policyGradLoss     | -0.0114     |\n",
      "|    value_loss         | 0.236       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 815        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 190        |\n",
      "|    total_timesteps    | 7364608    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0135626  |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0289     |\n",
      "|    mean_step_reward   | 0.14320703 |\n",
      "|    n_updates          | 3592       |\n",
      "|    policyGradLoss     | -0.0129    |\n",
      "|    value_loss         | 0.241      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 7372800     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013430963 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0151     |\n",
      "|    mean_step_reward   | 0.1426632   |\n",
      "|    n_updates          | 3596        |\n",
      "|    policyGradLoss     | -0.00866    |\n",
      "|    value_loss         | 0.228       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 7380992     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008398059 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0234      |\n",
      "|    mean_step_reward   | 0.1393704   |\n",
      "|    n_updates          | 3600        |\n",
      "|    policyGradLoss     | -0.00206    |\n",
      "|    value_loss         | 0.427       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 7389184     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012644146 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.03        |\n",
      "|    mean_step_reward   | 0.14004815  |\n",
      "|    n_updates          | 3604        |\n",
      "|    policyGradLoss     | -0.00879    |\n",
      "|    value_loss         | 0.369       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 7397376     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012454933 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.175       |\n",
      "|    mean_step_reward   | 0.1442154   |\n",
      "|    n_updates          | 3608        |\n",
      "|    policyGradLoss     | -0.00889    |\n",
      "|    value_loss         | 0.404       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 814          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 241          |\n",
      "|    total_timesteps    | 7405568      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0075832205 |\n",
      "|    entropy_loss       | -1.87        |\n",
      "|    explained_variance | 0.934        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0519       |\n",
      "|    mean_step_reward   | 0.13242698   |\n",
      "|    n_updates          | 3612         |\n",
      "|    policyGradLoss     | -0.00489     |\n",
      "|    value_loss         | 0.505        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 7413760     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012106818 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0666      |\n",
      "|    mean_step_reward   | 0.14377809  |\n",
      "|    n_updates          | 3616        |\n",
      "|    policyGradLoss     | -0.00899    |\n",
      "|    value_loss         | 0.277       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 811          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 262          |\n",
      "|    total_timesteps    | 7421952      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0096371835 |\n",
      "|    entropy_loss       | -1.89        |\n",
      "|    explained_variance | 0.959        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.11         |\n",
      "|    mean_step_reward   | 0.14079358   |\n",
      "|    n_updates          | 3620         |\n",
      "|    policyGradLoss     | -0.007       |\n",
      "|    value_loss         | 0.491        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 7430144     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011641572 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.124       |\n",
      "|    mean_step_reward   | 0.1243784   |\n",
      "|    n_updates          | 3624        |\n",
      "|    policyGradLoss     | -0.00329    |\n",
      "|    value_loss         | 0.807       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 7438336     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011254335 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.942       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.136       |\n",
      "|    mean_step_reward   | 0.1282677   |\n",
      "|    n_updates          | 3628        |\n",
      "|    policyGradLoss     | -0.006      |\n",
      "|    value_loss         | 0.671       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 7446528     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008385322 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.124       |\n",
      "|    mean_step_reward   | 0.13940975  |\n",
      "|    n_updates          | 3632        |\n",
      "|    policyGradLoss     | -0.00754    |\n",
      "|    value_loss         | 0.539       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 303         |\n",
      "|    total_timesteps    | 7454720     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009713981 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0448      |\n",
      "|    mean_step_reward   | 0.13463596  |\n",
      "|    n_updates          | 3636        |\n",
      "|    policyGradLoss     | -0.00923    |\n",
      "|    value_loss         | 0.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 313         |\n",
      "|    total_timesteps    | 7462912     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006554231 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0976      |\n",
      "|    mean_step_reward   | 0.13540146  |\n",
      "|    n_updates          | 3640        |\n",
      "|    policyGradLoss     | -0.0047     |\n",
      "|    value_loss         | 0.571       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 323         |\n",
      "|    total_timesteps    | 7471104     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015779676 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0386      |\n",
      "|    mean_step_reward   | 0.14359696  |\n",
      "|    n_updates          | 3644        |\n",
      "|    policyGradLoss     | -0.00605    |\n",
      "|    value_loss         | 0.415       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 7479296     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009082184 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.102       |\n",
      "|    mean_step_reward   | 0.14491259  |\n",
      "|    n_updates          | 3648        |\n",
      "|    policyGradLoss     | -0.00727    |\n",
      "|    value_loss         | 0.422       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 344         |\n",
      "|    total_timesteps    | 7487488     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010754786 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0171     |\n",
      "|    mean_step_reward   | 0.14303078  |\n",
      "|    n_updates          | 3652        |\n",
      "|    policyGradLoss     | -0.0111     |\n",
      "|    value_loss         | 0.242       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 354         |\n",
      "|    total_timesteps    | 7495680     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009355146 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.13        |\n",
      "|    mean_step_reward   | 0.13227294  |\n",
      "|    n_updates          | 3656        |\n",
      "|    policyGradLoss     | -0.0114     |\n",
      "|    value_loss         | 0.473       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 364         |\n",
      "|    total_timesteps    | 7503872     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015299766 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.031       |\n",
      "|    mean_step_reward   | 0.14070654  |\n",
      "|    n_updates          | 3660        |\n",
      "|    policyGradLoss     | -0.00695    |\n",
      "|    value_loss         | 0.345       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 374         |\n",
      "|    total_timesteps    | 7512064     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011688988 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0557      |\n",
      "|    mean_step_reward   | 0.15388973  |\n",
      "|    n_updates          | 3664        |\n",
      "|    policyGradLoss     | -0.00812    |\n",
      "|    value_loss         | 0.336       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 384         |\n",
      "|    total_timesteps    | 7520256     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008911458 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.181       |\n",
      "|    mean_step_reward   | 0.14463615  |\n",
      "|    n_updates          | 3668        |\n",
      "|    policyGradLoss     | -0.00827    |\n",
      "|    value_loss         | 0.419       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 394         |\n",
      "|    total_timesteps    | 7528448     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008433235 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.462       |\n",
      "|    mean_step_reward   | 0.13167724  |\n",
      "|    n_updates          | 3672        |\n",
      "|    policyGradLoss     | -0.00439    |\n",
      "|    value_loss         | 1.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 404         |\n",
      "|    total_timesteps    | 7536640     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.006569186 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0881      |\n",
      "|    mean_step_reward   | 0.12865049  |\n",
      "|    n_updates          | 3676        |\n",
      "|    policyGradLoss     | -0.00513    |\n",
      "|    value_loss         | 0.56        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_22.zip\n",
      "[EVAL] Mean Return: 187.482, Best Return: 187.782\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_22_187.48.mp4\n",
      "\n",
      "=== Round 24 | Learn 327680 steps (Total trained: 7536640) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1110    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 7544832 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 932         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 7553024     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008957449 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.086       |\n",
      "|    mean_step_reward   | 0.13369918  |\n",
      "|    n_updates          | 3684        |\n",
      "|    policyGradLoss     | -0.00919    |\n",
      "|    value_loss         | 0.369       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 889         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 7561216     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011637066 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0229      |\n",
      "|    mean_step_reward   | 0.13646746  |\n",
      "|    n_updates          | 3688        |\n",
      "|    policyGradLoss     | -0.00951    |\n",
      "|    value_loss         | 0.349       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 869         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 37          |\n",
      "|    total_timesteps    | 7569408     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011992295 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.114       |\n",
      "|    mean_step_reward   | 0.13063435  |\n",
      "|    n_updates          | 3692        |\n",
      "|    policyGradLoss     | -0.00955    |\n",
      "|    value_loss         | 0.392       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 859         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 47          |\n",
      "|    total_timesteps    | 7577600     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011500543 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0684      |\n",
      "|    mean_step_reward   | 0.13285129  |\n",
      "|    n_updates          | 3696        |\n",
      "|    policyGradLoss     | -0.00889    |\n",
      "|    value_loss         | 0.447       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 845         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 7585792     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012750659 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0573      |\n",
      "|    mean_step_reward   | 0.12948187  |\n",
      "|    n_updates          | 3700        |\n",
      "|    policyGradLoss     | -0.00598    |\n",
      "|    value_loss         | 0.453       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 7593984     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009162393 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.12        |\n",
      "|    mean_step_reward   | 0.12553287  |\n",
      "|    n_updates          | 3704        |\n",
      "|    policyGradLoss     | -0.00559    |\n",
      "|    value_loss         | 0.647       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 836         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 7602176     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009814857 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0907      |\n",
      "|    mean_step_reward   | 0.14475447  |\n",
      "|    n_updates          | 3708        |\n",
      "|    policyGradLoss     | -0.00921    |\n",
      "|    value_loss         | 0.443       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 834         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 88          |\n",
      "|    total_timesteps    | 7610368     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009608395 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00158    |\n",
      "|    mean_step_reward   | 0.12964281  |\n",
      "|    n_updates          | 3712        |\n",
      "|    policyGradLoss     | -0.00947    |\n",
      "|    value_loss         | 0.332       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 829         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 7618560     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011883121 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00328    |\n",
      "|    mean_step_reward   | 0.13006411  |\n",
      "|    n_updates          | 3716        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.335       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 828         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 108         |\n",
      "|    total_timesteps    | 7626752     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011727031 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0122      |\n",
      "|    mean_step_reward   | 0.13581821  |\n",
      "|    n_updates          | 3720        |\n",
      "|    policyGradLoss     | -0.0113     |\n",
      "|    value_loss         | 0.291       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 828         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 118         |\n",
      "|    total_timesteps    | 7634944     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010902623 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0821      |\n",
      "|    mean_step_reward   | 0.13547471  |\n",
      "|    n_updates          | 3724        |\n",
      "|    policyGradLoss     | -0.00983    |\n",
      "|    value_loss         | 0.589       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 827         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 128         |\n",
      "|    total_timesteps    | 7643136     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008813808 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0471      |\n",
      "|    mean_step_reward   | 0.13219637  |\n",
      "|    n_updates          | 3728        |\n",
      "|    policyGradLoss     | -0.00824    |\n",
      "|    value_loss         | 0.45        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 827         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 7651328     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011025436 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0655      |\n",
      "|    mean_step_reward   | 0.12820461  |\n",
      "|    n_updates          | 3732        |\n",
      "|    policyGradLoss     | -0.00949    |\n",
      "|    value_loss         | 0.568       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 7659520     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010170614 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0178      |\n",
      "|    mean_step_reward   | 0.1386507   |\n",
      "|    n_updates          | 3736        |\n",
      "|    policyGradLoss     | -0.00825    |\n",
      "|    value_loss         | 0.281       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 823         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 159         |\n",
      "|    total_timesteps    | 7667712     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012324644 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.181       |\n",
      "|    mean_step_reward   | 0.11780668  |\n",
      "|    n_updates          | 3740        |\n",
      "|    policyGradLoss     | -0.00765    |\n",
      "|    value_loss         | 0.66        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 824          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 168          |\n",
      "|    total_timesteps    | 7675904      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0107696755 |\n",
      "|    entropy_loss       | -1.87        |\n",
      "|    explained_variance | 0.981        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.00384     |\n",
      "|    mean_step_reward   | 0.13200326   |\n",
      "|    n_updates          | 3744         |\n",
      "|    policyGradLoss     | -0.0105      |\n",
      "|    value_loss         | 0.288        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 823         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 7684096     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009837413 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0407      |\n",
      "|    mean_step_reward   | 0.14515215  |\n",
      "|    n_updates          | 3748        |\n",
      "|    policyGradLoss     | -0.006      |\n",
      "|    value_loss         | 0.295       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 7692288     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009909352 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0451      |\n",
      "|    mean_step_reward   | 0.13774355  |\n",
      "|    n_updates          | 3752        |\n",
      "|    policyGradLoss     | -0.00544    |\n",
      "|    value_loss         | 0.341       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 823         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 7700480     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011249474 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.000954    |\n",
      "|    mean_step_reward   | 0.13637021  |\n",
      "|    n_updates          | 3756        |\n",
      "|    policyGradLoss     | -0.0101     |\n",
      "|    value_loss         | 0.255       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 7708672     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013229402 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0637      |\n",
      "|    mean_step_reward   | 0.13378334  |\n",
      "|    n_updates          | 3760        |\n",
      "|    policyGradLoss     | -0.00944    |\n",
      "|    value_loss         | 0.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 7716864     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010733079 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0243     |\n",
      "|    mean_step_reward   | 0.14483668  |\n",
      "|    n_updates          | 3764        |\n",
      "|    policyGradLoss     | -0.0117     |\n",
      "|    value_loss         | 0.261       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 7725056     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011656808 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0163     |\n",
      "|    mean_step_reward   | 0.15132743  |\n",
      "|    n_updates          | 3768        |\n",
      "|    policyGradLoss     | -0.00605    |\n",
      "|    value_loss         | 0.199       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 239         |\n",
      "|    total_timesteps    | 7733248     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013267335 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0196     |\n",
      "|    mean_step_reward   | 0.13871652  |\n",
      "|    n_updates          | 3772        |\n",
      "|    policyGradLoss     | -0.00974    |\n",
      "|    value_loss         | 0.231       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 250         |\n",
      "|    total_timesteps    | 7741440     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009233665 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00279    |\n",
      "|    mean_step_reward   | 0.1401685   |\n",
      "|    n_updates          | 3776        |\n",
      "|    policyGradLoss     | -0.00751    |\n",
      "|    value_loss         | 0.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 260         |\n",
      "|    total_timesteps    | 7749632     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010924513 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.115       |\n",
      "|    mean_step_reward   | 0.14398581  |\n",
      "|    n_updates          | 3780        |\n",
      "|    policyGradLoss     | -0.00649    |\n",
      "|    value_loss         | 0.446       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 270         |\n",
      "|    total_timesteps    | 7757824     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008910067 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0589      |\n",
      "|    mean_step_reward   | 0.13976347  |\n",
      "|    n_updates          | 3784        |\n",
      "|    policyGradLoss     | -0.00789    |\n",
      "|    value_loss         | 0.418       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 280         |\n",
      "|    total_timesteps    | 7766016     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010745431 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.132       |\n",
      "|    mean_step_reward   | 0.14384821  |\n",
      "|    n_updates          | 3788        |\n",
      "|    policyGradLoss     | -0.00923    |\n",
      "|    value_loss         | 0.459       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 291         |\n",
      "|    total_timesteps    | 7774208     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012814481 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0811      |\n",
      "|    mean_step_reward   | 0.13302602  |\n",
      "|    n_updates          | 3792        |\n",
      "|    policyGradLoss     | -0.00984    |\n",
      "|    value_loss         | 0.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 301         |\n",
      "|    total_timesteps    | 7782400     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009602204 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0338      |\n",
      "|    mean_step_reward   | 0.13161285  |\n",
      "|    n_updates          | 3796        |\n",
      "|    policyGradLoss     | -0.00673    |\n",
      "|    value_loss         | 0.502       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 311         |\n",
      "|    total_timesteps    | 7790592     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011887503 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.072       |\n",
      "|    mean_step_reward   | 0.1306727   |\n",
      "|    n_updates          | 3800        |\n",
      "|    policyGradLoss     | -0.0077     |\n",
      "|    value_loss         | 0.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 321         |\n",
      "|    total_timesteps    | 7798784     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009278394 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.284       |\n",
      "|    mean_step_reward   | 0.11887342  |\n",
      "|    n_updates          | 3804        |\n",
      "|    policyGradLoss     | -0.00556    |\n",
      "|    value_loss         | 1.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 331         |\n",
      "|    total_timesteps    | 7806976     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010072904 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.103       |\n",
      "|    mean_step_reward   | 0.13626137  |\n",
      "|    n_updates          | 3808        |\n",
      "|    policyGradLoss     | -0.00667    |\n",
      "|    value_loss         | 0.485       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 341         |\n",
      "|    total_timesteps    | 7815168     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009517709 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.931       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0371      |\n",
      "|    mean_step_reward   | 0.12199565  |\n",
      "|    n_updates          | 3812        |\n",
      "|    policyGradLoss     | -0.00426    |\n",
      "|    value_loss         | 0.524       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 351         |\n",
      "|    total_timesteps    | 7823360     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009364115 |\n",
      "|    entropy_loss       | -1.92       |\n",
      "|    explained_variance | 0.903       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.183       |\n",
      "|    mean_step_reward   | 0.14107564  |\n",
      "|    n_updates          | 3816        |\n",
      "|    policyGradLoss     | -0.00229    |\n",
      "|    value_loss         | 1.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 362         |\n",
      "|    total_timesteps    | 7831552     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010875642 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.06        |\n",
      "|    mean_step_reward   | 0.12923846  |\n",
      "|    n_updates          | 3820        |\n",
      "|    policyGradLoss     | -0.00721    |\n",
      "|    value_loss         | 0.515       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 372         |\n",
      "|    total_timesteps    | 7839744     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011197291 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0319      |\n",
      "|    mean_step_reward   | 0.13867502  |\n",
      "|    n_updates          | 3824        |\n",
      "|    policyGradLoss     | -0.0101     |\n",
      "|    value_loss         | 0.352       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 382         |\n",
      "|    total_timesteps    | 7847936     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008105721 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.186       |\n",
      "|    mean_step_reward   | 0.13978252  |\n",
      "|    n_updates          | 3828        |\n",
      "|    policyGradLoss     | -0.00853    |\n",
      "|    value_loss         | 0.702       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 392         |\n",
      "|    total_timesteps    | 7856128     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010309894 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0636      |\n",
      "|    mean_step_reward   | 0.13328135  |\n",
      "|    n_updates          | 3832        |\n",
      "|    policyGradLoss     | -0.00799    |\n",
      "|    value_loss         | 0.605       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 402         |\n",
      "|    total_timesteps    | 7864320     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009535285 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0316      |\n",
      "|    mean_step_reward   | 0.14716767  |\n",
      "|    n_updates          | 3836        |\n",
      "|    policyGradLoss     | -0.00644    |\n",
      "|    value_loss         | 0.419       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_23.zip\n",
      "[EVAL] Mean Return: 188.283, Best Return: 188.583\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_23_188.28.mp4\n",
      "\n",
      "=== Round 25 | Learn 327680 steps (Total trained: 7864320) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1078    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 7872512 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 919         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 7880704     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008159247 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0392      |\n",
      "|    mean_step_reward   | 0.1321527   |\n",
      "|    n_updates          | 3844        |\n",
      "|    policyGradLoss     | -0.00316    |\n",
      "|    value_loss         | 0.563       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 877         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 7888896     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010560973 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0198      |\n",
      "|    mean_step_reward   | 0.14278445  |\n",
      "|    n_updates          | 3848        |\n",
      "|    policyGradLoss     | -0.00751    |\n",
      "|    value_loss         | 0.523       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 858          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 38           |\n",
      "|    total_timesteps    | 7897088      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0129017625 |\n",
      "|    entropy_loss       | -1.86        |\n",
      "|    explained_variance | 0.96         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.00563     |\n",
      "|    mean_step_reward   | 0.12683749   |\n",
      "|    n_updates          | 3852         |\n",
      "|    policyGradLoss     | -0.00773     |\n",
      "|    value_loss         | 0.256        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 845         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 48          |\n",
      "|    total_timesteps    | 7905280     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011354026 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00664     |\n",
      "|    mean_step_reward   | 0.14510642  |\n",
      "|    n_updates          | 3856        |\n",
      "|    policyGradLoss     | -0.00946    |\n",
      "|    value_loss         | 0.226       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 839        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 58         |\n",
      "|    total_timesteps    | 7913472    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01207072 |\n",
      "|    entropy_loss       | -1.88      |\n",
      "|    explained_variance | 0.971      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.114      |\n",
      "|    mean_step_reward   | 0.13576059 |\n",
      "|    n_updates          | 3860       |\n",
      "|    policyGradLoss     | -0.007     |\n",
      "|    value_loss         | 0.471      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 836         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 7921664     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012844156 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.05        |\n",
      "|    mean_step_reward   | 0.1423428   |\n",
      "|    n_updates          | 3864        |\n",
      "|    policyGradLoss     | -0.00851    |\n",
      "|    value_loss         | 0.328       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 830         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 7929856     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010859596 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0487      |\n",
      "|    mean_step_reward   | 0.15046117  |\n",
      "|    n_updates          | 3868        |\n",
      "|    policyGradLoss     | -0.000546   |\n",
      "|    value_loss         | 0.453       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 827         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 89          |\n",
      "|    total_timesteps    | 7938048     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012829302 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.127       |\n",
      "|    mean_step_reward   | 0.12959172  |\n",
      "|    n_updates          | 3872        |\n",
      "|    policyGradLoss     | -0.00786    |\n",
      "|    value_loss         | 0.533       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 99          |\n",
      "|    total_timesteps    | 7946240     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010931222 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.161       |\n",
      "|    mean_step_reward   | 0.14345567  |\n",
      "|    n_updates          | 3876        |\n",
      "|    policyGradLoss     | -0.00683    |\n",
      "|    value_loss         | 0.804       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 7954432     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009128162 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.081       |\n",
      "|    mean_step_reward   | 0.1286627   |\n",
      "|    n_updates          | 3880        |\n",
      "|    policyGradLoss     | -0.00863    |\n",
      "|    value_loss         | 0.584       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 7962624     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013971699 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0693      |\n",
      "|    mean_step_reward   | 0.13268918  |\n",
      "|    n_updates          | 3884        |\n",
      "|    policyGradLoss     | -0.00972    |\n",
      "|    value_loss         | 0.482       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 130         |\n",
      "|    total_timesteps    | 7970816     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009195546 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.199       |\n",
      "|    mean_step_reward   | 0.13209952  |\n",
      "|    n_updates          | 3888        |\n",
      "|    policyGradLoss     | -0.0051     |\n",
      "|    value_loss         | 1.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 140         |\n",
      "|    total_timesteps    | 7979008     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011180095 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0053     |\n",
      "|    mean_step_reward   | 0.13393284  |\n",
      "|    n_updates          | 3892        |\n",
      "|    policyGradLoss     | -0.00803    |\n",
      "|    value_loss         | 0.261       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 817          |\n",
      "|    iterations         | 15           |\n",
      "|    time_elapsed       | 150          |\n",
      "|    total_timesteps    | 7987200      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0110583715 |\n",
      "|    entropy_loss       | -1.84        |\n",
      "|    explained_variance | 0.949        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.248        |\n",
      "|    mean_step_reward   | 0.1388157    |\n",
      "|    n_updates          | 3896         |\n",
      "|    policyGradLoss     | -0.00295     |\n",
      "|    value_loss         | 0.85         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 7995392     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008895323 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0661      |\n",
      "|    mean_step_reward   | 0.13223778  |\n",
      "|    n_updates          | 3900        |\n",
      "|    policyGradLoss     | -0.00441    |\n",
      "|    value_loss         | 0.665       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 171         |\n",
      "|    total_timesteps    | 8003584     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012893143 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.177       |\n",
      "|    mean_step_reward   | 0.1264128   |\n",
      "|    n_updates          | 3904        |\n",
      "|    policyGradLoss     | -0.00622    |\n",
      "|    value_loss         | 0.685       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 8011776     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008944929 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0173      |\n",
      "|    mean_step_reward   | 0.14421679  |\n",
      "|    n_updates          | 3908        |\n",
      "|    policyGradLoss     | -0.00454    |\n",
      "|    value_loss         | 0.435       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 812          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 191          |\n",
      "|    total_timesteps    | 8019968      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0076223332 |\n",
      "|    entropy_loss       | -1.84        |\n",
      "|    explained_variance | 0.94         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.146        |\n",
      "|    mean_step_reward   | 0.14289278   |\n",
      "|    n_updates          | 3912         |\n",
      "|    policyGradLoss     | -0.00169     |\n",
      "|    value_loss         | 0.575        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 812        |\n",
      "|    iterations         | 20         |\n",
      "|    time_elapsed       | 201        |\n",
      "|    total_timesteps    | 8028160    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00830338 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.961      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0464     |\n",
      "|    mean_step_reward   | 0.14029473 |\n",
      "|    n_updates          | 3916       |\n",
      "|    policyGradLoss     | -0.00798   |\n",
      "|    value_loss         | 0.343      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 212         |\n",
      "|    total_timesteps    | 8036352     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011727566 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0911      |\n",
      "|    mean_step_reward   | 0.14818397  |\n",
      "|    n_updates          | 3920        |\n",
      "|    policyGradLoss     | -0.00585    |\n",
      "|    value_loss         | 0.561       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 8044544     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013008667 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0762      |\n",
      "|    mean_step_reward   | 0.1342065   |\n",
      "|    n_updates          | 3924        |\n",
      "|    policyGradLoss     | -0.006      |\n",
      "|    value_loss         | 0.329       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 810          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 232          |\n",
      "|    total_timesteps    | 8052736      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0073045893 |\n",
      "|    entropy_loss       | -1.82        |\n",
      "|    explained_variance | 0.938        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0616       |\n",
      "|    mean_step_reward   | 0.13216956   |\n",
      "|    n_updates          | 3928         |\n",
      "|    policyGradLoss     | -0.00278     |\n",
      "|    value_loss         | 0.585        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 8060928     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008080925 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.111       |\n",
      "|    mean_step_reward   | 0.15251756  |\n",
      "|    n_updates          | 3932        |\n",
      "|    policyGradLoss     | -0.00211    |\n",
      "|    value_loss         | 0.765       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 809          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 253          |\n",
      "|    total_timesteps    | 8069120      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0127620865 |\n",
      "|    entropy_loss       | -1.82        |\n",
      "|    explained_variance | 0.951        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.129        |\n",
      "|    mean_step_reward   | 0.12848198   |\n",
      "|    n_updates          | 3936         |\n",
      "|    policyGradLoss     | -0.00566     |\n",
      "|    value_loss         | 0.596        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 8077312     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010801059 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0778      |\n",
      "|    mean_step_reward   | 0.13910136  |\n",
      "|    n_updates          | 3940        |\n",
      "|    policyGradLoss     | -0.00464    |\n",
      "|    value_loss         | 0.607       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 807         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 8085504     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010644633 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0384      |\n",
      "|    mean_step_reward   | 0.14096719  |\n",
      "|    n_updates          | 3944        |\n",
      "|    policyGradLoss     | -0.00635    |\n",
      "|    value_loss         | 0.471       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 8093696     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013252101 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0245      |\n",
      "|    mean_step_reward   | 0.13258648  |\n",
      "|    n_updates          | 3948        |\n",
      "|    policyGradLoss     | -0.0089     |\n",
      "|    value_loss         | 0.395       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 807          |\n",
      "|    iterations         | 29           |\n",
      "|    time_elapsed       | 294          |\n",
      "|    total_timesteps    | 8101888      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0146434195 |\n",
      "|    entropy_loss       | -1.86        |\n",
      "|    explained_variance | 0.984        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0249       |\n",
      "|    mean_step_reward   | 0.1498622    |\n",
      "|    n_updates          | 3952         |\n",
      "|    policyGradLoss     | -0.0117      |\n",
      "|    value_loss         | 0.275        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 807        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 304        |\n",
      "|    total_timesteps    | 8110080    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01215414 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.964      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0455     |\n",
      "|    mean_step_reward   | 0.14182843 |\n",
      "|    n_updates          | 3956       |\n",
      "|    policyGradLoss     | -0.00463   |\n",
      "|    value_loss         | 0.486      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 314         |\n",
      "|    total_timesteps    | 8118272     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012715206 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0607      |\n",
      "|    mean_step_reward   | 0.15317228  |\n",
      "|    n_updates          | 3960        |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.276       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 8126464     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011258224 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0016      |\n",
      "|    mean_step_reward   | 0.12960166  |\n",
      "|    n_updates          | 3964        |\n",
      "|    policyGradLoss     | -0.00563    |\n",
      "|    value_loss         | 0.304       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 335         |\n",
      "|    total_timesteps    | 8134656     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011552931 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0665      |\n",
      "|    mean_step_reward   | 0.13953397  |\n",
      "|    n_updates          | 3968        |\n",
      "|    policyGradLoss     | -0.00735    |\n",
      "|    value_loss         | 0.38        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 345         |\n",
      "|    total_timesteps    | 8142848     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012595286 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.957       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.159       |\n",
      "|    mean_step_reward   | 0.13630147  |\n",
      "|    n_updates          | 3972        |\n",
      "|    policyGradLoss     | -0.00705    |\n",
      "|    value_loss         | 0.587       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 355         |\n",
      "|    total_timesteps    | 8151040     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010960512 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00954    |\n",
      "|    mean_step_reward   | 0.14549223  |\n",
      "|    n_updates          | 3976        |\n",
      "|    policyGradLoss     | -0.00968    |\n",
      "|    value_loss         | 0.241       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 365         |\n",
      "|    total_timesteps    | 8159232     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012207894 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.111       |\n",
      "|    mean_step_reward   | 0.14041924  |\n",
      "|    n_updates          | 3980        |\n",
      "|    policyGradLoss     | -0.0099     |\n",
      "|    value_loss         | 0.457       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 805         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 376         |\n",
      "|    total_timesteps    | 8167424     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011769555 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.248       |\n",
      "|    mean_step_reward   | 0.13324535  |\n",
      "|    n_updates          | 3984        |\n",
      "|    policyGradLoss     | -0.00551    |\n",
      "|    value_loss         | 0.819       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 386         |\n",
      "|    total_timesteps    | 8175616     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016098185 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00513     |\n",
      "|    mean_step_reward   | 0.13369557  |\n",
      "|    n_updates          | 3988        |\n",
      "|    policyGradLoss     | -0.00991    |\n",
      "|    value_loss         | 0.275       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 396         |\n",
      "|    total_timesteps    | 8183808     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012279479 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.298       |\n",
      "|    mean_step_reward   | 0.14208119  |\n",
      "|    n_updates          | 3992        |\n",
      "|    policyGradLoss     | -0.00502    |\n",
      "|    value_loss         | 0.669       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 806         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 406         |\n",
      "|    total_timesteps    | 8192000     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015543488 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0211     |\n",
      "|    mean_step_reward   | 0.13821071  |\n",
      "|    n_updates          | 3996        |\n",
      "|    policyGradLoss     | -0.0101     |\n",
      "|    value_loss         | 0.189       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_24.zip\n",
      "[EVAL] Mean Return: 189.383, Best Return: 189.683\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_24_189.38.mp4\n",
      "\n",
      "=== Round 26 | Learn 327680 steps (Total trained: 8192000) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1057    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 8200192 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 926         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 8208384     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019005472 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.901       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.145       |\n",
      "|    mean_step_reward   | 0.119914934 |\n",
      "|    n_updates          | 4004        |\n",
      "|    policyGradLoss     | -0.00381    |\n",
      "|    value_loss         | 0.734       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 881         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 8216576     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011750743 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0878      |\n",
      "|    mean_step_reward   | 0.12926231  |\n",
      "|    n_updates          | 4008        |\n",
      "|    policyGradLoss     | -0.0065     |\n",
      "|    value_loss         | 0.709       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 859         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 8224768     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011287594 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.119       |\n",
      "|    mean_step_reward   | 0.14546968  |\n",
      "|    n_updates          | 4012        |\n",
      "|    policyGradLoss     | -0.00178    |\n",
      "|    value_loss         | 0.665       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 847         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 48          |\n",
      "|    total_timesteps    | 8232960     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017339759 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.000253    |\n",
      "|    mean_step_reward   | 0.13526347  |\n",
      "|    n_updates          | 4016        |\n",
      "|    policyGradLoss     | -0.00716    |\n",
      "|    value_loss         | 0.255       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 8241152     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012384914 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0478      |\n",
      "|    mean_step_reward   | 0.14649385  |\n",
      "|    n_updates          | 4020        |\n",
      "|    policyGradLoss     | -0.00754    |\n",
      "|    value_loss         | 0.291       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 832         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 8249344     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012788527 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.27        |\n",
      "|    mean_step_reward   | 0.13230985  |\n",
      "|    n_updates          | 4024        |\n",
      "|    policyGradLoss     | -0.00921    |\n",
      "|    value_loss         | 0.597       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 831          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 78           |\n",
      "|    total_timesteps    | 8257536      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0114802215 |\n",
      "|    entropy_loss       | -1.86        |\n",
      "|    explained_variance | 0.981        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0474       |\n",
      "|    mean_step_reward   | 0.13484275   |\n",
      "|    n_updates          | 4028         |\n",
      "|    policyGradLoss     | -0.00903     |\n",
      "|    value_loss         | 0.356        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 831        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 88         |\n",
      "|    total_timesteps    | 8265728    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01616103 |\n",
      "|    entropy_loss       | -1.85      |\n",
      "|    explained_variance | 0.969      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.134      |\n",
      "|    mean_step_reward   | 0.13754912 |\n",
      "|    n_updates          | 4032       |\n",
      "|    policyGradLoss     | -0.0118    |\n",
      "|    value_loss         | 0.622      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 828         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 8273920     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010191763 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0554      |\n",
      "|    mean_step_reward   | 0.15110932  |\n",
      "|    n_updates          | 4036        |\n",
      "|    policyGradLoss     | -0.00812    |\n",
      "|    value_loss         | 0.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 8282112     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015142659 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0323     |\n",
      "|    mean_step_reward   | 0.14132848  |\n",
      "|    n_updates          | 4040        |\n",
      "|    policyGradLoss     | -0.01       |\n",
      "|    value_loss         | 0.162       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 823          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 119          |\n",
      "|    total_timesteps    | 8290304      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0132276835 |\n",
      "|    entropy_loss       | -1.82        |\n",
      "|    explained_variance | 0.986        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0114      |\n",
      "|    mean_step_reward   | 0.14668983   |\n",
      "|    n_updates          | 4044         |\n",
      "|    policyGradLoss     | -0.00945     |\n",
      "|    value_loss         | 0.249        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 129         |\n",
      "|    total_timesteps    | 8298496     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018455531 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0931      |\n",
      "|    mean_step_reward   | 0.142149    |\n",
      "|    n_updates          | 4048        |\n",
      "|    policyGradLoss     | -0.00631    |\n",
      "|    value_loss         | 0.286       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 140         |\n",
      "|    total_timesteps    | 8306688     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015310811 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0378      |\n",
      "|    mean_step_reward   | 0.13974273  |\n",
      "|    n_updates          | 4052        |\n",
      "|    policyGradLoss     | -0.00749    |\n",
      "|    value_loss         | 0.285       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 150         |\n",
      "|    total_timesteps    | 8314880     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012869446 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0107      |\n",
      "|    mean_step_reward   | 0.14546774  |\n",
      "|    n_updates          | 4056        |\n",
      "|    policyGradLoss     | -0.0094     |\n",
      "|    value_loss         | 0.333       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 8323072     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015594104 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.029      |\n",
      "|    mean_step_reward   | 0.13474561  |\n",
      "|    n_updates          | 4060        |\n",
      "|    policyGradLoss     | -0.0117     |\n",
      "|    value_loss         | 0.206       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 8331264     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012574825 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0162      |\n",
      "|    mean_step_reward   | 0.14939329  |\n",
      "|    n_updates          | 4064        |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.281       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 8339456     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014090634 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0313      |\n",
      "|    mean_step_reward   | 0.14390165  |\n",
      "|    n_updates          | 4068        |\n",
      "|    policyGradLoss     | -0.0097     |\n",
      "|    value_loss         | 0.205       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 8347648     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014806116 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.000735   |\n",
      "|    mean_step_reward   | 0.14291835  |\n",
      "|    n_updates          | 4072        |\n",
      "|    policyGradLoss     | -0.00726    |\n",
      "|    value_loss         | 0.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 8355840     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009613503 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.189       |\n",
      "|    mean_step_reward   | 0.13745356  |\n",
      "|    n_updates          | 4076        |\n",
      "|    policyGradLoss     | -0.00387    |\n",
      "|    value_loss         | 0.708       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 8364032     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011130484 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.151       |\n",
      "|    mean_step_reward   | 0.13064884  |\n",
      "|    n_updates          | 4080        |\n",
      "|    policyGradLoss     | -0.00624    |\n",
      "|    value_loss         | 0.543       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 8372224     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010279803 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0974      |\n",
      "|    mean_step_reward   | 0.1366585   |\n",
      "|    n_updates          | 4084        |\n",
      "|    policyGradLoss     | -0.00609    |\n",
      "|    value_loss         | 0.606       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 8380416     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011606339 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0552      |\n",
      "|    mean_step_reward   | 0.14158916  |\n",
      "|    n_updates          | 4088        |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.302       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 8388608     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010828918 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.125       |\n",
      "|    mean_step_reward   | 0.14184475  |\n",
      "|    n_updates          | 4092        |\n",
      "|    policyGradLoss     | -0.00387    |\n",
      "|    value_loss         | 0.571       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 8396800     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020434912 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.204       |\n",
      "|    mean_step_reward   | 0.13544184  |\n",
      "|    n_updates          | 4096        |\n",
      "|    policyGradLoss     | -0.00742    |\n",
      "|    value_loss         | 0.659       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 812          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 262          |\n",
      "|    total_timesteps    | 8404992      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0139179425 |\n",
      "|    entropy_loss       | -1.85        |\n",
      "|    explained_variance | 0.979        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0491       |\n",
      "|    mean_step_reward   | 0.15040953   |\n",
      "|    n_updates          | 4100         |\n",
      "|    policyGradLoss     | -0.00453     |\n",
      "|    value_loss         | 0.4          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 8413184     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014089072 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0198      |\n",
      "|    mean_step_reward   | 0.13645227  |\n",
      "|    n_updates          | 4104        |\n",
      "|    policyGradLoss     | -0.0099     |\n",
      "|    value_loss         | 0.338       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 8421376     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012217615 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0411      |\n",
      "|    mean_step_reward   | 0.1483373   |\n",
      "|    n_updates          | 4108        |\n",
      "|    policyGradLoss     | -0.00978    |\n",
      "|    value_loss         | 0.375       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 8429568     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011289066 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.946       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.105       |\n",
      "|    mean_step_reward   | 0.12801781  |\n",
      "|    n_updates          | 4112        |\n",
      "|    policyGradLoss     | -0.00528    |\n",
      "|    value_loss         | 0.547       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 810        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 303        |\n",
      "|    total_timesteps    | 8437760    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01157753 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0238    |\n",
      "|    mean_step_reward   | 0.14890519 |\n",
      "|    n_updates          | 4116       |\n",
      "|    policyGradLoss     | -0.00944   |\n",
      "|    value_loss         | 0.177      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 313         |\n",
      "|    total_timesteps    | 8445952     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013589956 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0551      |\n",
      "|    mean_step_reward   | 0.14427248  |\n",
      "|    n_updates          | 4120        |\n",
      "|    policyGradLoss     | -0.00725    |\n",
      "|    value_loss         | 0.392       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 809        |\n",
      "|    iterations         | 32         |\n",
      "|    time_elapsed       | 323        |\n",
      "|    total_timesteps    | 8454144    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01032586 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.937      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.17       |\n",
      "|    mean_step_reward   | 0.12939972 |\n",
      "|    n_updates          | 4124       |\n",
      "|    policyGradLoss     | -0.00262   |\n",
      "|    value_loss         | 0.411      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 8462336     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012412209 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0108     |\n",
      "|    mean_step_reward   | 0.15209934  |\n",
      "|    n_updates          | 4128        |\n",
      "|    policyGradLoss     | -0.00952    |\n",
      "|    value_loss         | 0.239       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 343         |\n",
      "|    total_timesteps    | 8470528     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009188255 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.917       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.152       |\n",
      "|    mean_step_reward   | 0.13199915  |\n",
      "|    n_updates          | 4132        |\n",
      "|    policyGradLoss     | -0.00194    |\n",
      "|    value_loss         | 0.786       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 810          |\n",
      "|    iterations         | 35           |\n",
      "|    time_elapsed       | 353          |\n",
      "|    total_timesteps    | 8478720      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0140417125 |\n",
      "|    entropy_loss       | -1.85        |\n",
      "|    explained_variance | 0.984        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0078       |\n",
      "|    mean_step_reward   | 0.13876584   |\n",
      "|    n_updates          | 4136         |\n",
      "|    policyGradLoss     | -0.0128      |\n",
      "|    value_loss         | 0.205        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 809          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 364          |\n",
      "|    total_timesteps    | 8486912      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0137844905 |\n",
      "|    entropy_loss       | -1.86        |\n",
      "|    explained_variance | 0.977        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.111        |\n",
      "|    mean_step_reward   | 0.14651422   |\n",
      "|    n_updates          | 4140         |\n",
      "|    policyGradLoss     | -0.00734     |\n",
      "|    value_loss         | 0.368        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 374         |\n",
      "|    total_timesteps    | 8495104     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007819246 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00155    |\n",
      "|    mean_step_reward   | 0.13532695  |\n",
      "|    n_updates          | 4144        |\n",
      "|    policyGradLoss     | -0.00403    |\n",
      "|    value_loss         | 0.381       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 384         |\n",
      "|    total_timesteps    | 8503296     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010210948 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.147       |\n",
      "|    mean_step_reward   | 0.14677504  |\n",
      "|    n_updates          | 4148        |\n",
      "|    policyGradLoss     | -0.00431    |\n",
      "|    value_loss         | 0.323       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 809          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 394          |\n",
      "|    total_timesteps    | 8511488      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0071219415 |\n",
      "|    entropy_loss       | -1.86        |\n",
      "|    explained_variance | 0.954        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0904       |\n",
      "|    mean_step_reward   | 0.14038837   |\n",
      "|    n_updates          | 4152         |\n",
      "|    policyGradLoss     | -0.00432     |\n",
      "|    value_loss         | 0.673        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 404         |\n",
      "|    total_timesteps    | 8519680     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012396214 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0165     |\n",
      "|    mean_step_reward   | 0.13828874  |\n",
      "|    n_updates          | 4156        |\n",
      "|    policyGradLoss     | -0.00995    |\n",
      "|    value_loss         | 0.243       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_25.zip\n",
      "[EVAL] Mean Return: 188.982, Best Return: 189.282\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_25_188.98.mp4\n",
      "\n",
      "=== Round 27 | Learn 327680 steps (Total trained: 8519680) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1142    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 8527872 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 947         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 8536064     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010166215 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0195      |\n",
      "|    mean_step_reward   | 0.13724841  |\n",
      "|    n_updates          | 4164        |\n",
      "|    policyGradLoss     | -0.0074     |\n",
      "|    value_loss         | 0.348       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 889        |\n",
      "|    iterations         | 3          |\n",
      "|    time_elapsed       | 27         |\n",
      "|    total_timesteps    | 8544256    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01002322 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.97       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.061      |\n",
      "|    mean_step_reward   | 0.14362472 |\n",
      "|    n_updates          | 4168       |\n",
      "|    policyGradLoss     | -0.00791   |\n",
      "|    value_loss         | 0.491      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 863          |\n",
      "|    iterations         | 4            |\n",
      "|    time_elapsed       | 37           |\n",
      "|    total_timesteps    | 8552448      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0109133385 |\n",
      "|    entropy_loss       | -1.91        |\n",
      "|    explained_variance | 0.98         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.171        |\n",
      "|    mean_step_reward   | 0.14139351   |\n",
      "|    n_updates          | 4172         |\n",
      "|    policyGradLoss     | -0.00692     |\n",
      "|    value_loss         | 0.413        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 848         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 48          |\n",
      "|    total_timesteps    | 8560640     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012230238 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0442      |\n",
      "|    mean_step_reward   | 0.13248955  |\n",
      "|    n_updates          | 4176        |\n",
      "|    policyGradLoss     | -0.0095     |\n",
      "|    value_loss         | 0.433       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 839         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 8568832     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009143538 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0725      |\n",
      "|    mean_step_reward   | 0.1482968   |\n",
      "|    n_updates          | 4180        |\n",
      "|    policyGradLoss     | -0.00623    |\n",
      "|    value_loss         | 0.566       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 836         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 8577024     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010874642 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.898       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.135       |\n",
      "|    mean_step_reward   | 0.123688556 |\n",
      "|    n_updates          | 4184        |\n",
      "|    policyGradLoss     | -0.00637    |\n",
      "|    value_loss         | 0.722       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 830         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 8585216     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009029098 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.935       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0986      |\n",
      "|    mean_step_reward   | 0.12736368  |\n",
      "|    n_updates          | 4188        |\n",
      "|    policyGradLoss     | -0.00498    |\n",
      "|    value_loss         | 0.677       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 829        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 88         |\n",
      "|    total_timesteps    | 8593408    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01265259 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.972      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0175     |\n",
      "|    mean_step_reward   | 0.13920632 |\n",
      "|    n_updates          | 4192       |\n",
      "|    policyGradLoss     | -0.0093    |\n",
      "|    value_loss         | 0.284      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 99          |\n",
      "|    total_timesteps    | 8601600     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010820228 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0107     |\n",
      "|    mean_step_reward   | 0.14648426  |\n",
      "|    n_updates          | 4196        |\n",
      "|    policyGradLoss     | -0.00999    |\n",
      "|    value_loss         | 0.232       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 823         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 8609792     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013572279 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0132     |\n",
      "|    mean_step_reward   | 0.14535424  |\n",
      "|    n_updates          | 4200        |\n",
      "|    policyGradLoss     | -0.0088     |\n",
      "|    value_loss         | 0.199       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 821          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 119          |\n",
      "|    total_timesteps    | 8617984      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0136113465 |\n",
      "|    entropy_loss       | -1.83        |\n",
      "|    explained_variance | 0.99         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0295      |\n",
      "|    mean_step_reward   | 0.14654222   |\n",
      "|    n_updates          | 4204         |\n",
      "|    policyGradLoss     | -0.0138      |\n",
      "|    value_loss         | 0.153        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 130         |\n",
      "|    total_timesteps    | 8626176     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011109171 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.325       |\n",
      "|    mean_step_reward   | 0.1350553   |\n",
      "|    n_updates          | 4208        |\n",
      "|    policyGradLoss     | -0.00529    |\n",
      "|    value_loss         | 1.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 140         |\n",
      "|    total_timesteps    | 8634368     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009302668 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.925       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.166       |\n",
      "|    mean_step_reward   | 0.12892789  |\n",
      "|    n_updates          | 4212        |\n",
      "|    policyGradLoss     | -0.00648    |\n",
      "|    value_loss         | 0.893       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 150         |\n",
      "|    total_timesteps    | 8642560     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009808965 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.948       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0674      |\n",
      "|    mean_step_reward   | 0.12853503  |\n",
      "|    n_updates          | 4216        |\n",
      "|    policyGradLoss     | -0.00994    |\n",
      "|    value_loss         | 0.543       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 8650752     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008196413 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.884       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.274       |\n",
      "|    mean_step_reward   | 0.13426045  |\n",
      "|    n_updates          | 4220        |\n",
      "|    policyGradLoss     | -0.00252    |\n",
      "|    value_loss         | 1.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 8658944     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008718587 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.906       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0924      |\n",
      "|    mean_step_reward   | 0.12704119  |\n",
      "|    n_updates          | 4224        |\n",
      "|    policyGradLoss     | -0.00713    |\n",
      "|    value_loss         | 0.668       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 8667136     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011004611 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.238       |\n",
      "|    mean_step_reward   | 0.13508128  |\n",
      "|    n_updates          | 4228        |\n",
      "|    policyGradLoss     | -0.00845    |\n",
      "|    value_loss         | 0.694       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 813        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 191        |\n",
      "|    total_timesteps    | 8675328    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01165623 |\n",
      "|    entropy_loss       | -1.85      |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0092    |\n",
      "|    mean_step_reward   | 0.14705136 |\n",
      "|    n_updates          | 4232       |\n",
      "|    policyGradLoss     | -0.0101    |\n",
      "|    value_loss         | 0.227      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 8683520     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011321229 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0283      |\n",
      "|    mean_step_reward   | 0.14567798  |\n",
      "|    n_updates          | 4236        |\n",
      "|    policyGradLoss     | -0.00895    |\n",
      "|    value_loss         | 0.311       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 8691712     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011285988 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0267      |\n",
      "|    mean_step_reward   | 0.1466805   |\n",
      "|    n_updates          | 4240        |\n",
      "|    policyGradLoss     | -0.00947    |\n",
      "|    value_loss         | 0.275       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 8699904     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015780147 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.053       |\n",
      "|    mean_step_reward   | 0.12503834  |\n",
      "|    n_updates          | 4244        |\n",
      "|    policyGradLoss     | -0.00679    |\n",
      "|    value_loss         | 0.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 8708096     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012548725 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0612      |\n",
      "|    mean_step_reward   | 0.1498563   |\n",
      "|    n_updates          | 4248        |\n",
      "|    policyGradLoss     | -0.00425    |\n",
      "|    value_loss         | 0.295       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 8716288     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008465201 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.929       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.163       |\n",
      "|    mean_step_reward   | 0.13004984  |\n",
      "|    n_updates          | 4252        |\n",
      "|    policyGradLoss     | -0.00761    |\n",
      "|    value_loss         | 0.566       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 8724480     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012764659 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0459      |\n",
      "|    mean_step_reward   | 0.1389649   |\n",
      "|    n_updates          | 4256        |\n",
      "|    policyGradLoss     | -0.00872    |\n",
      "|    value_loss         | 0.346       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 8732672     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009128537 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0239      |\n",
      "|    mean_step_reward   | 0.13419467  |\n",
      "|    n_updates          | 4260        |\n",
      "|    policyGradLoss     | -0.00531    |\n",
      "|    value_loss         | 0.433       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 8740864     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009674105 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0433      |\n",
      "|    mean_step_reward   | 0.13693443  |\n",
      "|    n_updates          | 4264        |\n",
      "|    policyGradLoss     | -0.00611    |\n",
      "|    value_loss         | 0.63        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 8749056     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010241077 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.137       |\n",
      "|    mean_step_reward   | 0.12906212  |\n",
      "|    n_updates          | 4268        |\n",
      "|    policyGradLoss     | -0.00465    |\n",
      "|    value_loss         | 0.871       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 8757248     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008949293 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.926       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.772       |\n",
      "|    mean_step_reward   | 0.12699743  |\n",
      "|    n_updates          | 4272        |\n",
      "|    policyGradLoss     | -0.00638    |\n",
      "|    value_loss         | 1.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 302         |\n",
      "|    total_timesteps    | 8765440     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010933839 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.113       |\n",
      "|    mean_step_reward   | 0.12304766  |\n",
      "|    n_updates          | 4276        |\n",
      "|    policyGradLoss     | -0.00786    |\n",
      "|    value_loss         | 0.724       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 312         |\n",
      "|    total_timesteps    | 8773632     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011878037 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.149       |\n",
      "|    mean_step_reward   | 0.14299004  |\n",
      "|    n_updates          | 4280        |\n",
      "|    policyGradLoss     | -0.00917    |\n",
      "|    value_loss         | 0.426       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 323         |\n",
      "|    total_timesteps    | 8781824     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009948464 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.289       |\n",
      "|    mean_step_reward   | 0.14801785  |\n",
      "|    n_updates          | 4284        |\n",
      "|    policyGradLoss     | -0.00366    |\n",
      "|    value_loss         | 0.778       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 8790016     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014101993 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0467      |\n",
      "|    mean_step_reward   | 0.115807034 |\n",
      "|    n_updates          | 4288        |\n",
      "|    policyGradLoss     | -0.00536    |\n",
      "|    value_loss         | 0.603       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 343         |\n",
      "|    total_timesteps    | 8798208     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008955789 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.914       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0782      |\n",
      "|    mean_step_reward   | 0.137135    |\n",
      "|    n_updates          | 4292        |\n",
      "|    policyGradLoss     | -0.00272    |\n",
      "|    value_loss         | 0.657       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 353         |\n",
      "|    total_timesteps    | 8806400     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011507761 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.108       |\n",
      "|    mean_step_reward   | 0.15015694  |\n",
      "|    n_updates          | 4296        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.298       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 810          |\n",
      "|    iterations         | 36           |\n",
      "|    time_elapsed       | 363          |\n",
      "|    total_timesteps    | 8814592      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0119737685 |\n",
      "|    entropy_loss       | -1.88        |\n",
      "|    explained_variance | 0.987        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.00747      |\n",
      "|    mean_step_reward   | 0.14615285   |\n",
      "|    n_updates          | 4300         |\n",
      "|    policyGradLoss     | -0.0128      |\n",
      "|    value_loss         | 0.221        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 374         |\n",
      "|    total_timesteps    | 8822784     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010827438 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0298      |\n",
      "|    mean_step_reward   | 0.14522032  |\n",
      "|    n_updates          | 4304        |\n",
      "|    policyGradLoss     | -0.0129     |\n",
      "|    value_loss         | 0.252       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 384         |\n",
      "|    total_timesteps    | 8830976     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011313127 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0362      |\n",
      "|    mean_step_reward   | 0.13836706  |\n",
      "|    n_updates          | 4308        |\n",
      "|    policyGradLoss     | -0.00991    |\n",
      "|    value_loss         | 0.458       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 809          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 394          |\n",
      "|    total_timesteps    | 8839168      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0154270725 |\n",
      "|    entropy_loss       | -1.88        |\n",
      "|    explained_variance | 0.983        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0318       |\n",
      "|    mean_step_reward   | 0.13917722   |\n",
      "|    n_updates          | 4312         |\n",
      "|    policyGradLoss     | -0.014       |\n",
      "|    value_loss         | 0.318        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 404         |\n",
      "|    total_timesteps    | 8847360     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014537942 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0418      |\n",
      "|    mean_step_reward   | 0.140621    |\n",
      "|    n_updates          | 4316        |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.359       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_26.zip\n",
      "[EVAL] Mean Return: 191.448, Best Return: 191.748\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_26_191.45.mp4\n",
      "\n",
      "=== Round 28 | Learn 327680 steps (Total trained: 8847360) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1132    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 8855552 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 915         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 8863744     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011459177 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.126       |\n",
      "|    mean_step_reward   | 0.13848841  |\n",
      "|    n_updates          | 4324        |\n",
      "|    policyGradLoss     | -0.00697    |\n",
      "|    value_loss         | 0.501       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 875         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 8871936     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011103995 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.109       |\n",
      "|    mean_step_reward   | 0.13795301  |\n",
      "|    n_updates          | 4328        |\n",
      "|    policyGradLoss     | -0.00827    |\n",
      "|    value_loss         | 0.51        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 862         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 37          |\n",
      "|    total_timesteps    | 8880128     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019152794 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0377      |\n",
      "|    mean_step_reward   | 0.14266801  |\n",
      "|    n_updates          | 4332        |\n",
      "|    policyGradLoss     | -0.0105     |\n",
      "|    value_loss         | 0.377       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 843         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 48          |\n",
      "|    total_timesteps    | 8888320     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011053914 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0121      |\n",
      "|    mean_step_reward   | 0.13630585  |\n",
      "|    n_updates          | 4336        |\n",
      "|    policyGradLoss     | -0.0104     |\n",
      "|    value_loss         | 0.379       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 8896512     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008568099 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.186       |\n",
      "|    mean_step_reward   | 0.13029215  |\n",
      "|    n_updates          | 4340        |\n",
      "|    policyGradLoss     | -0.00544    |\n",
      "|    value_loss         | 0.728       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 833         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 8904704     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009303634 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.951       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.126       |\n",
      "|    mean_step_reward   | 0.13641246  |\n",
      "|    n_updates          | 4344        |\n",
      "|    policyGradLoss     | -0.0062     |\n",
      "|    value_loss         | 0.667       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 830          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 78           |\n",
      "|    total_timesteps    | 8912896      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0103512835 |\n",
      "|    entropy_loss       | -1.87        |\n",
      "|    explained_variance | 0.965        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0376       |\n",
      "|    mean_step_reward   | 0.14055337   |\n",
      "|    n_updates          | 4348         |\n",
      "|    policyGradLoss     | -0.00459     |\n",
      "|    value_loss         | 0.421        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 89          |\n",
      "|    total_timesteps    | 8921088     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011088623 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.267       |\n",
      "|    mean_step_reward   | 0.13986146  |\n",
      "|    n_updates          | 4352        |\n",
      "|    policyGradLoss     | -0.00545    |\n",
      "|    value_loss         | 0.749       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 99          |\n",
      "|    total_timesteps    | 8929280     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007971431 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.897       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0941      |\n",
      "|    mean_step_reward   | 0.12442975  |\n",
      "|    n_updates          | 4356        |\n",
      "|    policyGradLoss     | -0.00177    |\n",
      "|    value_loss         | 0.619       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 821        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 109        |\n",
      "|    total_timesteps    | 8937472    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01028966 |\n",
      "|    entropy_loss       | -1.89      |\n",
      "|    explained_variance | 0.927      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0816     |\n",
      "|    mean_step_reward   | 0.13799162 |\n",
      "|    n_updates          | 4360       |\n",
      "|    policyGradLoss     | -0.00441   |\n",
      "|    value_loss         | 0.646      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 8945664     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007666436 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.119       |\n",
      "|    mean_step_reward   | 0.13234659  |\n",
      "|    n_updates          | 4364        |\n",
      "|    policyGradLoss     | -0.00592    |\n",
      "|    value_loss         | 0.674       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 819          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 130          |\n",
      "|    total_timesteps    | 8953856      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0075049065 |\n",
      "|    entropy_loss       | -1.88        |\n",
      "|    explained_variance | 0.957        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0568       |\n",
      "|    mean_step_reward   | 0.13944495   |\n",
      "|    n_updates          | 4368         |\n",
      "|    policyGradLoss     | -0.00534     |\n",
      "|    value_loss         | 0.619        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 818          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 140          |\n",
      "|    total_timesteps    | 8962048      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0096484665 |\n",
      "|    entropy_loss       | -1.91        |\n",
      "|    explained_variance | 0.937        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0716       |\n",
      "|    mean_step_reward   | 0.1378648    |\n",
      "|    n_updates          | 4372         |\n",
      "|    policyGradLoss     | -0.00782     |\n",
      "|    value_loss         | 0.633        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 150         |\n",
      "|    total_timesteps    | 8970240     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009520337 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.913       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0766      |\n",
      "|    mean_step_reward   | 0.12024532  |\n",
      "|    n_updates          | 4376        |\n",
      "|    policyGradLoss     | -0.00749    |\n",
      "|    value_loss         | 0.799       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 8978432     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013137272 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0876      |\n",
      "|    mean_step_reward   | 0.13095802  |\n",
      "|    n_updates          | 4380        |\n",
      "|    policyGradLoss     | -0.00838    |\n",
      "|    value_loss         | 0.646       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 8986624     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008113237 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.905       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.146       |\n",
      "|    mean_step_reward   | 0.12987605  |\n",
      "|    n_updates          | 4384        |\n",
      "|    policyGradLoss     | -0.00324    |\n",
      "|    value_loss         | 0.756       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 8994816     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013983108 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.91        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0799      |\n",
      "|    mean_step_reward   | 0.12701161  |\n",
      "|    n_updates          | 4388        |\n",
      "|    policyGradLoss     | -0.00386    |\n",
      "|    value_loss         | 0.768       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 815        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 190        |\n",
      "|    total_timesteps    | 9003008    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01007238 |\n",
      "|    entropy_loss       | -1.87      |\n",
      "|    explained_variance | 0.948      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.266      |\n",
      "|    mean_step_reward   | 0.13429846 |\n",
      "|    n_updates          | 4392       |\n",
      "|    policyGradLoss     | -0.00985   |\n",
      "|    value_loss         | 0.842      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 9011200     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008202054 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0369      |\n",
      "|    mean_step_reward   | 0.13266899  |\n",
      "|    n_updates          | 4396        |\n",
      "|    policyGradLoss     | -0.00432    |\n",
      "|    value_loss         | 0.476       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 9019392     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008503636 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.906       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00883    |\n",
      "|    mean_step_reward   | 0.1254674   |\n",
      "|    n_updates          | 4400        |\n",
      "|    policyGradLoss     | -0.00632    |\n",
      "|    value_loss         | 0.455       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 9027584     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009451491 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.96        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.144       |\n",
      "|    mean_step_reward   | 0.1379439   |\n",
      "|    n_updates          | 4404        |\n",
      "|    policyGradLoss     | -0.00589    |\n",
      "|    value_loss         | 0.707       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 813          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 231          |\n",
      "|    total_timesteps    | 9035776      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0068186084 |\n",
      "|    entropy_loss       | -1.89        |\n",
      "|    explained_variance | 0.893        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.113        |\n",
      "|    mean_step_reward   | 0.13260883   |\n",
      "|    n_updates          | 4408         |\n",
      "|    policyGradLoss     | -0.00201     |\n",
      "|    value_loss         | 0.626        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 9043968     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008435146 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00979    |\n",
      "|    mean_step_reward   | 0.13556206  |\n",
      "|    n_updates          | 4412        |\n",
      "|    policyGradLoss     | -0.0115     |\n",
      "|    value_loss         | 0.29        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 813          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 251          |\n",
      "|    total_timesteps    | 9052160      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0072440477 |\n",
      "|    entropy_loss       | -1.93        |\n",
      "|    explained_variance | 0.93         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.185        |\n",
      "|    mean_step_reward   | 0.13863114   |\n",
      "|    n_updates          | 4416         |\n",
      "|    policyGradLoss     | -0.00332     |\n",
      "|    value_loss         | 0.915        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 9060352     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009247227 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.9         |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0836      |\n",
      "|    mean_step_reward   | 0.117535084 |\n",
      "|    n_updates          | 4420        |\n",
      "|    policyGradLoss     | -0.00792    |\n",
      "|    value_loss         | 0.657       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 9068544     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007929713 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.881       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0848      |\n",
      "|    mean_step_reward   | 0.14400658  |\n",
      "|    n_updates          | 4424        |\n",
      "|    policyGradLoss     | -0.00112    |\n",
      "|    value_loss         | 0.88        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 812          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 282          |\n",
      "|    total_timesteps    | 9076736      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0063929376 |\n",
      "|    entropy_loss       | -1.94        |\n",
      "|    explained_variance | 0.93         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0246       |\n",
      "|    mean_step_reward   | 0.1370593    |\n",
      "|    n_updates          | 4428         |\n",
      "|    policyGradLoss     | -0.00676     |\n",
      "|    value_loss         | 0.552        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 9084928     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007835591 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.21        |\n",
      "|    mean_step_reward   | 0.139759    |\n",
      "|    n_updates          | 4432        |\n",
      "|    policyGradLoss     | -0.00663    |\n",
      "|    value_loss         | 0.708       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 812          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 302          |\n",
      "|    total_timesteps    | 9093120      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0074802805 |\n",
      "|    entropy_loss       | -1.94        |\n",
      "|    explained_variance | 0.96         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.101        |\n",
      "|    mean_step_reward   | 0.13815704   |\n",
      "|    n_updates          | 4436         |\n",
      "|    policyGradLoss     | -0.00549     |\n",
      "|    value_loss         | 0.56         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 812        |\n",
      "|    iterations         | 31         |\n",
      "|    time_elapsed       | 312        |\n",
      "|    total_timesteps    | 9101312    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00848393 |\n",
      "|    entropy_loss       | -1.91      |\n",
      "|    explained_variance | 0.95       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.167      |\n",
      "|    mean_step_reward   | 0.12070468 |\n",
      "|    n_updates          | 4440       |\n",
      "|    policyGradLoss     | -0.00474   |\n",
      "|    value_loss         | 0.72       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 322         |\n",
      "|    total_timesteps    | 9109504     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008235883 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.904       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.155       |\n",
      "|    mean_step_reward   | 0.1249383   |\n",
      "|    n_updates          | 4444        |\n",
      "|    policyGradLoss     | -0.00643    |\n",
      "|    value_loss         | 0.844       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 9117696     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007713182 |\n",
      "|    entropy_loss       | -1.93       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.101       |\n",
      "|    mean_step_reward   | 0.1313678   |\n",
      "|    n_updates          | 4448        |\n",
      "|    policyGradLoss     | -0.00821    |\n",
      "|    value_loss         | 0.602       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 812          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 342          |\n",
      "|    total_timesteps    | 9125888      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0077350456 |\n",
      "|    entropy_loss       | -1.89        |\n",
      "|    explained_variance | 0.954        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.00954      |\n",
      "|    mean_step_reward   | 0.1275215    |\n",
      "|    n_updates          | 4452         |\n",
      "|    policyGradLoss     | -0.0107      |\n",
      "|    value_loss         | 0.391        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 353         |\n",
      "|    total_timesteps    | 9134080     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009352016 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0173      |\n",
      "|    mean_step_reward   | 0.1392641   |\n",
      "|    n_updates          | 4456        |\n",
      "|    policyGradLoss     | -0.0085     |\n",
      "|    value_loss         | 0.435       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 811        |\n",
      "|    iterations         | 36         |\n",
      "|    time_elapsed       | 363        |\n",
      "|    total_timesteps    | 9142272    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00935107 |\n",
      "|    entropy_loss       | -1.92      |\n",
      "|    explained_variance | 0.957      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.151      |\n",
      "|    mean_step_reward   | 0.13955444 |\n",
      "|    n_updates          | 4460       |\n",
      "|    policyGradLoss     | -0.00581   |\n",
      "|    value_loss         | 0.551      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 373         |\n",
      "|    total_timesteps    | 9150464     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007940214 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.787       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.16        |\n",
      "|    mean_step_reward   | 0.11966497  |\n",
      "|    n_updates          | 4464        |\n",
      "|    policyGradLoss     | 0.000995    |\n",
      "|    value_loss         | 0.813       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 383         |\n",
      "|    total_timesteps    | 9158656     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010096884 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0687      |\n",
      "|    mean_step_reward   | 0.13337731  |\n",
      "|    n_updates          | 4468        |\n",
      "|    policyGradLoss     | -0.00857    |\n",
      "|    value_loss         | 0.547       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 393         |\n",
      "|    total_timesteps    | 9166848     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012429351 |\n",
      "|    entropy_loss       | -1.94       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0368      |\n",
      "|    mean_step_reward   | 0.14577807  |\n",
      "|    n_updates          | 4472        |\n",
      "|    policyGradLoss     | -0.00898    |\n",
      "|    value_loss         | 0.278       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 811        |\n",
      "|    iterations         | 40         |\n",
      "|    time_elapsed       | 403        |\n",
      "|    total_timesteps    | 9175040    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01266985 |\n",
      "|    entropy_loss       | -1.87      |\n",
      "|    explained_variance | 0.971      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.000724  |\n",
      "|    mean_step_reward   | 0.1391174  |\n",
      "|    n_updates          | 4476       |\n",
      "|    policyGradLoss     | -0.0106    |\n",
      "|    value_loss         | 0.296      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_27.zip\n",
      "[EVAL] Mean Return: 189.635, Best Return: 189.935\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_27_189.63.mp4\n",
      "\n",
      "=== Round 29 | Learn 327680 steps (Total trained: 9175040) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1114    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 9183232 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 929         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 9191424     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010408166 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0655      |\n",
      "|    mean_step_reward   | 0.13948712  |\n",
      "|    n_updates          | 4484        |\n",
      "|    policyGradLoss     | -0.0108     |\n",
      "|    value_loss         | 0.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 889         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 9199616     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010436769 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.147       |\n",
      "|    mean_step_reward   | 0.1403701   |\n",
      "|    n_updates          | 4488        |\n",
      "|    policyGradLoss     | -0.00928    |\n",
      "|    value_loss         | 0.435       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 871         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 37          |\n",
      "|    total_timesteps    | 9207808     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014042655 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00382     |\n",
      "|    mean_step_reward   | 0.14552112  |\n",
      "|    n_updates          | 4492        |\n",
      "|    policyGradLoss     | -0.0121     |\n",
      "|    value_loss         | 0.269       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 856         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 47          |\n",
      "|    total_timesteps    | 9216000     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010068756 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.055       |\n",
      "|    mean_step_reward   | 0.13767663  |\n",
      "|    n_updates          | 4496        |\n",
      "|    policyGradLoss     | -0.0104     |\n",
      "|    value_loss         | 0.368       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 844         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 9224192     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012533364 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.181       |\n",
      "|    mean_step_reward   | 0.13760184  |\n",
      "|    n_updates          | 4500        |\n",
      "|    policyGradLoss     | -0.00797    |\n",
      "|    value_loss         | 0.526       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 834         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 9232384     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010807533 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0443      |\n",
      "|    mean_step_reward   | 0.13835746  |\n",
      "|    n_updates          | 4504        |\n",
      "|    policyGradLoss     | -0.0106     |\n",
      "|    value_loss         | 0.322       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 830         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 9240576     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008388098 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0404      |\n",
      "|    mean_step_reward   | 0.14840242  |\n",
      "|    n_updates          | 4508        |\n",
      "|    policyGradLoss     | -0.00846    |\n",
      "|    value_loss         | 0.461       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 824          |\n",
      "|    iterations         | 9            |\n",
      "|    time_elapsed       | 89           |\n",
      "|    total_timesteps    | 9248768      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0097213425 |\n",
      "|    entropy_loss       | -1.88        |\n",
      "|    explained_variance | 0.959        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.248        |\n",
      "|    mean_step_reward   | 0.14043005   |\n",
      "|    n_updates          | 4512         |\n",
      "|    policyGradLoss     | -0.00594     |\n",
      "|    value_loss         | 0.983        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 99          |\n",
      "|    total_timesteps    | 9256960     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012542332 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0908      |\n",
      "|    mean_step_reward   | 0.13781758  |\n",
      "|    n_updates          | 4516        |\n",
      "|    policyGradLoss     | -0.00927    |\n",
      "|    value_loss         | 0.396       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 110         |\n",
      "|    total_timesteps    | 9265152     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010881123 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.943       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0917      |\n",
      "|    mean_step_reward   | 0.13930322  |\n",
      "|    n_updates          | 4520        |\n",
      "|    policyGradLoss     | -0.0028     |\n",
      "|    value_loss         | 0.686       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 9273344     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012264373 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0251      |\n",
      "|    mean_step_reward   | 0.14356448  |\n",
      "|    n_updates          | 4524        |\n",
      "|    policyGradLoss     | -0.0137     |\n",
      "|    value_loss         | 0.244       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 130         |\n",
      "|    total_timesteps    | 9281536     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013110943 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00974    |\n",
      "|    mean_step_reward   | 0.1381233   |\n",
      "|    n_updates          | 4528        |\n",
      "|    policyGradLoss     | -0.00974    |\n",
      "|    value_loss         | 0.357       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 140         |\n",
      "|    total_timesteps    | 9289728     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011675974 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0339      |\n",
      "|    mean_step_reward   | 0.14335406  |\n",
      "|    n_updates          | 4532        |\n",
      "|    policyGradLoss     | -0.00879    |\n",
      "|    value_loss         | 0.352       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 151         |\n",
      "|    total_timesteps    | 9297920     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012337912 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0473      |\n",
      "|    mean_step_reward   | 0.13821912  |\n",
      "|    n_updates          | 4536        |\n",
      "|    policyGradLoss     | -0.012      |\n",
      "|    value_loss         | 0.401       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 161         |\n",
      "|    total_timesteps    | 9306112     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009077447 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.289       |\n",
      "|    mean_step_reward   | 0.14075989  |\n",
      "|    n_updates          | 4540        |\n",
      "|    policyGradLoss     | -0.00376    |\n",
      "|    value_loss         | 0.756       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 171         |\n",
      "|    total_timesteps    | 9314304     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009856889 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.923       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.391       |\n",
      "|    mean_step_reward   | 0.12671822  |\n",
      "|    n_updates          | 4544        |\n",
      "|    policyGradLoss     | -0.00321    |\n",
      "|    value_loss         | 1.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 9322496     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011244046 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0527      |\n",
      "|    mean_step_reward   | 0.14103618  |\n",
      "|    n_updates          | 4548        |\n",
      "|    policyGradLoss     | -0.00929    |\n",
      "|    value_loss         | 0.412       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 811          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 191          |\n",
      "|    total_timesteps    | 9330688      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0134342685 |\n",
      "|    entropy_loss       | -1.85        |\n",
      "|    explained_variance | 0.96         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.18         |\n",
      "|    mean_step_reward   | 0.1298016    |\n",
      "|    n_updates          | 4552         |\n",
      "|    policyGradLoss     | -0.00548     |\n",
      "|    value_loss         | 0.755        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 9338880     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015172375 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0735      |\n",
      "|    mean_step_reward   | 0.12682186  |\n",
      "|    n_updates          | 4556        |\n",
      "|    policyGradLoss     | -0.0119     |\n",
      "|    value_loss         | 0.269       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 9347072     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012075234 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.331       |\n",
      "|    mean_step_reward   | 0.14578333  |\n",
      "|    n_updates          | 4560        |\n",
      "|    policyGradLoss     | -0.00604    |\n",
      "|    value_loss         | 0.601       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 9355264     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013933771 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0214     |\n",
      "|    mean_step_reward   | 0.13880885  |\n",
      "|    n_updates          | 4564        |\n",
      "|    policyGradLoss     | -0.0143     |\n",
      "|    value_loss         | 0.166       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 811          |\n",
      "|    iterations         | 23           |\n",
      "|    time_elapsed       | 232          |\n",
      "|    total_timesteps    | 9363456      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0101291295 |\n",
      "|    entropy_loss       | -1.85        |\n",
      "|    explained_variance | 0.971        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0965       |\n",
      "|    mean_step_reward   | 0.13717794   |\n",
      "|    n_updates          | 4568         |\n",
      "|    policyGradLoss     | -0.00977     |\n",
      "|    value_loss         | 0.479        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 9371648     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009359149 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0339      |\n",
      "|    mean_step_reward   | 0.14026247  |\n",
      "|    n_updates          | 4572        |\n",
      "|    policyGradLoss     | -0.0113     |\n",
      "|    value_loss         | 0.308       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 9379840     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012144171 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0857      |\n",
      "|    mean_step_reward   | 0.13369839  |\n",
      "|    n_updates          | 4576        |\n",
      "|    policyGradLoss     | -0.0108     |\n",
      "|    value_loss         | 0.356       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 9388032     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013025294 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0101      |\n",
      "|    mean_step_reward   | 0.13972598  |\n",
      "|    n_updates          | 4580        |\n",
      "|    policyGradLoss     | -0.0106     |\n",
      "|    value_loss         | 0.377       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 9396224     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012424259 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.938       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.135       |\n",
      "|    mean_step_reward   | 0.13541006  |\n",
      "|    n_updates          | 4584        |\n",
      "|    policyGradLoss     | -0.00442    |\n",
      "|    value_loss         | 0.743       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 810        |\n",
      "|    iterations         | 28         |\n",
      "|    time_elapsed       | 282        |\n",
      "|    total_timesteps    | 9404416    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01025199 |\n",
      "|    entropy_loss       | -1.85      |\n",
      "|    explained_variance | 0.964      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0325     |\n",
      "|    mean_step_reward   | 0.14252399 |\n",
      "|    n_updates          | 4588       |\n",
      "|    policyGradLoss     | -0.00356   |\n",
      "|    value_loss         | 0.58       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 9412608     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012001174 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0375      |\n",
      "|    mean_step_reward   | 0.14901006  |\n",
      "|    n_updates          | 4592        |\n",
      "|    policyGradLoss     | -0.01       |\n",
      "|    value_loss         | 0.452       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 303         |\n",
      "|    total_timesteps    | 9420800     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010661816 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.058       |\n",
      "|    mean_step_reward   | 0.13603204  |\n",
      "|    n_updates          | 4596        |\n",
      "|    policyGradLoss     | -0.00773    |\n",
      "|    value_loss         | 0.572       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 313         |\n",
      "|    total_timesteps    | 9428992     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011599676 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00908    |\n",
      "|    mean_step_reward   | 0.1514532   |\n",
      "|    n_updates          | 4600        |\n",
      "|    policyGradLoss     | -0.0105     |\n",
      "|    value_loss         | 0.262       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 323         |\n",
      "|    total_timesteps    | 9437184     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012147099 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0214      |\n",
      "|    mean_step_reward   | 0.1474485   |\n",
      "|    n_updates          | 4604        |\n",
      "|    policyGradLoss     | -0.00694    |\n",
      "|    value_loss         | 0.322       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 9445376     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013079142 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0186      |\n",
      "|    mean_step_reward   | 0.13782424  |\n",
      "|    n_updates          | 4608        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.256       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 343         |\n",
      "|    total_timesteps    | 9453568     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010071602 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.158       |\n",
      "|    mean_step_reward   | 0.13864723  |\n",
      "|    n_updates          | 4612        |\n",
      "|    policyGradLoss     | -0.00544    |\n",
      "|    value_loss         | 0.619       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 353         |\n",
      "|    total_timesteps    | 9461760     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010619452 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.937       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0443      |\n",
      "|    mean_step_reward   | 0.1273819   |\n",
      "|    n_updates          | 4616        |\n",
      "|    policyGradLoss     | -0.00793    |\n",
      "|    value_loss         | 0.471       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 364         |\n",
      "|    total_timesteps    | 9469952     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014739007 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00192    |\n",
      "|    mean_step_reward   | 0.1461705   |\n",
      "|    n_updates          | 4620        |\n",
      "|    policyGradLoss     | -0.0105     |\n",
      "|    value_loss         | 0.202       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 373         |\n",
      "|    total_timesteps    | 9478144     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009897225 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.142       |\n",
      "|    mean_step_reward   | 0.14298372  |\n",
      "|    n_updates          | 4624        |\n",
      "|    policyGradLoss     | -0.00614    |\n",
      "|    value_loss         | 0.487       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 384         |\n",
      "|    total_timesteps    | 9486336     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013916053 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.026       |\n",
      "|    mean_step_reward   | 0.15047798  |\n",
      "|    n_updates          | 4628        |\n",
      "|    policyGradLoss     | -0.00928    |\n",
      "|    value_loss         | 0.251       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 394         |\n",
      "|    total_timesteps    | 9494528     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011922904 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0213     |\n",
      "|    mean_step_reward   | 0.14191245  |\n",
      "|    n_updates          | 4632        |\n",
      "|    policyGradLoss     | -0.00909    |\n",
      "|    value_loss         | 0.191       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 404         |\n",
      "|    total_timesteps    | 9502720     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014508281 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.109       |\n",
      "|    mean_step_reward   | 0.14059272  |\n",
      "|    n_updates          | 4636        |\n",
      "|    policyGradLoss     | -0.01       |\n",
      "|    value_loss         | 0.332       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_28.zip\n",
      "[EVAL] Mean Return: 282.261, Best Return: 282.361\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_28_282.26.mp4\n",
      "\n",
      "=== Round 30 | Learn 327680 steps (Total trained: 9502720) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1131    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 9510912 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 944          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 9519104      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0128744645 |\n",
      "|    entropy_loss       | -1.81        |\n",
      "|    explained_variance | 0.97         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0153       |\n",
      "|    mean_step_reward   | 0.13471389   |\n",
      "|    n_updates          | 4644         |\n",
      "|    policyGradLoss     | -0.00929     |\n",
      "|    value_loss         | 0.304        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 886         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 9527296     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012208674 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.024       |\n",
      "|    mean_step_reward   | 0.14685962  |\n",
      "|    n_updates          | 4648        |\n",
      "|    policyGradLoss     | -0.00757    |\n",
      "|    value_loss         | 0.399       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 870         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 37          |\n",
      "|    total_timesteps    | 9535488     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012063097 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00562    |\n",
      "|    mean_step_reward   | 0.14522946  |\n",
      "|    n_updates          | 4652        |\n",
      "|    policyGradLoss     | -0.0119     |\n",
      "|    value_loss         | 0.242       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 854         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 47          |\n",
      "|    total_timesteps    | 9543680     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007890413 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0737      |\n",
      "|    mean_step_reward   | 0.15133533  |\n",
      "|    n_updates          | 4656        |\n",
      "|    policyGradLoss     | -0.0059     |\n",
      "|    value_loss         | 0.477       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 846         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 9551872     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012052009 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.996       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0451     |\n",
      "|    mean_step_reward   | 0.15533799  |\n",
      "|    n_updates          | 4660        |\n",
      "|    policyGradLoss     | -0.0151     |\n",
      "|    value_loss         | 0.0871      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 841         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 9560064     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014176748 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.996       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0423     |\n",
      "|    mean_step_reward   | 0.15330109  |\n",
      "|    n_updates          | 4664        |\n",
      "|    policyGradLoss     | -0.0115     |\n",
      "|    value_loss         | 0.112       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 838          |\n",
      "|    iterations         | 8            |\n",
      "|    time_elapsed       | 78           |\n",
      "|    total_timesteps    | 9568256      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0128723895 |\n",
      "|    entropy_loss       | -1.85        |\n",
      "|    explained_variance | 0.985        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0183       |\n",
      "|    mean_step_reward   | 0.14838004   |\n",
      "|    n_updates          | 4668         |\n",
      "|    policyGradLoss     | -0.00724     |\n",
      "|    value_loss         | 0.331        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 838         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 87          |\n",
      "|    total_timesteps    | 9576448     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014922264 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.173       |\n",
      "|    mean_step_reward   | 0.15065984  |\n",
      "|    n_updates          | 4672        |\n",
      "|    policyGradLoss     | -0.011      |\n",
      "|    value_loss         | 0.338       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 834         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 9584640     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010952465 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0387      |\n",
      "|    mean_step_reward   | 0.15617818  |\n",
      "|    n_updates          | 4676        |\n",
      "|    policyGradLoss     | -0.0097     |\n",
      "|    value_loss         | 0.255       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 832         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 108         |\n",
      "|    total_timesteps    | 9592832     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013763253 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.87        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.102       |\n",
      "|    mean_step_reward   | 0.117613606 |\n",
      "|    n_updates          | 4680        |\n",
      "|    policyGradLoss     | -0.0011     |\n",
      "|    value_loss         | 0.637       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 829          |\n",
      "|    iterations         | 12           |\n",
      "|    time_elapsed       | 118          |\n",
      "|    total_timesteps    | 9601024      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0132074235 |\n",
      "|    entropy_loss       | -1.85        |\n",
      "|    explained_variance | 0.948        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.119        |\n",
      "|    mean_step_reward   | 0.1421526    |\n",
      "|    n_updates          | 4684         |\n",
      "|    policyGradLoss     | -0.00336     |\n",
      "|    value_loss         | 0.636        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 827         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 128         |\n",
      "|    total_timesteps    | 9609216     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009945005 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00272     |\n",
      "|    mean_step_reward   | 0.13714421  |\n",
      "|    n_updates          | 4688        |\n",
      "|    policyGradLoss     | -0.00613    |\n",
      "|    value_loss         | 0.454       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 9617408     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011092722 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0298      |\n",
      "|    mean_step_reward   | 0.14398211  |\n",
      "|    n_updates          | 4692        |\n",
      "|    policyGradLoss     | -0.00903    |\n",
      "|    value_loss         | 0.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 823         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 149         |\n",
      "|    total_timesteps    | 9625600     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011371166 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0104      |\n",
      "|    mean_step_reward   | 0.15145819  |\n",
      "|    n_updates          | 4696        |\n",
      "|    policyGradLoss     | -0.00608    |\n",
      "|    value_loss         | 0.42        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 159         |\n",
      "|    total_timesteps    | 9633792     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012310581 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0568      |\n",
      "|    mean_step_reward   | 0.13598055  |\n",
      "|    n_updates          | 4700        |\n",
      "|    policyGradLoss     | -0.00853    |\n",
      "|    value_loss         | 0.272       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 9641984     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011783883 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0995      |\n",
      "|    mean_step_reward   | 0.15820599  |\n",
      "|    n_updates          | 4704        |\n",
      "|    policyGradLoss     | -0.00658    |\n",
      "|    value_loss         | 0.466       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 821          |\n",
      "|    iterations         | 18           |\n",
      "|    time_elapsed       | 179          |\n",
      "|    total_timesteps    | 9650176      |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0122622065 |\n",
      "|    entropy_loss       | -1.83        |\n",
      "|    explained_variance | 0.958        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0115       |\n",
      "|    mean_step_reward   | 0.12494599   |\n",
      "|    n_updates          | 4708         |\n",
      "|    policyGradLoss     | -0.00501     |\n",
      "|    value_loss         | 0.35         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 9658368     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010782293 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00923     |\n",
      "|    mean_step_reward   | 0.14379264  |\n",
      "|    n_updates          | 4712        |\n",
      "|    policyGradLoss     | -0.00764    |\n",
      "|    value_loss         | 0.348       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 9666560     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011262696 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.318       |\n",
      "|    mean_step_reward   | 0.14346896  |\n",
      "|    n_updates          | 4716        |\n",
      "|    policyGradLoss     | -0.009      |\n",
      "|    value_loss         | 0.515       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 9674752     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013725243 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0227      |\n",
      "|    mean_step_reward   | 0.13894683  |\n",
      "|    n_updates          | 4720        |\n",
      "|    policyGradLoss     | -0.00928    |\n",
      "|    value_loss         | 0.216       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 9682944     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011533259 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0147      |\n",
      "|    mean_step_reward   | 0.15444413  |\n",
      "|    n_updates          | 4724        |\n",
      "|    policyGradLoss     | -0.00233    |\n",
      "|    value_loss         | 0.463       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 9691136     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012258094 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.141       |\n",
      "|    mean_step_reward   | 0.13027598  |\n",
      "|    n_updates          | 4728        |\n",
      "|    policyGradLoss     | -0.00163    |\n",
      "|    value_loss         | 0.946       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 9699328     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008391455 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.018       |\n",
      "|    mean_step_reward   | 0.14254245  |\n",
      "|    n_updates          | 4732        |\n",
      "|    policyGradLoss     | -0.00676    |\n",
      "|    value_loss         | 0.439       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 250         |\n",
      "|    total_timesteps    | 9707520     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.007950965 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0331      |\n",
      "|    mean_step_reward   | 0.15115514  |\n",
      "|    n_updates          | 4736        |\n",
      "|    policyGradLoss     | -0.00451    |\n",
      "|    value_loss         | 0.532       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 9715712     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010289001 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.155       |\n",
      "|    mean_step_reward   | 0.13428727  |\n",
      "|    n_updates          | 4740        |\n",
      "|    policyGradLoss     | -0.00298    |\n",
      "|    value_loss         | 0.734       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 814        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 271        |\n",
      "|    total_timesteps    | 9723904    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0081452  |\n",
      "|    entropy_loss       | -1.9       |\n",
      "|    explained_variance | 0.951      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.13       |\n",
      "|    mean_step_reward   | 0.14575933 |\n",
      "|    n_updates          | 4744       |\n",
      "|    policyGradLoss     | -0.00431   |\n",
      "|    value_loss         | 0.69       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 281         |\n",
      "|    total_timesteps    | 9732096     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010432053 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.922       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0252      |\n",
      "|    mean_step_reward   | 0.13535449  |\n",
      "|    n_updates          | 4748        |\n",
      "|    policyGradLoss     | -0.00191    |\n",
      "|    value_loss         | 0.536       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 9740288     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013187352 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0361     |\n",
      "|    mean_step_reward   | 0.14429756  |\n",
      "|    n_updates          | 4752        |\n",
      "|    policyGradLoss     | -0.014      |\n",
      "|    value_loss         | 0.143       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 302         |\n",
      "|    total_timesteps    | 9748480     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012752732 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0489      |\n",
      "|    mean_step_reward   | 0.14750046  |\n",
      "|    n_updates          | 4756        |\n",
      "|    policyGradLoss     | -0.0108     |\n",
      "|    value_loss         | 0.253       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 312         |\n",
      "|    total_timesteps    | 9756672     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014644128 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.195       |\n",
      "|    mean_step_reward   | 0.13889337  |\n",
      "|    n_updates          | 4760        |\n",
      "|    policyGradLoss     | -0.00953    |\n",
      "|    value_loss         | 0.675       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 322         |\n",
      "|    total_timesteps    | 9764864     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010963786 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0835      |\n",
      "|    mean_step_reward   | 0.14371991  |\n",
      "|    n_updates          | 4764        |\n",
      "|    policyGradLoss     | -0.0109     |\n",
      "|    value_loss         | 0.313       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 332         |\n",
      "|    total_timesteps    | 9773056     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014806062 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.172       |\n",
      "|    mean_step_reward   | 0.14992951  |\n",
      "|    n_updates          | 4768        |\n",
      "|    policyGradLoss     | -0.00987    |\n",
      "|    value_loss         | 0.629       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 342         |\n",
      "|    total_timesteps    | 9781248     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011943709 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00884     |\n",
      "|    mean_step_reward   | 0.14265126  |\n",
      "|    n_updates          | 4772        |\n",
      "|    policyGradLoss     | -0.00349    |\n",
      "|    value_loss         | 0.326       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 352         |\n",
      "|    total_timesteps    | 9789440     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010293809 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00173     |\n",
      "|    mean_step_reward   | 0.12909225  |\n",
      "|    n_updates          | 4776        |\n",
      "|    policyGradLoss     | -0.0084     |\n",
      "|    value_loss         | 0.567       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 812       |\n",
      "|    iterations         | 36        |\n",
      "|    time_elapsed       | 363       |\n",
      "|    total_timesteps    | 9797632   |\n",
      "| train/                |           |\n",
      "|    approx_kl          | 0.0086262 |\n",
      "|    entropy_loss       | -1.86     |\n",
      "|    explained_variance | 0.921     |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    loss               | 0.187     |\n",
      "|    mean_step_reward   | 0.1307986 |\n",
      "|    n_updates          | 4780      |\n",
      "|    policyGradLoss     | -0.00429  |\n",
      "|    value_loss         | 0.791     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 373         |\n",
      "|    total_timesteps    | 9805824     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010014911 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.93        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0755      |\n",
      "|    mean_step_reward   | 0.1345326   |\n",
      "|    n_updates          | 4784        |\n",
      "|    policyGradLoss     | -0.0056     |\n",
      "|    value_loss         | 0.686       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 383         |\n",
      "|    total_timesteps    | 9814016     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011946856 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.934       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.254       |\n",
      "|    mean_step_reward   | 0.12653981  |\n",
      "|    n_updates          | 4788        |\n",
      "|    policyGradLoss     | -0.00328    |\n",
      "|    value_loss         | 1.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 393         |\n",
      "|    total_timesteps    | 9822208     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012586417 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.11        |\n",
      "|    mean_step_reward   | 0.12971088  |\n",
      "|    n_updates          | 4792        |\n",
      "|    policyGradLoss     | -0.00855    |\n",
      "|    value_loss         | 0.534       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 403         |\n",
      "|    total_timesteps    | 9830400     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013026587 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.047       |\n",
      "|    mean_step_reward   | 0.14968175  |\n",
      "|    n_updates          | 4796        |\n",
      "|    policyGradLoss     | -0.00746    |\n",
      "|    value_loss         | 0.46        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_29.zip\n",
      "[EVAL] Mean Return: 190.652, Best Return: 190.952\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_29_190.65.mp4\n",
      "\n",
      "=== Round 31 | Learn 327680 steps (Total trained: 9830400) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1126    |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 7       |\n",
      "|    total_timesteps | 9838592 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 925         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 9846784     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012118503 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00433     |\n",
      "|    mean_step_reward   | 0.14239743  |\n",
      "|    n_updates          | 4804        |\n",
      "|    policyGradLoss     | -0.0095     |\n",
      "|    value_loss         | 0.306       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 883         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 9854976     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014881188 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0489      |\n",
      "|    mean_step_reward   | 0.13416977  |\n",
      "|    n_updates          | 4808        |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.378       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 859         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 9863168     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010984458 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.927       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0967      |\n",
      "|    mean_step_reward   | 0.13651773  |\n",
      "|    n_updates          | 4812        |\n",
      "|    policyGradLoss     | -0.00537    |\n",
      "|    value_loss         | 1.09        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 842         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 48          |\n",
      "|    total_timesteps    | 9871360     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014253734 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0902      |\n",
      "|    mean_step_reward   | 0.13997197  |\n",
      "|    n_updates          | 4816        |\n",
      "|    policyGradLoss     | -0.00788    |\n",
      "|    value_loss         | 0.543       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 9879552     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011657622 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0178      |\n",
      "|    mean_step_reward   | 0.14221883  |\n",
      "|    n_updates          | 4820        |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.284       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 833         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 9887744     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010440147 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.109       |\n",
      "|    mean_step_reward   | 0.1390484   |\n",
      "|    n_updates          | 4824        |\n",
      "|    policyGradLoss     | -0.00822    |\n",
      "|    value_loss         | 0.691       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 829         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 9895936     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009673359 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.121       |\n",
      "|    mean_step_reward   | 0.13014537  |\n",
      "|    n_updates          | 4828        |\n",
      "|    policyGradLoss     | -0.00466    |\n",
      "|    value_loss         | 0.731       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 826        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 89         |\n",
      "|    total_timesteps    | 9904128    |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01249596 |\n",
      "|    entropy_loss       | -1.9       |\n",
      "|    explained_variance | 0.973      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00762    |\n",
      "|    mean_step_reward   | 0.13251975 |\n",
      "|    n_updates          | 4832       |\n",
      "|    policyGradLoss     | -0.0119    |\n",
      "|    value_loss         | 0.317      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 99          |\n",
      "|    total_timesteps    | 9912320     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013348874 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.012       |\n",
      "|    mean_step_reward   | 0.1433228   |\n",
      "|    n_updates          | 4836        |\n",
      "|    policyGradLoss     | -0.00935    |\n",
      "|    value_loss         | 0.266       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 9920512     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010906096 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.13        |\n",
      "|    mean_step_reward   | 0.14567092  |\n",
      "|    n_updates          | 4840        |\n",
      "|    policyGradLoss     | -0.00289    |\n",
      "|    value_loss         | 0.624       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 9928704     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.01308837  |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.895       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.395       |\n",
      "|    mean_step_reward   | 0.120153174 |\n",
      "|    n_updates          | 4844        |\n",
      "|    policyGradLoss     | -0.0037     |\n",
      "|    value_loss         | 0.937       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 129         |\n",
      "|    total_timesteps    | 9936896     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010831669 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0526      |\n",
      "|    mean_step_reward   | 0.12975113  |\n",
      "|    n_updates          | 4848        |\n",
      "|    policyGradLoss     | -0.00702    |\n",
      "|    value_loss         | 0.731       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 140         |\n",
      "|    total_timesteps    | 9945088     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012662831 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.155       |\n",
      "|    mean_step_reward   | 0.13923132  |\n",
      "|    n_updates          | 4852        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.663       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 150         |\n",
      "|    total_timesteps    | 9953280     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013742013 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.102       |\n",
      "|    mean_step_reward   | 0.13707471  |\n",
      "|    n_updates          | 4856        |\n",
      "|    policyGradLoss     | -0.0085     |\n",
      "|    value_loss         | 0.424       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 9961472     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010423347 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0119      |\n",
      "|    mean_step_reward   | 0.14600372  |\n",
      "|    n_updates          | 4860        |\n",
      "|    policyGradLoss     | -0.00701    |\n",
      "|    value_loss         | 0.417       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 9969664     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008674258 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.316       |\n",
      "|    mean_step_reward   | 0.12720728  |\n",
      "|    n_updates          | 4864        |\n",
      "|    policyGradLoss     | -0.00727    |\n",
      "|    value_loss         | 0.804       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 9977856     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010593721 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0234      |\n",
      "|    mean_step_reward   | 0.14042345  |\n",
      "|    n_updates          | 4868        |\n",
      "|    policyGradLoss     | -0.00991    |\n",
      "|    value_loss         | 0.385       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 9986048     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010403524 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00823     |\n",
      "|    mean_step_reward   | 0.1525738   |\n",
      "|    n_updates          | 4872        |\n",
      "|    policyGradLoss     | -0.00904    |\n",
      "|    value_loss         | 0.286       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 9994240     |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009202637 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00982     |\n",
      "|    mean_step_reward   | 0.13807765  |\n",
      "|    n_updates          | 4876        |\n",
      "|    policyGradLoss     | -0.00841    |\n",
      "|    value_loss         | 0.325       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 10002432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013536818 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.119       |\n",
      "|    mean_step_reward   | 0.131312    |\n",
      "|    n_updates          | 4880        |\n",
      "|    policyGradLoss     | -0.00821    |\n",
      "|    value_loss         | 0.609       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 10010624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010007074 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0467      |\n",
      "|    mean_step_reward   | 0.13781612  |\n",
      "|    n_updates          | 4884        |\n",
      "|    policyGradLoss     | -0.00647    |\n",
      "|    value_loss         | 0.384       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 10018816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010960296 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0901      |\n",
      "|    mean_step_reward   | 0.15106875  |\n",
      "|    n_updates          | 4888        |\n",
      "|    policyGradLoss     | -0.00678    |\n",
      "|    value_loss         | 0.411       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 10027008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010752511 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.161       |\n",
      "|    mean_step_reward   | 0.14002366  |\n",
      "|    n_updates          | 4892        |\n",
      "|    policyGradLoss     | -0.00829    |\n",
      "|    value_loss         | 0.541       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 10035200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012184218 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.111       |\n",
      "|    mean_step_reward   | 0.1470123   |\n",
      "|    n_updates          | 4896        |\n",
      "|    policyGradLoss     | -0.00594    |\n",
      "|    value_loss         | 0.608       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 10043392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010532422 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0956      |\n",
      "|    mean_step_reward   | 0.13792571  |\n",
      "|    n_updates          | 4900        |\n",
      "|    policyGradLoss     | -0.00919    |\n",
      "|    value_loss         | 0.636       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 812        |\n",
      "|    iterations         | 27         |\n",
      "|    time_elapsed       | 272        |\n",
      "|    total_timesteps    | 10051584   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01212989 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.978      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0379     |\n",
      "|    mean_step_reward   | 0.13562647 |\n",
      "|    n_updates          | 4904       |\n",
      "|    policyGradLoss     | -0.00998   |\n",
      "|    value_loss         | 0.372      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 10059776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014241543 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0297      |\n",
      "|    mean_step_reward   | 0.15371697  |\n",
      "|    n_updates          | 4908        |\n",
      "|    policyGradLoss     | -0.00566    |\n",
      "|    value_loss         | 0.396       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 811        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 292        |\n",
      "|    total_timesteps    | 10067968   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01379119 |\n",
      "|    entropy_loss       | -1.85      |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0839     |\n",
      "|    mean_step_reward   | 0.14335772 |\n",
      "|    n_updates          | 4912       |\n",
      "|    policyGradLoss     | -0.00887   |\n",
      "|    value_loss         | 0.426      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 303         |\n",
      "|    total_timesteps    | 10076160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013676275 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0228     |\n",
      "|    mean_step_reward   | 0.15096444  |\n",
      "|    n_updates          | 4916        |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.14        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 313         |\n",
      "|    total_timesteps    | 10084352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008593913 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0756      |\n",
      "|    mean_step_reward   | 0.15360801  |\n",
      "|    n_updates          | 4920        |\n",
      "|    policyGradLoss     | -0.00603    |\n",
      "|    value_loss         | 0.361       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 323         |\n",
      "|    total_timesteps    | 10092544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013190756 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0142      |\n",
      "|    mean_step_reward   | 0.13129044  |\n",
      "|    n_updates          | 4924        |\n",
      "|    policyGradLoss     | -0.00748    |\n",
      "|    value_loss         | 0.342       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 10100736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012110085 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00693    |\n",
      "|    mean_step_reward   | 0.14708555  |\n",
      "|    n_updates          | 4928        |\n",
      "|    policyGradLoss     | -0.00984    |\n",
      "|    value_loss         | 0.219       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 810          |\n",
      "|    iterations         | 34           |\n",
      "|    time_elapsed       | 343          |\n",
      "|    total_timesteps    | 10108928     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0142960055 |\n",
      "|    entropy_loss       | -1.78        |\n",
      "|    explained_variance | 0.984        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0132      |\n",
      "|    mean_step_reward   | 0.15003628   |\n",
      "|    n_updates          | 4932         |\n",
      "|    policyGradLoss     | -0.00874     |\n",
      "|    value_loss         | 0.213        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 354         |\n",
      "|    total_timesteps    | 10117120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012664261 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0888      |\n",
      "|    mean_step_reward   | 0.1486635   |\n",
      "|    n_updates          | 4936        |\n",
      "|    policyGradLoss     | -0.00965    |\n",
      "|    value_loss         | 0.383       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 364         |\n",
      "|    total_timesteps    | 10125312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012367626 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0266     |\n",
      "|    mean_step_reward   | 0.15325749  |\n",
      "|    n_updates          | 4940        |\n",
      "|    policyGradLoss     | -0.00755    |\n",
      "|    value_loss         | 0.201       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 374         |\n",
      "|    total_timesteps    | 10133504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012914361 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.054       |\n",
      "|    mean_step_reward   | 0.14979066  |\n",
      "|    n_updates          | 4944        |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.313       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 808          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 384          |\n",
      "|    total_timesteps    | 10141696     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0144402785 |\n",
      "|    entropy_loss       | -1.86        |\n",
      "|    explained_variance | 0.993        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.00361     |\n",
      "|    mean_step_reward   | 0.1574898    |\n",
      "|    n_updates          | 4948         |\n",
      "|    policyGradLoss     | -0.0131      |\n",
      "|    value_loss         | 0.163        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 808          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 395          |\n",
      "|    total_timesteps    | 10149888     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0143017545 |\n",
      "|    entropy_loss       | -1.79        |\n",
      "|    explained_variance | 0.973        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0273      |\n",
      "|    mean_step_reward   | 0.14021716   |\n",
      "|    n_updates          | 4952         |\n",
      "|    policyGradLoss     | -0.00662     |\n",
      "|    value_loss         | 0.289        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 808          |\n",
      "|    iterations         | 40           |\n",
      "|    time_elapsed       | 405          |\n",
      "|    total_timesteps    | 10158080     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0119607765 |\n",
      "|    entropy_loss       | -1.81        |\n",
      "|    explained_variance | 0.978        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0375       |\n",
      "|    mean_step_reward   | 0.15550655   |\n",
      "|    n_updates          | 4956         |\n",
      "|    policyGradLoss     | -0.00673     |\n",
      "|    value_loss         | 0.46         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_30.zip\n",
      "[EVAL] Mean Return: 189.467, Best Return: 189.767\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_30_189.47.mp4\n",
      "\n",
      "=== Round 32 | Learn 327680 steps (Total trained: 10158080) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1119     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 10166272 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 929         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 10174464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012197516 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0172     |\n",
      "|    mean_step_reward   | 0.15965961  |\n",
      "|    n_updates          | 4964        |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.148       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 875         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 10182656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012901021 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0119      |\n",
      "|    mean_step_reward   | 0.14830504  |\n",
      "|    n_updates          | 4968        |\n",
      "|    policyGradLoss     | -0.00737    |\n",
      "|    value_loss         | 0.368       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 857         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 10190848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018170733 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0964      |\n",
      "|    mean_step_reward   | 0.14713265  |\n",
      "|    n_updates          | 4972        |\n",
      "|    policyGradLoss     | -0.0057     |\n",
      "|    value_loss         | 0.673       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 841         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 48          |\n",
      "|    total_timesteps    | 10199040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010059665 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0117      |\n",
      "|    mean_step_reward   | 0.14912939  |\n",
      "|    n_updates          | 4976        |\n",
      "|    policyGradLoss     | -0.00551    |\n",
      "|    value_loss         | 0.564       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 837          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 58           |\n",
      "|    total_timesteps    | 10207232     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0133351255 |\n",
      "|    entropy_loss       | -1.77        |\n",
      "|    explained_variance | 0.984        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.00953     |\n",
      "|    mean_step_reward   | 0.14741057   |\n",
      "|    n_updates          | 4980         |\n",
      "|    policyGradLoss     | -0.011       |\n",
      "|    value_loss         | 0.203        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 834          |\n",
      "|    iterations         | 7            |\n",
      "|    time_elapsed       | 68           |\n",
      "|    total_timesteps    | 10215424     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0074859327 |\n",
      "|    entropy_loss       | -1.8         |\n",
      "|    explained_variance | 0.927        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0975       |\n",
      "|    mean_step_reward   | 0.14455287   |\n",
      "|    n_updates          | 4984         |\n",
      "|    policyGradLoss     | -0.000281    |\n",
      "|    value_loss         | 0.516        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 830         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 10223616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014324025 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0185     |\n",
      "|    mean_step_reward   | 0.13921306  |\n",
      "|    n_updates          | 4988        |\n",
      "|    policyGradLoss     | -0.0121     |\n",
      "|    value_loss         | 0.243       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 827         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 89          |\n",
      "|    total_timesteps    | 10231808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011794407 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0141      |\n",
      "|    mean_step_reward   | 0.15127848  |\n",
      "|    n_updates          | 4992        |\n",
      "|    policyGradLoss     | -0.00868    |\n",
      "|    value_loss         | 0.35        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 99          |\n",
      "|    total_timesteps    | 10240000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012504159 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0236      |\n",
      "|    mean_step_reward   | 0.15278092  |\n",
      "|    n_updates          | 4996        |\n",
      "|    policyGradLoss     | -0.00876    |\n",
      "|    value_loss         | 0.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 10248192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009089543 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.947       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0518      |\n",
      "|    mean_step_reward   | 0.1357256   |\n",
      "|    n_updates          | 5000        |\n",
      "|    policyGradLoss     | -0.00397    |\n",
      "|    value_loss         | 0.401       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 10256384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009605492 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.958       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.115       |\n",
      "|    mean_step_reward   | 0.13551937  |\n",
      "|    n_updates          | 5004        |\n",
      "|    policyGradLoss     | -0.00754    |\n",
      "|    value_loss         | 0.829       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 819          |\n",
      "|    iterations         | 13           |\n",
      "|    time_elapsed       | 129          |\n",
      "|    total_timesteps    | 10264576     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0110622635 |\n",
      "|    entropy_loss       | -1.86        |\n",
      "|    explained_variance | 0.913        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.256        |\n",
      "|    mean_step_reward   | 0.13820569   |\n",
      "|    n_updates          | 5008         |\n",
      "|    policyGradLoss     | -0.00665     |\n",
      "|    value_loss         | 0.882        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 140         |\n",
      "|    total_timesteps    | 10272768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010491192 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0106      |\n",
      "|    mean_step_reward   | 0.1388149   |\n",
      "|    n_updates          | 5012        |\n",
      "|    policyGradLoss     | -0.00994    |\n",
      "|    value_loss         | 0.392       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 150         |\n",
      "|    total_timesteps    | 10280960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010357097 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.136       |\n",
      "|    mean_step_reward   | 0.14617804  |\n",
      "|    n_updates          | 5016        |\n",
      "|    policyGradLoss     | -0.00782    |\n",
      "|    value_loss         | 0.611       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 10289152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014192951 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0761      |\n",
      "|    mean_step_reward   | 0.1350094   |\n",
      "|    n_updates          | 5020        |\n",
      "|    policyGradLoss     | -0.00908    |\n",
      "|    value_loss         | 0.288       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 10297344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015270103 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.164       |\n",
      "|    mean_step_reward   | 0.14912173  |\n",
      "|    n_updates          | 5024        |\n",
      "|    policyGradLoss     | -0.0059     |\n",
      "|    value_loss         | 0.598       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 10305536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010475548 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.286       |\n",
      "|    mean_step_reward   | 0.1448337   |\n",
      "|    n_updates          | 5028        |\n",
      "|    policyGradLoss     | -0.00715    |\n",
      "|    value_loss         | 0.562       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 815          |\n",
      "|    iterations         | 19           |\n",
      "|    time_elapsed       | 190          |\n",
      "|    total_timesteps    | 10313728     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0149190035 |\n",
      "|    entropy_loss       | -1.82        |\n",
      "|    explained_variance | 0.978        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0052       |\n",
      "|    mean_step_reward   | 0.14068292   |\n",
      "|    n_updates          | 5032         |\n",
      "|    policyGradLoss     | -0.009       |\n",
      "|    value_loss         | 0.37         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 10321920    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011956535 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.115       |\n",
      "|    mean_step_reward   | 0.16067053  |\n",
      "|    n_updates          | 5036        |\n",
      "|    policyGradLoss     | -0.00578    |\n",
      "|    value_loss         | 0.319       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 10330112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013107004 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0247      |\n",
      "|    mean_step_reward   | 0.13495342  |\n",
      "|    n_updates          | 5040        |\n",
      "|    policyGradLoss     | -0.0062     |\n",
      "|    value_loss         | 0.279       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 10338304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011290535 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00574     |\n",
      "|    mean_step_reward   | 0.1473117   |\n",
      "|    n_updates          | 5044        |\n",
      "|    policyGradLoss     | -0.00983    |\n",
      "|    value_loss         | 0.37        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 10346496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013985713 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0176     |\n",
      "|    mean_step_reward   | 0.13896488  |\n",
      "|    n_updates          | 5048        |\n",
      "|    policyGradLoss     | -0.0109     |\n",
      "|    value_loss         | 0.298       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 10354688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010077705 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00809     |\n",
      "|    mean_step_reward   | 0.14488523  |\n",
      "|    n_updates          | 5052        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.298       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 10362880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010803994 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0505      |\n",
      "|    mean_step_reward   | 0.15793404  |\n",
      "|    n_updates          | 5056        |\n",
      "|    policyGradLoss     | -0.00721    |\n",
      "|    value_loss         | 0.314       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 10371072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011357237 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0111      |\n",
      "|    mean_step_reward   | 0.14720812  |\n",
      "|    n_updates          | 5060        |\n",
      "|    policyGradLoss     | -0.00983    |\n",
      "|    value_loss         | 0.299       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 10379264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012237512 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0138      |\n",
      "|    mean_step_reward   | 0.14467174  |\n",
      "|    n_updates          | 5064        |\n",
      "|    policyGradLoss     | -0.0115     |\n",
      "|    value_loss         | 0.255       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 10387456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013335032 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00834     |\n",
      "|    mean_step_reward   | 0.13707903  |\n",
      "|    n_updates          | 5068        |\n",
      "|    policyGradLoss     | -0.00561    |\n",
      "|    value_loss         | 0.296       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 10395648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015818307 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0287      |\n",
      "|    mean_step_reward   | 0.15138511  |\n",
      "|    n_updates          | 5072        |\n",
      "|    policyGradLoss     | -0.012      |\n",
      "|    value_loss         | 0.291       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 303         |\n",
      "|    total_timesteps    | 10403840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014305492 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00211     |\n",
      "|    mean_step_reward   | 0.14842546  |\n",
      "|    n_updates          | 5076        |\n",
      "|    policyGradLoss     | -0.011      |\n",
      "|    value_loss         | 0.167       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 313         |\n",
      "|    total_timesteps    | 10412032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011286832 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0507      |\n",
      "|    mean_step_reward   | 0.1466593   |\n",
      "|    n_updates          | 5080        |\n",
      "|    policyGradLoss     | -0.00767    |\n",
      "|    value_loss         | 0.367       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 323         |\n",
      "|    total_timesteps    | 10420224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012790187 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0121     |\n",
      "|    mean_step_reward   | 0.15045336  |\n",
      "|    n_updates          | 5084        |\n",
      "|    policyGradLoss     | -0.00241    |\n",
      "|    value_loss         | 0.216       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 10428416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011439542 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0239      |\n",
      "|    mean_step_reward   | 0.14961547  |\n",
      "|    n_updates          | 5088        |\n",
      "|    policyGradLoss     | -0.00842    |\n",
      "|    value_loss         | 0.213       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 343         |\n",
      "|    total_timesteps    | 10436608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014436249 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0145      |\n",
      "|    mean_step_reward   | 0.15453604  |\n",
      "|    n_updates          | 5092        |\n",
      "|    policyGradLoss     | -0.011      |\n",
      "|    value_loss         | 0.233       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 353         |\n",
      "|    total_timesteps    | 10444800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012039947 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0484      |\n",
      "|    mean_step_reward   | 0.15442596  |\n",
      "|    n_updates          | 5096        |\n",
      "|    policyGradLoss     | -0.00881    |\n",
      "|    value_loss         | 0.311       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 364         |\n",
      "|    total_timesteps    | 10452992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008556165 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0763      |\n",
      "|    mean_step_reward   | 0.1424931   |\n",
      "|    n_updates          | 5100        |\n",
      "|    policyGradLoss     | -0.00803    |\n",
      "|    value_loss         | 0.589       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 374         |\n",
      "|    total_timesteps    | 10461184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010130798 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.026       |\n",
      "|    mean_step_reward   | 0.14674744  |\n",
      "|    n_updates          | 5104        |\n",
      "|    policyGradLoss     | -0.00626    |\n",
      "|    value_loss         | 0.334       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 384         |\n",
      "|    total_timesteps    | 10469376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008305815 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.911       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0528      |\n",
      "|    mean_step_reward   | 0.15048538  |\n",
      "|    n_updates          | 5108        |\n",
      "|    policyGradLoss     | -0.0011     |\n",
      "|    value_loss         | 0.72        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 394         |\n",
      "|    total_timesteps    | 10477568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008070616 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00276     |\n",
      "|    mean_step_reward   | 0.14803079  |\n",
      "|    n_updates          | 5112        |\n",
      "|    policyGradLoss     | -0.00837    |\n",
      "|    value_loss         | 0.379       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 404         |\n",
      "|    total_timesteps    | 10485760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008819816 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0299      |\n",
      "|    mean_step_reward   | 0.15599608  |\n",
      "|    n_updates          | 5116        |\n",
      "|    policyGradLoss     | -0.00603    |\n",
      "|    value_loss         | 0.631       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_31.zip\n",
      "[EVAL] Mean Return: 190.587, Best Return: 190.887\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_31_190.59.mp4\n",
      "\n",
      "=== Round 33 | Learn 327680 steps (Total trained: 10485760) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1083     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 10493952 |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 935          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 10502144     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0118289385 |\n",
      "|    entropy_loss       | -1.83        |\n",
      "|    explained_variance | 0.991        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0093      |\n",
      "|    mean_step_reward   | 0.15685625   |\n",
      "|    n_updates          | 5124         |\n",
      "|    policyGradLoss     | -0.0121      |\n",
      "|    value_loss         | 0.176        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 895         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 10510336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012178931 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.142       |\n",
      "|    mean_step_reward   | 0.15810254  |\n",
      "|    n_updates          | 5128        |\n",
      "|    policyGradLoss     | -0.0105     |\n",
      "|    value_loss         | 0.276       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 868         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 37          |\n",
      "|    total_timesteps    | 10518528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012106451 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0807      |\n",
      "|    mean_step_reward   | 0.13867007  |\n",
      "|    n_updates          | 5132        |\n",
      "|    policyGradLoss     | -0.00651    |\n",
      "|    value_loss         | 0.332       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 845         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 48          |\n",
      "|    total_timesteps    | 10526720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011523755 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0555      |\n",
      "|    mean_step_reward   | 0.15524729  |\n",
      "|    n_updates          | 5136        |\n",
      "|    policyGradLoss     | -0.00821    |\n",
      "|    value_loss         | 0.408       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 841         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 10534912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012856698 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00857    |\n",
      "|    mean_step_reward   | 0.1438184   |\n",
      "|    n_updates          | 5140        |\n",
      "|    policyGradLoss     | -0.00596    |\n",
      "|    value_loss         | 0.242       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 838         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 10543104    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014024474 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0368      |\n",
      "|    mean_step_reward   | 0.1472528   |\n",
      "|    n_updates          | 5144        |\n",
      "|    policyGradLoss     | -0.0083     |\n",
      "|    value_loss         | 0.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 833         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 10551296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013587406 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0716      |\n",
      "|    mean_step_reward   | 0.16085495  |\n",
      "|    n_updates          | 5148        |\n",
      "|    policyGradLoss     | -0.00915    |\n",
      "|    value_loss         | 0.369       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 829         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 88          |\n",
      "|    total_timesteps    | 10559488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017396297 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00765     |\n",
      "|    mean_step_reward   | 0.13852337  |\n",
      "|    n_updates          | 5152        |\n",
      "|    policyGradLoss     | -0.00742    |\n",
      "|    value_loss         | 0.369       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 828         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 10567680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010162569 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0235      |\n",
      "|    mean_step_reward   | 0.14397182  |\n",
      "|    n_updates          | 5156        |\n",
      "|    policyGradLoss     | -0.00185    |\n",
      "|    value_loss         | 0.417       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 10575872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015367226 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0555      |\n",
      "|    mean_step_reward   | 0.13064061  |\n",
      "|    n_updates          | 5160        |\n",
      "|    policyGradLoss     | -0.00579    |\n",
      "|    value_loss         | 0.398       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 10584064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013143423 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0126      |\n",
      "|    mean_step_reward   | 0.16242036  |\n",
      "|    n_updates          | 5164        |\n",
      "|    policyGradLoss     | -0.000423   |\n",
      "|    value_loss         | 0.407       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 823         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 129         |\n",
      "|    total_timesteps    | 10592256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013289344 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00411    |\n",
      "|    mean_step_reward   | 0.13269114  |\n",
      "|    n_updates          | 5168        |\n",
      "|    policyGradLoss     | -0.00842    |\n",
      "|    value_loss         | 0.345       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 822          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 139          |\n",
      "|    total_timesteps    | 10600448     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0128028495 |\n",
      "|    entropy_loss       | -1.8         |\n",
      "|    explained_variance | 0.964        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.103        |\n",
      "|    mean_step_reward   | 0.14644915   |\n",
      "|    n_updates          | 5172         |\n",
      "|    policyGradLoss     | -0.00661     |\n",
      "|    value_loss         | 0.692        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 149         |\n",
      "|    total_timesteps    | 10608640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009754719 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.302       |\n",
      "|    mean_step_reward   | 0.14519623  |\n",
      "|    n_updates          | 5176        |\n",
      "|    policyGradLoss     | -0.00469    |\n",
      "|    value_loss         | 0.937       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 819        |\n",
      "|    iterations         | 16         |\n",
      "|    time_elapsed       | 159        |\n",
      "|    total_timesteps    | 10616832   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01362236 |\n",
      "|    entropy_loss       | -1.76      |\n",
      "|    explained_variance | 0.86       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.124      |\n",
      "|    mean_step_reward   | 0.12328654 |\n",
      "|    n_updates          | 5180       |\n",
      "|    policyGradLoss     | -0.000598  |\n",
      "|    value_loss         | 0.995      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 818          |\n",
      "|    iterations         | 17           |\n",
      "|    time_elapsed       | 170          |\n",
      "|    total_timesteps    | 10625024     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0115405265 |\n",
      "|    entropy_loss       | -1.86        |\n",
      "|    explained_variance | 0.952        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.037        |\n",
      "|    mean_step_reward   | 0.1623744    |\n",
      "|    n_updates          | 5184         |\n",
      "|    policyGradLoss     | -0.00158     |\n",
      "|    value_loss         | 0.411        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 10633216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011382887 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0821      |\n",
      "|    mean_step_reward   | 0.14133845  |\n",
      "|    n_updates          | 5188        |\n",
      "|    policyGradLoss     | -0.0106     |\n",
      "|    value_loss         | 0.371       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 10641408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012339994 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0338     |\n",
      "|    mean_step_reward   | 0.14843233  |\n",
      "|    n_updates          | 5192        |\n",
      "|    policyGradLoss     | -0.0128     |\n",
      "|    value_loss         | 0.15        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 10649600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012669025 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00321     |\n",
      "|    mean_step_reward   | 0.14651638  |\n",
      "|    n_updates          | 5196        |\n",
      "|    policyGradLoss     | -0.00791    |\n",
      "|    value_loss         | 0.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 10657792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012480911 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00229     |\n",
      "|    mean_step_reward   | 0.14529707  |\n",
      "|    n_updates          | 5200        |\n",
      "|    policyGradLoss     | -0.0153     |\n",
      "|    value_loss         | 0.263       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 10665984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009488551 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.921       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.27        |\n",
      "|    mean_step_reward   | 0.13865894  |\n",
      "|    n_updates          | 5204        |\n",
      "|    policyGradLoss     | -0.00623    |\n",
      "|    value_loss         | 1.07        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 10674176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009810077 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0218     |\n",
      "|    mean_step_reward   | 0.13607901  |\n",
      "|    n_updates          | 5208        |\n",
      "|    policyGradLoss     | -0.00796    |\n",
      "|    value_loss         | 0.332       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 10682368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013844988 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00138    |\n",
      "|    mean_step_reward   | 0.14638063  |\n",
      "|    n_updates          | 5212        |\n",
      "|    policyGradLoss     | -0.0136     |\n",
      "|    value_loss         | 0.174       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 10690560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011082839 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00639    |\n",
      "|    mean_step_reward   | 0.15768494  |\n",
      "|    n_updates          | 5216        |\n",
      "|    policyGradLoss     | -0.00928    |\n",
      "|    value_loss         | 0.277       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 10698752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010711674 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0651      |\n",
      "|    mean_step_reward   | 0.14463486  |\n",
      "|    n_updates          | 5220        |\n",
      "|    policyGradLoss     | -0.00792    |\n",
      "|    value_loss         | 0.503       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 10706944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010770211 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0698      |\n",
      "|    mean_step_reward   | 0.1348218   |\n",
      "|    n_updates          | 5224        |\n",
      "|    policyGradLoss     | -0.0078     |\n",
      "|    value_loss         | 0.58        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 811          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 282          |\n",
      "|    total_timesteps    | 10715136     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0154181775 |\n",
      "|    entropy_loss       | -1.79        |\n",
      "|    explained_variance | 0.983        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0157      |\n",
      "|    mean_step_reward   | 0.14115496   |\n",
      "|    n_updates          | 5228         |\n",
      "|    policyGradLoss     | -0.0104      |\n",
      "|    value_loss         | 0.224        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 10723328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012132956 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0392     |\n",
      "|    mean_step_reward   | 0.15583283  |\n",
      "|    n_updates          | 5232        |\n",
      "|    policyGradLoss     | -0.00922    |\n",
      "|    value_loss         | 0.166       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 811        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 302        |\n",
      "|    total_timesteps    | 10731520   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.00988438 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.973      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00181    |\n",
      "|    mean_step_reward   | 0.15296498 |\n",
      "|    n_updates          | 5236       |\n",
      "|    policyGradLoss     | -0.0088    |\n",
      "|    value_loss         | 0.271      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 313         |\n",
      "|    total_timesteps    | 10739712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012349117 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.111       |\n",
      "|    mean_step_reward   | 0.15972024  |\n",
      "|    n_updates          | 5240        |\n",
      "|    policyGradLoss     | -0.0059     |\n",
      "|    value_loss         | 0.386       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 323         |\n",
      "|    total_timesteps    | 10747904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019292735 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0422     |\n",
      "|    mean_step_reward   | 0.14442436  |\n",
      "|    n_updates          | 5244        |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.125       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 10756096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012349037 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0685      |\n",
      "|    mean_step_reward   | 0.16202351  |\n",
      "|    n_updates          | 5248        |\n",
      "|    policyGradLoss     | -0.00711    |\n",
      "|    value_loss         | 0.556       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 343         |\n",
      "|    total_timesteps    | 10764288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016472096 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0233     |\n",
      "|    mean_step_reward   | 0.14533782  |\n",
      "|    n_updates          | 5252        |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.161       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 353         |\n",
      "|    total_timesteps    | 10772480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013503029 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00797     |\n",
      "|    mean_step_reward   | 0.1504902   |\n",
      "|    n_updates          | 5256        |\n",
      "|    policyGradLoss     | -0.00718    |\n",
      "|    value_loss         | 0.468       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 364         |\n",
      "|    total_timesteps    | 10780672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010017835 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0183      |\n",
      "|    mean_step_reward   | 0.13337696  |\n",
      "|    n_updates          | 5260        |\n",
      "|    policyGradLoss     | -0.00925    |\n",
      "|    value_loss         | 0.348       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 374         |\n",
      "|    total_timesteps    | 10788864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008725817 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.102       |\n",
      "|    mean_step_reward   | 0.1412152   |\n",
      "|    n_updates          | 5264        |\n",
      "|    policyGradLoss     | -0.00884    |\n",
      "|    value_loss         | 0.536       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 809          |\n",
      "|    iterations         | 38           |\n",
      "|    time_elapsed       | 384          |\n",
      "|    total_timesteps    | 10797056     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0125815775 |\n",
      "|    entropy_loss       | -1.87        |\n",
      "|    explained_variance | 0.976        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0552       |\n",
      "|    mean_step_reward   | 0.14209646   |\n",
      "|    n_updates          | 5268         |\n",
      "|    policyGradLoss     | -0.00697     |\n",
      "|    value_loss         | 0.475        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 395         |\n",
      "|    total_timesteps    | 10805248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016404592 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0331     |\n",
      "|    mean_step_reward   | 0.13743031  |\n",
      "|    n_updates          | 5272        |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.156       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 808         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 405         |\n",
      "|    total_timesteps    | 10813440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019101877 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0437      |\n",
      "|    mean_step_reward   | 0.14880952  |\n",
      "|    n_updates          | 5276        |\n",
      "|    policyGradLoss     | -0.00549    |\n",
      "|    value_loss         | 0.657       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_32.zip\n",
      "[EVAL] Mean Return: 190.989, Best Return: 191.289\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_32_190.99.mp4\n",
      "\n",
      "=== Round 34 | Learn 327680 steps (Total trained: 10813440) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1084     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 10821632 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 927         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 10829824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012063393 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0266      |\n",
      "|    mean_step_reward   | 0.14370595  |\n",
      "|    n_updates          | 5284        |\n",
      "|    policyGradLoss     | -0.00978    |\n",
      "|    value_loss         | 0.319       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 873         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 10838016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013510279 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0264     |\n",
      "|    mean_step_reward   | 0.15343243  |\n",
      "|    n_updates          | 5288        |\n",
      "|    policyGradLoss     | -0.0134     |\n",
      "|    value_loss         | 0.148       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 857         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 10846208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012558436 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0935      |\n",
      "|    mean_step_reward   | 0.14982018  |\n",
      "|    n_updates          | 5292        |\n",
      "|    policyGradLoss     | -0.00736    |\n",
      "|    value_loss         | 0.529       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 847         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 48          |\n",
      "|    total_timesteps    | 10854400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009067951 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.108       |\n",
      "|    mean_step_reward   | 0.14785838  |\n",
      "|    n_updates          | 5296        |\n",
      "|    policyGradLoss     | -0.00608    |\n",
      "|    value_loss         | 0.487       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 841        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 58         |\n",
      "|    total_timesteps    | 10862592   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01659182 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.981      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00766    |\n",
      "|    mean_step_reward   | 0.14050135 |\n",
      "|    n_updates          | 5300       |\n",
      "|    policyGradLoss     | -0.0105    |\n",
      "|    value_loss         | 0.317      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 834         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 10870784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015791066 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00188    |\n",
      "|    mean_step_reward   | 0.15698105  |\n",
      "|    n_updates          | 5304        |\n",
      "|    policyGradLoss     | -0.0113     |\n",
      "|    value_loss         | 0.276       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 830         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 10878976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013923624 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.131       |\n",
      "|    mean_step_reward   | 0.14462677  |\n",
      "|    n_updates          | 5308        |\n",
      "|    policyGradLoss     | -0.00852    |\n",
      "|    value_loss         | 0.327       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 829        |\n",
      "|    iterations         | 9          |\n",
      "|    time_elapsed       | 88         |\n",
      "|    total_timesteps    | 10887168   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01581692 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.995      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0147    |\n",
      "|    mean_step_reward   | 0.16111685 |\n",
      "|    n_updates          | 5312       |\n",
      "|    policyGradLoss     | -0.0163    |\n",
      "|    value_loss         | 0.134      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 826         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 99          |\n",
      "|    total_timesteps    | 10895360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013066882 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0261      |\n",
      "|    mean_step_reward   | 0.14629182  |\n",
      "|    n_updates          | 5316        |\n",
      "|    policyGradLoss     | -0.0112     |\n",
      "|    value_loss         | 0.342       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 10903552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011928589 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.134       |\n",
      "|    mean_step_reward   | 0.14057982  |\n",
      "|    n_updates          | 5320        |\n",
      "|    policyGradLoss     | -0.00865    |\n",
      "|    value_loss         | 0.489       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 10911744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010704203 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0467      |\n",
      "|    mean_step_reward   | 0.15296039  |\n",
      "|    n_updates          | 5324        |\n",
      "|    policyGradLoss     | -0.012      |\n",
      "|    value_loss         | 0.26        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 129         |\n",
      "|    total_timesteps    | 10919936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011513211 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.27        |\n",
      "|    mean_step_reward   | 0.13875431  |\n",
      "|    n_updates          | 5328        |\n",
      "|    policyGradLoss     | -0.00966    |\n",
      "|    value_loss         | 0.495       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 139         |\n",
      "|    total_timesteps    | 10928128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014522897 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0201     |\n",
      "|    mean_step_reward   | 0.14862779  |\n",
      "|    n_updates          | 5332        |\n",
      "|    policyGradLoss     | -0.0105     |\n",
      "|    value_loss         | 0.172       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 817        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 150        |\n",
      "|    total_timesteps    | 10936320   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0159694  |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0234    |\n",
      "|    mean_step_reward   | 0.14850083 |\n",
      "|    n_updates          | 5336       |\n",
      "|    policyGradLoss     | -0.0125    |\n",
      "|    value_loss         | 0.214      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 10944512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012274355 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0643      |\n",
      "|    mean_step_reward   | 0.14829934  |\n",
      "|    n_updates          | 5340        |\n",
      "|    policyGradLoss     | -0.0113     |\n",
      "|    value_loss         | 0.404       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 10952704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012119466 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00837    |\n",
      "|    mean_step_reward   | 0.14841242  |\n",
      "|    n_updates          | 5344        |\n",
      "|    policyGradLoss     | -0.00925    |\n",
      "|    value_loss         | 0.192       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 10960896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011972429 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0206      |\n",
      "|    mean_step_reward   | 0.1444268   |\n",
      "|    n_updates          | 5348        |\n",
      "|    policyGradLoss     | -0.00534    |\n",
      "|    value_loss         | 0.424       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 10969088    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011317926 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.102       |\n",
      "|    mean_step_reward   | 0.1480467   |\n",
      "|    n_updates          | 5352        |\n",
      "|    policyGradLoss     | -0.012      |\n",
      "|    value_loss         | 0.365       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 10977280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015278202 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00574     |\n",
      "|    mean_step_reward   | 0.15184915  |\n",
      "|    n_updates          | 5356        |\n",
      "|    policyGradLoss     | -0.00933    |\n",
      "|    value_loss         | 0.322       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 10985472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018175783 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.137       |\n",
      "|    mean_step_reward   | 0.14095004  |\n",
      "|    n_updates          | 5360        |\n",
      "|    policyGradLoss     | -0.00496    |\n",
      "|    value_loss         | 0.701       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 815          |\n",
      "|    iterations         | 22           |\n",
      "|    time_elapsed       | 221          |\n",
      "|    total_timesteps    | 10993664     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0153725995 |\n",
      "|    entropy_loss       | -1.78        |\n",
      "|    explained_variance | 0.96         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.11         |\n",
      "|    mean_step_reward   | 0.13016793   |\n",
      "|    n_updates          | 5364         |\n",
      "|    policyGradLoss     | -0.00468     |\n",
      "|    value_loss         | 0.494        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 11001856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012864679 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.1         |\n",
      "|    mean_step_reward   | 0.15028939  |\n",
      "|    n_updates          | 5368        |\n",
      "|    policyGradLoss     | -0.00648    |\n",
      "|    value_loss         | 0.434       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 813        |\n",
      "|    iterations         | 24         |\n",
      "|    time_elapsed       | 241        |\n",
      "|    total_timesteps    | 11010048   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01194649 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.98       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0772     |\n",
      "|    mean_step_reward   | 0.14223954 |\n",
      "|    n_updates          | 5372       |\n",
      "|    policyGradLoss     | -0.0072    |\n",
      "|    value_loss         | 0.325      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 11018240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011262231 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0488      |\n",
      "|    mean_step_reward   | 0.14766347  |\n",
      "|    n_updates          | 5376        |\n",
      "|    policyGradLoss     | -0.00585    |\n",
      "|    value_loss         | 0.472       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 812        |\n",
      "|    iterations         | 26         |\n",
      "|    time_elapsed       | 262        |\n",
      "|    total_timesteps    | 11026432   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01376427 |\n",
      "|    entropy_loss       | -1.87      |\n",
      "|    explained_variance | 0.986      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0175     |\n",
      "|    mean_step_reward   | 0.1539536  |\n",
      "|    n_updates          | 5380       |\n",
      "|    policyGradLoss     | 0.00955    |\n",
      "|    value_loss         | 0.365      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 11034624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011868304 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0716      |\n",
      "|    mean_step_reward   | 0.14688227  |\n",
      "|    n_updates          | 5384        |\n",
      "|    policyGradLoss     | -0.00585    |\n",
      "|    value_loss         | 0.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 11042816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009456322 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.145       |\n",
      "|    mean_step_reward   | 0.1421812   |\n",
      "|    n_updates          | 5388        |\n",
      "|    policyGradLoss     | -0.00741    |\n",
      "|    value_loss         | 0.625       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 11051008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015055026 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00252     |\n",
      "|    mean_step_reward   | 0.14332208  |\n",
      "|    n_updates          | 5392        |\n",
      "|    policyGradLoss     | -0.00998    |\n",
      "|    value_loss         | 0.277       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 302         |\n",
      "|    total_timesteps    | 11059200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013279891 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.023      |\n",
      "|    mean_step_reward   | 0.16298202  |\n",
      "|    n_updates          | 5396        |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.142       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 313         |\n",
      "|    total_timesteps    | 11067392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012037897 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0252      |\n",
      "|    mean_step_reward   | 0.14266893  |\n",
      "|    n_updates          | 5400        |\n",
      "|    policyGradLoss     | -0.0122     |\n",
      "|    value_loss         | 0.165       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 322         |\n",
      "|    total_timesteps    | 11075584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013890005 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0871      |\n",
      "|    mean_step_reward   | 0.15065521  |\n",
      "|    n_updates          | 5404        |\n",
      "|    policyGradLoss     | -0.00447    |\n",
      "|    value_loss         | 0.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 11083776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010977412 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.125       |\n",
      "|    mean_step_reward   | 0.15016061  |\n",
      "|    n_updates          | 5408        |\n",
      "|    policyGradLoss     | -0.00688    |\n",
      "|    value_loss         | 0.451       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 343         |\n",
      "|    total_timesteps    | 11091968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011115553 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0442      |\n",
      "|    mean_step_reward   | 0.15133855  |\n",
      "|    n_updates          | 5412        |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.283       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 353         |\n",
      "|    total_timesteps    | 11100160    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010115592 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.933       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0379      |\n",
      "|    mean_step_reward   | 0.13467625  |\n",
      "|    n_updates          | 5416        |\n",
      "|    policyGradLoss     | -0.00109    |\n",
      "|    value_loss         | 0.614       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 363         |\n",
      "|    total_timesteps    | 11108352    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012498494 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0622      |\n",
      "|    mean_step_reward   | 0.14612806  |\n",
      "|    n_updates          | 5420        |\n",
      "|    policyGradLoss     | -0.0114     |\n",
      "|    value_loss         | 0.383       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 374         |\n",
      "|    total_timesteps    | 11116544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012474885 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0305      |\n",
      "|    mean_step_reward   | 0.15506     |\n",
      "|    n_updates          | 5424        |\n",
      "|    policyGradLoss     | -0.00917    |\n",
      "|    value_loss         | 0.323       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 384         |\n",
      "|    total_timesteps    | 11124736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012411315 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.97        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0161      |\n",
      "|    mean_step_reward   | 0.14228438  |\n",
      "|    n_updates          | 5428        |\n",
      "|    policyGradLoss     | -0.00949    |\n",
      "|    value_loss         | 0.356       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 394         |\n",
      "|    total_timesteps    | 11132928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013861739 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.03        |\n",
      "|    mean_step_reward   | 0.1592265   |\n",
      "|    n_updates          | 5432        |\n",
      "|    policyGradLoss     | -0.0078     |\n",
      "|    value_loss         | 0.405       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 405         |\n",
      "|    total_timesteps    | 11141120    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017436959 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0359      |\n",
      "|    mean_step_reward   | 0.13949153  |\n",
      "|    n_updates          | 5436        |\n",
      "|    policyGradLoss     | -0.0065     |\n",
      "|    value_loss         | 0.377       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_33.zip\n",
      "[EVAL] Mean Return: 190.782, Best Return: 191.082\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_33_190.78.mp4\n",
      "\n",
      "=== Round 35 | Learn 327680 steps (Total trained: 11141120) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1118     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 11149312 |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 937          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 11157504     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0122812735 |\n",
      "|    entropy_loss       | -1.84        |\n",
      "|    explained_variance | 0.982        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0841       |\n",
      "|    mean_step_reward   | 0.14464179   |\n",
      "|    n_updates          | 5444         |\n",
      "|    policyGradLoss     | -0.0103      |\n",
      "|    value_loss         | 0.35         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 889         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 11165696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011731967 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.954       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.288       |\n",
      "|    mean_step_reward   | 0.14496781  |\n",
      "|    n_updates          | 5448        |\n",
      "|    policyGradLoss     | -0.0093     |\n",
      "|    value_loss         | 0.968       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 868         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 37          |\n",
      "|    total_timesteps    | 11173888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011782528 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0517      |\n",
      "|    mean_step_reward   | 0.13296013  |\n",
      "|    n_updates          | 5452        |\n",
      "|    policyGradLoss     | -0.0101     |\n",
      "|    value_loss         | 0.327       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 854         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 47          |\n",
      "|    total_timesteps    | 11182080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011149467 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00545     |\n",
      "|    mean_step_reward   | 0.14761795  |\n",
      "|    n_updates          | 5456        |\n",
      "|    policyGradLoss     | -0.0113     |\n",
      "|    value_loss         | 0.299       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 845         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 11190272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012430463 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0232     |\n",
      "|    mean_step_reward   | 0.14969334  |\n",
      "|    n_updates          | 5460        |\n",
      "|    policyGradLoss     | -0.0112     |\n",
      "|    value_loss         | 0.165       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 840         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 11198464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009900707 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0788      |\n",
      "|    mean_step_reward   | 0.14493012  |\n",
      "|    n_updates          | 5464        |\n",
      "|    policyGradLoss     | -0.0086     |\n",
      "|    value_loss         | 0.759       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 832         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 11206656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013526462 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0121     |\n",
      "|    mean_step_reward   | 0.14315942  |\n",
      "|    n_updates          | 5468        |\n",
      "|    policyGradLoss     | -0.00954    |\n",
      "|    value_loss         | 0.163       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 831         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 88          |\n",
      "|    total_timesteps    | 11214848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013890563 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.014      |\n",
      "|    mean_step_reward   | 0.14046922  |\n",
      "|    n_updates          | 5472        |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.191       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 827         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 11223040    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011932494 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.129       |\n",
      "|    mean_step_reward   | 0.14751533  |\n",
      "|    n_updates          | 5476        |\n",
      "|    policyGradLoss     | -0.00524    |\n",
      "|    value_loss         | 0.499       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 11231232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010411967 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.142       |\n",
      "|    mean_step_reward   | 0.13379827  |\n",
      "|    n_updates          | 5480        |\n",
      "|    policyGradLoss     | -0.00623    |\n",
      "|    value_loss         | 0.775       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 11239424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011204576 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.228       |\n",
      "|    mean_step_reward   | 0.1364836   |\n",
      "|    n_updates          | 5484        |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.565       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 129         |\n",
      "|    total_timesteps    | 11247616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016878156 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0257     |\n",
      "|    mean_step_reward   | 0.15530097  |\n",
      "|    n_updates          | 5488        |\n",
      "|    policyGradLoss     | -0.00816    |\n",
      "|    value_loss         | 0.155       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 139         |\n",
      "|    total_timesteps    | 11255808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016549002 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0695      |\n",
      "|    mean_step_reward   | 0.14525113  |\n",
      "|    n_updates          | 5492        |\n",
      "|    policyGradLoss     | -0.00862    |\n",
      "|    value_loss         | 0.49        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 149         |\n",
      "|    total_timesteps    | 11264000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016828824 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.154       |\n",
      "|    mean_step_reward   | 0.14449982  |\n",
      "|    n_updates          | 5496        |\n",
      "|    policyGradLoss     | -0.00643    |\n",
      "|    value_loss         | 0.769       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 818          |\n",
      "|    iterations         | 16           |\n",
      "|    time_elapsed       | 160          |\n",
      "|    total_timesteps    | 11272192     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0116751725 |\n",
      "|    entropy_loss       | -1.85        |\n",
      "|    explained_variance | 0.972        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.228        |\n",
      "|    mean_step_reward   | 0.14115769   |\n",
      "|    n_updates          | 5500         |\n",
      "|    policyGradLoss     | -0.0103      |\n",
      "|    value_loss         | 0.628        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 11280384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015386205 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.112       |\n",
      "|    mean_step_reward   | 0.1382589   |\n",
      "|    n_updates          | 5504        |\n",
      "|    policyGradLoss     | -0.00834    |\n",
      "|    value_loss         | 0.572       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 11288576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013097095 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0342     |\n",
      "|    mean_step_reward   | 0.1528633   |\n",
      "|    n_updates          | 5508        |\n",
      "|    policyGradLoss     | -0.0142     |\n",
      "|    value_loss         | 0.124       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 11296768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016483001 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.994       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.031      |\n",
      "|    mean_step_reward   | 0.15208167  |\n",
      "|    n_updates          | 5512        |\n",
      "|    policyGradLoss     | -0.0146     |\n",
      "|    value_loss         | 0.123       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 11304960    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015855767 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.156       |\n",
      "|    mean_step_reward   | 0.15308054  |\n",
      "|    n_updates          | 5516        |\n",
      "|    policyGradLoss     | -0.00628    |\n",
      "|    value_loss         | 0.741       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 11313152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015661096 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0472      |\n",
      "|    mean_step_reward   | 0.13883689  |\n",
      "|    n_updates          | 5520        |\n",
      "|    policyGradLoss     | -0.00901    |\n",
      "|    value_loss         | 0.235       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 811        |\n",
      "|    iterations         | 22         |\n",
      "|    time_elapsed       | 222        |\n",
      "|    total_timesteps    | 11321344   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01368714 |\n",
      "|    entropy_loss       | -1.89      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00579    |\n",
      "|    mean_step_reward   | 0.16485684 |\n",
      "|    n_updates          | 5524       |\n",
      "|    policyGradLoss     | -0.0105    |\n",
      "|    value_loss         | 0.235      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 11329536    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017089628 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.036       |\n",
      "|    mean_step_reward   | 0.13696957  |\n",
      "|    n_updates          | 5528        |\n",
      "|    policyGradLoss     | -0.0095     |\n",
      "|    value_loss         | 0.323       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 11337728    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014208076 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.996       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0377     |\n",
      "|    mean_step_reward   | 0.15777749  |\n",
      "|    n_updates          | 5532        |\n",
      "|    policyGradLoss     | -0.0148     |\n",
      "|    value_loss         | 0.111       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 810          |\n",
      "|    iterations         | 25           |\n",
      "|    time_elapsed       | 252          |\n",
      "|    total_timesteps    | 11345920     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0144867925 |\n",
      "|    entropy_loss       | -1.83        |\n",
      "|    explained_variance | 0.978        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0697       |\n",
      "|    mean_step_reward   | 0.1492423    |\n",
      "|    n_updates          | 5536         |\n",
      "|    policyGradLoss     | -0.0093      |\n",
      "|    value_loss         | 0.363        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 810          |\n",
      "|    iterations         | 26           |\n",
      "|    time_elapsed       | 262          |\n",
      "|    total_timesteps    | 11354112     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0140179675 |\n",
      "|    entropy_loss       | -1.81        |\n",
      "|    explained_variance | 0.969        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0295       |\n",
      "|    mean_step_reward   | 0.13549832   |\n",
      "|    n_updates          | 5540         |\n",
      "|    policyGradLoss     | -0.00972     |\n",
      "|    value_loss         | 0.627        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 273         |\n",
      "|    total_timesteps    | 11362304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013706226 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00423     |\n",
      "|    mean_step_reward   | 0.16194785  |\n",
      "|    n_updates          | 5544        |\n",
      "|    policyGradLoss     | -0.00805    |\n",
      "|    value_loss         | 0.245       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 11370496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016995396 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0131     |\n",
      "|    mean_step_reward   | 0.14281133  |\n",
      "|    n_updates          | 5548        |\n",
      "|    policyGradLoss     | -0.00748    |\n",
      "|    value_loss         | 0.264       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 809        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 293        |\n",
      "|    total_timesteps    | 11378688   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01418079 |\n",
      "|    entropy_loss       | -1.86      |\n",
      "|    explained_variance | 0.994      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0117     |\n",
      "|    mean_step_reward   | 0.16063038 |\n",
      "|    n_updates          | 5552       |\n",
      "|    policyGradLoss     | -0.00884   |\n",
      "|    value_loss         | 0.194      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 303         |\n",
      "|    total_timesteps    | 11386880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012487182 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0269     |\n",
      "|    mean_step_reward   | 0.15061824  |\n",
      "|    n_updates          | 5556        |\n",
      "|    policyGradLoss     | -0.0113     |\n",
      "|    value_loss         | 0.105       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 313         |\n",
      "|    total_timesteps    | 11395072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014495052 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0208     |\n",
      "|    mean_step_reward   | 0.1569384   |\n",
      "|    n_updates          | 5560        |\n",
      "|    policyGradLoss     | -0.0111     |\n",
      "|    value_loss         | 0.125       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 323         |\n",
      "|    total_timesteps    | 11403264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013233835 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.996       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0341     |\n",
      "|    mean_step_reward   | 0.14551651  |\n",
      "|    n_updates          | 5564        |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.0948      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 11411456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014780144 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0615      |\n",
      "|    mean_step_reward   | 0.14072216  |\n",
      "|    n_updates          | 5568        |\n",
      "|    policyGradLoss     | -0.00814    |\n",
      "|    value_loss         | 0.331       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 343         |\n",
      "|    total_timesteps    | 11419648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010784965 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00359     |\n",
      "|    mean_step_reward   | 0.15852697  |\n",
      "|    n_updates          | 5572        |\n",
      "|    policyGradLoss     | -0.00652    |\n",
      "|    value_loss         | 0.307       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 354         |\n",
      "|    total_timesteps    | 11427840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017501172 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.955       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.144       |\n",
      "|    mean_step_reward   | 0.12731104  |\n",
      "|    n_updates          | 5576        |\n",
      "|    policyGradLoss     | -0.00631    |\n",
      "|    value_loss         | 0.603       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 364         |\n",
      "|    total_timesteps    | 11436032    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012074389 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0264      |\n",
      "|    mean_step_reward   | 0.14650615  |\n",
      "|    n_updates          | 5580        |\n",
      "|    policyGradLoss     | -0.0104     |\n",
      "|    value_loss         | 0.34        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 374         |\n",
      "|    total_timesteps    | 11444224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016234277 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0574      |\n",
      "|    mean_step_reward   | 0.15214702  |\n",
      "|    n_updates          | 5584        |\n",
      "|    policyGradLoss     | -0.00632    |\n",
      "|    value_loss         | 0.493       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 384         |\n",
      "|    total_timesteps    | 11452416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011568404 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00199     |\n",
      "|    mean_step_reward   | 0.15189323  |\n",
      "|    n_updates          | 5588        |\n",
      "|    policyGradLoss     | -0.0116     |\n",
      "|    value_loss         | 0.229       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 394         |\n",
      "|    total_timesteps    | 11460608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013816498 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.056       |\n",
      "|    mean_step_reward   | 0.14605725  |\n",
      "|    n_updates          | 5592        |\n",
      "|    policyGradLoss     | -0.00603    |\n",
      "|    value_loss         | 0.566       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 404         |\n",
      "|    total_timesteps    | 11468800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012432957 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00826     |\n",
      "|    mean_step_reward   | 0.14559415  |\n",
      "|    n_updates          | 5596        |\n",
      "|    policyGradLoss     | -0.0123     |\n",
      "|    value_loss         | 0.385       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_34.zip\n",
      "[EVAL] Mean Return: 189.250, Best Return: 189.550\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_34_189.25.mp4\n",
      "\n",
      "=== Round 36 | Learn 327680 steps (Total trained: 11468800) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1150     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 11476992 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 948         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 11485184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013888847 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.031      |\n",
      "|    mean_step_reward   | 0.15328507  |\n",
      "|    n_updates          | 5604        |\n",
      "|    policyGradLoss     | -0.0136     |\n",
      "|    value_loss         | 0.12        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 896         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 11493376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014388905 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0325      |\n",
      "|    mean_step_reward   | 0.14606303  |\n",
      "|    n_updates          | 5608        |\n",
      "|    policyGradLoss     | -0.00833    |\n",
      "|    value_loss         | 0.3         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 876         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 37          |\n",
      "|    total_timesteps    | 11501568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015339031 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00416    |\n",
      "|    mean_step_reward   | 0.14781108  |\n",
      "|    n_updates          | 5612        |\n",
      "|    policyGradLoss     | -0.0104     |\n",
      "|    value_loss         | 0.281       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 859         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 47          |\n",
      "|    total_timesteps    | 11509760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019124258 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.148       |\n",
      "|    mean_step_reward   | 0.1455389   |\n",
      "|    n_updates          | 5616        |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.328       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 851        |\n",
      "|    iterations         | 6          |\n",
      "|    time_elapsed       | 57         |\n",
      "|    total_timesteps    | 11517952   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01734564 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.988      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0244     |\n",
      "|    mean_step_reward   | 0.1481358  |\n",
      "|    n_updates          | 5620       |\n",
      "|    policyGradLoss     | -0.012     |\n",
      "|    value_loss         | 0.261      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 842         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 11526144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013724046 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0421      |\n",
      "|    mean_step_reward   | 0.13870436  |\n",
      "|    n_updates          | 5624        |\n",
      "|    policyGradLoss     | -0.00959    |\n",
      "|    value_loss         | 0.362       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 840         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 77          |\n",
      "|    total_timesteps    | 11534336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014728201 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0539      |\n",
      "|    mean_step_reward   | 0.14083235  |\n",
      "|    n_updates          | 5628        |\n",
      "|    policyGradLoss     | -0.0135     |\n",
      "|    value_loss         | 0.319       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 88          |\n",
      "|    total_timesteps    | 11542528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012504995 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0623      |\n",
      "|    mean_step_reward   | 0.15461713  |\n",
      "|    n_updates          | 5632        |\n",
      "|    policyGradLoss     | -0.0116     |\n",
      "|    value_loss         | 0.313       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 835         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 11550720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015622709 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00373     |\n",
      "|    mean_step_reward   | 0.14891121  |\n",
      "|    n_updates          | 5636        |\n",
      "|    policyGradLoss     | -0.0113     |\n",
      "|    value_loss         | 0.282       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 833         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 108         |\n",
      "|    total_timesteps    | 11558912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011326944 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0373      |\n",
      "|    mean_step_reward   | 0.15507296  |\n",
      "|    n_updates          | 5640        |\n",
      "|    policyGradLoss     | -0.00422    |\n",
      "|    value_loss         | 0.379       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 829        |\n",
      "|    iterations         | 12         |\n",
      "|    time_elapsed       | 118        |\n",
      "|    total_timesteps    | 11567104   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01960795 |\n",
      "|    entropy_loss       | -1.78      |\n",
      "|    explained_variance | 0.982      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00205   |\n",
      "|    mean_step_reward   | 0.1456469  |\n",
      "|    n_updates          | 5644       |\n",
      "|    policyGradLoss     | -0.0103    |\n",
      "|    value_loss         | 0.259      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 827        |\n",
      "|    iterations         | 13         |\n",
      "|    time_elapsed       | 128        |\n",
      "|    total_timesteps    | 11575296   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01564754 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0157    |\n",
      "|    mean_step_reward   | 0.1544942  |\n",
      "|    n_updates          | 5648       |\n",
      "|    policyGradLoss     | -0.00959   |\n",
      "|    value_loss         | 0.223      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 824          |\n",
      "|    iterations         | 14           |\n",
      "|    time_elapsed       | 139          |\n",
      "|    total_timesteps    | 11583488     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0145921735 |\n",
      "|    entropy_loss       | -1.76        |\n",
      "|    explained_variance | 0.984        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.00134      |\n",
      "|    mean_step_reward   | 0.15504283   |\n",
      "|    n_updates          | 5652         |\n",
      "|    policyGradLoss     | -0.00664     |\n",
      "|    value_loss         | 0.231        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 11591680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014292108 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0115     |\n",
      "|    mean_step_reward   | 0.15492892  |\n",
      "|    n_updates          | 5656        |\n",
      "|    policyGradLoss     | -0.0108     |\n",
      "|    value_loss         | 0.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 824         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 11599872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011969339 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0221     |\n",
      "|    mean_step_reward   | 0.14618374  |\n",
      "|    n_updates          | 5660        |\n",
      "|    policyGradLoss     | -0.0117     |\n",
      "|    value_loss         | 0.217       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 823         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 11608064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014007914 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.027       |\n",
      "|    mean_step_reward   | 0.15244645  |\n",
      "|    n_updates          | 5664        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.509       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 823         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 11616256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016075727 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0168      |\n",
      "|    mean_step_reward   | 0.15418664  |\n",
      "|    n_updates          | 5668        |\n",
      "|    policyGradLoss     | -0.0104     |\n",
      "|    value_loss         | 0.188       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 821        |\n",
      "|    iterations         | 19         |\n",
      "|    time_elapsed       | 189        |\n",
      "|    total_timesteps    | 11624448   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01870004 |\n",
      "|    entropy_loss       | -1.74      |\n",
      "|    explained_variance | 0.989      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0358    |\n",
      "|    mean_step_reward   | 0.14195351 |\n",
      "|    n_updates          | 5672       |\n",
      "|    policyGradLoss     | -0.0161    |\n",
      "|    value_loss         | 0.133      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 11632640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012692917 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0869      |\n",
      "|    mean_step_reward   | 0.1572497   |\n",
      "|    n_updates          | 5676        |\n",
      "|    policyGradLoss     | -0.00657    |\n",
      "|    value_loss         | 0.484       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 11640832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017115183 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0169     |\n",
      "|    mean_step_reward   | 0.14529707  |\n",
      "|    n_updates          | 5680        |\n",
      "|    policyGradLoss     | -0.0129     |\n",
      "|    value_loss         | 0.2         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 11649024    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017008357 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.996       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0293     |\n",
      "|    mean_step_reward   | 0.1599037   |\n",
      "|    n_updates          | 5684        |\n",
      "|    policyGradLoss     | -0.0152     |\n",
      "|    value_loss         | 0.105       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 819        |\n",
      "|    iterations         | 23         |\n",
      "|    time_elapsed       | 230        |\n",
      "|    total_timesteps    | 11657216   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01400999 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.99       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00156    |\n",
      "|    mean_step_reward   | 0.14847349 |\n",
      "|    n_updates          | 5688       |\n",
      "|    policyGradLoss     | -0.0101    |\n",
      "|    value_loss         | 0.155      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 11665408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012313873 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00245     |\n",
      "|    mean_step_reward   | 0.15768589  |\n",
      "|    n_updates          | 5692        |\n",
      "|    policyGradLoss     | -0.0101     |\n",
      "|    value_loss         | 0.334       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 250         |\n",
      "|    total_timesteps    | 11673600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012545312 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.486       |\n",
      "|    mean_step_reward   | 0.14598611  |\n",
      "|    n_updates          | 5696        |\n",
      "|    policyGradLoss     | -0.00483    |\n",
      "|    value_loss         | 1.04        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 260         |\n",
      "|    total_timesteps    | 11681792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012688272 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.23        |\n",
      "|    mean_step_reward   | 0.14442822  |\n",
      "|    n_updates          | 5700        |\n",
      "|    policyGradLoss     | -0.00221    |\n",
      "|    value_loss         | 0.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 270         |\n",
      "|    total_timesteps    | 11689984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016366957 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0236     |\n",
      "|    mean_step_reward   | 0.15734729  |\n",
      "|    n_updates          | 5704        |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 281         |\n",
      "|    total_timesteps    | 11698176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013741706 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0802      |\n",
      "|    mean_step_reward   | 0.15114251  |\n",
      "|    n_updates          | 5708        |\n",
      "|    policyGradLoss     | -0.00686    |\n",
      "|    value_loss         | 0.345       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 291         |\n",
      "|    total_timesteps    | 11706368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013354776 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00336     |\n",
      "|    mean_step_reward   | 0.14738342  |\n",
      "|    n_updates          | 5712        |\n",
      "|    policyGradLoss     | -0.0116     |\n",
      "|    value_loss         | 0.194       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 301         |\n",
      "|    total_timesteps    | 11714560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015015717 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0136      |\n",
      "|    mean_step_reward   | 0.15096015  |\n",
      "|    n_updates          | 5716        |\n",
      "|    policyGradLoss     | -0.00821    |\n",
      "|    value_loss         | 0.373       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 312         |\n",
      "|    total_timesteps    | 11722752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017245714 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0364      |\n",
      "|    mean_step_reward   | 0.14921647  |\n",
      "|    n_updates          | 5720        |\n",
      "|    policyGradLoss     | -0.0061     |\n",
      "|    value_loss         | 0.328       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 322         |\n",
      "|    total_timesteps    | 11730944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015512275 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00937    |\n",
      "|    mean_step_reward   | 0.15648273  |\n",
      "|    n_updates          | 5724        |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.167       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 812        |\n",
      "|    iterations         | 33         |\n",
      "|    time_elapsed       | 332        |\n",
      "|    total_timesteps    | 11739136   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01888926 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.994      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0251    |\n",
      "|    mean_step_reward   | 0.15044245 |\n",
      "|    n_updates          | 5728       |\n",
      "|    policyGradLoss     | -0.0137    |\n",
      "|    value_loss         | 0.115      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 342         |\n",
      "|    total_timesteps    | 11747328    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014962917 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0174     |\n",
      "|    mean_step_reward   | 0.15667818  |\n",
      "|    n_updates          | 5732        |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.142       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 352         |\n",
      "|    total_timesteps    | 11755520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011746793 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.012      |\n",
      "|    mean_step_reward   | 0.149885    |\n",
      "|    n_updates          | 5736        |\n",
      "|    policyGradLoss     | -0.0109     |\n",
      "|    value_loss         | 0.374       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 362         |\n",
      "|    total_timesteps    | 11763712    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014236739 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0361     |\n",
      "|    mean_step_reward   | 0.15125239  |\n",
      "|    n_updates          | 5740        |\n",
      "|    policyGradLoss     | -0.0117     |\n",
      "|    value_loss         | 0.135       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 372         |\n",
      "|    total_timesteps    | 11771904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014894208 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0147      |\n",
      "|    mean_step_reward   | 0.14694178  |\n",
      "|    n_updates          | 5744        |\n",
      "|    policyGradLoss     | -0.0101     |\n",
      "|    value_loss         | 0.357       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 382         |\n",
      "|    total_timesteps    | 11780096    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014125746 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0104      |\n",
      "|    mean_step_reward   | 0.14783788  |\n",
      "|    n_updates          | 5748        |\n",
      "|    policyGradLoss     | -0.0078     |\n",
      "|    value_loss         | 0.257       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 392         |\n",
      "|    total_timesteps    | 11788288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011229329 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0333      |\n",
      "|    mean_step_reward   | 0.14943671  |\n",
      "|    n_updates          | 5752        |\n",
      "|    policyGradLoss     | -0.00771    |\n",
      "|    value_loss         | 0.344       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 812        |\n",
      "|    iterations         | 40         |\n",
      "|    time_elapsed       | 403        |\n",
      "|    total_timesteps    | 11796480   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01264872 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.959      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.00839    |\n",
      "|    mean_step_reward   | 0.13793895 |\n",
      "|    n_updates          | 5756       |\n",
      "|    policyGradLoss     | -0.0101    |\n",
      "|    value_loss         | 0.392      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_35.zip\n",
      "[EVAL] Mean Return: 191.029, Best Return: 191.329\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_35_191.03.mp4\n",
      "\n",
      "=== Round 37 | Learn 327680 steps (Total trained: 11796480) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1064     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 11804672 |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 902          |\n",
      "|    iterations         | 2            |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 11812864     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0140617415 |\n",
      "|    entropy_loss       | -1.85        |\n",
      "|    explained_variance | 0.978        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.00761      |\n",
      "|    mean_step_reward   | 0.14948605   |\n",
      "|    n_updates          | 5764         |\n",
      "|    policyGradLoss     | -0.00779     |\n",
      "|    value_loss         | 0.408        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 869          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 11821056     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0126267895 |\n",
      "|    entropy_loss       | -1.82        |\n",
      "|    explained_variance | 0.979        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0662       |\n",
      "|    mean_step_reward   | 0.14656241   |\n",
      "|    n_updates          | 5768         |\n",
      "|    policyGradLoss     | -0.00845     |\n",
      "|    value_loss         | 0.367        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 855         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 11829248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015878888 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00692    |\n",
      "|    mean_step_reward   | 0.15402582  |\n",
      "|    n_updates          | 5772        |\n",
      "|    policyGradLoss     | -0.0122     |\n",
      "|    value_loss         | 0.215       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 849         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 48          |\n",
      "|    total_timesteps    | 11837440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014694166 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0649      |\n",
      "|    mean_step_reward   | 0.13873054  |\n",
      "|    n_updates          | 5776        |\n",
      "|    policyGradLoss     | -0.0109     |\n",
      "|    value_loss         | 0.325       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 838          |\n",
      "|    iterations         | 6            |\n",
      "|    time_elapsed       | 58           |\n",
      "|    total_timesteps    | 11845632     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0127621405 |\n",
      "|    entropy_loss       | -1.86        |\n",
      "|    explained_variance | 0.98         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0525       |\n",
      "|    mean_step_reward   | 0.14989385   |\n",
      "|    n_updates          | 5780         |\n",
      "|    policyGradLoss     | -0.00703     |\n",
      "|    value_loss         | 0.437        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 834         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 11853824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009043063 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.963       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.245       |\n",
      "|    mean_step_reward   | 0.13984913  |\n",
      "|    n_updates          | 5784        |\n",
      "|    policyGradLoss     | -0.00863    |\n",
      "|    value_loss         | 0.432       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 829         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 11862016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014047607 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00352     |\n",
      "|    mean_step_reward   | 0.15674642  |\n",
      "|    n_updates          | 5788        |\n",
      "|    policyGradLoss     | -0.0137     |\n",
      "|    value_loss         | 0.185       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 89          |\n",
      "|    total_timesteps    | 11870208    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010367895 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0637      |\n",
      "|    mean_step_reward   | 0.15235874  |\n",
      "|    n_updates          | 5792        |\n",
      "|    policyGradLoss     | -0.00466    |\n",
      "|    value_loss         | 0.487       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 820          |\n",
      "|    iterations         | 10           |\n",
      "|    time_elapsed       | 99           |\n",
      "|    total_timesteps    | 11878400     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0155173885 |\n",
      "|    entropy_loss       | -1.81        |\n",
      "|    explained_variance | 0.971        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.0255       |\n",
      "|    mean_step_reward   | 0.13435084   |\n",
      "|    n_updates          | 5796         |\n",
      "|    policyGradLoss     | -0.00737     |\n",
      "|    value_loss         | 0.385        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 110         |\n",
      "|    total_timesteps    | 11886592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013089158 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00167     |\n",
      "|    mean_step_reward   | 0.15398702  |\n",
      "|    n_updates          | 5800        |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 11894784    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015770692 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00839    |\n",
      "|    mean_step_reward   | 0.14470756  |\n",
      "|    n_updates          | 5804        |\n",
      "|    policyGradLoss     | -0.0118     |\n",
      "|    value_loss         | 0.191       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 130         |\n",
      "|    total_timesteps    | 11902976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010558492 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.214       |\n",
      "|    mean_step_reward   | 0.14818558  |\n",
      "|    n_updates          | 5808        |\n",
      "|    policyGradLoss     | -0.00674    |\n",
      "|    value_loss         | 0.518       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 140         |\n",
      "|    total_timesteps    | 11911168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013318814 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.33        |\n",
      "|    mean_step_reward   | 0.13716269  |\n",
      "|    n_updates          | 5812        |\n",
      "|    policyGradLoss     | -0.00921    |\n",
      "|    value_loss         | 0.587       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 150         |\n",
      "|    total_timesteps    | 11919360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014045205 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.000801   |\n",
      "|    mean_step_reward   | 0.15302858  |\n",
      "|    n_updates          | 5816        |\n",
      "|    policyGradLoss     | -0.0114     |\n",
      "|    value_loss         | 0.285       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 11927552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012347609 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0421      |\n",
      "|    mean_step_reward   | 0.15608221  |\n",
      "|    n_updates          | 5820        |\n",
      "|    policyGradLoss     | -0.00834    |\n",
      "|    value_loss         | 0.404       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 11935744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009429193 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0179      |\n",
      "|    mean_step_reward   | 0.14501987  |\n",
      "|    n_updates          | 5824        |\n",
      "|    policyGradLoss     | -0.00611    |\n",
      "|    value_loss         | 0.345       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 11943936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015301798 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.967       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0385      |\n",
      "|    mean_step_reward   | 0.14160067  |\n",
      "|    n_updates          | 5828        |\n",
      "|    policyGradLoss     | -0.00434    |\n",
      "|    value_loss         | 0.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 11952128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011332884 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.284       |\n",
      "|    mean_step_reward   | 0.16043603  |\n",
      "|    n_updates          | 5832        |\n",
      "|    policyGradLoss     | -0.00522    |\n",
      "|    value_loss         | 0.604       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 11960320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011387458 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0833      |\n",
      "|    mean_step_reward   | 0.13871607  |\n",
      "|    n_updates          | 5836        |\n",
      "|    policyGradLoss     | -0.00897    |\n",
      "|    value_loss         | 0.482       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 11968512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014960379 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0492      |\n",
      "|    mean_step_reward   | 0.15504216  |\n",
      "|    n_updates          | 5840        |\n",
      "|    policyGradLoss     | -0.00899    |\n",
      "|    value_loss         | 0.508       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 11976704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009311436 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.101       |\n",
      "|    mean_step_reward   | 0.1430099   |\n",
      "|    n_updates          | 5844        |\n",
      "|    policyGradLoss     | -0.0094     |\n",
      "|    value_loss         | 0.402       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 11984896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012034539 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.936       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0971      |\n",
      "|    mean_step_reward   | 0.13682221  |\n",
      "|    n_updates          | 5848        |\n",
      "|    policyGradLoss     | -0.000718   |\n",
      "|    value_loss         | 0.398       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 812          |\n",
      "|    iterations         | 24           |\n",
      "|    time_elapsed       | 241          |\n",
      "|    total_timesteps    | 11993088     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0121693555 |\n",
      "|    entropy_loss       | -1.91        |\n",
      "|    explained_variance | 0.97         |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.224        |\n",
      "|    mean_step_reward   | 0.14866415   |\n",
      "|    n_updates          | 5852         |\n",
      "|    policyGradLoss     | -0.00882     |\n",
      "|    value_loss         | 0.656        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 12001280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014232149 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.015      |\n",
      "|    mean_step_reward   | 0.13765687  |\n",
      "|    n_updates          | 5856        |\n",
      "|    policyGradLoss     | -0.00729    |\n",
      "|    value_loss         | 0.147       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 12009472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011239954 |\n",
      "|    entropy_loss       | -1.9        |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00453     |\n",
      "|    mean_step_reward   | 0.16393542  |\n",
      "|    n_updates          | 5860        |\n",
      "|    policyGradLoss     | -0.00711    |\n",
      "|    value_loss         | 0.287       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 12017664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017642628 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0377     |\n",
      "|    mean_step_reward   | 0.14197259  |\n",
      "|    n_updates          | 5864        |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.131       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 282         |\n",
      "|    total_timesteps    | 12025856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011336384 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0607      |\n",
      "|    mean_step_reward   | 0.15581381  |\n",
      "|    n_updates          | 5868        |\n",
      "|    policyGradLoss     | -0.00885    |\n",
      "|    value_loss         | 0.511       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 12034048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017386265 |\n",
      "|    entropy_loss       | -1.87       |\n",
      "|    explained_variance | 0.966       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.128       |\n",
      "|    mean_step_reward   | 0.14151889  |\n",
      "|    n_updates          | 5872        |\n",
      "|    policyGradLoss     | -0.00837    |\n",
      "|    value_loss         | 0.753       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 811          |\n",
      "|    iterations         | 30           |\n",
      "|    time_elapsed       | 302          |\n",
      "|    total_timesteps    | 12042240     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0124011235 |\n",
      "|    entropy_loss       | -1.78        |\n",
      "|    explained_variance | 0.973        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.011       |\n",
      "|    mean_step_reward   | 0.1433434    |\n",
      "|    n_updates          | 5876         |\n",
      "|    policyGradLoss     | -0.0068      |\n",
      "|    value_loss         | 0.303        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 312         |\n",
      "|    total_timesteps    | 12050432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.019816563 |\n",
      "|    entropy_loss       | -1.91       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.145       |\n",
      "|    mean_step_reward   | 0.16017094  |\n",
      "|    n_updates          | 5880        |\n",
      "|    policyGradLoss     | -0.00375    |\n",
      "|    value_loss         | 0.48        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 323         |\n",
      "|    total_timesteps    | 12058624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017596148 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.168       |\n",
      "|    mean_step_reward   | 0.14418077  |\n",
      "|    n_updates          | 5884        |\n",
      "|    policyGradLoss     | -0.00886    |\n",
      "|    value_loss         | 0.296       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 810        |\n",
      "|    iterations         | 33         |\n",
      "|    time_elapsed       | 333        |\n",
      "|    total_timesteps    | 12066816   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01645141 |\n",
      "|    entropy_loss       | -1.84      |\n",
      "|    explained_variance | 0.996      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0374    |\n",
      "|    mean_step_reward   | 0.16553429 |\n",
      "|    n_updates          | 5888       |\n",
      "|    policyGradLoss     | -0.0151    |\n",
      "|    value_loss         | 0.113      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 343         |\n",
      "|    total_timesteps    | 12075008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011745701 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0183     |\n",
      "|    mean_step_reward   | 0.14562483  |\n",
      "|    n_updates          | 5892        |\n",
      "|    policyGradLoss     | -0.0047     |\n",
      "|    value_loss         | 0.337       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 354         |\n",
      "|    total_timesteps    | 12083200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016292114 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.988       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0403      |\n",
      "|    mean_step_reward   | 0.15393707  |\n",
      "|    n_updates          | 5896        |\n",
      "|    policyGradLoss     | -0.00848    |\n",
      "|    value_loss         | 0.229       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 364         |\n",
      "|    total_timesteps    | 12091392    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014600538 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0214      |\n",
      "|    mean_step_reward   | 0.15850422  |\n",
      "|    n_updates          | 5900        |\n",
      "|    policyGradLoss     | -0.0051     |\n",
      "|    value_loss         | 0.542       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 374         |\n",
      "|    total_timesteps    | 12099584    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011830909 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.949       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0884      |\n",
      "|    mean_step_reward   | 0.12983634  |\n",
      "|    n_updates          | 5904        |\n",
      "|    policyGradLoss     | -0.00702    |\n",
      "|    value_loss         | 0.779       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 383         |\n",
      "|    total_timesteps    | 12107776    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012752084 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0114     |\n",
      "|    mean_step_reward   | 0.16033992  |\n",
      "|    n_updates          | 5908        |\n",
      "|    policyGradLoss     | -0.00874    |\n",
      "|    value_loss         | 0.256       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 394         |\n",
      "|    total_timesteps    | 12115968    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014091317 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0199     |\n",
      "|    mean_step_reward   | 0.15043211  |\n",
      "|    n_updates          | 5912        |\n",
      "|    policyGradLoss     | -0.0139     |\n",
      "|    value_loss         | 0.232       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 810        |\n",
      "|    iterations         | 40         |\n",
      "|    time_elapsed       | 404        |\n",
      "|    total_timesteps    | 12124160   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01379917 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.986      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.014      |\n",
      "|    mean_step_reward   | 0.15056214 |\n",
      "|    n_updates          | 5916       |\n",
      "|    policyGradLoss     | -0.01      |\n",
      "|    value_loss         | 0.23       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_36.zip\n",
      "[EVAL] Mean Return: 191.346, Best Return: 191.646\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_36_191.35.mp4\n",
      "\n",
      "=== Round 38 | Learn 327680 steps (Total trained: 12124160) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1117     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 12132352 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 944         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 12140544    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010707034 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0712      |\n",
      "|    mean_step_reward   | 0.15084198  |\n",
      "|    n_updates          | 5924        |\n",
      "|    policyGradLoss     | -0.00469    |\n",
      "|    value_loss         | 0.516       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 888         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 12148736    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012704537 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0627      |\n",
      "|    mean_step_reward   | 0.14597166  |\n",
      "|    n_updates          | 5928        |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.716       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 865         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 37          |\n",
      "|    total_timesteps    | 12156928    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016468791 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0197     |\n",
      "|    mean_step_reward   | 0.15491924  |\n",
      "|    n_updates          | 5932        |\n",
      "|    policyGradLoss     | -0.0128     |\n",
      "|    value_loss         | 0.166       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 848        |\n",
      "|    iterations         | 5          |\n",
      "|    time_elapsed       | 48         |\n",
      "|    total_timesteps    | 12165120   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01163142 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0146    |\n",
      "|    mean_step_reward   | 0.1563938  |\n",
      "|    n_updates          | 5936       |\n",
      "|    policyGradLoss     | -0.0072    |\n",
      "|    value_loss         | 0.167      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 840         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 12173312    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012928864 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0277     |\n",
      "|    mean_step_reward   | 0.15618262  |\n",
      "|    n_updates          | 5940        |\n",
      "|    policyGradLoss     | -0.0112     |\n",
      "|    value_loss         | 0.148       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 833         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 12181504    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010230926 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0999      |\n",
      "|    mean_step_reward   | 0.14449477  |\n",
      "|    n_updates          | 5944        |\n",
      "|    policyGradLoss     | -0.00734    |\n",
      "|    value_loss         | 0.596       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 831         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 12189696    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013631113 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.282       |\n",
      "|    mean_step_reward   | 0.13891053  |\n",
      "|    n_updates          | 5948        |\n",
      "|    policyGradLoss     | -0.0106     |\n",
      "|    value_loss         | 0.636       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 829         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 88          |\n",
      "|    total_timesteps    | 12197888    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010198501 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0522      |\n",
      "|    mean_step_reward   | 0.14337942  |\n",
      "|    n_updates          | 5952        |\n",
      "|    policyGradLoss     | -0.00729    |\n",
      "|    value_loss         | 0.461       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 827         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 12206080    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010688238 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00703     |\n",
      "|    mean_step_reward   | 0.14857939  |\n",
      "|    n_updates          | 5956        |\n",
      "|    policyGradLoss     | -0.011      |\n",
      "|    value_loss         | 0.176       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 825         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 12214272    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012177871 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.106       |\n",
      "|    mean_step_reward   | 0.14961813  |\n",
      "|    n_updates          | 5960        |\n",
      "|    policyGradLoss     | -0.0126     |\n",
      "|    value_loss         | 0.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 12222464    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009427693 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.195       |\n",
      "|    mean_step_reward   | 0.15498734  |\n",
      "|    n_updates          | 5964        |\n",
      "|    policyGradLoss     | -0.00942    |\n",
      "|    value_loss         | 0.557       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 129         |\n",
      "|    total_timesteps    | 12230656    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014130234 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0111     |\n",
      "|    mean_step_reward   | 0.15748692  |\n",
      "|    n_updates          | 5968        |\n",
      "|    policyGradLoss     | -0.0136     |\n",
      "|    value_loss         | 0.141       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 139         |\n",
      "|    total_timesteps    | 12238848    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015942516 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0367      |\n",
      "|    mean_step_reward   | 0.15162635  |\n",
      "|    n_updates          | 5972        |\n",
      "|    policyGradLoss     | -0.0159     |\n",
      "|    value_loss         | 0.192       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 818        |\n",
      "|    iterations         | 15         |\n",
      "|    time_elapsed       | 150        |\n",
      "|    total_timesteps    | 12247040   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01120303 |\n",
      "|    entropy_loss       | -1.79      |\n",
      "|    explained_variance | 0.979      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.087      |\n",
      "|    mean_step_reward   | 0.15276748 |\n",
      "|    n_updates          | 5976       |\n",
      "|    policyGradLoss     | -0.00897   |\n",
      "|    value_loss         | 0.328      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 818         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 12255232    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012857055 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0412     |\n",
      "|    mean_step_reward   | 0.15549897  |\n",
      "|    n_updates          | 5980        |\n",
      "|    policyGradLoss     | -0.0157     |\n",
      "|    value_loss         | 0.102       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 17          |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 12263424    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011828491 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.969       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.089       |\n",
      "|    mean_step_reward   | 0.15015319  |\n",
      "|    n_updates          | 5984        |\n",
      "|    policyGradLoss     | -0.00474    |\n",
      "|    value_loss         | 0.422       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 12271616    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012145231 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00605     |\n",
      "|    mean_step_reward   | 0.15645178  |\n",
      "|    n_updates          | 5988        |\n",
      "|    policyGradLoss     | -0.00879    |\n",
      "|    value_loss         | 0.448       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 12279808    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010155499 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0251     |\n",
      "|    mean_step_reward   | 0.15987355  |\n",
      "|    n_updates          | 5992        |\n",
      "|    policyGradLoss     | -0.00656    |\n",
      "|    value_loss         | 0.233       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 12288000    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011978792 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0271      |\n",
      "|    mean_step_reward   | 0.15143646  |\n",
      "|    n_updates          | 5996        |\n",
      "|    policyGradLoss     | -0.00771    |\n",
      "|    value_loss         | 0.437       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 12296192    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013317989 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0385     |\n",
      "|    mean_step_reward   | 0.14734647  |\n",
      "|    n_updates          | 6000        |\n",
      "|    policyGradLoss     | -0.00706    |\n",
      "|    value_loss         | 0.187       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 12304384    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.021536686 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0131      |\n",
      "|    mean_step_reward   | 0.15827936  |\n",
      "|    n_updates          | 6004        |\n",
      "|    policyGradLoss     | -0.0045     |\n",
      "|    value_loss         | 0.287       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 12312576    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014875365 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00554    |\n",
      "|    mean_step_reward   | 0.14571697  |\n",
      "|    n_updates          | 6008        |\n",
      "|    policyGradLoss     | -0.00976    |\n",
      "|    value_loss         | 0.189       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 12320768    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011292112 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.163       |\n",
      "|    mean_step_reward   | 0.138109    |\n",
      "|    n_updates          | 6012        |\n",
      "|    policyGradLoss     | -0.0044     |\n",
      "|    value_loss         | 0.786       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 815        |\n",
      "|    iterations         | 25         |\n",
      "|    time_elapsed       | 251        |\n",
      "|    total_timesteps    | 12328960   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01832426 |\n",
      "|    entropy_loss       | -1.8       |\n",
      "|    explained_variance | 0.978      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.0129    |\n",
      "|    mean_step_reward   | 0.15473148 |\n",
      "|    n_updates          | 6016       |\n",
      "|    policyGradLoss     | -0.00679   |\n",
      "|    value_loss         | 0.4        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 12337152    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012305904 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0629      |\n",
      "|    mean_step_reward   | 0.15824494  |\n",
      "|    n_updates          | 6020        |\n",
      "|    policyGradLoss     | -0.00961    |\n",
      "|    value_loss         | 0.29        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 12345344    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013575119 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00793     |\n",
      "|    mean_step_reward   | 0.14078894  |\n",
      "|    n_updates          | 6024        |\n",
      "|    policyGradLoss     | -0.00716    |\n",
      "|    value_loss         | 0.328       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 812          |\n",
      "|    iterations         | 28           |\n",
      "|    time_elapsed       | 282          |\n",
      "|    total_timesteps    | 12353536     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0108738085 |\n",
      "|    entropy_loss       | -1.82        |\n",
      "|    explained_variance | 0.977        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.00946     |\n",
      "|    mean_step_reward   | 0.14790073   |\n",
      "|    n_updates          | 6028         |\n",
      "|    policyGradLoss     | -0.00743     |\n",
      "|    value_loss         | 0.272        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 812        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 292        |\n",
      "|    total_timesteps    | 12361728   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01368439 |\n",
      "|    entropy_loss       | -1.81      |\n",
      "|    explained_variance | 0.991      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0151     |\n",
      "|    mean_step_reward   | 0.1565302  |\n",
      "|    n_updates          | 6032       |\n",
      "|    policyGradLoss     | -0.013     |\n",
      "|    value_loss         | 0.168      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 812        |\n",
      "|    iterations         | 30         |\n",
      "|    time_elapsed       | 302        |\n",
      "|    total_timesteps    | 12369920   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01480259 |\n",
      "|    entropy_loss       | -1.86      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0579     |\n",
      "|    mean_step_reward   | 0.14458466 |\n",
      "|    n_updates          | 6036       |\n",
      "|    policyGradLoss     | -0.00897   |\n",
      "|    value_loss         | 0.253      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 312         |\n",
      "|    total_timesteps    | 12378112    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013345284 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00411    |\n",
      "|    mean_step_reward   | 0.1543124   |\n",
      "|    n_updates          | 6040        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.182       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 322         |\n",
      "|    total_timesteps    | 12386304    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014440423 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00859     |\n",
      "|    mean_step_reward   | 0.1527555   |\n",
      "|    n_updates          | 6044        |\n",
      "|    policyGradLoss     | -0.0099     |\n",
      "|    value_loss         | 0.248       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 12394496    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015392853 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.984       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00642     |\n",
      "|    mean_step_reward   | 0.14410804  |\n",
      "|    n_updates          | 6048        |\n",
      "|    policyGradLoss     | -0.0115     |\n",
      "|    value_loss         | 0.279       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 343         |\n",
      "|    total_timesteps    | 12402688    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014544234 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0305      |\n",
      "|    mean_step_reward   | 0.14770427  |\n",
      "|    n_updates          | 6052        |\n",
      "|    policyGradLoss     | -0.00951    |\n",
      "|    value_loss         | 0.345       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 353         |\n",
      "|    total_timesteps    | 12410880    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013615922 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.977       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0245      |\n",
      "|    mean_step_reward   | 0.14733826  |\n",
      "|    n_updates          | 6056        |\n",
      "|    policyGradLoss     | -0.00693    |\n",
      "|    value_loss         | 0.39        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 810         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 364         |\n",
      "|    total_timesteps    | 12419072    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011342052 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.109       |\n",
      "|    mean_step_reward   | 0.15102023  |\n",
      "|    n_updates          | 6060        |\n",
      "|    policyGradLoss     | -0.0111     |\n",
      "|    value_loss         | 0.375       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 374         |\n",
      "|    total_timesteps    | 12427264    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011003048 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.113       |\n",
      "|    mean_step_reward   | 0.1540783   |\n",
      "|    n_updates          | 6064        |\n",
      "|    policyGradLoss     | -0.00653    |\n",
      "|    value_loss         | 0.594       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 384         |\n",
      "|    total_timesteps    | 12435456    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015896238 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.013       |\n",
      "|    mean_step_reward   | 0.1438807   |\n",
      "|    n_updates          | 6068        |\n",
      "|    policyGradLoss     | -0.00877    |\n",
      "|    value_loss         | 0.273       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 394         |\n",
      "|    total_timesteps    | 12443648    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016273972 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.997       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0294     |\n",
      "|    mean_step_reward   | 0.17785268  |\n",
      "|    n_updates          | 6072        |\n",
      "|    policyGradLoss     | -0.00882    |\n",
      "|    value_loss         | 0.113       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 809         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 404         |\n",
      "|    total_timesteps    | 12451840    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016126659 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0315     |\n",
      "|    mean_step_reward   | 0.14580777  |\n",
      "|    n_updates          | 6076        |\n",
      "|    policyGradLoss     | -0.00927    |\n",
      "|    value_loss         | 0.179       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_37.zip\n",
      "[EVAL] Mean Return: 191.734, Best Return: 192.034\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_37_191.73.mp4\n",
      "\n",
      "=== Round 39 | Learn 327680 steps (Total trained: 12451840) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1110     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 12460032 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 914         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 12468224    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008797487 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0475      |\n",
      "|    mean_step_reward   | 0.14084281  |\n",
      "|    n_updates          | 6084        |\n",
      "|    policyGradLoss     | -0.0104     |\n",
      "|    value_loss         | 0.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 880         |\n",
      "|    iterations         | 3           |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 12476416    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013519026 |\n",
      "|    entropy_loss       | -1.74       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.034      |\n",
      "|    mean_step_reward   | 0.15505952  |\n",
      "|    n_updates          | 6088        |\n",
      "|    policyGradLoss     | -0.0133     |\n",
      "|    value_loss         | 0.146       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 857         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 12484608    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015024111 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.996       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00601    |\n",
      "|    mean_step_reward   | 0.16072151  |\n",
      "|    n_updates          | 6092        |\n",
      "|    policyGradLoss     | -0.00931    |\n",
      "|    value_loss         | 0.148       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 844         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 48          |\n",
      "|    total_timesteps    | 12492800    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017861657 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0429     |\n",
      "|    mean_step_reward   | 0.13726997  |\n",
      "|    n_updates          | 6096        |\n",
      "|    policyGradLoss     | -0.0121     |\n",
      "|    value_loss         | 0.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 12500992    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015222721 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0181      |\n",
      "|    mean_step_reward   | 0.15092823  |\n",
      "|    n_updates          | 6100        |\n",
      "|    policyGradLoss     | -0.00794    |\n",
      "|    value_loss         | 0.265       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 835         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 12509184    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014181364 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.919       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.16        |\n",
      "|    mean_step_reward   | 0.1309882   |\n",
      "|    n_updates          | 6104        |\n",
      "|    policyGradLoss     | -0.00647    |\n",
      "|    value_loss         | 0.628       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 831         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 12517376    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012383964 |\n",
      "|    entropy_loss       | -1.89       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00415    |\n",
      "|    mean_step_reward   | 0.15232736  |\n",
      "|    n_updates          | 6108        |\n",
      "|    policyGradLoss     | -0.00803    |\n",
      "|    value_loss         | 0.211       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 827         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 89          |\n",
      "|    total_timesteps    | 12525568    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015580626 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0247      |\n",
      "|    mean_step_reward   | 0.13200264  |\n",
      "|    n_updates          | 6112        |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 827         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 12533760    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014193067 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0515      |\n",
      "|    mean_step_reward   | 0.15002245  |\n",
      "|    n_updates          | 6116        |\n",
      "|    policyGradLoss     | -0.00429    |\n",
      "|    value_loss         | 0.35        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 824        |\n",
      "|    iterations         | 11         |\n",
      "|    time_elapsed       | 109        |\n",
      "|    total_timesteps    | 12541952   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.0149613  |\n",
      "|    entropy_loss       | -1.89      |\n",
      "|    explained_variance | 0.985      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.0409     |\n",
      "|    mean_step_reward   | 0.15600692 |\n",
      "|    n_updates          | 6120       |\n",
      "|    policyGradLoss     | -0.00848   |\n",
      "|    value_loss         | 0.362      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 12550144    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016073193 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0148     |\n",
      "|    mean_step_reward   | 0.13727027  |\n",
      "|    n_updates          | 6124        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.144       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 129         |\n",
      "|    total_timesteps    | 12558336    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013976573 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.183       |\n",
      "|    mean_step_reward   | 0.16256706  |\n",
      "|    n_updates          | 6128        |\n",
      "|    policyGradLoss     | -0.0051     |\n",
      "|    value_loss         | 0.344       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 14          |\n",
      "|    time_elapsed       | 139         |\n",
      "|    total_timesteps    | 12566528    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015444856 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0292      |\n",
      "|    mean_step_reward   | 0.14283358  |\n",
      "|    n_updates          | 6132        |\n",
      "|    policyGradLoss     | -0.0086     |\n",
      "|    value_loss         | 0.288       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 150         |\n",
      "|    total_timesteps    | 12574720    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017286453 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00156     |\n",
      "|    mean_step_reward   | 0.15108278  |\n",
      "|    n_updates          | 6136        |\n",
      "|    policyGradLoss     | -0.013      |\n",
      "|    value_loss         | 0.235       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 12582912    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012151452 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0973      |\n",
      "|    mean_step_reward   | 0.14351204  |\n",
      "|    n_updates          | 6140        |\n",
      "|    policyGradLoss     | -0.00904    |\n",
      "|    value_loss         | 0.371       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 816        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 170        |\n",
      "|    total_timesteps    | 12591104   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01522341 |\n",
      "|    entropy_loss       | -1.82      |\n",
      "|    explained_variance | 0.98       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.114      |\n",
      "|    mean_step_reward   | 0.1559659  |\n",
      "|    n_updates          | 6144       |\n",
      "|    policyGradLoss     | -0.00891   |\n",
      "|    value_loss         | 0.417      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 12599296    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015756663 |\n",
      "|    entropy_loss       | -1.88       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0575      |\n",
      "|    mean_step_reward   | 0.15586387  |\n",
      "|    n_updates          | 6148        |\n",
      "|    policyGradLoss     | -0.00855    |\n",
      "|    value_loss         | 0.229       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 12607488    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012538873 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.959       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0036      |\n",
      "|    mean_step_reward   | 0.1474247   |\n",
      "|    n_updates          | 6152        |\n",
      "|    policyGradLoss     | 0.000747    |\n",
      "|    value_loss         | 0.386       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 12615680    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010046336 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.953       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0784      |\n",
      "|    mean_step_reward   | 0.14516072  |\n",
      "|    n_updates          | 6156        |\n",
      "|    policyGradLoss     | 0.00737     |\n",
      "|    value_loss         | 0.605       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 12623872    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012752639 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0129      |\n",
      "|    mean_step_reward   | 0.13943894  |\n",
      "|    n_updates          | 6160        |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.394       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 12632064    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010181148 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.965       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.156       |\n",
      "|    mean_step_reward   | 0.15124847  |\n",
      "|    n_updates          | 6164        |\n",
      "|    policyGradLoss     | -0.00335    |\n",
      "|    value_loss         | 0.645       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 12640256    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016286228 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.979       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0935      |\n",
      "|    mean_step_reward   | 0.13849446  |\n",
      "|    n_updates          | 6168        |\n",
      "|    policyGradLoss     | -0.00376    |\n",
      "|    value_loss         | 0.265       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 12648448    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008817839 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.956       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0203      |\n",
      "|    mean_step_reward   | 0.15447637  |\n",
      "|    n_updates          | 6172        |\n",
      "|    policyGradLoss     | -0.00499    |\n",
      "|    value_loss         | 0.453       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 12656640    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012946528 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00164     |\n",
      "|    mean_step_reward   | 0.1471157   |\n",
      "|    n_updates          | 6176        |\n",
      "|    policyGradLoss     | -0.0102     |\n",
      "|    value_loss         | 0.195       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 261         |\n",
      "|    total_timesteps    | 12664832    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008211805 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.057       |\n",
      "|    mean_step_reward   | 0.15714651  |\n",
      "|    n_updates          | 6180        |\n",
      "|    policyGradLoss     | -0.00618    |\n",
      "|    value_loss         | 0.721       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 816          |\n",
      "|    iterations         | 27           |\n",
      "|    time_elapsed       | 271          |\n",
      "|    total_timesteps    | 12673024     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0121353045 |\n",
      "|    entropy_loss       | -1.86        |\n",
      "|    explained_variance | 0.983        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.00378     |\n",
      "|    mean_step_reward   | 0.15335628   |\n",
      "|    n_updates          | 6184         |\n",
      "|    policyGradLoss     | -0.00559     |\n",
      "|    value_loss         | 0.193        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 281         |\n",
      "|    total_timesteps    | 12681216    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011699511 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.974       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.12        |\n",
      "|    mean_step_reward   | 0.14836094  |\n",
      "|    n_updates          | 6188        |\n",
      "|    policyGradLoss     | -0.00924    |\n",
      "|    value_loss         | 0.458       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 29          |\n",
      "|    time_elapsed       | 291         |\n",
      "|    total_timesteps    | 12689408    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014726078 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00194    |\n",
      "|    mean_step_reward   | 0.15619078  |\n",
      "|    n_updates          | 6192        |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.158       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 301         |\n",
      "|    total_timesteps    | 12697600    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009830056 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.961       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0785      |\n",
      "|    mean_step_reward   | 0.13227928  |\n",
      "|    n_updates          | 6196        |\n",
      "|    policyGradLoss     | -0.00649    |\n",
      "|    value_loss         | 0.603       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 312         |\n",
      "|    total_timesteps    | 12705792    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018264908 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0379     |\n",
      "|    mean_step_reward   | 0.14691325  |\n",
      "|    n_updates          | 6200        |\n",
      "|    policyGradLoss     | -0.013      |\n",
      "|    value_loss         | 0.117       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 322         |\n",
      "|    total_timesteps    | 12713984    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014319416 |\n",
      "|    entropy_loss       | -1.84       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.00288    |\n",
      "|    mean_step_reward   | 0.1577717   |\n",
      "|    n_updates          | 6204        |\n",
      "|    policyGradLoss     | -0.00968    |\n",
      "|    value_loss         | 0.159       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 332         |\n",
      "|    total_timesteps    | 12722176    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014154255 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.311       |\n",
      "|    mean_step_reward   | 0.16575572  |\n",
      "|    n_updates          | 6208        |\n",
      "|    policyGradLoss     | -0.00713    |\n",
      "|    value_loss         | 0.299       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 342         |\n",
      "|    total_timesteps    | 12730368    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013394263 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0109      |\n",
      "|    mean_step_reward   | 0.15818425  |\n",
      "|    n_updates          | 6212        |\n",
      "|    policyGradLoss     | -0.00982    |\n",
      "|    value_loss         | 0.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 352         |\n",
      "|    total_timesteps    | 12738560    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014598338 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.992       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0356     |\n",
      "|    mean_step_reward   | 0.14916664  |\n",
      "|    n_updates          | 6216        |\n",
      "|    policyGradLoss     | -0.0125     |\n",
      "|    value_loss         | 0.143       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 363         |\n",
      "|    total_timesteps    | 12746752    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012938068 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.989       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.188       |\n",
      "|    mean_step_reward   | 0.15792578  |\n",
      "|    n_updates          | 6220        |\n",
      "|    policyGradLoss     | -0.00725    |\n",
      "|    value_loss         | 0.275       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 373         |\n",
      "|    total_timesteps    | 12754944    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017009426 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.997       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0244     |\n",
      "|    mean_step_reward   | 0.16572733  |\n",
      "|    n_updates          | 6224        |\n",
      "|    policyGradLoss     | -0.0132     |\n",
      "|    value_loss         | 0.0921      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 383         |\n",
      "|    total_timesteps    | 12763136    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012308714 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0246      |\n",
      "|    mean_step_reward   | 0.14642665  |\n",
      "|    n_updates          | 6228        |\n",
      "|    policyGradLoss     | -0.0105     |\n",
      "|    value_loss         | 0.375       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 811          |\n",
      "|    iterations         | 39           |\n",
      "|    time_elapsed       | 393          |\n",
      "|    total_timesteps    | 12771328     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0144540835 |\n",
      "|    entropy_loss       | -1.8         |\n",
      "|    explained_variance | 0.984        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | 0.113        |\n",
      "|    mean_step_reward   | 0.15839371   |\n",
      "|    n_updates          | 6232         |\n",
      "|    policyGradLoss     | -0.0107      |\n",
      "|    value_loss         | 0.427        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 403         |\n",
      "|    total_timesteps    | 12779520    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015144475 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.993       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0316     |\n",
      "|    mean_step_reward   | 0.14958513  |\n",
      "|    n_updates          | 6236        |\n",
      "|    policyGradLoss     | -0.0144     |\n",
      "|    value_loss         | 0.123       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_38.zip\n",
      "[EVAL] Mean Return: 191.578, Best Return: 191.878\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_38_191.58.mp4\n",
      "\n",
      "=== Round 40 | Learn 327680 steps (Total trained: 12779520) ===\n",
      "Logging to ./runs_smw/tb/PIPE_0\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1124     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 12787712 |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 944         |\n",
      "|    iterations         | 2           |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 12795904    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012831092 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.991       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0336     |\n",
      "|    mean_step_reward   | 0.15257823  |\n",
      "|    n_updates          | 6244        |\n",
      "|    policyGradLoss     | -0.0124     |\n",
      "|    value_loss         | 0.166       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 889          |\n",
      "|    iterations         | 3            |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 12804096     |\n",
      "| train/                |              |\n",
      "|    approx_kl          | 0.0105956085 |\n",
      "|    entropy_loss       | -1.79        |\n",
      "|    explained_variance | 0.988        |\n",
      "|    learning_rate      | 0.0001       |\n",
      "|    loss               | -0.0122      |\n",
      "|    mean_step_reward   | 0.16070142   |\n",
      "|    n_updates          | 6248         |\n",
      "|    policyGradLoss     | -0.00911     |\n",
      "|    value_loss         | 0.16         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 870         |\n",
      "|    iterations         | 4           |\n",
      "|    time_elapsed       | 37          |\n",
      "|    total_timesteps    | 12812288    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014541583 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.973       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0214      |\n",
      "|    mean_step_reward   | 0.13886213  |\n",
      "|    n_updates          | 6252        |\n",
      "|    policyGradLoss     | -0.00723    |\n",
      "|    value_loss         | 0.426       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 858         |\n",
      "|    iterations         | 5           |\n",
      "|    time_elapsed       | 47          |\n",
      "|    total_timesteps    | 12820480    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012857867 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.983       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00985     |\n",
      "|    mean_step_reward   | 0.14596927  |\n",
      "|    n_updates          | 6256        |\n",
      "|    policyGradLoss     | -0.00963    |\n",
      "|    value_loss         | 0.236       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 850         |\n",
      "|    iterations         | 6           |\n",
      "|    time_elapsed       | 57          |\n",
      "|    total_timesteps    | 12828672    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014549043 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.075       |\n",
      "|    mean_step_reward   | 0.16288222  |\n",
      "|    n_updates          | 6260        |\n",
      "|    policyGradLoss     | -0.0115     |\n",
      "|    value_loss         | 0.242       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 845         |\n",
      "|    iterations         | 7           |\n",
      "|    time_elapsed       | 67          |\n",
      "|    total_timesteps    | 12836864    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.017123032 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.995       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0216     |\n",
      "|    mean_step_reward   | 0.15578005  |\n",
      "|    n_updates          | 6264        |\n",
      "|    policyGradLoss     | -0.0168     |\n",
      "|    value_loss         | 0.0983      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 843         |\n",
      "|    iterations         | 8           |\n",
      "|    time_elapsed       | 77          |\n",
      "|    total_timesteps    | 12845056    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.009648315 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.939       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.071       |\n",
      "|    mean_step_reward   | 0.15186623  |\n",
      "|    n_updates          | 6268        |\n",
      "|    policyGradLoss     | -0.00294    |\n",
      "|    value_loss         | 0.458       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 837         |\n",
      "|    iterations         | 9           |\n",
      "|    time_elapsed       | 88          |\n",
      "|    total_timesteps    | 12853248    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014802005 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0316      |\n",
      "|    mean_step_reward   | 0.1559664   |\n",
      "|    n_updates          | 6272        |\n",
      "|    policyGradLoss     | -0.0104     |\n",
      "|    value_loss         | 0.255       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 836         |\n",
      "|    iterations         | 10          |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 12861440    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.008931788 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.00904     |\n",
      "|    mean_step_reward   | 0.15538846  |\n",
      "|    n_updates          | 6276        |\n",
      "|    policyGradLoss     | -0.00417    |\n",
      "|    value_loss         | 0.603       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 833         |\n",
      "|    iterations         | 11          |\n",
      "|    time_elapsed       | 108         |\n",
      "|    total_timesteps    | 12869632    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013384351 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.972       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0883      |\n",
      "|    mean_step_reward   | 0.1502899   |\n",
      "|    n_updates          | 6280        |\n",
      "|    policyGradLoss     | -0.00822    |\n",
      "|    value_loss         | 0.342       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 833         |\n",
      "|    iterations         | 12          |\n",
      "|    time_elapsed       | 118         |\n",
      "|    total_timesteps    | 12877824    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011302665 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.986       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0216     |\n",
      "|    mean_step_reward   | 0.1608987   |\n",
      "|    n_updates          | 6284        |\n",
      "|    policyGradLoss     | -0.00853    |\n",
      "|    value_loss         | 0.228       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 831         |\n",
      "|    iterations         | 13          |\n",
      "|    time_elapsed       | 128         |\n",
      "|    total_timesteps    | 12886016    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012465107 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0035     |\n",
      "|    mean_step_reward   | 0.15145862  |\n",
      "|    n_updates          | 6288        |\n",
      "|    policyGradLoss     | -0.0131     |\n",
      "|    value_loss         | 0.184       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 829        |\n",
      "|    iterations         | 14         |\n",
      "|    time_elapsed       | 138        |\n",
      "|    total_timesteps    | 12894208   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01390391 |\n",
      "|    entropy_loss       | -1.83      |\n",
      "|    explained_variance | 0.98       |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.15       |\n",
      "|    mean_step_reward   | 0.15215    |\n",
      "|    n_updates          | 6292       |\n",
      "|    policyGradLoss     | -0.0109    |\n",
      "|    value_loss         | 0.538      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 828         |\n",
      "|    iterations         | 15          |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 12902400    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011343829 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.968       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.133       |\n",
      "|    mean_step_reward   | 0.1464493   |\n",
      "|    n_updates          | 6296        |\n",
      "|    policyGradLoss     | -0.00448    |\n",
      "|    value_loss         | 0.772       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 827         |\n",
      "|    iterations         | 16          |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 12910592    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013591144 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.982       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0155     |\n",
      "|    mean_step_reward   | 0.1543508   |\n",
      "|    n_updates          | 6300        |\n",
      "|    policyGradLoss     | -0.0133     |\n",
      "|    value_loss         | 0.208       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 824        |\n",
      "|    iterations         | 17         |\n",
      "|    time_elapsed       | 168        |\n",
      "|    total_timesteps    | 12918784   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01483296 |\n",
      "|    entropy_loss       | -1.86      |\n",
      "|    explained_variance | 0.974      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | 0.155      |\n",
      "|    mean_step_reward   | 0.15063971 |\n",
      "|    n_updates          | 6304       |\n",
      "|    policyGradLoss     | -0.0079    |\n",
      "|    value_loss         | 0.681      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 822         |\n",
      "|    iterations         | 18          |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 12926976    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012101136 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.95        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.104       |\n",
      "|    mean_step_reward   | 0.13484608  |\n",
      "|    n_updates          | 6308        |\n",
      "|    policyGradLoss     | -0.0034     |\n",
      "|    value_loss         | 0.467       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 821         |\n",
      "|    iterations         | 19          |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 12935168    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012531318 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0104     |\n",
      "|    mean_step_reward   | 0.16618088  |\n",
      "|    n_updates          | 6312        |\n",
      "|    policyGradLoss     | -0.0107     |\n",
      "|    value_loss         | 0.19        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 820         |\n",
      "|    iterations         | 20          |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 12943360    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011810642 |\n",
      "|    entropy_loss       | -1.82       |\n",
      "|    explained_variance | 0.976       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0264      |\n",
      "|    mean_step_reward   | 0.14465898  |\n",
      "|    n_updates          | 6316        |\n",
      "|    policyGradLoss     | -0.0105     |\n",
      "|    value_loss         | 0.411       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 819         |\n",
      "|    iterations         | 21          |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 12951552    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.018499698 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.985       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.097       |\n",
      "|    mean_step_reward   | 0.14526993  |\n",
      "|    n_updates          | 6320        |\n",
      "|    policyGradLoss     | -0.0138     |\n",
      "|    value_loss         | 0.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 22          |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 12959744    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.010802189 |\n",
      "|    entropy_loss       | -1.85       |\n",
      "|    explained_variance | 0.964       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0269      |\n",
      "|    mean_step_reward   | 0.1574421   |\n",
      "|    n_updates          | 6324        |\n",
      "|    policyGradLoss     | -0.006      |\n",
      "|    value_loss         | 0.821       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 23          |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 12967936    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013500633 |\n",
      "|    entropy_loss       | -1.76       |\n",
      "|    explained_variance | 0.952       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0257      |\n",
      "|    mean_step_reward   | 0.1402052   |\n",
      "|    n_updates          | 6328        |\n",
      "|    policyGradLoss     | -0.00808    |\n",
      "|    value_loss         | 0.642       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 817         |\n",
      "|    iterations         | 24          |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 12976128    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014308989 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0802      |\n",
      "|    mean_step_reward   | 0.15735896  |\n",
      "|    n_updates          | 6332        |\n",
      "|    policyGradLoss     | -0.00895    |\n",
      "|    value_loss         | 0.345       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 25          |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 12984320    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014639553 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.928       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.195       |\n",
      "|    mean_step_reward   | 0.14048018  |\n",
      "|    n_updates          | 6336        |\n",
      "|    policyGradLoss     | -0.00305    |\n",
      "|    value_loss         | 0.939       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 816         |\n",
      "|    iterations         | 26          |\n",
      "|    time_elapsed       | 260         |\n",
      "|    total_timesteps    | 12992512    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016750246 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.975       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0187     |\n",
      "|    mean_step_reward   | 0.15037012  |\n",
      "|    n_updates          | 6340        |\n",
      "|    policyGradLoss     | -0.00727    |\n",
      "|    value_loss         | 0.257       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 815         |\n",
      "|    iterations         | 27          |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 13000704    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.011119736 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.932       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.228       |\n",
      "|    mean_step_reward   | 0.14508103  |\n",
      "|    n_updates          | 6344        |\n",
      "|    policyGradLoss     | -0.0024     |\n",
      "|    value_loss         | 1.23        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 28          |\n",
      "|    time_elapsed       | 281         |\n",
      "|    total_timesteps    | 13008896    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016431298 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0197     |\n",
      "|    mean_step_reward   | 0.13566208  |\n",
      "|    n_updates          | 6348        |\n",
      "|    policyGradLoss     | -0.011      |\n",
      "|    value_loss         | 0.287       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 814        |\n",
      "|    iterations         | 29         |\n",
      "|    time_elapsed       | 291        |\n",
      "|    total_timesteps    | 13017088   |\n",
      "| train/                |            |\n",
      "|    approx_kl          | 0.01430398 |\n",
      "|    entropy_loss       | -1.87      |\n",
      "|    explained_variance | 0.987      |\n",
      "|    learning_rate      | 0.0001     |\n",
      "|    loss               | -0.00161   |\n",
      "|    mean_step_reward   | 0.164785   |\n",
      "|    n_updates          | 6352       |\n",
      "|    policyGradLoss     | -0.00808   |\n",
      "|    value_loss         | 0.255      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 814         |\n",
      "|    iterations         | 30          |\n",
      "|    time_elapsed       | 301         |\n",
      "|    total_timesteps    | 13025280    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014608015 |\n",
      "|    entropy_loss       | -1.79       |\n",
      "|    explained_variance | 0.971       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.312       |\n",
      "|    mean_step_reward   | 0.1419291   |\n",
      "|    n_updates          | 6356        |\n",
      "|    policyGradLoss     | -0.0076     |\n",
      "|    value_loss         | 0.505       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 813         |\n",
      "|    iterations         | 31          |\n",
      "|    time_elapsed       | 312         |\n",
      "|    total_timesteps    | 13033472    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012575412 |\n",
      "|    entropy_loss       | -1.83       |\n",
      "|    explained_variance | 0.987       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0145     |\n",
      "|    mean_step_reward   | 0.16168198  |\n",
      "|    n_updates          | 6360        |\n",
      "|    policyGradLoss     | -0.0115     |\n",
      "|    value_loss         | 0.241       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 32          |\n",
      "|    time_elapsed       | 322         |\n",
      "|    total_timesteps    | 13041664    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.016069615 |\n",
      "|    entropy_loss       | -1.81       |\n",
      "|    explained_variance | 0.978       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.165       |\n",
      "|    mean_step_reward   | 0.14371997  |\n",
      "|    n_updates          | 6364        |\n",
      "|    policyGradLoss     | -0.00607    |\n",
      "|    value_loss         | 0.475       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 33          |\n",
      "|    time_elapsed       | 332         |\n",
      "|    total_timesteps    | 13049856    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.013362363 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.98        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0194     |\n",
      "|    mean_step_reward   | 0.15690255  |\n",
      "|    n_updates          | 6368        |\n",
      "|    policyGradLoss     | -0.00591    |\n",
      "|    value_loss         | 0.149       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 812         |\n",
      "|    iterations         | 34          |\n",
      "|    time_elapsed       | 343         |\n",
      "|    total_timesteps    | 13058048    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012377327 |\n",
      "|    entropy_loss       | -1.86       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0167      |\n",
      "|    mean_step_reward   | 0.16363657  |\n",
      "|    n_updates          | 6372        |\n",
      "|    policyGradLoss     | -0.00772    |\n",
      "|    value_loss         | 0.341       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 35          |\n",
      "|    time_elapsed       | 353         |\n",
      "|    total_timesteps    | 13066240    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012882613 |\n",
      "|    entropy_loss       | -1.75       |\n",
      "|    explained_variance | 0.962       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.114       |\n",
      "|    mean_step_reward   | 0.14171025  |\n",
      "|    n_updates          | 6376        |\n",
      "|    policyGradLoss     | -0.00581    |\n",
      "|    value_loss         | 0.413       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 36          |\n",
      "|    time_elapsed       | 363         |\n",
      "|    total_timesteps    | 13074432    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015235184 |\n",
      "|    entropy_loss       | -1.8        |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0151      |\n",
      "|    mean_step_reward   | 0.1479817   |\n",
      "|    n_updates          | 6380        |\n",
      "|    policyGradLoss     | -0.012      |\n",
      "|    value_loss         | 0.286       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 37          |\n",
      "|    time_elapsed       | 373         |\n",
      "|    total_timesteps    | 13082624    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.020215614 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | 0.0363      |\n",
      "|    mean_step_reward   | 0.154693    |\n",
      "|    n_updates          | 6384        |\n",
      "|    policyGradLoss     | -0.0103     |\n",
      "|    value_loss         | 0.459       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 38          |\n",
      "|    time_elapsed       | 383         |\n",
      "|    total_timesteps    | 13090816    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.012641358 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0281     |\n",
      "|    mean_step_reward   | 0.15203187  |\n",
      "|    n_updates          | 6388        |\n",
      "|    policyGradLoss     | -0.00992    |\n",
      "|    value_loss         | 0.376       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 39          |\n",
      "|    time_elapsed       | 393         |\n",
      "|    total_timesteps    | 13099008    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.014003068 |\n",
      "|    entropy_loss       | -1.78       |\n",
      "|    explained_variance | 0.99        |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0314     |\n",
      "|    mean_step_reward   | 0.1530039   |\n",
      "|    n_updates          | 6392        |\n",
      "|    policyGradLoss     | -0.0119     |\n",
      "|    value_loss         | 0.216       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 811         |\n",
      "|    iterations         | 40          |\n",
      "|    time_elapsed       | 403         |\n",
      "|    total_timesteps    | 13107200    |\n",
      "| train/                |             |\n",
      "|    approx_kl          | 0.015793115 |\n",
      "|    entropy_loss       | -1.77       |\n",
      "|    explained_variance | 0.981       |\n",
      "|    learning_rate      | 0.0001      |\n",
      "|    loss               | -0.0183     |\n",
      "|    mean_step_reward   | 0.15087733  |\n",
      "|    n_updates          | 6396        |\n",
      "|    policyGradLoss     | -0.00886    |\n",
      "|    value_loss         | 0.223       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: ./runs_smw/checkpoints/PIPE_39.zip\n",
      "[EVAL] Mean Return: 191.202, Best Return: 191.502\n",
      "Saved video to ./runs_smw/videos/PIPE/PIPE_39_191.20.mp4\n",
      "Training finished. Environment closed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntensorboard --logdir=./runs_smw/tb\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mean = -1e18\n",
    "trained = 0\n",
    "round_idx = 0\n",
    "\n",
    "try:\n",
    "    while trained < TOTAL_STEPS:\n",
    "        round_idx += 1\n",
    "        chunk = min(TRAIN_CHUNK, TOTAL_STEPS - trained)\n",
    "        # chunk = 2000\n",
    "        label = \"PIPE\"\n",
    "        tagged_label = f\"{label}_{int(trained/TRAIN_CHUNK)}\"\n",
    "\n",
    "        print(f\"\\n=== Round {round_idx} | Learn {chunk} steps (Total trained: {trained}) ===\")\n",
    "        \n",
    "        # --- Train ---\n",
    "        model.learn(total_timesteps=chunk, reset_num_timesteps=False, tb_log_name=label)\n",
    "        trained += chunk\n",
    "        \n",
    "\n",
    "        # --- Save Checkpoint ---\n",
    "        ckpt_path = os.path.join(CKPT_DIR, f\"{tagged_label}.zip\")\n",
    "        model.save(ckpt_path)\n",
    "        print(f\"Saved checkpoint: {ckpt_path}\")\n",
    "\n",
    "        # --- Evaluate ---\n",
    "        mean_ret, best_ret = evaluate_policy(\n",
    "            model,\n",
    "            GAME,\n",
    "            STATE,\n",
    "            n_episodes=EVAL_EPISODES,\n",
    "            max_steps=EVAL_MAX_STEPS,\n",
    "        )\n",
    "        print(f\"[EVAL] Mean Return: {mean_ret:.3f}, Best Return: {best_ret:.3f}\")\n",
    "\n",
    "        # --- Save Best Model ---\n",
    "        # if mean_ret > best_mean:\n",
    "        #     best_mean = mean_ret\n",
    "        #     best_path = os.path.join(LOG_DIR, \"best_model.zip\")\n",
    "        #     model.save(best_path)\n",
    "        #     print(f\"New best record. Saved to {best_path}\")\n",
    "\n",
    "        # --- Record Video ---\n",
    "        out_path = os.path.join(VIDEO_DIR, label)\n",
    "        os.makedirs(out_path,  exist_ok=True)\n",
    "        record_video(\n",
    "            model,\n",
    "            GAME,\n",
    "            STATE,\n",
    "            VIDEO_DIR,\n",
    "            video_len=RECORD_STEPS,\n",
    "            prefix=f\"{label}/{tagged_label}_{mean_ret:.2f}\",\n",
    "        )\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nTraining interrupted manually.\")\n",
    "\n",
    "finally:\n",
    "    train_env.close()\n",
    "    print(\"Training finished. Environment closed.\")\n",
    "    \n",
    "\"\"\"\n",
    "tensorboard --logdir=./runs_smw/tb\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f088b0b3-2418-4866-b332-0312c9f6467f",
   "metadata": {},
   "source": [
    "## Display Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a73191bb-e875-4939-b04c-a4670abd9612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Video\n",
    "# import glob\n",
    "\n",
    "# list_of_files = glob.glob(os.path.join(VIDEO_DIR, '*.mp4')) \n",
    "# if list_of_files:\n",
    "#     latest_file = max(list_of_files, key=os.path.getctime)\n",
    "#     print(f\"Playing: {latest_file}\")\n",
    "#     display(Video(latest_file, embed=True, width=600))\n",
    "# else:\n",
    "#     print(\"No videos found yet.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lab8 (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
